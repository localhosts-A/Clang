/*===---- riscv_vector.h - RISC-V V-extension RVVIntrinsics -------------------===
 *
 *
 * Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
 * See https://llvm.org/LICENSE.txt for license information.
 * SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
 *
 *===-----------------------------------------------------------------------===
 */

#ifndef __RISCV_VECTOR_H
#define __RISCV_VECTOR_H

#include <stdint.h>
#include <stddef.h>

#ifndef __riscv_vector
#error "Vector intrinsics require the vector extension."
#endif

#ifdef __cplusplus
extern "C" {
#endif


#define vsetvl_e8mf8(avl) __builtin_rvv_vsetvli((size_t)(avl), 0, 5)
#define vsetvl_e8mf4(avl) __builtin_rvv_vsetvli((size_t)(avl), 0, 6)
#define vsetvl_e8mf2(avl) __builtin_rvv_vsetvli((size_t)(avl), 0, 7)
#define vsetvl_e8m1(avl) __builtin_rvv_vsetvli((size_t)(avl), 0, 0)
#define vsetvl_e8m2(avl) __builtin_rvv_vsetvli((size_t)(avl), 0, 1)
#define vsetvl_e8m4(avl) __builtin_rvv_vsetvli((size_t)(avl), 0, 2)
#define vsetvl_e8m8(avl) __builtin_rvv_vsetvli((size_t)(avl), 0, 3)

#define vsetvl_e16mf4(avl) __builtin_rvv_vsetvli((size_t)(avl), 1, 6)
#define vsetvl_e16mf2(avl) __builtin_rvv_vsetvli((size_t)(avl), 1, 7)
#define vsetvl_e16m1(avl) __builtin_rvv_vsetvli((size_t)(avl), 1, 0)
#define vsetvl_e16m2(avl) __builtin_rvv_vsetvli((size_t)(avl), 1, 1)
#define vsetvl_e16m4(avl) __builtin_rvv_vsetvli((size_t)(avl), 1, 2)
#define vsetvl_e16m8(avl) __builtin_rvv_vsetvli((size_t)(avl), 1, 3)

#define vsetvl_e32mf2(avl) __builtin_rvv_vsetvli((size_t)(avl), 2, 7)
#define vsetvl_e32m1(avl) __builtin_rvv_vsetvli((size_t)(avl), 2, 0)
#define vsetvl_e32m2(avl) __builtin_rvv_vsetvli((size_t)(avl), 2, 1)
#define vsetvl_e32m4(avl) __builtin_rvv_vsetvli((size_t)(avl), 2, 2)
#define vsetvl_e32m8(avl) __builtin_rvv_vsetvli((size_t)(avl), 2, 3)

#define vsetvl_e64m1(avl) __builtin_rvv_vsetvli((size_t)(avl), 3, 0)
#define vsetvl_e64m2(avl) __builtin_rvv_vsetvli((size_t)(avl), 3, 1)
#define vsetvl_e64m4(avl) __builtin_rvv_vsetvli((size_t)(avl), 3, 2)
#define vsetvl_e64m8(avl) __builtin_rvv_vsetvli((size_t)(avl), 3, 3)


#define vsetvlmax_e8mf8() __builtin_rvv_vsetvlimax(0, 5)
#define vsetvlmax_e8mf4() __builtin_rvv_vsetvlimax(0, 6)
#define vsetvlmax_e8mf2() __builtin_rvv_vsetvlimax(0, 7)
#define vsetvlmax_e8m1() __builtin_rvv_vsetvlimax(0, 0)
#define vsetvlmax_e8m2() __builtin_rvv_vsetvlimax(0, 1)
#define vsetvlmax_e8m4() __builtin_rvv_vsetvlimax(0, 2)
#define vsetvlmax_e8m8() __builtin_rvv_vsetvlimax(0, 3)

#define vsetvlmax_e16mf4() __builtin_rvv_vsetvlimax(1, 6)
#define vsetvlmax_e16mf2() __builtin_rvv_vsetvlimax(1, 7)
#define vsetvlmax_e16m1() __builtin_rvv_vsetvlimax(1, 0)
#define vsetvlmax_e16m2() __builtin_rvv_vsetvlimax(1, 1)
#define vsetvlmax_e16m4() __builtin_rvv_vsetvlimax(1, 2)
#define vsetvlmax_e16m8() __builtin_rvv_vsetvlimax(1, 3)

#define vsetvlmax_e32mf2() __builtin_rvv_vsetvlimax(2, 7)
#define vsetvlmax_e32m1() __builtin_rvv_vsetvlimax(2, 0)
#define vsetvlmax_e32m2() __builtin_rvv_vsetvlimax(2, 1)
#define vsetvlmax_e32m4() __builtin_rvv_vsetvlimax(2, 2)
#define vsetvlmax_e32m8() __builtin_rvv_vsetvlimax(2, 3)

#define vsetvlmax_e64m1() __builtin_rvv_vsetvlimax(3, 0)
#define vsetvlmax_e64m2() __builtin_rvv_vsetvlimax(3, 1)
#define vsetvlmax_e64m4() __builtin_rvv_vsetvlimax(3, 2)
#define vsetvlmax_e64m8() __builtin_rvv_vsetvlimax(3, 3)

typedef __rvv_bool64_t vbool64_t;
typedef __rvv_bool32_t vbool32_t;
typedef __rvv_bool16_t vbool16_t;
typedef __rvv_bool8_t vbool8_t;
typedef __rvv_bool4_t vbool4_t;
typedef __rvv_bool2_t vbool2_t;
typedef __rvv_bool1_t vbool1_t;
typedef __rvv_int8mf8_t vint8mf8_t;
typedef __rvv_uint8mf8_t vuint8mf8_t;
typedef __rvv_int8mf4_t vint8mf4_t;
typedef __rvv_uint8mf4_t vuint8mf4_t;
typedef __rvv_int8mf2_t vint8mf2_t;
typedef __rvv_uint8mf2_t vuint8mf2_t;
typedef __rvv_int8m1_t vint8m1_t;
typedef __rvv_uint8m1_t vuint8m1_t;
typedef __rvv_int8m2_t vint8m2_t;
typedef __rvv_uint8m2_t vuint8m2_t;
typedef __rvv_int8m4_t vint8m4_t;
typedef __rvv_uint8m4_t vuint8m4_t;
typedef __rvv_int8m8_t vint8m8_t;
typedef __rvv_uint8m8_t vuint8m8_t;
typedef __rvv_int16mf4_t vint16mf4_t;
typedef __rvv_uint16mf4_t vuint16mf4_t;
typedef __rvv_int16mf2_t vint16mf2_t;
typedef __rvv_uint16mf2_t vuint16mf2_t;
typedef __rvv_int16m1_t vint16m1_t;
typedef __rvv_uint16m1_t vuint16m1_t;
typedef __rvv_int16m2_t vint16m2_t;
typedef __rvv_uint16m2_t vuint16m2_t;
typedef __rvv_int16m4_t vint16m4_t;
typedef __rvv_uint16m4_t vuint16m4_t;
typedef __rvv_int16m8_t vint16m8_t;
typedef __rvv_uint16m8_t vuint16m8_t;
typedef __rvv_int32mf2_t vint32mf2_t;
typedef __rvv_uint32mf2_t vuint32mf2_t;
typedef __rvv_int32m1_t vint32m1_t;
typedef __rvv_uint32m1_t vuint32m1_t;
typedef __rvv_int32m2_t vint32m2_t;
typedef __rvv_uint32m2_t vuint32m2_t;
typedef __rvv_int32m4_t vint32m4_t;
typedef __rvv_uint32m4_t vuint32m4_t;
typedef __rvv_int32m8_t vint32m8_t;
typedef __rvv_uint32m8_t vuint32m8_t;
typedef __rvv_int64m1_t vint64m1_t;
typedef __rvv_uint64m1_t vuint64m1_t;
typedef __rvv_int64m2_t vint64m2_t;
typedef __rvv_uint64m2_t vuint64m2_t;
typedef __rvv_int64m4_t vint64m4_t;
typedef __rvv_uint64m4_t vuint64m4_t;
typedef __rvv_int64m8_t vint64m8_t;
typedef __rvv_uint64m8_t vuint64m8_t;
#if defined(__riscv_zfh)
typedef __rvv_float16mf4_t vfloat16mf4_t;
typedef __rvv_float16mf2_t vfloat16mf2_t;
typedef __rvv_float16m1_t vfloat16m1_t;
typedef __rvv_float16m2_t vfloat16m2_t;
typedef __rvv_float16m4_t vfloat16m4_t;
typedef __rvv_float16m8_t vfloat16m8_t;
#endif
#if defined(__riscv_f)
typedef __rvv_float32mf2_t vfloat32mf2_t;
typedef __rvv_float32m1_t vfloat32m1_t;
typedef __rvv_float32m2_t vfloat32m2_t;
typedef __rvv_float32m4_t vfloat32m4_t;
typedef __rvv_float32m8_t vfloat32m8_t;
#endif
#if defined(__riscv_d)
typedef __rvv_float64m1_t vfloat64m1_t;
typedef __rvv_float64m2_t vfloat64m2_t;
typedef __rvv_float64m4_t vfloat64m4_t;
typedef __rvv_float64m8_t vfloat64m8_t;
#endif

#define vadd_vv_i8m1(op0, op1, op2) \
__builtin_rvv_vadd_vv_i8m1((vint8m1_t)(op0), (vint8m1_t)(op1), (size_t)(op2))
#define vadd_vv_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vadd_vv_i8m2(op0, op1, op2) \
__builtin_rvv_vadd_vv_i8m2((vint8m2_t)(op0), (vint8m2_t)(op1), (size_t)(op2))
#define vadd_vv_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vadd_vv_i8m4(op0, op1, op2) \
__builtin_rvv_vadd_vv_i8m4((vint8m4_t)(op0), (vint8m4_t)(op1), (size_t)(op2))
#define vadd_vv_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vadd_vv_i8m8(op0, op1, op2) \
__builtin_rvv_vadd_vv_i8m8((vint8m8_t)(op0), (vint8m8_t)(op1), (size_t)(op2))
#define vadd_vv_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (vint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vadd_vv_i8mf2(op0, op1, op2) \
__builtin_rvv_vadd_vv_i8mf2((vint8mf2_t)(op0), (vint8mf2_t)(op1), (size_t)(op2))
#define vadd_vv_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vadd_vv_i8mf4(op0, op1, op2) \
__builtin_rvv_vadd_vv_i8mf4((vint8mf4_t)(op0), (vint8mf4_t)(op1), (size_t)(op2))
#define vadd_vv_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vadd_vv_i8mf8(op0, op1, op2) \
__builtin_rvv_vadd_vv_i8mf8((vint8mf8_t)(op0), (vint8mf8_t)(op1), (size_t)(op2))
#define vadd_vv_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vadd_vv_i16m1(op0, op1, op2) \
__builtin_rvv_vadd_vv_i16m1((vint16m1_t)(op0), (vint16m1_t)(op1), (size_t)(op2))
#define vadd_vv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vadd_vv_i16m2(op0, op1, op2) \
__builtin_rvv_vadd_vv_i16m2((vint16m2_t)(op0), (vint16m2_t)(op1), (size_t)(op2))
#define vadd_vv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vadd_vv_i16m4(op0, op1, op2) \
__builtin_rvv_vadd_vv_i16m4((vint16m4_t)(op0), (vint16m4_t)(op1), (size_t)(op2))
#define vadd_vv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vadd_vv_i16m8(op0, op1, op2) \
__builtin_rvv_vadd_vv_i16m8((vint16m8_t)(op0), (vint16m8_t)(op1), (size_t)(op2))
#define vadd_vv_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (vint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vadd_vv_i16mf2(op0, op1, op2) \
__builtin_rvv_vadd_vv_i16mf2((vint16mf2_t)(op0), (vint16mf2_t)(op1), (size_t)(op2))
#define vadd_vv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vadd_vv_i16mf4(op0, op1, op2) \
__builtin_rvv_vadd_vv_i16mf4((vint16mf4_t)(op0), (vint16mf4_t)(op1), (size_t)(op2))
#define vadd_vv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vadd_vv_i32m1(op0, op1, op2) \
__builtin_rvv_vadd_vv_i32m1((vint32m1_t)(op0), (vint32m1_t)(op1), (size_t)(op2))
#define vadd_vv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vadd_vv_i32m2(op0, op1, op2) \
__builtin_rvv_vadd_vv_i32m2((vint32m2_t)(op0), (vint32m2_t)(op1), (size_t)(op2))
#define vadd_vv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vadd_vv_i32m4(op0, op1, op2) \
__builtin_rvv_vadd_vv_i32m4((vint32m4_t)(op0), (vint32m4_t)(op1), (size_t)(op2))
#define vadd_vv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vadd_vv_i32m8(op0, op1, op2) \
__builtin_rvv_vadd_vv_i32m8((vint32m8_t)(op0), (vint32m8_t)(op1), (size_t)(op2))
#define vadd_vv_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (vint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vadd_vv_i32mf2(op0, op1, op2) \
__builtin_rvv_vadd_vv_i32mf2((vint32mf2_t)(op0), (vint32mf2_t)(op1), (size_t)(op2))
#define vadd_vv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vadd_vv_i64m1(op0, op1, op2) \
__builtin_rvv_vadd_vv_i64m1((vint64m1_t)(op0), (vint64m1_t)(op1), (size_t)(op2))
#define vadd_vv_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vadd_vv_i64m2(op0, op1, op2) \
__builtin_rvv_vadd_vv_i64m2((vint64m2_t)(op0), (vint64m2_t)(op1), (size_t)(op2))
#define vadd_vv_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (vint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vadd_vv_i64m4(op0, op1, op2) \
__builtin_rvv_vadd_vv_i64m4((vint64m4_t)(op0), (vint64m4_t)(op1), (size_t)(op2))
#define vadd_vv_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (vint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vadd_vv_i64m8(op0, op1, op2) \
__builtin_rvv_vadd_vv_i64m8((vint64m8_t)(op0), (vint64m8_t)(op1), (size_t)(op2))
#define vadd_vv_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (vint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vle8_v_i8m1(op0, op1) \
__builtin_rvv_vle8_v_i8m1((const int8_t *)(op0), (size_t)(op1))
#define vle8_v_i8m1_m(op2, op0, op1, op3) \
__builtin_rvv_vle8_v_i8m1_m((vint8m1_t)(op0), (const int8_t *)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vle8_v_i8m2(op0, op1) \
__builtin_rvv_vle8_v_i8m2((const int8_t *)(op0), (size_t)(op1))
#define vle8_v_i8m2_m(op2, op0, op1, op3) \
__builtin_rvv_vle8_v_i8m2_m((vint8m2_t)(op0), (const int8_t *)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vle8_v_i8m4(op0, op1) \
__builtin_rvv_vle8_v_i8m4((const int8_t *)(op0), (size_t)(op1))
#define vle8_v_i8m4_m(op2, op0, op1, op3) \
__builtin_rvv_vle8_v_i8m4_m((vint8m4_t)(op0), (const int8_t *)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vle8_v_i8m8(op0, op1) \
__builtin_rvv_vle8_v_i8m8((const int8_t *)(op0), (size_t)(op1))
#define vle8_v_i8m8_m(op2, op0, op1, op3) \
__builtin_rvv_vle8_v_i8m8_m((vint8m8_t)(op0), (const int8_t *)(op1), (vbool1_t)(op2), (size_t)(op3))
#define vle8_v_i8mf2(op0, op1) \
__builtin_rvv_vle8_v_i8mf2((const int8_t *)(op0), (size_t)(op1))
#define vle8_v_i8mf2_m(op2, op0, op1, op3) \
__builtin_rvv_vle8_v_i8mf2_m((vint8mf2_t)(op0), (const int8_t *)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vle8_v_i8mf4(op0, op1) \
__builtin_rvv_vle8_v_i8mf4((const int8_t *)(op0), (size_t)(op1))
#define vle8_v_i8mf4_m(op2, op0, op1, op3) \
__builtin_rvv_vle8_v_i8mf4_m((vint8mf4_t)(op0), (const int8_t *)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vle8_v_i8mf8(op0, op1) \
__builtin_rvv_vle8_v_i8mf8((const int8_t *)(op0), (size_t)(op1))
#define vle8_v_i8mf8_m(op2, op0, op1, op3) \
__builtin_rvv_vle8_v_i8mf8_m((vint8mf8_t)(op0), (const int8_t *)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vloxei32_v_u32m1(op0, op1, op2) \
__builtin_rvv_vloxei32_v_u32m1((const uint32_t *)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vloxei32_v_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_u32m1_m((vuint32m1_t)(op0), (const uint32_t *)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei32_v_u32m2(op0, op1, op2) \
__builtin_rvv_vloxei32_v_u32m2((const uint32_t *)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vloxei32_v_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_u32m2_m((vuint32m2_t)(op0), (const uint32_t *)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei32_v_u32m4(op0, op1, op2) \
__builtin_rvv_vloxei32_v_u32m4((const uint32_t *)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vloxei32_v_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_u32m4_m((vuint32m4_t)(op0), (const uint32_t *)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei32_v_u32m8(op0, op1, op2) \
__builtin_rvv_vloxei32_v_u32m8((const uint32_t *)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vloxei32_v_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_u32m8_m((vuint32m8_t)(op0), (const uint32_t *)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vloxei32_v_u32mf2(op0, op1, op2) \
__builtin_rvv_vloxei32_v_u32mf2((const uint32_t *)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vloxei32_v_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_u32mf2_m((vuint32mf2_t)(op0), (const uint32_t *)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei64_v_i32m1(op0, op1, op2) \
__builtin_rvv_vloxei64_v_i32m1((const int32_t *)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vloxei64_v_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_i32m1_m((vint32m1_t)(op0), (const int32_t *)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei64_v_i32m2(op0, op1, op2) \
__builtin_rvv_vloxei64_v_i32m2((const int32_t *)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vloxei64_v_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_i32m2_m((vint32m2_t)(op0), (const int32_t *)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei64_v_i32m4(op0, op1, op2) \
__builtin_rvv_vloxei64_v_i32m4((const int32_t *)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vloxei64_v_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_i32m4_m((vint32m4_t)(op0), (const int32_t *)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei64_v_i32mf2(op0, op1, op2) \
__builtin_rvv_vloxei64_v_i32mf2((const int32_t *)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vloxei64_v_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_i32mf2_m((vint32mf2_t)(op0), (const int32_t *)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei64_v_u32m1(op0, op1, op2) \
__builtin_rvv_vloxei64_v_u32m1((const uint32_t *)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vloxei64_v_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_u32m1_m((vuint32m1_t)(op0), (const uint32_t *)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei64_v_u32m2(op0, op1, op2) \
__builtin_rvv_vloxei64_v_u32m2((const uint32_t *)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vloxei64_v_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_u32m2_m((vuint32m2_t)(op0), (const uint32_t *)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei64_v_u32m4(op0, op1, op2) \
__builtin_rvv_vloxei64_v_u32m4((const uint32_t *)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vloxei64_v_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_u32m4_m((vuint32m4_t)(op0), (const uint32_t *)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei64_v_u32mf2(op0, op1, op2) \
__builtin_rvv_vloxei64_v_u32mf2((const uint32_t *)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vloxei64_v_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_u32mf2_m((vuint32mf2_t)(op0), (const uint32_t *)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei8_v_i64m1(op0, op1, op2) \
__builtin_rvv_vloxei8_v_i64m1((const int64_t *)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vloxei8_v_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_i64m1_m((vint64m1_t)(op0), (const int64_t *)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei8_v_i64m2(op0, op1, op2) \
__builtin_rvv_vloxei8_v_i64m2((const int64_t *)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vloxei8_v_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_i64m2_m((vint64m2_t)(op0), (const int64_t *)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei8_v_i64m4(op0, op1, op2) \
__builtin_rvv_vloxei8_v_i64m4((const int64_t *)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vloxei8_v_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_i64m4_m((vint64m4_t)(op0), (const int64_t *)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei8_v_i64m8(op0, op1, op2) \
__builtin_rvv_vloxei8_v_i64m8((const int64_t *)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vloxei8_v_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_i64m8_m((vint64m8_t)(op0), (const int64_t *)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei8_v_u64m1(op0, op1, op2) \
__builtin_rvv_vloxei8_v_u64m1((const uint64_t *)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vloxei8_v_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_u64m1_m((vuint64m1_t)(op0), (const uint64_t *)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei8_v_u64m2(op0, op1, op2) \
__builtin_rvv_vloxei8_v_u64m2((const uint64_t *)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vloxei8_v_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_u64m2_m((vuint64m2_t)(op0), (const uint64_t *)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei8_v_u64m4(op0, op1, op2) \
__builtin_rvv_vloxei8_v_u64m4((const uint64_t *)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vloxei8_v_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_u64m4_m((vuint64m4_t)(op0), (const uint64_t *)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei8_v_u64m8(op0, op1, op2) \
__builtin_rvv_vloxei8_v_u64m8((const uint64_t *)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vloxei8_v_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_u64m8_m((vuint64m8_t)(op0), (const uint64_t *)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei16_v_i64m1(op0, op1, op2) \
__builtin_rvv_vloxei16_v_i64m1((const int64_t *)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vloxei16_v_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_i64m1_m((vint64m1_t)(op0), (const int64_t *)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei16_v_i64m2(op0, op1, op2) \
__builtin_rvv_vloxei16_v_i64m2((const int64_t *)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vloxei16_v_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_i64m2_m((vint64m2_t)(op0), (const int64_t *)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei16_v_i64m4(op0, op1, op2) \
__builtin_rvv_vloxei16_v_i64m4((const int64_t *)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vloxei16_v_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_i64m4_m((vint64m4_t)(op0), (const int64_t *)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei16_v_i64m8(op0, op1, op2) \
__builtin_rvv_vloxei16_v_i64m8((const int64_t *)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vloxei16_v_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_i64m8_m((vint64m8_t)(op0), (const int64_t *)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei16_v_u64m1(op0, op1, op2) \
__builtin_rvv_vloxei16_v_u64m1((const uint64_t *)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vloxei16_v_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_u64m1_m((vuint64m1_t)(op0), (const uint64_t *)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei16_v_u64m2(op0, op1, op2) \
__builtin_rvv_vloxei16_v_u64m2((const uint64_t *)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vloxei16_v_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_u64m2_m((vuint64m2_t)(op0), (const uint64_t *)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei16_v_u64m4(op0, op1, op2) \
__builtin_rvv_vloxei16_v_u64m4((const uint64_t *)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vloxei16_v_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_u64m4_m((vuint64m4_t)(op0), (const uint64_t *)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei16_v_u64m8(op0, op1, op2) \
__builtin_rvv_vloxei16_v_u64m8((const uint64_t *)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vloxei16_v_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_u64m8_m((vuint64m8_t)(op0), (const uint64_t *)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei32_v_i64m1(op0, op1, op2) \
__builtin_rvv_vloxei32_v_i64m1((const int64_t *)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vloxei32_v_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_i64m1_m((vint64m1_t)(op0), (const int64_t *)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei32_v_i64m2(op0, op1, op2) \
__builtin_rvv_vloxei32_v_i64m2((const int64_t *)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vloxei32_v_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_i64m2_m((vint64m2_t)(op0), (const int64_t *)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei32_v_i64m4(op0, op1, op2) \
__builtin_rvv_vloxei32_v_i64m4((const int64_t *)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vloxei32_v_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_i64m4_m((vint64m4_t)(op0), (const int64_t *)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei32_v_i64m8(op0, op1, op2) \
__builtin_rvv_vloxei32_v_i64m8((const int64_t *)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vloxei32_v_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_i64m8_m((vint64m8_t)(op0), (const int64_t *)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei32_v_u64m1(op0, op1, op2) \
__builtin_rvv_vloxei32_v_u64m1((const uint64_t *)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vloxei32_v_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_u64m1_m((vuint64m1_t)(op0), (const uint64_t *)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei32_v_u64m2(op0, op1, op2) \
__builtin_rvv_vloxei32_v_u64m2((const uint64_t *)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vloxei32_v_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_u64m2_m((vuint64m2_t)(op0), (const uint64_t *)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei32_v_u64m4(op0, op1, op2) \
__builtin_rvv_vloxei32_v_u64m4((const uint64_t *)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vloxei32_v_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_u64m4_m((vuint64m4_t)(op0), (const uint64_t *)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei32_v_u64m8(op0, op1, op2) \
__builtin_rvv_vloxei32_v_u64m8((const uint64_t *)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vloxei32_v_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_u64m8_m((vuint64m8_t)(op0), (const uint64_t *)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei64_v_i64m1(op0, op1, op2) \
__builtin_rvv_vloxei64_v_i64m1((const int64_t *)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vloxei64_v_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_i64m1_m((vint64m1_t)(op0), (const int64_t *)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei64_v_i64m2(op0, op1, op2) \
__builtin_rvv_vloxei64_v_i64m2((const int64_t *)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vloxei64_v_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_i64m2_m((vint64m2_t)(op0), (const int64_t *)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei64_v_i64m4(op0, op1, op2) \
__builtin_rvv_vloxei64_v_i64m4((const int64_t *)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vloxei64_v_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_i64m4_m((vint64m4_t)(op0), (const int64_t *)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei64_v_i64m8(op0, op1, op2) \
__builtin_rvv_vloxei64_v_i64m8((const int64_t *)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vloxei64_v_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_i64m8_m((vint64m8_t)(op0), (const int64_t *)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vle8ff_v_i8m1(op0, op1, op2) \
__builtin_rvv_vle8ff_v_i8m1((const int8_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle8ff_v_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle8ff_v_i8m1_m((vint8m1_t)(op0), (const int8_t *)(op1), (size_t *)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vle8ff_v_i8m2(op0, op1, op2) \
__builtin_rvv_vle8ff_v_i8m2((const int8_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle8ff_v_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle8ff_v_i8m2_m((vint8m2_t)(op0), (const int8_t *)(op1), (size_t *)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vle8ff_v_i8m4(op0, op1, op2) \
__builtin_rvv_vle8ff_v_i8m4((const int8_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle8ff_v_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle8ff_v_i8m4_m((vint8m4_t)(op0), (const int8_t *)(op1), (size_t *)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vle8ff_v_i8m8(op0, op1, op2) \
__builtin_rvv_vle8ff_v_i8m8((const int8_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle8ff_v_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle8ff_v_i8m8_m((vint8m8_t)(op0), (const int8_t *)(op1), (size_t *)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vle8ff_v_i8mf2(op0, op1, op2) \
__builtin_rvv_vle8ff_v_i8mf2((const int8_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle8ff_v_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle8ff_v_i8mf2_m((vint8mf2_t)(op0), (const int8_t *)(op1), (size_t *)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vle8ff_v_i8mf4(op0, op1, op2) \
__builtin_rvv_vle8ff_v_i8mf4((const int8_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle8ff_v_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle8ff_v_i8mf4_m((vint8mf4_t)(op0), (const int8_t *)(op1), (size_t *)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vle8ff_v_i8mf8(op0, op1, op2) \
__builtin_rvv_vle8ff_v_i8mf8((const int8_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle8ff_v_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle8ff_v_i8mf8_m((vint8mf8_t)(op0), (const int8_t *)(op1), (size_t *)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei64_v_u64m1(op0, op1, op2) \
__builtin_rvv_vloxei64_v_u64m1((const uint64_t *)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vloxei64_v_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_u64m1_m((vuint64m1_t)(op0), (const uint64_t *)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei64_v_u64m2(op0, op1, op2) \
__builtin_rvv_vloxei64_v_u64m2((const uint64_t *)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vloxei64_v_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_u64m2_m((vuint64m2_t)(op0), (const uint64_t *)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei64_v_u64m4(op0, op1, op2) \
__builtin_rvv_vloxei64_v_u64m4((const uint64_t *)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vloxei64_v_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_u64m4_m((vuint64m4_t)(op0), (const uint64_t *)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei64_v_u64m8(op0, op1, op2) \
__builtin_rvv_vloxei64_v_u64m8((const uint64_t *)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vloxei64_v_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_u64m8_m((vuint64m8_t)(op0), (const uint64_t *)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vadd_vx_i8m1(op0, op1, op2) \
__builtin_rvv_vadd_vx_i8m1((vint8m1_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vadd_vx_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (int8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vadd_vx_i8m2(op0, op1, op2) \
__builtin_rvv_vadd_vx_i8m2((vint8m2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vadd_vx_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (int8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vadd_vx_i8m4(op0, op1, op2) \
__builtin_rvv_vadd_vx_i8m4((vint8m4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vadd_vx_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (int8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vadd_vx_i8m8(op0, op1, op2) \
__builtin_rvv_vadd_vx_i8m8((vint8m8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vadd_vx_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (int8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vadd_vx_i8mf2(op0, op1, op2) \
__builtin_rvv_vadd_vx_i8mf2((vint8mf2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vadd_vx_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (int8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vadd_vx_i8mf4(op0, op1, op2) \
__builtin_rvv_vadd_vx_i8mf4((vint8mf4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vadd_vx_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (int8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vadd_vx_i8mf8(op0, op1, op2) \
__builtin_rvv_vadd_vx_i8mf8((vint8mf8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vadd_vx_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (int8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vadd_vx_i16m1(op0, op1, op2) \
__builtin_rvv_vadd_vx_i16m1((vint16m1_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vadd_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (int16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vadd_vx_i16m2(op0, op1, op2) \
__builtin_rvv_vadd_vx_i16m2((vint16m2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vadd_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (int16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vadd_vx_i16m4(op0, op1, op2) \
__builtin_rvv_vadd_vx_i16m4((vint16m4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vadd_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (int16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vadd_vx_i16m8(op0, op1, op2) \
__builtin_rvv_vadd_vx_i16m8((vint16m8_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vadd_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (int16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vadd_vx_i16mf2(op0, op1, op2) \
__builtin_rvv_vadd_vx_i16mf2((vint16mf2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vadd_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (int16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vadd_vx_i16mf4(op0, op1, op2) \
__builtin_rvv_vadd_vx_i16mf4((vint16mf4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vadd_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (int16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vadd_vx_i32m1(op0, op1, op2) \
__builtin_rvv_vadd_vx_i32m1((vint32m1_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vadd_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (int32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vadd_vx_i32m2(op0, op1, op2) \
__builtin_rvv_vadd_vx_i32m2((vint32m2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vadd_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (int32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vadd_vx_i32m4(op0, op1, op2) \
__builtin_rvv_vadd_vx_i32m4((vint32m4_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vadd_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (int32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vadd_vx_i32m8(op0, op1, op2) \
__builtin_rvv_vadd_vx_i32m8((vint32m8_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vadd_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (int32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vadd_vx_i32mf2(op0, op1, op2) \
__builtin_rvv_vadd_vx_i32mf2((vint32mf2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vadd_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (int32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vadd_vx_i64m1(op0, op1, op2) \
__builtin_rvv_vadd_vx_i64m1((vint64m1_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vadd_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (int64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vadd_vx_i64m2(op0, op1, op2) \
__builtin_rvv_vadd_vx_i64m2((vint64m2_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vadd_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (int64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vadd_vx_i64m4(op0, op1, op2) \
__builtin_rvv_vadd_vx_i64m4((vint64m4_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vadd_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (int64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vadd_vx_i64m8(op0, op1, op2) \
__builtin_rvv_vadd_vx_i64m8((vint64m8_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vadd_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (int64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vle8ff_v_u8m1(op0, op1, op2) \
__builtin_rvv_vle8ff_v_u8m1((const uint8_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle8ff_v_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle8ff_v_u8m1_m((vuint8m1_t)(op0), (const uint8_t *)(op1), (size_t *)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vle8ff_v_u8m2(op0, op1, op2) \
__builtin_rvv_vle8ff_v_u8m2((const uint8_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle8ff_v_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle8ff_v_u8m2_m((vuint8m2_t)(op0), (const uint8_t *)(op1), (size_t *)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vle8ff_v_u8m4(op0, op1, op2) \
__builtin_rvv_vle8ff_v_u8m4((const uint8_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle8ff_v_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle8ff_v_u8m4_m((vuint8m4_t)(op0), (const uint8_t *)(op1), (size_t *)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vle8ff_v_u8m8(op0, op1, op2) \
__builtin_rvv_vle8ff_v_u8m8((const uint8_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle8ff_v_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle8ff_v_u8m8_m((vuint8m8_t)(op0), (const uint8_t *)(op1), (size_t *)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vle8ff_v_u8mf2(op0, op1, op2) \
__builtin_rvv_vle8ff_v_u8mf2((const uint8_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle8ff_v_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle8ff_v_u8mf2_m((vuint8mf2_t)(op0), (const uint8_t *)(op1), (size_t *)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vle8ff_v_u8mf4(op0, op1, op2) \
__builtin_rvv_vle8ff_v_u8mf4((const uint8_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle8ff_v_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle8ff_v_u8mf4_m((vuint8mf4_t)(op0), (const uint8_t *)(op1), (size_t *)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vle8ff_v_u8mf8(op0, op1, op2) \
__builtin_rvv_vle8ff_v_u8mf8((const uint8_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle8ff_v_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle8ff_v_u8mf8_m((vuint8mf8_t)(op0), (const uint8_t *)(op1), (size_t *)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vadd_vv_u8m1(op0, op1, op2) \
__builtin_rvv_vadd_vv_u8m1((vuint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vadd_vv_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vadd_vv_u8m2(op0, op1, op2) \
__builtin_rvv_vadd_vv_u8m2((vuint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vadd_vv_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vadd_vv_u8m4(op0, op1, op2) \
__builtin_rvv_vadd_vv_u8m4((vuint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vadd_vv_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vadd_vv_u8m8(op0, op1, op2) \
__builtin_rvv_vadd_vv_u8m8((vuint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vadd_vv_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vadd_vv_u8mf2(op0, op1, op2) \
__builtin_rvv_vadd_vv_u8mf2((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vadd_vv_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vadd_vv_u8mf4(op0, op1, op2) \
__builtin_rvv_vadd_vv_u8mf4((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vadd_vv_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vadd_vv_u8mf8(op0, op1, op2) \
__builtin_rvv_vadd_vv_u8mf8((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vadd_vv_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vadd_vv_u16m1(op0, op1, op2) \
__builtin_rvv_vadd_vv_u16m1((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vadd_vv_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vadd_vv_u16m2(op0, op1, op2) \
__builtin_rvv_vadd_vv_u16m2((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vadd_vv_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vadd_vv_u16m4(op0, op1, op2) \
__builtin_rvv_vadd_vv_u16m4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vadd_vv_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vadd_vv_u16m8(op0, op1, op2) \
__builtin_rvv_vadd_vv_u16m8((vuint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vadd_vv_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vadd_vv_u16mf2(op0, op1, op2) \
__builtin_rvv_vadd_vv_u16mf2((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vadd_vv_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vadd_vv_u16mf4(op0, op1, op2) \
__builtin_rvv_vadd_vv_u16mf4((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vadd_vv_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vadd_vv_u32m1(op0, op1, op2) \
__builtin_rvv_vadd_vv_u32m1((vuint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vadd_vv_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vadd_vv_u32m2(op0, op1, op2) \
__builtin_rvv_vadd_vv_u32m2((vuint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vadd_vv_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vadd_vv_u32m4(op0, op1, op2) \
__builtin_rvv_vadd_vv_u32m4((vuint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vadd_vv_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vadd_vv_u32m8(op0, op1, op2) \
__builtin_rvv_vadd_vv_u32m8((vuint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vadd_vv_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vadd_vv_u32mf2(op0, op1, op2) \
__builtin_rvv_vadd_vv_u32mf2((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vadd_vv_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vadd_vv_u64m1(op0, op1, op2) \
__builtin_rvv_vadd_vv_u64m1((vuint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vadd_vv_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vadd_vv_u64m2(op0, op1, op2) \
__builtin_rvv_vadd_vv_u64m2((vuint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vadd_vv_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vadd_vv_u64m4(op0, op1, op2) \
__builtin_rvv_vadd_vv_u64m4((vuint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vadd_vv_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vadd_vv_u64m8(op0, op1, op2) \
__builtin_rvv_vadd_vv_u64m8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vadd_vv_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vadd_vx_u8m1(op0, op1, op2) \
__builtin_rvv_vadd_vx_u8m1((vuint8m1_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vadd_vx_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (uint8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vadd_vx_u8m2(op0, op1, op2) \
__builtin_rvv_vadd_vx_u8m2((vuint8m2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vadd_vx_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (uint8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vadd_vx_u8m4(op0, op1, op2) \
__builtin_rvv_vadd_vx_u8m4((vuint8m4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vadd_vx_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (uint8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vadd_vx_u8m8(op0, op1, op2) \
__builtin_rvv_vadd_vx_u8m8((vuint8m8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vadd_vx_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (uint8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vadd_vx_u8mf2(op0, op1, op2) \
__builtin_rvv_vadd_vx_u8mf2((vuint8mf2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vadd_vx_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (uint8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vadd_vx_u8mf4(op0, op1, op2) \
__builtin_rvv_vadd_vx_u8mf4((vuint8mf4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vadd_vx_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (uint8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vadd_vx_u8mf8(op0, op1, op2) \
__builtin_rvv_vadd_vx_u8mf8((vuint8mf8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vadd_vx_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (uint8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vadd_vx_u16m1(op0, op1, op2) \
__builtin_rvv_vadd_vx_u16m1((vuint16m1_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vadd_vx_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (uint16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vadd_vx_u16m2(op0, op1, op2) \
__builtin_rvv_vadd_vx_u16m2((vuint16m2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vadd_vx_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (uint16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vadd_vx_u16m4(op0, op1, op2) \
__builtin_rvv_vadd_vx_u16m4((vuint16m4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vadd_vx_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (uint16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vadd_vx_u16m8(op0, op1, op2) \
__builtin_rvv_vadd_vx_u16m8((vuint16m8_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vadd_vx_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (uint16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vadd_vx_u16mf2(op0, op1, op2) \
__builtin_rvv_vadd_vx_u16mf2((vuint16mf2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vadd_vx_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (uint16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vadd_vx_u16mf4(op0, op1, op2) \
__builtin_rvv_vadd_vx_u16mf4((vuint16mf4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vadd_vx_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (uint16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vadd_vx_u32m1(op0, op1, op2) \
__builtin_rvv_vadd_vx_u32m1((vuint32m1_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vadd_vx_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (uint32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vadd_vx_u32m2(op0, op1, op2) \
__builtin_rvv_vadd_vx_u32m2((vuint32m2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vadd_vx_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (uint32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vadd_vx_u32m4(op0, op1, op2) \
__builtin_rvv_vadd_vx_u32m4((vuint32m4_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vadd_vx_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (uint32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vadd_vx_u32m8(op0, op1, op2) \
__builtin_rvv_vadd_vx_u32m8((vuint32m8_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vadd_vx_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (uint32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vadd_vx_u32mf2(op0, op1, op2) \
__builtin_rvv_vadd_vx_u32mf2((vuint32mf2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vadd_vx_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (uint32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vadd_vx_u64m1(op0, op1, op2) \
__builtin_rvv_vadd_vx_u64m1((vuint64m1_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vadd_vx_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (uint64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vadd_vx_u64m2(op0, op1, op2) \
__builtin_rvv_vadd_vx_u64m2((vuint64m2_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vadd_vx_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (uint64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vadd_vx_u64m4(op0, op1, op2) \
__builtin_rvv_vadd_vx_u64m4((vuint64m4_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vadd_vx_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (uint64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vadd_vx_u64m8(op0, op1, op2) \
__builtin_rvv_vadd_vx_u64m8((vuint64m8_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vadd_vx_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (uint64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsub_vv_i8m1(op0, op1, op2) \
__builtin_rvv_vsub_vv_i8m1((vint8m1_t)(op0), (vint8m1_t)(op1), (size_t)(op2))
#define vsub_vv_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsub_vv_i8m2(op0, op1, op2) \
__builtin_rvv_vsub_vv_i8m2((vint8m2_t)(op0), (vint8m2_t)(op1), (size_t)(op2))
#define vsub_vv_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsub_vv_i8m4(op0, op1, op2) \
__builtin_rvv_vsub_vv_i8m4((vint8m4_t)(op0), (vint8m4_t)(op1), (size_t)(op2))
#define vsub_vv_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsub_vv_i8m8(op0, op1, op2) \
__builtin_rvv_vsub_vv_i8m8((vint8m8_t)(op0), (vint8m8_t)(op1), (size_t)(op2))
#define vsub_vv_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (vint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vsub_vv_i8mf2(op0, op1, op2) \
__builtin_rvv_vsub_vv_i8mf2((vint8mf2_t)(op0), (vint8mf2_t)(op1), (size_t)(op2))
#define vsub_vv_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsub_vv_i8mf4(op0, op1, op2) \
__builtin_rvv_vsub_vv_i8mf4((vint8mf4_t)(op0), (vint8mf4_t)(op1), (size_t)(op2))
#define vsub_vv_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsub_vv_i8mf8(op0, op1, op2) \
__builtin_rvv_vsub_vv_i8mf8((vint8mf8_t)(op0), (vint8mf8_t)(op1), (size_t)(op2))
#define vsub_vv_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsub_vv_i16m1(op0, op1, op2) \
__builtin_rvv_vsub_vv_i16m1((vint16m1_t)(op0), (vint16m1_t)(op1), (size_t)(op2))
#define vsub_vv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsub_vv_i16m2(op0, op1, op2) \
__builtin_rvv_vsub_vv_i16m2((vint16m2_t)(op0), (vint16m2_t)(op1), (size_t)(op2))
#define vsub_vv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsub_vv_i16m4(op0, op1, op2) \
__builtin_rvv_vsub_vv_i16m4((vint16m4_t)(op0), (vint16m4_t)(op1), (size_t)(op2))
#define vsub_vv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsub_vv_i16m8(op0, op1, op2) \
__builtin_rvv_vsub_vv_i16m8((vint16m8_t)(op0), (vint16m8_t)(op1), (size_t)(op2))
#define vsub_vv_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (vint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsub_vv_i16mf2(op0, op1, op2) \
__builtin_rvv_vsub_vv_i16mf2((vint16mf2_t)(op0), (vint16mf2_t)(op1), (size_t)(op2))
#define vsub_vv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsub_vv_i16mf4(op0, op1, op2) \
__builtin_rvv_vsub_vv_i16mf4((vint16mf4_t)(op0), (vint16mf4_t)(op1), (size_t)(op2))
#define vsub_vv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsub_vv_i32m1(op0, op1, op2) \
__builtin_rvv_vsub_vv_i32m1((vint32m1_t)(op0), (vint32m1_t)(op1), (size_t)(op2))
#define vsub_vv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsub_vv_i32m2(op0, op1, op2) \
__builtin_rvv_vsub_vv_i32m2((vint32m2_t)(op0), (vint32m2_t)(op1), (size_t)(op2))
#define vsub_vv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsub_vv_i32m4(op0, op1, op2) \
__builtin_rvv_vsub_vv_i32m4((vint32m4_t)(op0), (vint32m4_t)(op1), (size_t)(op2))
#define vsub_vv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsub_vv_i32m8(op0, op1, op2) \
__builtin_rvv_vsub_vv_i32m8((vint32m8_t)(op0), (vint32m8_t)(op1), (size_t)(op2))
#define vsub_vv_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (vint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsub_vv_i32mf2(op0, op1, op2) \
__builtin_rvv_vsub_vv_i32mf2((vint32mf2_t)(op0), (vint32mf2_t)(op1), (size_t)(op2))
#define vsub_vv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsub_vv_i64m1(op0, op1, op2) \
__builtin_rvv_vsub_vv_i64m1((vint64m1_t)(op0), (vint64m1_t)(op1), (size_t)(op2))
#define vsub_vv_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsub_vv_i64m2(op0, op1, op2) \
__builtin_rvv_vsub_vv_i64m2((vint64m2_t)(op0), (vint64m2_t)(op1), (size_t)(op2))
#define vsub_vv_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (vint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsub_vv_i64m4(op0, op1, op2) \
__builtin_rvv_vsub_vv_i64m4((vint64m4_t)(op0), (vint64m4_t)(op1), (size_t)(op2))
#define vsub_vv_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (vint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsub_vv_i64m8(op0, op1, op2) \
__builtin_rvv_vsub_vv_i64m8((vint64m8_t)(op0), (vint64m8_t)(op1), (size_t)(op2))
#define vsub_vv_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (vint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsub_vx_i8m1(op0, op1, op2) \
__builtin_rvv_vsub_vx_i8m1((vint8m1_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vsub_vx_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (int8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsub_vx_i8m2(op0, op1, op2) \
__builtin_rvv_vsub_vx_i8m2((vint8m2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vsub_vx_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (int8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsub_vx_i8m4(op0, op1, op2) \
__builtin_rvv_vsub_vx_i8m4((vint8m4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vsub_vx_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (int8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsub_vx_i8m8(op0, op1, op2) \
__builtin_rvv_vsub_vx_i8m8((vint8m8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vsub_vx_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (int8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vsub_vx_i8mf2(op0, op1, op2) \
__builtin_rvv_vsub_vx_i8mf2((vint8mf2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vsub_vx_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (int8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsub_vx_i8mf4(op0, op1, op2) \
__builtin_rvv_vsub_vx_i8mf4((vint8mf4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vsub_vx_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (int8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsub_vx_i8mf8(op0, op1, op2) \
__builtin_rvv_vsub_vx_i8mf8((vint8mf8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vsub_vx_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (int8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsub_vx_i16m1(op0, op1, op2) \
__builtin_rvv_vsub_vx_i16m1((vint16m1_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vsub_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (int16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsub_vx_i16m2(op0, op1, op2) \
__builtin_rvv_vsub_vx_i16m2((vint16m2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vsub_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (int16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsub_vx_i16m4(op0, op1, op2) \
__builtin_rvv_vsub_vx_i16m4((vint16m4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vsub_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (int16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsub_vx_i16m8(op0, op1, op2) \
__builtin_rvv_vsub_vx_i16m8((vint16m8_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vsub_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (int16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsub_vx_i16mf2(op0, op1, op2) \
__builtin_rvv_vsub_vx_i16mf2((vint16mf2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vsub_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (int16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsub_vx_i16mf4(op0, op1, op2) \
__builtin_rvv_vsub_vx_i16mf4((vint16mf4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vsub_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (int16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsub_vx_i32m1(op0, op1, op2) \
__builtin_rvv_vsub_vx_i32m1((vint32m1_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vsub_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (int32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsub_vx_i32m2(op0, op1, op2) \
__builtin_rvv_vsub_vx_i32m2((vint32m2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vsub_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (int32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsub_vx_i32m4(op0, op1, op2) \
__builtin_rvv_vsub_vx_i32m4((vint32m4_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vsub_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (int32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsub_vx_i32m8(op0, op1, op2) \
__builtin_rvv_vsub_vx_i32m8((vint32m8_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vsub_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (int32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsub_vx_i32mf2(op0, op1, op2) \
__builtin_rvv_vsub_vx_i32mf2((vint32mf2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vsub_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (int32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsub_vx_i64m1(op0, op1, op2) \
__builtin_rvv_vsub_vx_i64m1((vint64m1_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vsub_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (int64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsub_vx_i64m2(op0, op1, op2) \
__builtin_rvv_vsub_vx_i64m2((vint64m2_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vsub_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (int64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsub_vx_i64m4(op0, op1, op2) \
__builtin_rvv_vsub_vx_i64m4((vint64m4_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vsub_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (int64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsub_vx_i64m8(op0, op1, op2) \
__builtin_rvv_vsub_vx_i64m8((vint64m8_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vsub_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (int64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsub_vv_u8m1(op0, op1, op2) \
__builtin_rvv_vsub_vv_u8m1((vuint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vsub_vv_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsub_vv_u8m2(op0, op1, op2) \
__builtin_rvv_vsub_vv_u8m2((vuint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vsub_vv_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsub_vv_u8m4(op0, op1, op2) \
__builtin_rvv_vsub_vv_u8m4((vuint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vsub_vv_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsub_vv_u8m8(op0, op1, op2) \
__builtin_rvv_vsub_vv_u8m8((vuint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vsub_vv_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vsub_vv_u8mf2(op0, op1, op2) \
__builtin_rvv_vsub_vv_u8mf2((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vsub_vv_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsub_vv_u8mf4(op0, op1, op2) \
__builtin_rvv_vsub_vv_u8mf4((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vsub_vv_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsub_vv_u8mf8(op0, op1, op2) \
__builtin_rvv_vsub_vv_u8mf8((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vsub_vv_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsub_vv_u16m1(op0, op1, op2) \
__builtin_rvv_vsub_vv_u16m1((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vsub_vv_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsub_vv_u16m2(op0, op1, op2) \
__builtin_rvv_vsub_vv_u16m2((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vsub_vv_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsub_vv_u16m4(op0, op1, op2) \
__builtin_rvv_vsub_vv_u16m4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vsub_vv_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsub_vv_u16m8(op0, op1, op2) \
__builtin_rvv_vsub_vv_u16m8((vuint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vsub_vv_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsub_vv_u16mf2(op0, op1, op2) \
__builtin_rvv_vsub_vv_u16mf2((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vsub_vv_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsub_vv_u16mf4(op0, op1, op2) \
__builtin_rvv_vsub_vv_u16mf4((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vsub_vv_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsub_vv_u32m1(op0, op1, op2) \
__builtin_rvv_vsub_vv_u32m1((vuint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vsub_vv_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsub_vv_u32m2(op0, op1, op2) \
__builtin_rvv_vsub_vv_u32m2((vuint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vsub_vv_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsub_vv_u32m4(op0, op1, op2) \
__builtin_rvv_vsub_vv_u32m4((vuint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vsub_vv_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsub_vv_u32m8(op0, op1, op2) \
__builtin_rvv_vsub_vv_u32m8((vuint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vsub_vv_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsub_vv_u32mf2(op0, op1, op2) \
__builtin_rvv_vsub_vv_u32mf2((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vsub_vv_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsub_vv_u64m1(op0, op1, op2) \
__builtin_rvv_vsub_vv_u64m1((vuint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vsub_vv_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsub_vv_u64m2(op0, op1, op2) \
__builtin_rvv_vsub_vv_u64m2((vuint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vsub_vv_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsub_vv_u64m4(op0, op1, op2) \
__builtin_rvv_vsub_vv_u64m4((vuint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vsub_vv_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsub_vv_u64m8(op0, op1, op2) \
__builtin_rvv_vsub_vv_u64m8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vsub_vv_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsub_vx_u8m1(op0, op1, op2) \
__builtin_rvv_vsub_vx_u8m1((vuint8m1_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vsub_vx_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (uint8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsub_vx_u8m2(op0, op1, op2) \
__builtin_rvv_vsub_vx_u8m2((vuint8m2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vsub_vx_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (uint8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsub_vx_u8m4(op0, op1, op2) \
__builtin_rvv_vsub_vx_u8m4((vuint8m4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vsub_vx_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (uint8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsub_vx_u8m8(op0, op1, op2) \
__builtin_rvv_vsub_vx_u8m8((vuint8m8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vsub_vx_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (uint8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vsub_vx_u8mf2(op0, op1, op2) \
__builtin_rvv_vsub_vx_u8mf2((vuint8mf2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vsub_vx_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (uint8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsub_vx_u8mf4(op0, op1, op2) \
__builtin_rvv_vsub_vx_u8mf4((vuint8mf4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vsub_vx_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (uint8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsub_vx_u8mf8(op0, op1, op2) \
__builtin_rvv_vsub_vx_u8mf8((vuint8mf8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vsub_vx_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (uint8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsub_vx_u16m1(op0, op1, op2) \
__builtin_rvv_vsub_vx_u16m1((vuint16m1_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vsub_vx_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (uint16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsub_vx_u16m2(op0, op1, op2) \
__builtin_rvv_vsub_vx_u16m2((vuint16m2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vsub_vx_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (uint16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsub_vx_u16m4(op0, op1, op2) \
__builtin_rvv_vsub_vx_u16m4((vuint16m4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vsub_vx_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (uint16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsub_vx_u16m8(op0, op1, op2) \
__builtin_rvv_vsub_vx_u16m8((vuint16m8_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vsub_vx_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (uint16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsub_vx_u16mf2(op0, op1, op2) \
__builtin_rvv_vsub_vx_u16mf2((vuint16mf2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vsub_vx_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (uint16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsub_vx_u16mf4(op0, op1, op2) \
__builtin_rvv_vsub_vx_u16mf4((vuint16mf4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vsub_vx_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (uint16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsub_vx_u32m1(op0, op1, op2) \
__builtin_rvv_vsub_vx_u32m1((vuint32m1_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vsub_vx_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (uint32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsub_vx_u32m2(op0, op1, op2) \
__builtin_rvv_vsub_vx_u32m2((vuint32m2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vsub_vx_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (uint32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsub_vx_u32m4(op0, op1, op2) \
__builtin_rvv_vsub_vx_u32m4((vuint32m4_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vsub_vx_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (uint32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsub_vx_u32m8(op0, op1, op2) \
__builtin_rvv_vsub_vx_u32m8((vuint32m8_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vsub_vx_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (uint32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsub_vx_u32mf2(op0, op1, op2) \
__builtin_rvv_vsub_vx_u32mf2((vuint32mf2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vsub_vx_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (uint32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsub_vx_u64m1(op0, op1, op2) \
__builtin_rvv_vsub_vx_u64m1((vuint64m1_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vsub_vx_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (uint64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsub_vx_u64m2(op0, op1, op2) \
__builtin_rvv_vsub_vx_u64m2((vuint64m2_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vsub_vx_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (uint64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsub_vx_u64m4(op0, op1, op2) \
__builtin_rvv_vsub_vx_u64m4((vuint64m4_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vsub_vx_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (uint64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsub_vx_u64m8(op0, op1, op2) \
__builtin_rvv_vsub_vx_u64m8((vuint64m8_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vsub_vx_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (uint64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vrsub_vx_i8m1(op0, op1, op2) \
__builtin_rvv_vrsub_vx_i8m1((vint8m1_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vrsub_vx_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (int8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vrsub_vx_i8m2(op0, op1, op2) \
__builtin_rvv_vrsub_vx_i8m2((vint8m2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vrsub_vx_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (int8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vrsub_vx_i8m4(op0, op1, op2) \
__builtin_rvv_vrsub_vx_i8m4((vint8m4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vrsub_vx_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (int8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vrsub_vx_i8m8(op0, op1, op2) \
__builtin_rvv_vrsub_vx_i8m8((vint8m8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vrsub_vx_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (int8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vrsub_vx_i8mf2(op0, op1, op2) \
__builtin_rvv_vrsub_vx_i8mf2((vint8mf2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vrsub_vx_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (int8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vrsub_vx_i8mf4(op0, op1, op2) \
__builtin_rvv_vrsub_vx_i8mf4((vint8mf4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vrsub_vx_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (int8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vrsub_vx_i8mf8(op0, op1, op2) \
__builtin_rvv_vrsub_vx_i8mf8((vint8mf8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vrsub_vx_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (int8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vrsub_vx_i16m1(op0, op1, op2) \
__builtin_rvv_vrsub_vx_i16m1((vint16m1_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vrsub_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (int16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vrsub_vx_i16m2(op0, op1, op2) \
__builtin_rvv_vrsub_vx_i16m2((vint16m2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vrsub_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (int16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vrsub_vx_i16m4(op0, op1, op2) \
__builtin_rvv_vrsub_vx_i16m4((vint16m4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vrsub_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (int16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vrsub_vx_i16m8(op0, op1, op2) \
__builtin_rvv_vrsub_vx_i16m8((vint16m8_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vrsub_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (int16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vrsub_vx_i16mf2(op0, op1, op2) \
__builtin_rvv_vrsub_vx_i16mf2((vint16mf2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vrsub_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (int16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vrsub_vx_i16mf4(op0, op1, op2) \
__builtin_rvv_vrsub_vx_i16mf4((vint16mf4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vrsub_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (int16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vrsub_vx_i32m1(op0, op1, op2) \
__builtin_rvv_vrsub_vx_i32m1((vint32m1_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vrsub_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (int32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vrsub_vx_i32m2(op0, op1, op2) \
__builtin_rvv_vrsub_vx_i32m2((vint32m2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vrsub_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (int32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vrsub_vx_i32m4(op0, op1, op2) \
__builtin_rvv_vrsub_vx_i32m4((vint32m4_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vrsub_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (int32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vrsub_vx_i32m8(op0, op1, op2) \
__builtin_rvv_vrsub_vx_i32m8((vint32m8_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vrsub_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (int32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vrsub_vx_i32mf2(op0, op1, op2) \
__builtin_rvv_vrsub_vx_i32mf2((vint32mf2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vrsub_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (int32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vrsub_vx_i64m1(op0, op1, op2) \
__builtin_rvv_vrsub_vx_i64m1((vint64m1_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vrsub_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (int64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vrsub_vx_i64m2(op0, op1, op2) \
__builtin_rvv_vrsub_vx_i64m2((vint64m2_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vrsub_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (int64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vrsub_vx_i64m4(op0, op1, op2) \
__builtin_rvv_vrsub_vx_i64m4((vint64m4_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vrsub_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (int64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vrsub_vx_i64m8(op0, op1, op2) \
__builtin_rvv_vrsub_vx_i64m8((vint64m8_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vrsub_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (int64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vrsub_vx_u8m1(op0, op1, op2) \
__builtin_rvv_vrsub_vx_u8m1((vuint8m1_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vrsub_vx_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (uint8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vrsub_vx_u8m2(op0, op1, op2) \
__builtin_rvv_vrsub_vx_u8m2((vuint8m2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vrsub_vx_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (uint8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vrsub_vx_u8m4(op0, op1, op2) \
__builtin_rvv_vrsub_vx_u8m4((vuint8m4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vrsub_vx_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (uint8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vrsub_vx_u8m8(op0, op1, op2) \
__builtin_rvv_vrsub_vx_u8m8((vuint8m8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vrsub_vx_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (uint8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vrsub_vx_u8mf2(op0, op1, op2) \
__builtin_rvv_vrsub_vx_u8mf2((vuint8mf2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vrsub_vx_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (uint8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vrsub_vx_u8mf4(op0, op1, op2) \
__builtin_rvv_vrsub_vx_u8mf4((vuint8mf4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vrsub_vx_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (uint8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vrsub_vx_u8mf8(op0, op1, op2) \
__builtin_rvv_vrsub_vx_u8mf8((vuint8mf8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vrsub_vx_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (uint8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vrsub_vx_u16m1(op0, op1, op2) \
__builtin_rvv_vrsub_vx_u16m1((vuint16m1_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vrsub_vx_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (uint16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vrsub_vx_u16m2(op0, op1, op2) \
__builtin_rvv_vrsub_vx_u16m2((vuint16m2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vrsub_vx_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (uint16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vrsub_vx_u16m4(op0, op1, op2) \
__builtin_rvv_vrsub_vx_u16m4((vuint16m4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vrsub_vx_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (uint16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vrsub_vx_u16m8(op0, op1, op2) \
__builtin_rvv_vrsub_vx_u16m8((vuint16m8_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vrsub_vx_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (uint16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vrsub_vx_u16mf2(op0, op1, op2) \
__builtin_rvv_vrsub_vx_u16mf2((vuint16mf2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vrsub_vx_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (uint16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vrsub_vx_u16mf4(op0, op1, op2) \
__builtin_rvv_vrsub_vx_u16mf4((vuint16mf4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vrsub_vx_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (uint16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vrsub_vx_u32m1(op0, op1, op2) \
__builtin_rvv_vrsub_vx_u32m1((vuint32m1_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vrsub_vx_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (uint32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vrsub_vx_u32m2(op0, op1, op2) \
__builtin_rvv_vrsub_vx_u32m2((vuint32m2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vrsub_vx_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (uint32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vrsub_vx_u32m4(op0, op1, op2) \
__builtin_rvv_vrsub_vx_u32m4((vuint32m4_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vrsub_vx_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (uint32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vrsub_vx_u32m8(op0, op1, op2) \
__builtin_rvv_vrsub_vx_u32m8((vuint32m8_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vrsub_vx_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (uint32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vrsub_vx_u32mf2(op0, op1, op2) \
__builtin_rvv_vrsub_vx_u32mf2((vuint32mf2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vrsub_vx_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (uint32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vrsub_vx_u64m1(op0, op1, op2) \
__builtin_rvv_vrsub_vx_u64m1((vuint64m1_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vrsub_vx_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (uint64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vrsub_vx_u64m2(op0, op1, op2) \
__builtin_rvv_vrsub_vx_u64m2((vuint64m2_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vrsub_vx_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (uint64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vrsub_vx_u64m4(op0, op1, op2) \
__builtin_rvv_vrsub_vx_u64m4((vuint64m4_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vrsub_vx_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (uint64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vrsub_vx_u64m8(op0, op1, op2) \
__builtin_rvv_vrsub_vx_u64m8((vuint64m8_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vrsub_vx_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (uint64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vadc_vvm_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_i8m1((vint8m1_t)(op0), (vint8m1_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vadc_vvm_i8m2(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_i8m2((vint8m2_t)(op0), (vint8m2_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vadc_vvm_i8m4(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_i8m4((vint8m4_t)(op0), (vint8m4_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vadc_vvm_i8m8(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_i8m8((vint8m8_t)(op0), (vint8m8_t)(op1), (vbool1_t)(op2), (size_t)(op3))
#define vadc_vvm_i8mf2(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_i8mf2((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vadc_vvm_i8mf4(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_i8mf4((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vadc_vvm_i8mf8(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_i8mf8((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vadc_vvm_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_i16m1((vint16m1_t)(op0), (vint16m1_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vadc_vvm_i16m2(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_i16m2((vint16m2_t)(op0), (vint16m2_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vadc_vvm_i16m4(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_i16m4((vint16m4_t)(op0), (vint16m4_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vadc_vvm_i16m8(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_i16m8((vint16m8_t)(op0), (vint16m8_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vadc_vvm_i16mf2(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_i16mf2((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vadc_vvm_i16mf4(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_i16mf4((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vadc_vvm_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_i32m1((vint32m1_t)(op0), (vint32m1_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vadc_vvm_i32m2(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_i32m2((vint32m2_t)(op0), (vint32m2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vadc_vvm_i32m4(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_i32m4((vint32m4_t)(op0), (vint32m4_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vadc_vvm_i32m8(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_i32m8((vint32m8_t)(op0), (vint32m8_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vadc_vvm_i32mf2(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_i32mf2((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vadc_vvm_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_i64m1((vint64m1_t)(op0), (vint64m1_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vadc_vvm_i64m2(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_i64m2((vint64m2_t)(op0), (vint64m2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vadc_vvm_i64m4(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_i64m4((vint64m4_t)(op0), (vint64m4_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vadc_vvm_i64m8(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_i64m8((vint64m8_t)(op0), (vint64m8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vadc_vxm_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_i8m1((vint8m1_t)(op0), (int8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vadc_vxm_i8m2(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_i8m2((vint8m2_t)(op0), (int8_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vadc_vxm_i8m4(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_i8m4((vint8m4_t)(op0), (int8_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vadc_vxm_i8m8(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_i8m8((vint8m8_t)(op0), (int8_t)(op1), (vbool1_t)(op2), (size_t)(op3))
#define vadc_vxm_i8mf2(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_i8mf2((vint8mf2_t)(op0), (int8_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vadc_vxm_i8mf4(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_i8mf4((vint8mf4_t)(op0), (int8_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vadc_vxm_i8mf8(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_i8mf8((vint8mf8_t)(op0), (int8_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vadc_vxm_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_i16m1((vint16m1_t)(op0), (int16_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vadc_vxm_i16m2(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_i16m2((vint16m2_t)(op0), (int16_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vadc_vxm_i16m4(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_i16m4((vint16m4_t)(op0), (int16_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vadc_vxm_i16m8(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_i16m8((vint16m8_t)(op0), (int16_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vadc_vxm_i16mf2(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_i16mf2((vint16mf2_t)(op0), (int16_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vadc_vxm_i16mf4(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_i16mf4((vint16mf4_t)(op0), (int16_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vadc_vxm_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_i32m1((vint32m1_t)(op0), (int32_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vadc_vxm_i32m2(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_i32m2((vint32m2_t)(op0), (int32_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vadc_vxm_i32m4(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_i32m4((vint32m4_t)(op0), (int32_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vadc_vxm_i32m8(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_i32m8((vint32m8_t)(op0), (int32_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vadc_vxm_i32mf2(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_i32mf2((vint32mf2_t)(op0), (int32_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vadc_vxm_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_i64m1((vint64m1_t)(op0), (int64_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vadc_vxm_i64m2(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_i64m2((vint64m2_t)(op0), (int64_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vadc_vxm_i64m4(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_i64m4((vint64m4_t)(op0), (int64_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vadc_vxm_i64m8(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_i64m8((vint64m8_t)(op0), (int64_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vse8_v_i8m1(op1, op0, op2) \
__builtin_rvv_vse8_v_i8m1((vint8m1_t)(op0), (int8_t *)(op1), (size_t)(op2))
#define vse8_v_i8m1_m(op2, op1, op0, op3) \
__builtin_rvv_vse8_v_i8m1_m((vint8m1_t)(op0), (int8_t *)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vse8_v_i8m2(op1, op0, op2) \
__builtin_rvv_vse8_v_i8m2((vint8m2_t)(op0), (int8_t *)(op1), (size_t)(op2))
#define vse8_v_i8m2_m(op2, op1, op0, op3) \
__builtin_rvv_vse8_v_i8m2_m((vint8m2_t)(op0), (int8_t *)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vse8_v_i8m4(op1, op0, op2) \
__builtin_rvv_vse8_v_i8m4((vint8m4_t)(op0), (int8_t *)(op1), (size_t)(op2))
#define vse8_v_i8m4_m(op2, op1, op0, op3) \
__builtin_rvv_vse8_v_i8m4_m((vint8m4_t)(op0), (int8_t *)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vse8_v_i8m8(op1, op0, op2) \
__builtin_rvv_vse8_v_i8m8((vint8m8_t)(op0), (int8_t *)(op1), (size_t)(op2))
#define vse8_v_i8m8_m(op2, op1, op0, op3) \
__builtin_rvv_vse8_v_i8m8_m((vint8m8_t)(op0), (int8_t *)(op1), (vbool1_t)(op2), (size_t)(op3))
#define vse8_v_i8mf2(op1, op0, op2) \
__builtin_rvv_vse8_v_i8mf2((vint8mf2_t)(op0), (int8_t *)(op1), (size_t)(op2))
#define vse8_v_i8mf2_m(op2, op1, op0, op3) \
__builtin_rvv_vse8_v_i8mf2_m((vint8mf2_t)(op0), (int8_t *)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vse8_v_i8mf4(op1, op0, op2) \
__builtin_rvv_vse8_v_i8mf4((vint8mf4_t)(op0), (int8_t *)(op1), (size_t)(op2))
#define vse8_v_i8mf4_m(op2, op1, op0, op3) \
__builtin_rvv_vse8_v_i8mf4_m((vint8mf4_t)(op0), (int8_t *)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vse8_v_i8mf8(op1, op0, op2) \
__builtin_rvv_vse8_v_i8mf8((vint8mf8_t)(op0), (int8_t *)(op1), (size_t)(op2))
#define vse8_v_i8mf8_m(op2, op1, op0, op3) \
__builtin_rvv_vse8_v_i8mf8_m((vint8mf8_t)(op0), (int8_t *)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vadc_vvm_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_u8m1((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vadc_vvm_u8m2(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_u8m2((vuint8m2_t)(op0), (vuint8m2_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vadc_vvm_u8m4(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_u8m4((vuint8m4_t)(op0), (vuint8m4_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vadc_vvm_u8m8(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_u8m8((vuint8m8_t)(op0), (vuint8m8_t)(op1), (vbool1_t)(op2), (size_t)(op3))
#define vadc_vvm_u8mf2(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_u8mf2((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vadc_vvm_u8mf4(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_u8mf4((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vadc_vvm_u8mf8(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_u8mf8((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vadc_vvm_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_u16m1((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vadc_vvm_u16m2(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_u16m2((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vadc_vvm_u16m4(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_u16m4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vadc_vvm_u16m8(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_u16m8((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vadc_vvm_u16mf2(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_u16mf2((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vadc_vvm_u16mf4(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_u16mf4((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vadc_vvm_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_u32m1((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vadc_vvm_u32m2(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_u32m2((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vadc_vvm_u32m4(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_u32m4((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vadc_vvm_u32m8(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_u32m8((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vadc_vvm_u32mf2(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_u32mf2((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vadc_vvm_u64m1(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_u64m1((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vadc_vvm_u64m2(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_u64m2((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vadc_vvm_u64m4(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_u64m4((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vadc_vvm_u64m8(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_u64m8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vadc_vxm_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_u8m1((vuint8m1_t)(op0), (uint8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vadc_vxm_u8m2(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_u8m2((vuint8m2_t)(op0), (uint8_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vadc_vxm_u8m4(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_u8m4((vuint8m4_t)(op0), (uint8_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vadc_vxm_u8m8(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_u8m8((vuint8m8_t)(op0), (uint8_t)(op1), (vbool1_t)(op2), (size_t)(op3))
#define vadc_vxm_u8mf2(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_u8mf2((vuint8mf2_t)(op0), (uint8_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vadc_vxm_u8mf4(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_u8mf4((vuint8mf4_t)(op0), (uint8_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vadc_vxm_u8mf8(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_u8mf8((vuint8mf8_t)(op0), (uint8_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vadc_vxm_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_u16m1((vuint16m1_t)(op0), (uint16_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vadc_vxm_u16m2(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_u16m2((vuint16m2_t)(op0), (uint16_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vadc_vxm_u16m4(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_u16m4((vuint16m4_t)(op0), (uint16_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vadc_vxm_u16m8(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_u16m8((vuint16m8_t)(op0), (uint16_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vadc_vxm_u16mf2(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_u16mf2((vuint16mf2_t)(op0), (uint16_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vadc_vxm_u16mf4(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_u16mf4((vuint16mf4_t)(op0), (uint16_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vadc_vxm_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_u32m1((vuint32m1_t)(op0), (uint32_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vadc_vxm_u32m2(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_u32m2((vuint32m2_t)(op0), (uint32_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vadc_vxm_u32m4(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_u32m4((vuint32m4_t)(op0), (uint32_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vadc_vxm_u32m8(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_u32m8((vuint32m8_t)(op0), (uint32_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vadc_vxm_u32mf2(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_u32mf2((vuint32mf2_t)(op0), (uint32_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vadc_vxm_u64m1(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_u64m1((vuint64m1_t)(op0), (uint64_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vadc_vxm_u64m2(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_u64m2((vuint64m2_t)(op0), (uint64_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vadc_vxm_u64m4(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_u64m4((vuint64m4_t)(op0), (uint64_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vadc_vxm_u64m8(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_u64m8((vuint64m8_t)(op0), (uint64_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmadc_vvm_i8m1_b8(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_i8m1_b8((vint8m1_t)(op0), (vint8m1_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmadc_vvm_i8m2_b4(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_i8m2_b4((vint8m2_t)(op0), (vint8m2_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vmadc_vvm_i8m4_b2(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_i8m4_b2((vint8m4_t)(op0), (vint8m4_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vmadc_vvm_i8m8_b1(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_i8m8_b1((vint8m8_t)(op0), (vint8m8_t)(op1), (vbool1_t)(op2), (size_t)(op3))
#define vmadc_vvm_i8mf2_b16(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_i8mf2_b16((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmadc_vvm_i8mf4_b32(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_i8mf4_b32((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmadc_vvm_i8mf8_b64(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_i8mf8_b64((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmadc_vvm_i16m1_b16(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_i16m1_b16((vint16m1_t)(op0), (vint16m1_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmadc_vvm_i16m2_b8(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_i16m2_b8((vint16m2_t)(op0), (vint16m2_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmadc_vvm_i16m4_b4(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_i16m4_b4((vint16m4_t)(op0), (vint16m4_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vmadc_vvm_i16m8_b2(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_i16m8_b2((vint16m8_t)(op0), (vint16m8_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vmadc_vvm_i16mf2_b32(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_i16mf2_b32((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmadc_vvm_i16mf4_b64(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_i16mf4_b64((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmadc_vvm_i32m1_b32(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_i32m1_b32((vint32m1_t)(op0), (vint32m1_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmadc_vvm_i32m2_b16(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_i32m2_b16((vint32m2_t)(op0), (vint32m2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmadc_vvm_i32m4_b8(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_i32m4_b8((vint32m4_t)(op0), (vint32m4_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmadc_vvm_i32m8_b4(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_i32m8_b4((vint32m8_t)(op0), (vint32m8_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vmadc_vvm_i32mf2_b64(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_i32mf2_b64((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmadc_vvm_i64m1_b64(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_i64m1_b64((vint64m1_t)(op0), (vint64m1_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmadc_vvm_i64m2_b32(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_i64m2_b32((vint64m2_t)(op0), (vint64m2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmadc_vvm_i64m4_b16(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_i64m4_b16((vint64m4_t)(op0), (vint64m4_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmadc_vvm_i64m8_b8(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_i64m8_b8((vint64m8_t)(op0), (vint64m8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmadc_vxm_i8m1_b8(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_i8m1_b8((vint8m1_t)(op0), (int8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmadc_vxm_i8m2_b4(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_i8m2_b4((vint8m2_t)(op0), (int8_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vmadc_vxm_i8m4_b2(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_i8m4_b2((vint8m4_t)(op0), (int8_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vmadc_vxm_i8m8_b1(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_i8m8_b1((vint8m8_t)(op0), (int8_t)(op1), (vbool1_t)(op2), (size_t)(op3))
#define vmadc_vxm_i8mf2_b16(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_i8mf2_b16((vint8mf2_t)(op0), (int8_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmadc_vxm_i8mf4_b32(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_i8mf4_b32((vint8mf4_t)(op0), (int8_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmadc_vxm_i8mf8_b64(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_i8mf8_b64((vint8mf8_t)(op0), (int8_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmadc_vxm_i16m1_b16(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_i16m1_b16((vint16m1_t)(op0), (int16_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmadc_vxm_i16m2_b8(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_i16m2_b8((vint16m2_t)(op0), (int16_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmadc_vxm_i16m4_b4(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_i16m4_b4((vint16m4_t)(op0), (int16_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vmadc_vxm_i16m8_b2(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_i16m8_b2((vint16m8_t)(op0), (int16_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vmadc_vxm_i16mf2_b32(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_i16mf2_b32((vint16mf2_t)(op0), (int16_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmadc_vxm_i16mf4_b64(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_i16mf4_b64((vint16mf4_t)(op0), (int16_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmadc_vxm_i32m1_b32(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_i32m1_b32((vint32m1_t)(op0), (int32_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmadc_vxm_i32m2_b16(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_i32m2_b16((vint32m2_t)(op0), (int32_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmadc_vxm_i32m4_b8(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_i32m4_b8((vint32m4_t)(op0), (int32_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmadc_vxm_i32m8_b4(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_i32m8_b4((vint32m8_t)(op0), (int32_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vmadc_vxm_i32mf2_b64(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_i32mf2_b64((vint32mf2_t)(op0), (int32_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmadc_vxm_i64m1_b64(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_i64m1_b64((vint64m1_t)(op0), (int64_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmadc_vxm_i64m2_b32(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_i64m2_b32((vint64m2_t)(op0), (int64_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmadc_vxm_i64m4_b16(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_i64m4_b16((vint64m4_t)(op0), (int64_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmadc_vxm_i64m8_b8(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_i64m8_b8((vint64m8_t)(op0), (int64_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmadc_vvm_u8m1_b8(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_u8m1_b8((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmadc_vvm_u8m2_b4(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_u8m2_b4((vuint8m2_t)(op0), (vuint8m2_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vmadc_vvm_u8m4_b2(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_u8m4_b2((vuint8m4_t)(op0), (vuint8m4_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vmadc_vvm_u8m8_b1(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_u8m8_b1((vuint8m8_t)(op0), (vuint8m8_t)(op1), (vbool1_t)(op2), (size_t)(op3))
#define vmadc_vvm_u8mf2_b16(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_u8mf2_b16((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmadc_vvm_u8mf4_b32(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_u8mf4_b32((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmadc_vvm_u8mf8_b64(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_u8mf8_b64((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmadc_vvm_u16m1_b16(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_u16m1_b16((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmadc_vvm_u16m2_b8(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_u16m2_b8((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmadc_vvm_u16m4_b4(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_u16m4_b4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vmadc_vvm_u16m8_b2(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_u16m8_b2((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vmadc_vvm_u16mf2_b32(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_u16mf2_b32((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmadc_vvm_u16mf4_b64(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_u16mf4_b64((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmadc_vvm_u32m1_b32(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_u32m1_b32((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmadc_vvm_u32m2_b16(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_u32m2_b16((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmadc_vvm_u32m4_b8(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_u32m4_b8((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmadc_vvm_u32m8_b4(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_u32m8_b4((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vmadc_vvm_u32mf2_b64(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_u32mf2_b64((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmadc_vvm_u64m1_b64(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_u64m1_b64((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmadc_vvm_u64m2_b32(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_u64m2_b32((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmadc_vvm_u64m4_b16(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_u64m4_b16((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmadc_vvm_u64m8_b8(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_u64m8_b8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmadc_vxm_u8m1_b8(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_u8m1_b8((vuint8m1_t)(op0), (uint8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmadc_vxm_u8m2_b4(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_u8m2_b4((vuint8m2_t)(op0), (uint8_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vmadc_vxm_u8m4_b2(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_u8m4_b2((vuint8m4_t)(op0), (uint8_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vmadc_vxm_u8m8_b1(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_u8m8_b1((vuint8m8_t)(op0), (uint8_t)(op1), (vbool1_t)(op2), (size_t)(op3))
#define vmadc_vxm_u8mf2_b16(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_u8mf2_b16((vuint8mf2_t)(op0), (uint8_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmadc_vxm_u8mf4_b32(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_u8mf4_b32((vuint8mf4_t)(op0), (uint8_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmadc_vxm_u8mf8_b64(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_u8mf8_b64((vuint8mf8_t)(op0), (uint8_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmadc_vxm_u16m1_b16(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_u16m1_b16((vuint16m1_t)(op0), (uint16_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmadc_vxm_u16m2_b8(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_u16m2_b8((vuint16m2_t)(op0), (uint16_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmadc_vxm_u16m4_b4(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_u16m4_b4((vuint16m4_t)(op0), (uint16_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vmadc_vxm_u16m8_b2(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_u16m8_b2((vuint16m8_t)(op0), (uint16_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vmadc_vxm_u16mf2_b32(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_u16mf2_b32((vuint16mf2_t)(op0), (uint16_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmadc_vxm_u16mf4_b64(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_u16mf4_b64((vuint16mf4_t)(op0), (uint16_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmadc_vxm_u32m1_b32(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_u32m1_b32((vuint32m1_t)(op0), (uint32_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmadc_vxm_u32m2_b16(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_u32m2_b16((vuint32m2_t)(op0), (uint32_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmadc_vxm_u32m4_b8(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_u32m4_b8((vuint32m4_t)(op0), (uint32_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmadc_vxm_u32m8_b4(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_u32m8_b4((vuint32m8_t)(op0), (uint32_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vmadc_vxm_u32mf2_b64(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_u32mf2_b64((vuint32mf2_t)(op0), (uint32_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmadc_vxm_u64m1_b64(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_u64m1_b64((vuint64m1_t)(op0), (uint64_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmadc_vxm_u64m2_b32(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_u64m2_b32((vuint64m2_t)(op0), (uint64_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmadc_vxm_u64m4_b16(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_u64m4_b16((vuint64m4_t)(op0), (uint64_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmadc_vxm_u64m8_b8(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_u64m8_b8((vuint64m8_t)(op0), (uint64_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmadc_vv_i8m1_b8(op0, op1, op2) \
__builtin_rvv_vmadc_vv_i8m1_b8((vint8m1_t)(op0), (vint8m1_t)(op1), (size_t)(op2))
#define vmadc_vv_i8m2_b4(op0, op1, op2) \
__builtin_rvv_vmadc_vv_i8m2_b4((vint8m2_t)(op0), (vint8m2_t)(op1), (size_t)(op2))
#define vmadc_vv_i8m4_b2(op0, op1, op2) \
__builtin_rvv_vmadc_vv_i8m4_b2((vint8m4_t)(op0), (vint8m4_t)(op1), (size_t)(op2))
#define vmadc_vv_i8m8_b1(op0, op1, op2) \
__builtin_rvv_vmadc_vv_i8m8_b1((vint8m8_t)(op0), (vint8m8_t)(op1), (size_t)(op2))
#define vmadc_vv_i8mf2_b16(op0, op1, op2) \
__builtin_rvv_vmadc_vv_i8mf2_b16((vint8mf2_t)(op0), (vint8mf2_t)(op1), (size_t)(op2))
#define vmadc_vv_i8mf4_b32(op0, op1, op2) \
__builtin_rvv_vmadc_vv_i8mf4_b32((vint8mf4_t)(op0), (vint8mf4_t)(op1), (size_t)(op2))
#define vmadc_vv_i8mf8_b64(op0, op1, op2) \
__builtin_rvv_vmadc_vv_i8mf8_b64((vint8mf8_t)(op0), (vint8mf8_t)(op1), (size_t)(op2))
#define vmadc_vv_i16m1_b16(op0, op1, op2) \
__builtin_rvv_vmadc_vv_i16m1_b16((vint16m1_t)(op0), (vint16m1_t)(op1), (size_t)(op2))
#define vmadc_vv_i16m2_b8(op0, op1, op2) \
__builtin_rvv_vmadc_vv_i16m2_b8((vint16m2_t)(op0), (vint16m2_t)(op1), (size_t)(op2))
#define vmadc_vv_i16m4_b4(op0, op1, op2) \
__builtin_rvv_vmadc_vv_i16m4_b4((vint16m4_t)(op0), (vint16m4_t)(op1), (size_t)(op2))
#define vmadc_vv_i16m8_b2(op0, op1, op2) \
__builtin_rvv_vmadc_vv_i16m8_b2((vint16m8_t)(op0), (vint16m8_t)(op1), (size_t)(op2))
#define vmadc_vv_i16mf2_b32(op0, op1, op2) \
__builtin_rvv_vmadc_vv_i16mf2_b32((vint16mf2_t)(op0), (vint16mf2_t)(op1), (size_t)(op2))
#define vmadc_vv_i16mf4_b64(op0, op1, op2) \
__builtin_rvv_vmadc_vv_i16mf4_b64((vint16mf4_t)(op0), (vint16mf4_t)(op1), (size_t)(op2))
#define vmadc_vv_i32m1_b32(op0, op1, op2) \
__builtin_rvv_vmadc_vv_i32m1_b32((vint32m1_t)(op0), (vint32m1_t)(op1), (size_t)(op2))
#define vmadc_vv_i32m2_b16(op0, op1, op2) \
__builtin_rvv_vmadc_vv_i32m2_b16((vint32m2_t)(op0), (vint32m2_t)(op1), (size_t)(op2))
#define vmadc_vv_i32m4_b8(op0, op1, op2) \
__builtin_rvv_vmadc_vv_i32m4_b8((vint32m4_t)(op0), (vint32m4_t)(op1), (size_t)(op2))
#define vmadc_vv_i32m8_b4(op0, op1, op2) \
__builtin_rvv_vmadc_vv_i32m8_b4((vint32m8_t)(op0), (vint32m8_t)(op1), (size_t)(op2))
#define vmadc_vv_i32mf2_b64(op0, op1, op2) \
__builtin_rvv_vmadc_vv_i32mf2_b64((vint32mf2_t)(op0), (vint32mf2_t)(op1), (size_t)(op2))
#define vmadc_vv_i64m1_b64(op0, op1, op2) \
__builtin_rvv_vmadc_vv_i64m1_b64((vint64m1_t)(op0), (vint64m1_t)(op1), (size_t)(op2))
#define vmadc_vv_i64m2_b32(op0, op1, op2) \
__builtin_rvv_vmadc_vv_i64m2_b32((vint64m2_t)(op0), (vint64m2_t)(op1), (size_t)(op2))
#define vmadc_vv_i64m4_b16(op0, op1, op2) \
__builtin_rvv_vmadc_vv_i64m4_b16((vint64m4_t)(op0), (vint64m4_t)(op1), (size_t)(op2))
#define vmadc_vv_i64m8_b8(op0, op1, op2) \
__builtin_rvv_vmadc_vv_i64m8_b8((vint64m8_t)(op0), (vint64m8_t)(op1), (size_t)(op2))
#define vmadc_vx_i8m1_b8(op0, op1, op2) \
__builtin_rvv_vmadc_vx_i8m1_b8((vint8m1_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmadc_vx_i8m2_b4(op0, op1, op2) \
__builtin_rvv_vmadc_vx_i8m2_b4((vint8m2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmadc_vx_i8m4_b2(op0, op1, op2) \
__builtin_rvv_vmadc_vx_i8m4_b2((vint8m4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmadc_vx_i8m8_b1(op0, op1, op2) \
__builtin_rvv_vmadc_vx_i8m8_b1((vint8m8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmadc_vx_i8mf2_b16(op0, op1, op2) \
__builtin_rvv_vmadc_vx_i8mf2_b16((vint8mf2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmadc_vx_i8mf4_b32(op0, op1, op2) \
__builtin_rvv_vmadc_vx_i8mf4_b32((vint8mf4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmadc_vx_i8mf8_b64(op0, op1, op2) \
__builtin_rvv_vmadc_vx_i8mf8_b64((vint8mf8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmadc_vx_i16m1_b16(op0, op1, op2) \
__builtin_rvv_vmadc_vx_i16m1_b16((vint16m1_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmadc_vx_i16m2_b8(op0, op1, op2) \
__builtin_rvv_vmadc_vx_i16m2_b8((vint16m2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmadc_vx_i16m4_b4(op0, op1, op2) \
__builtin_rvv_vmadc_vx_i16m4_b4((vint16m4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmadc_vx_i16m8_b2(op0, op1, op2) \
__builtin_rvv_vmadc_vx_i16m8_b2((vint16m8_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmadc_vx_i16mf2_b32(op0, op1, op2) \
__builtin_rvv_vmadc_vx_i16mf2_b32((vint16mf2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmadc_vx_i16mf4_b64(op0, op1, op2) \
__builtin_rvv_vmadc_vx_i16mf4_b64((vint16mf4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmadc_vx_i32m1_b32(op0, op1, op2) \
__builtin_rvv_vmadc_vx_i32m1_b32((vint32m1_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmadc_vx_i32m2_b16(op0, op1, op2) \
__builtin_rvv_vmadc_vx_i32m2_b16((vint32m2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmadc_vx_i32m4_b8(op0, op1, op2) \
__builtin_rvv_vmadc_vx_i32m4_b8((vint32m4_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmadc_vx_i32m8_b4(op0, op1, op2) \
__builtin_rvv_vmadc_vx_i32m8_b4((vint32m8_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmadc_vx_i32mf2_b64(op0, op1, op2) \
__builtin_rvv_vmadc_vx_i32mf2_b64((vint32mf2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmadc_vx_i64m1_b64(op0, op1, op2) \
__builtin_rvv_vmadc_vx_i64m1_b64((vint64m1_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmadc_vx_i64m2_b32(op0, op1, op2) \
__builtin_rvv_vmadc_vx_i64m2_b32((vint64m2_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmadc_vx_i64m4_b16(op0, op1, op2) \
__builtin_rvv_vmadc_vx_i64m4_b16((vint64m4_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmadc_vx_i64m8_b8(op0, op1, op2) \
__builtin_rvv_vmadc_vx_i64m8_b8((vint64m8_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmadc_vv_u8m1_b8(op0, op1, op2) \
__builtin_rvv_vmadc_vv_u8m1_b8((vuint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vmadc_vv_u8m2_b4(op0, op1, op2) \
__builtin_rvv_vmadc_vv_u8m2_b4((vuint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vmadc_vv_u8m4_b2(op0, op1, op2) \
__builtin_rvv_vmadc_vv_u8m4_b2((vuint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vmadc_vv_u8m8_b1(op0, op1, op2) \
__builtin_rvv_vmadc_vv_u8m8_b1((vuint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vmadc_vv_u8mf2_b16(op0, op1, op2) \
__builtin_rvv_vmadc_vv_u8mf2_b16((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vmadc_vv_u8mf4_b32(op0, op1, op2) \
__builtin_rvv_vmadc_vv_u8mf4_b32((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vmadc_vv_u8mf8_b64(op0, op1, op2) \
__builtin_rvv_vmadc_vv_u8mf8_b64((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vmadc_vv_u16m1_b16(op0, op1, op2) \
__builtin_rvv_vmadc_vv_u16m1_b16((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vmadc_vv_u16m2_b8(op0, op1, op2) \
__builtin_rvv_vmadc_vv_u16m2_b8((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vmadc_vv_u16m4_b4(op0, op1, op2) \
__builtin_rvv_vmadc_vv_u16m4_b4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vmadc_vv_u16m8_b2(op0, op1, op2) \
__builtin_rvv_vmadc_vv_u16m8_b2((vuint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vmadc_vv_u16mf2_b32(op0, op1, op2) \
__builtin_rvv_vmadc_vv_u16mf2_b32((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vmadc_vv_u16mf4_b64(op0, op1, op2) \
__builtin_rvv_vmadc_vv_u16mf4_b64((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vmadc_vv_u32m1_b32(op0, op1, op2) \
__builtin_rvv_vmadc_vv_u32m1_b32((vuint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vmadc_vv_u32m2_b16(op0, op1, op2) \
__builtin_rvv_vmadc_vv_u32m2_b16((vuint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vmadc_vv_u32m4_b8(op0, op1, op2) \
__builtin_rvv_vmadc_vv_u32m4_b8((vuint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vmadc_vv_u32m8_b4(op0, op1, op2) \
__builtin_rvv_vmadc_vv_u32m8_b4((vuint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vmadc_vv_u32mf2_b64(op0, op1, op2) \
__builtin_rvv_vmadc_vv_u32mf2_b64((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vmadc_vv_u64m1_b64(op0, op1, op2) \
__builtin_rvv_vmadc_vv_u64m1_b64((vuint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vmadc_vv_u64m2_b32(op0, op1, op2) \
__builtin_rvv_vmadc_vv_u64m2_b32((vuint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vmadc_vv_u64m4_b16(op0, op1, op2) \
__builtin_rvv_vmadc_vv_u64m4_b16((vuint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vmadc_vv_u64m8_b8(op0, op1, op2) \
__builtin_rvv_vmadc_vv_u64m8_b8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vmadc_vx_u8m1_b8(op0, op1, op2) \
__builtin_rvv_vmadc_vx_u8m1_b8((vuint8m1_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmadc_vx_u8m2_b4(op0, op1, op2) \
__builtin_rvv_vmadc_vx_u8m2_b4((vuint8m2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmadc_vx_u8m4_b2(op0, op1, op2) \
__builtin_rvv_vmadc_vx_u8m4_b2((vuint8m4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmadc_vx_u8m8_b1(op0, op1, op2) \
__builtin_rvv_vmadc_vx_u8m8_b1((vuint8m8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmadc_vx_u8mf2_b16(op0, op1, op2) \
__builtin_rvv_vmadc_vx_u8mf2_b16((vuint8mf2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmadc_vx_u8mf4_b32(op0, op1, op2) \
__builtin_rvv_vmadc_vx_u8mf4_b32((vuint8mf4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmadc_vx_u8mf8_b64(op0, op1, op2) \
__builtin_rvv_vmadc_vx_u8mf8_b64((vuint8mf8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmadc_vx_u16m1_b16(op0, op1, op2) \
__builtin_rvv_vmadc_vx_u16m1_b16((vuint16m1_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmadc_vx_u16m2_b8(op0, op1, op2) \
__builtin_rvv_vmadc_vx_u16m2_b8((vuint16m2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmadc_vx_u16m4_b4(op0, op1, op2) \
__builtin_rvv_vmadc_vx_u16m4_b4((vuint16m4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmadc_vx_u16m8_b2(op0, op1, op2) \
__builtin_rvv_vmadc_vx_u16m8_b2((vuint16m8_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmadc_vx_u16mf2_b32(op0, op1, op2) \
__builtin_rvv_vmadc_vx_u16mf2_b32((vuint16mf2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmadc_vx_u16mf4_b64(op0, op1, op2) \
__builtin_rvv_vmadc_vx_u16mf4_b64((vuint16mf4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmadc_vx_u32m1_b32(op0, op1, op2) \
__builtin_rvv_vmadc_vx_u32m1_b32((vuint32m1_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmadc_vx_u32m2_b16(op0, op1, op2) \
__builtin_rvv_vmadc_vx_u32m2_b16((vuint32m2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmadc_vx_u32m4_b8(op0, op1, op2) \
__builtin_rvv_vmadc_vx_u32m4_b8((vuint32m4_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmadc_vx_u32m8_b4(op0, op1, op2) \
__builtin_rvv_vmadc_vx_u32m8_b4((vuint32m8_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmadc_vx_u32mf2_b64(op0, op1, op2) \
__builtin_rvv_vmadc_vx_u32mf2_b64((vuint32mf2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmadc_vx_u64m1_b64(op0, op1, op2) \
__builtin_rvv_vmadc_vx_u64m1_b64((vuint64m1_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmadc_vx_u64m2_b32(op0, op1, op2) \
__builtin_rvv_vmadc_vx_u64m2_b32((vuint64m2_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmadc_vx_u64m4_b16(op0, op1, op2) \
__builtin_rvv_vmadc_vx_u64m4_b16((vuint64m4_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmadc_vx_u64m8_b8(op0, op1, op2) \
__builtin_rvv_vmadc_vx_u64m8_b8((vuint64m8_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vse8_v_u8m1(op1, op0, op2) \
__builtin_rvv_vse8_v_u8m1((vuint8m1_t)(op0), (uint8_t *)(op1), (size_t)(op2))
#define vse8_v_u8m1_m(op2, op1, op0, op3) \
__builtin_rvv_vse8_v_u8m1_m((vuint8m1_t)(op0), (uint8_t *)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vse8_v_u8m2(op1, op0, op2) \
__builtin_rvv_vse8_v_u8m2((vuint8m2_t)(op0), (uint8_t *)(op1), (size_t)(op2))
#define vse8_v_u8m2_m(op2, op1, op0, op3) \
__builtin_rvv_vse8_v_u8m2_m((vuint8m2_t)(op0), (uint8_t *)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vse8_v_u8m4(op1, op0, op2) \
__builtin_rvv_vse8_v_u8m4((vuint8m4_t)(op0), (uint8_t *)(op1), (size_t)(op2))
#define vse8_v_u8m4_m(op2, op1, op0, op3) \
__builtin_rvv_vse8_v_u8m4_m((vuint8m4_t)(op0), (uint8_t *)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vse8_v_u8m8(op1, op0, op2) \
__builtin_rvv_vse8_v_u8m8((vuint8m8_t)(op0), (uint8_t *)(op1), (size_t)(op2))
#define vse8_v_u8m8_m(op2, op1, op0, op3) \
__builtin_rvv_vse8_v_u8m8_m((vuint8m8_t)(op0), (uint8_t *)(op1), (vbool1_t)(op2), (size_t)(op3))
#define vse8_v_u8mf2(op1, op0, op2) \
__builtin_rvv_vse8_v_u8mf2((vuint8mf2_t)(op0), (uint8_t *)(op1), (size_t)(op2))
#define vse8_v_u8mf2_m(op2, op1, op0, op3) \
__builtin_rvv_vse8_v_u8mf2_m((vuint8mf2_t)(op0), (uint8_t *)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vse8_v_u8mf4(op1, op0, op2) \
__builtin_rvv_vse8_v_u8mf4((vuint8mf4_t)(op0), (uint8_t *)(op1), (size_t)(op2))
#define vse8_v_u8mf4_m(op2, op1, op0, op3) \
__builtin_rvv_vse8_v_u8mf4_m((vuint8mf4_t)(op0), (uint8_t *)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vse8_v_u8mf8(op1, op0, op2) \
__builtin_rvv_vse8_v_u8mf8((vuint8mf8_t)(op0), (uint8_t *)(op1), (size_t)(op2))
#define vse8_v_u8mf8_m(op2, op1, op0, op3) \
__builtin_rvv_vse8_v_u8mf8_m((vuint8mf8_t)(op0), (uint8_t *)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vsbc_vvm_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_i8m1((vint8m1_t)(op0), (vint8m1_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vsbc_vvm_i8m2(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_i8m2((vint8m2_t)(op0), (vint8m2_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vsbc_vvm_i8m4(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_i8m4((vint8m4_t)(op0), (vint8m4_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vsbc_vvm_i8m8(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_i8m8((vint8m8_t)(op0), (vint8m8_t)(op1), (vbool1_t)(op2), (size_t)(op3))
#define vsbc_vvm_i8mf2(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_i8mf2((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vsbc_vvm_i8mf4(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_i8mf4((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vsbc_vvm_i8mf8(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_i8mf8((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vsbc_vvm_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_i16m1((vint16m1_t)(op0), (vint16m1_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vsbc_vvm_i16m2(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_i16m2((vint16m2_t)(op0), (vint16m2_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vsbc_vvm_i16m4(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_i16m4((vint16m4_t)(op0), (vint16m4_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vsbc_vvm_i16m8(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_i16m8((vint16m8_t)(op0), (vint16m8_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vsbc_vvm_i16mf2(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_i16mf2((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vsbc_vvm_i16mf4(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_i16mf4((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vsbc_vvm_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_i32m1((vint32m1_t)(op0), (vint32m1_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vsbc_vvm_i32m2(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_i32m2((vint32m2_t)(op0), (vint32m2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vsbc_vvm_i32m4(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_i32m4((vint32m4_t)(op0), (vint32m4_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vsbc_vvm_i32m8(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_i32m8((vint32m8_t)(op0), (vint32m8_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vsbc_vvm_i32mf2(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_i32mf2((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vsbc_vvm_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_i64m1((vint64m1_t)(op0), (vint64m1_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vsbc_vvm_i64m2(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_i64m2((vint64m2_t)(op0), (vint64m2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vsbc_vvm_i64m4(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_i64m4((vint64m4_t)(op0), (vint64m4_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vsbc_vvm_i64m8(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_i64m8((vint64m8_t)(op0), (vint64m8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vsbc_vxm_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_i8m1((vint8m1_t)(op0), (int8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vsbc_vxm_i8m2(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_i8m2((vint8m2_t)(op0), (int8_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vsbc_vxm_i8m4(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_i8m4((vint8m4_t)(op0), (int8_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vsbc_vxm_i8m8(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_i8m8((vint8m8_t)(op0), (int8_t)(op1), (vbool1_t)(op2), (size_t)(op3))
#define vsbc_vxm_i8mf2(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_i8mf2((vint8mf2_t)(op0), (int8_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vsbc_vxm_i8mf4(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_i8mf4((vint8mf4_t)(op0), (int8_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vsbc_vxm_i8mf8(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_i8mf8((vint8mf8_t)(op0), (int8_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vsbc_vxm_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_i16m1((vint16m1_t)(op0), (int16_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vsbc_vxm_i16m2(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_i16m2((vint16m2_t)(op0), (int16_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vsbc_vxm_i16m4(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_i16m4((vint16m4_t)(op0), (int16_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vsbc_vxm_i16m8(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_i16m8((vint16m8_t)(op0), (int16_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vsbc_vxm_i16mf2(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_i16mf2((vint16mf2_t)(op0), (int16_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vsbc_vxm_i16mf4(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_i16mf4((vint16mf4_t)(op0), (int16_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vsbc_vxm_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_i32m1((vint32m1_t)(op0), (int32_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vsbc_vxm_i32m2(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_i32m2((vint32m2_t)(op0), (int32_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vsbc_vxm_i32m4(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_i32m4((vint32m4_t)(op0), (int32_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vsbc_vxm_i32m8(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_i32m8((vint32m8_t)(op0), (int32_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vsbc_vxm_i32mf2(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_i32mf2((vint32mf2_t)(op0), (int32_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vsbc_vxm_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_i64m1((vint64m1_t)(op0), (int64_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vsbc_vxm_i64m2(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_i64m2((vint64m2_t)(op0), (int64_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vsbc_vxm_i64m4(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_i64m4((vint64m4_t)(op0), (int64_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vsbc_vxm_i64m8(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_i64m8((vint64m8_t)(op0), (int64_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vsbc_vvm_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_u8m1((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vsbc_vvm_u8m2(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_u8m2((vuint8m2_t)(op0), (vuint8m2_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vsbc_vvm_u8m4(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_u8m4((vuint8m4_t)(op0), (vuint8m4_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vsbc_vvm_u8m8(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_u8m8((vuint8m8_t)(op0), (vuint8m8_t)(op1), (vbool1_t)(op2), (size_t)(op3))
#define vsbc_vvm_u8mf2(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_u8mf2((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vsbc_vvm_u8mf4(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_u8mf4((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vsbc_vvm_u8mf8(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_u8mf8((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vsbc_vvm_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_u16m1((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vsbc_vvm_u16m2(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_u16m2((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vsbc_vvm_u16m4(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_u16m4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vsbc_vvm_u16m8(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_u16m8((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vsbc_vvm_u16mf2(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_u16mf2((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vsbc_vvm_u16mf4(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_u16mf4((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vsbc_vvm_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_u32m1((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vsbc_vvm_u32m2(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_u32m2((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vsbc_vvm_u32m4(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_u32m4((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vsbc_vvm_u32m8(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_u32m8((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vsbc_vvm_u32mf2(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_u32mf2((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vsbc_vvm_u64m1(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_u64m1((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vsbc_vvm_u64m2(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_u64m2((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vsbc_vvm_u64m4(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_u64m4((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vsbc_vvm_u64m8(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_u64m8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vsbc_vxm_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_u8m1((vuint8m1_t)(op0), (uint8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vsbc_vxm_u8m2(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_u8m2((vuint8m2_t)(op0), (uint8_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vsbc_vxm_u8m4(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_u8m4((vuint8m4_t)(op0), (uint8_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vsbc_vxm_u8m8(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_u8m8((vuint8m8_t)(op0), (uint8_t)(op1), (vbool1_t)(op2), (size_t)(op3))
#define vsbc_vxm_u8mf2(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_u8mf2((vuint8mf2_t)(op0), (uint8_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vsbc_vxm_u8mf4(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_u8mf4((vuint8mf4_t)(op0), (uint8_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vsbc_vxm_u8mf8(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_u8mf8((vuint8mf8_t)(op0), (uint8_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vsbc_vxm_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_u16m1((vuint16m1_t)(op0), (uint16_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vsbc_vxm_u16m2(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_u16m2((vuint16m2_t)(op0), (uint16_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vsbc_vxm_u16m4(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_u16m4((vuint16m4_t)(op0), (uint16_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vsbc_vxm_u16m8(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_u16m8((vuint16m8_t)(op0), (uint16_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vsbc_vxm_u16mf2(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_u16mf2((vuint16mf2_t)(op0), (uint16_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vsbc_vxm_u16mf4(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_u16mf4((vuint16mf4_t)(op0), (uint16_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vsbc_vxm_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_u32m1((vuint32m1_t)(op0), (uint32_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vsbc_vxm_u32m2(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_u32m2((vuint32m2_t)(op0), (uint32_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vsbc_vxm_u32m4(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_u32m4((vuint32m4_t)(op0), (uint32_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vsbc_vxm_u32m8(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_u32m8((vuint32m8_t)(op0), (uint32_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vsbc_vxm_u32mf2(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_u32mf2((vuint32mf2_t)(op0), (uint32_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vsbc_vxm_u64m1(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_u64m1((vuint64m1_t)(op0), (uint64_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vsbc_vxm_u64m2(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_u64m2((vuint64m2_t)(op0), (uint64_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vsbc_vxm_u64m4(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_u64m4((vuint64m4_t)(op0), (uint64_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vsbc_vxm_u64m8(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_u64m8((vuint64m8_t)(op0), (uint64_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmsbc_vvm_i8m1_b8(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_i8m1_b8((vint8m1_t)(op0), (vint8m1_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmsbc_vvm_i8m2_b4(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_i8m2_b4((vint8m2_t)(op0), (vint8m2_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vmsbc_vvm_i8m4_b2(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_i8m4_b2((vint8m4_t)(op0), (vint8m4_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vmsbc_vvm_i8m8_b1(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_i8m8_b1((vint8m8_t)(op0), (vint8m8_t)(op1), (vbool1_t)(op2), (size_t)(op3))
#define vmsbc_vvm_i8mf2_b16(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_i8mf2_b16((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmsbc_vvm_i8mf4_b32(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_i8mf4_b32((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmsbc_vvm_i8mf8_b64(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_i8mf8_b64((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmsbc_vvm_i16m1_b16(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_i16m1_b16((vint16m1_t)(op0), (vint16m1_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmsbc_vvm_i16m2_b8(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_i16m2_b8((vint16m2_t)(op0), (vint16m2_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmsbc_vvm_i16m4_b4(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_i16m4_b4((vint16m4_t)(op0), (vint16m4_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vmsbc_vvm_i16m8_b2(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_i16m8_b2((vint16m8_t)(op0), (vint16m8_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vmsbc_vvm_i16mf2_b32(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_i16mf2_b32((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmsbc_vvm_i16mf4_b64(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_i16mf4_b64((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmsbc_vvm_i32m1_b32(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_i32m1_b32((vint32m1_t)(op0), (vint32m1_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmsbc_vvm_i32m2_b16(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_i32m2_b16((vint32m2_t)(op0), (vint32m2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmsbc_vvm_i32m4_b8(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_i32m4_b8((vint32m4_t)(op0), (vint32m4_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmsbc_vvm_i32m8_b4(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_i32m8_b4((vint32m8_t)(op0), (vint32m8_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vmsbc_vvm_i32mf2_b64(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_i32mf2_b64((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmsbc_vvm_i64m1_b64(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_i64m1_b64((vint64m1_t)(op0), (vint64m1_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmsbc_vvm_i64m2_b32(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_i64m2_b32((vint64m2_t)(op0), (vint64m2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmsbc_vvm_i64m4_b16(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_i64m4_b16((vint64m4_t)(op0), (vint64m4_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmsbc_vvm_i64m8_b8(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_i64m8_b8((vint64m8_t)(op0), (vint64m8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmsbc_vxm_i8m1_b8(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_i8m1_b8((vint8m1_t)(op0), (int8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmsbc_vxm_i8m2_b4(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_i8m2_b4((vint8m2_t)(op0), (int8_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vmsbc_vxm_i8m4_b2(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_i8m4_b2((vint8m4_t)(op0), (int8_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vmsbc_vxm_i8m8_b1(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_i8m8_b1((vint8m8_t)(op0), (int8_t)(op1), (vbool1_t)(op2), (size_t)(op3))
#define vmsbc_vxm_i8mf2_b16(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_i8mf2_b16((vint8mf2_t)(op0), (int8_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmsbc_vxm_i8mf4_b32(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_i8mf4_b32((vint8mf4_t)(op0), (int8_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmsbc_vxm_i8mf8_b64(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_i8mf8_b64((vint8mf8_t)(op0), (int8_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmsbc_vxm_i16m1_b16(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_i16m1_b16((vint16m1_t)(op0), (int16_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmsbc_vxm_i16m2_b8(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_i16m2_b8((vint16m2_t)(op0), (int16_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmsbc_vxm_i16m4_b4(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_i16m4_b4((vint16m4_t)(op0), (int16_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vmsbc_vxm_i16m8_b2(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_i16m8_b2((vint16m8_t)(op0), (int16_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vmsbc_vxm_i16mf2_b32(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_i16mf2_b32((vint16mf2_t)(op0), (int16_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmsbc_vxm_i16mf4_b64(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_i16mf4_b64((vint16mf4_t)(op0), (int16_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmsbc_vxm_i32m1_b32(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_i32m1_b32((vint32m1_t)(op0), (int32_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmsbc_vxm_i32m2_b16(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_i32m2_b16((vint32m2_t)(op0), (int32_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmsbc_vxm_i32m4_b8(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_i32m4_b8((vint32m4_t)(op0), (int32_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmsbc_vxm_i32m8_b4(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_i32m8_b4((vint32m8_t)(op0), (int32_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vmsbc_vxm_i32mf2_b64(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_i32mf2_b64((vint32mf2_t)(op0), (int32_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmsbc_vxm_i64m1_b64(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_i64m1_b64((vint64m1_t)(op0), (int64_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmsbc_vxm_i64m2_b32(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_i64m2_b32((vint64m2_t)(op0), (int64_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmsbc_vxm_i64m4_b16(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_i64m4_b16((vint64m4_t)(op0), (int64_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmsbc_vxm_i64m8_b8(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_i64m8_b8((vint64m8_t)(op0), (int64_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmsbc_vvm_u8m1_b8(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_u8m1_b8((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmsbc_vvm_u8m2_b4(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_u8m2_b4((vuint8m2_t)(op0), (vuint8m2_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vmsbc_vvm_u8m4_b2(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_u8m4_b2((vuint8m4_t)(op0), (vuint8m4_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vmsbc_vvm_u8m8_b1(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_u8m8_b1((vuint8m8_t)(op0), (vuint8m8_t)(op1), (vbool1_t)(op2), (size_t)(op3))
#define vmsbc_vvm_u8mf2_b16(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_u8mf2_b16((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmsbc_vvm_u8mf4_b32(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_u8mf4_b32((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmsbc_vvm_u8mf8_b64(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_u8mf8_b64((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmsbc_vvm_u16m1_b16(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_u16m1_b16((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmsbc_vvm_u16m2_b8(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_u16m2_b8((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmsbc_vvm_u16m4_b4(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_u16m4_b4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vmsbc_vvm_u16m8_b2(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_u16m8_b2((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vmsbc_vvm_u16mf2_b32(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_u16mf2_b32((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmsbc_vvm_u16mf4_b64(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_u16mf4_b64((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmsbc_vvm_u32m1_b32(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_u32m1_b32((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmsbc_vvm_u32m2_b16(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_u32m2_b16((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmsbc_vvm_u32m4_b8(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_u32m4_b8((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmsbc_vvm_u32m8_b4(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_u32m8_b4((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vmsbc_vvm_u32mf2_b64(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_u32mf2_b64((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmsbc_vvm_u64m1_b64(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_u64m1_b64((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmsbc_vvm_u64m2_b32(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_u64m2_b32((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmsbc_vvm_u64m4_b16(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_u64m4_b16((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmsbc_vvm_u64m8_b8(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_u64m8_b8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmsbc_vxm_u8m1_b8(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_u8m1_b8((vuint8m1_t)(op0), (uint8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmsbc_vxm_u8m2_b4(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_u8m2_b4((vuint8m2_t)(op0), (uint8_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vmsbc_vxm_u8m4_b2(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_u8m4_b2((vuint8m4_t)(op0), (uint8_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vmsbc_vxm_u8m8_b1(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_u8m8_b1((vuint8m8_t)(op0), (uint8_t)(op1), (vbool1_t)(op2), (size_t)(op3))
#define vmsbc_vxm_u8mf2_b16(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_u8mf2_b16((vuint8mf2_t)(op0), (uint8_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmsbc_vxm_u8mf4_b32(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_u8mf4_b32((vuint8mf4_t)(op0), (uint8_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmsbc_vxm_u8mf8_b64(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_u8mf8_b64((vuint8mf8_t)(op0), (uint8_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmsbc_vxm_u16m1_b16(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_u16m1_b16((vuint16m1_t)(op0), (uint16_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmsbc_vxm_u16m2_b8(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_u16m2_b8((vuint16m2_t)(op0), (uint16_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmsbc_vxm_u16m4_b4(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_u16m4_b4((vuint16m4_t)(op0), (uint16_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vmsbc_vxm_u16m8_b2(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_u16m8_b2((vuint16m8_t)(op0), (uint16_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vmsbc_vxm_u16mf2_b32(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_u16mf2_b32((vuint16mf2_t)(op0), (uint16_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmsbc_vxm_u16mf4_b64(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_u16mf4_b64((vuint16mf4_t)(op0), (uint16_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmsbc_vxm_u32m1_b32(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_u32m1_b32((vuint32m1_t)(op0), (uint32_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmsbc_vxm_u32m2_b16(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_u32m2_b16((vuint32m2_t)(op0), (uint32_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmsbc_vxm_u32m4_b8(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_u32m4_b8((vuint32m4_t)(op0), (uint32_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmsbc_vxm_u32m8_b4(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_u32m8_b4((vuint32m8_t)(op0), (uint32_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vmsbc_vxm_u32mf2_b64(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_u32mf2_b64((vuint32mf2_t)(op0), (uint32_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmsbc_vxm_u64m1_b64(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_u64m1_b64((vuint64m1_t)(op0), (uint64_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmsbc_vxm_u64m2_b32(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_u64m2_b32((vuint64m2_t)(op0), (uint64_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmsbc_vxm_u64m4_b16(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_u64m4_b16((vuint64m4_t)(op0), (uint64_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmsbc_vxm_u64m8_b8(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_u64m8_b8((vuint64m8_t)(op0), (uint64_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmsbc_vv_i8m1_b8(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_i8m1_b8((vint8m1_t)(op0), (vint8m1_t)(op1), (size_t)(op2))
#define vmsbc_vv_i8m2_b4(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_i8m2_b4((vint8m2_t)(op0), (vint8m2_t)(op1), (size_t)(op2))
#define vmsbc_vv_i8m4_b2(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_i8m4_b2((vint8m4_t)(op0), (vint8m4_t)(op1), (size_t)(op2))
#define vmsbc_vv_i8m8_b1(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_i8m8_b1((vint8m8_t)(op0), (vint8m8_t)(op1), (size_t)(op2))
#define vmsbc_vv_i8mf2_b16(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_i8mf2_b16((vint8mf2_t)(op0), (vint8mf2_t)(op1), (size_t)(op2))
#define vmsbc_vv_i8mf4_b32(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_i8mf4_b32((vint8mf4_t)(op0), (vint8mf4_t)(op1), (size_t)(op2))
#define vmsbc_vv_i8mf8_b64(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_i8mf8_b64((vint8mf8_t)(op0), (vint8mf8_t)(op1), (size_t)(op2))
#define vmsbc_vv_i16m1_b16(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_i16m1_b16((vint16m1_t)(op0), (vint16m1_t)(op1), (size_t)(op2))
#define vmsbc_vv_i16m2_b8(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_i16m2_b8((vint16m2_t)(op0), (vint16m2_t)(op1), (size_t)(op2))
#define vmsbc_vv_i16m4_b4(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_i16m4_b4((vint16m4_t)(op0), (vint16m4_t)(op1), (size_t)(op2))
#define vmsbc_vv_i16m8_b2(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_i16m8_b2((vint16m8_t)(op0), (vint16m8_t)(op1), (size_t)(op2))
#define vmsbc_vv_i16mf2_b32(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_i16mf2_b32((vint16mf2_t)(op0), (vint16mf2_t)(op1), (size_t)(op2))
#define vmsbc_vv_i16mf4_b64(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_i16mf4_b64((vint16mf4_t)(op0), (vint16mf4_t)(op1), (size_t)(op2))
#define vmsbc_vv_i32m1_b32(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_i32m1_b32((vint32m1_t)(op0), (vint32m1_t)(op1), (size_t)(op2))
#define vmsbc_vv_i32m2_b16(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_i32m2_b16((vint32m2_t)(op0), (vint32m2_t)(op1), (size_t)(op2))
#define vmsbc_vv_i32m4_b8(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_i32m4_b8((vint32m4_t)(op0), (vint32m4_t)(op1), (size_t)(op2))
#define vmsbc_vv_i32m8_b4(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_i32m8_b4((vint32m8_t)(op0), (vint32m8_t)(op1), (size_t)(op2))
#define vmsbc_vv_i32mf2_b64(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_i32mf2_b64((vint32mf2_t)(op0), (vint32mf2_t)(op1), (size_t)(op2))
#define vmsbc_vv_i64m1_b64(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_i64m1_b64((vint64m1_t)(op0), (vint64m1_t)(op1), (size_t)(op2))
#define vmsbc_vv_i64m2_b32(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_i64m2_b32((vint64m2_t)(op0), (vint64m2_t)(op1), (size_t)(op2))
#define vmsbc_vv_i64m4_b16(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_i64m4_b16((vint64m4_t)(op0), (vint64m4_t)(op1), (size_t)(op2))
#define vmsbc_vv_i64m8_b8(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_i64m8_b8((vint64m8_t)(op0), (vint64m8_t)(op1), (size_t)(op2))
#define vmsbc_vx_i8m1_b8(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_i8m1_b8((vint8m1_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmsbc_vx_i8m2_b4(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_i8m2_b4((vint8m2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmsbc_vx_i8m4_b2(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_i8m4_b2((vint8m4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmsbc_vx_i8m8_b1(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_i8m8_b1((vint8m8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmsbc_vx_i8mf2_b16(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_i8mf2_b16((vint8mf2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmsbc_vx_i8mf4_b32(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_i8mf4_b32((vint8mf4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmsbc_vx_i8mf8_b64(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_i8mf8_b64((vint8mf8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmsbc_vx_i16m1_b16(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_i16m1_b16((vint16m1_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmsbc_vx_i16m2_b8(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_i16m2_b8((vint16m2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmsbc_vx_i16m4_b4(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_i16m4_b4((vint16m4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmsbc_vx_i16m8_b2(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_i16m8_b2((vint16m8_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmsbc_vx_i16mf2_b32(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_i16mf2_b32((vint16mf2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmsbc_vx_i16mf4_b64(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_i16mf4_b64((vint16mf4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmsbc_vx_i32m1_b32(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_i32m1_b32((vint32m1_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmsbc_vx_i32m2_b16(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_i32m2_b16((vint32m2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmsbc_vx_i32m4_b8(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_i32m4_b8((vint32m4_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmsbc_vx_i32m8_b4(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_i32m8_b4((vint32m8_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmsbc_vx_i32mf2_b64(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_i32mf2_b64((vint32mf2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmsbc_vx_i64m1_b64(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_i64m1_b64((vint64m1_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmsbc_vx_i64m2_b32(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_i64m2_b32((vint64m2_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmsbc_vx_i64m4_b16(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_i64m4_b16((vint64m4_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmsbc_vx_i64m8_b8(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_i64m8_b8((vint64m8_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vle16_v_i16m1(op0, op1) \
__builtin_rvv_vle16_v_i16m1((const int16_t *)(op0), (size_t)(op1))
#define vle16_v_i16m1_m(op2, op0, op1, op3) \
__builtin_rvv_vle16_v_i16m1_m((vint16m1_t)(op0), (const int16_t *)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vle16_v_i16m2(op0, op1) \
__builtin_rvv_vle16_v_i16m2((const int16_t *)(op0), (size_t)(op1))
#define vle16_v_i16m2_m(op2, op0, op1, op3) \
__builtin_rvv_vle16_v_i16m2_m((vint16m2_t)(op0), (const int16_t *)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vle16_v_i16m4(op0, op1) \
__builtin_rvv_vle16_v_i16m4((const int16_t *)(op0), (size_t)(op1))
#define vle16_v_i16m4_m(op2, op0, op1, op3) \
__builtin_rvv_vle16_v_i16m4_m((vint16m4_t)(op0), (const int16_t *)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vle16_v_i16m8(op0, op1) \
__builtin_rvv_vle16_v_i16m8((const int16_t *)(op0), (size_t)(op1))
#define vle16_v_i16m8_m(op2, op0, op1, op3) \
__builtin_rvv_vle16_v_i16m8_m((vint16m8_t)(op0), (const int16_t *)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vle16_v_i16mf2(op0, op1) \
__builtin_rvv_vle16_v_i16mf2((const int16_t *)(op0), (size_t)(op1))
#define vle16_v_i16mf2_m(op2, op0, op1, op3) \
__builtin_rvv_vle16_v_i16mf2_m((vint16mf2_t)(op0), (const int16_t *)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vle16_v_i16mf4(op0, op1) \
__builtin_rvv_vle16_v_i16mf4((const int16_t *)(op0), (size_t)(op1))
#define vle16_v_i16mf4_m(op2, op0, op1, op3) \
__builtin_rvv_vle16_v_i16mf4_m((vint16mf4_t)(op0), (const int16_t *)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmsbc_vv_u8m1_b8(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_u8m1_b8((vuint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vmsbc_vv_u8m2_b4(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_u8m2_b4((vuint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vmsbc_vv_u8m4_b2(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_u8m4_b2((vuint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vmsbc_vv_u8m8_b1(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_u8m8_b1((vuint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vmsbc_vv_u8mf2_b16(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_u8mf2_b16((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vmsbc_vv_u8mf4_b32(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_u8mf4_b32((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vmsbc_vv_u8mf8_b64(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_u8mf8_b64((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vmsbc_vv_u16m1_b16(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_u16m1_b16((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vmsbc_vv_u16m2_b8(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_u16m2_b8((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vmsbc_vv_u16m4_b4(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_u16m4_b4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vmsbc_vv_u16m8_b2(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_u16m8_b2((vuint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vmsbc_vv_u16mf2_b32(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_u16mf2_b32((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vmsbc_vv_u16mf4_b64(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_u16mf4_b64((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vmsbc_vv_u32m1_b32(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_u32m1_b32((vuint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vmsbc_vv_u32m2_b16(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_u32m2_b16((vuint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vmsbc_vv_u32m4_b8(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_u32m4_b8((vuint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vmsbc_vv_u32m8_b4(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_u32m8_b4((vuint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vmsbc_vv_u32mf2_b64(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_u32mf2_b64((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vmsbc_vv_u64m1_b64(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_u64m1_b64((vuint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vmsbc_vv_u64m2_b32(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_u64m2_b32((vuint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vmsbc_vv_u64m4_b16(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_u64m4_b16((vuint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vmsbc_vv_u64m8_b8(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_u64m8_b8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vmsbc_vx_u8m1_b8(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_u8m1_b8((vuint8m1_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsbc_vx_u8m2_b4(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_u8m2_b4((vuint8m2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsbc_vx_u8m4_b2(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_u8m4_b2((vuint8m4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsbc_vx_u8m8_b1(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_u8m8_b1((vuint8m8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsbc_vx_u8mf2_b16(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_u8mf2_b16((vuint8mf2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsbc_vx_u8mf4_b32(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_u8mf4_b32((vuint8mf4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsbc_vx_u8mf8_b64(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_u8mf8_b64((vuint8mf8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsbc_vx_u16m1_b16(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_u16m1_b16((vuint16m1_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmsbc_vx_u16m2_b8(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_u16m2_b8((vuint16m2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmsbc_vx_u16m4_b4(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_u16m4_b4((vuint16m4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmsbc_vx_u16m8_b2(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_u16m8_b2((vuint16m8_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmsbc_vx_u16mf2_b32(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_u16mf2_b32((vuint16mf2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmsbc_vx_u16mf4_b64(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_u16mf4_b64((vuint16mf4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmsbc_vx_u32m1_b32(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_u32m1_b32((vuint32m1_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmsbc_vx_u32m2_b16(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_u32m2_b16((vuint32m2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmsbc_vx_u32m4_b8(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_u32m4_b8((vuint32m4_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmsbc_vx_u32m8_b4(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_u32m8_b4((vuint32m8_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmsbc_vx_u32mf2_b64(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_u32mf2_b64((vuint32mf2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmsbc_vx_u64m1_b64(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_u64m1_b64((vuint64m1_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmsbc_vx_u64m2_b32(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_u64m2_b32((vuint64m2_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmsbc_vx_u64m4_b16(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_u64m4_b16((vuint64m4_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmsbc_vx_u64m8_b8(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_u64m8_b8((vuint64m8_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vand_vv_i8m1(op0, op1, op2) \
__builtin_rvv_vand_vv_i8m1((vint8m1_t)(op0), (vint8m1_t)(op1), (size_t)(op2))
#define vand_vv_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vand_vv_i8m2(op0, op1, op2) \
__builtin_rvv_vand_vv_i8m2((vint8m2_t)(op0), (vint8m2_t)(op1), (size_t)(op2))
#define vand_vv_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vand_vv_i8m4(op0, op1, op2) \
__builtin_rvv_vand_vv_i8m4((vint8m4_t)(op0), (vint8m4_t)(op1), (size_t)(op2))
#define vand_vv_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vand_vv_i8m8(op0, op1, op2) \
__builtin_rvv_vand_vv_i8m8((vint8m8_t)(op0), (vint8m8_t)(op1), (size_t)(op2))
#define vand_vv_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (vint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vand_vv_i8mf2(op0, op1, op2) \
__builtin_rvv_vand_vv_i8mf2((vint8mf2_t)(op0), (vint8mf2_t)(op1), (size_t)(op2))
#define vand_vv_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vand_vv_i8mf4(op0, op1, op2) \
__builtin_rvv_vand_vv_i8mf4((vint8mf4_t)(op0), (vint8mf4_t)(op1), (size_t)(op2))
#define vand_vv_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vand_vv_i8mf8(op0, op1, op2) \
__builtin_rvv_vand_vv_i8mf8((vint8mf8_t)(op0), (vint8mf8_t)(op1), (size_t)(op2))
#define vand_vv_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vand_vv_i16m1(op0, op1, op2) \
__builtin_rvv_vand_vv_i16m1((vint16m1_t)(op0), (vint16m1_t)(op1), (size_t)(op2))
#define vand_vv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vand_vv_i16m2(op0, op1, op2) \
__builtin_rvv_vand_vv_i16m2((vint16m2_t)(op0), (vint16m2_t)(op1), (size_t)(op2))
#define vand_vv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vand_vv_i16m4(op0, op1, op2) \
__builtin_rvv_vand_vv_i16m4((vint16m4_t)(op0), (vint16m4_t)(op1), (size_t)(op2))
#define vand_vv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vand_vv_i16m8(op0, op1, op2) \
__builtin_rvv_vand_vv_i16m8((vint16m8_t)(op0), (vint16m8_t)(op1), (size_t)(op2))
#define vand_vv_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (vint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vand_vv_i16mf2(op0, op1, op2) \
__builtin_rvv_vand_vv_i16mf2((vint16mf2_t)(op0), (vint16mf2_t)(op1), (size_t)(op2))
#define vand_vv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vand_vv_i16mf4(op0, op1, op2) \
__builtin_rvv_vand_vv_i16mf4((vint16mf4_t)(op0), (vint16mf4_t)(op1), (size_t)(op2))
#define vand_vv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vand_vv_i32m1(op0, op1, op2) \
__builtin_rvv_vand_vv_i32m1((vint32m1_t)(op0), (vint32m1_t)(op1), (size_t)(op2))
#define vand_vv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vand_vv_i32m2(op0, op1, op2) \
__builtin_rvv_vand_vv_i32m2((vint32m2_t)(op0), (vint32m2_t)(op1), (size_t)(op2))
#define vand_vv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vand_vv_i32m4(op0, op1, op2) \
__builtin_rvv_vand_vv_i32m4((vint32m4_t)(op0), (vint32m4_t)(op1), (size_t)(op2))
#define vand_vv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vand_vv_i32m8(op0, op1, op2) \
__builtin_rvv_vand_vv_i32m8((vint32m8_t)(op0), (vint32m8_t)(op1), (size_t)(op2))
#define vand_vv_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (vint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vand_vv_i32mf2(op0, op1, op2) \
__builtin_rvv_vand_vv_i32mf2((vint32mf2_t)(op0), (vint32mf2_t)(op1), (size_t)(op2))
#define vand_vv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vand_vv_i64m1(op0, op1, op2) \
__builtin_rvv_vand_vv_i64m1((vint64m1_t)(op0), (vint64m1_t)(op1), (size_t)(op2))
#define vand_vv_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vand_vv_i64m2(op0, op1, op2) \
__builtin_rvv_vand_vv_i64m2((vint64m2_t)(op0), (vint64m2_t)(op1), (size_t)(op2))
#define vand_vv_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (vint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vand_vv_i64m4(op0, op1, op2) \
__builtin_rvv_vand_vv_i64m4((vint64m4_t)(op0), (vint64m4_t)(op1), (size_t)(op2))
#define vand_vv_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (vint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vand_vv_i64m8(op0, op1, op2) \
__builtin_rvv_vand_vv_i64m8((vint64m8_t)(op0), (vint64m8_t)(op1), (size_t)(op2))
#define vand_vv_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (vint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vand_vx_i8m1(op0, op1, op2) \
__builtin_rvv_vand_vx_i8m1((vint8m1_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vand_vx_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (int8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vand_vx_i8m2(op0, op1, op2) \
__builtin_rvv_vand_vx_i8m2((vint8m2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vand_vx_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (int8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vand_vx_i8m4(op0, op1, op2) \
__builtin_rvv_vand_vx_i8m4((vint8m4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vand_vx_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (int8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vand_vx_i8m8(op0, op1, op2) \
__builtin_rvv_vand_vx_i8m8((vint8m8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vand_vx_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (int8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vand_vx_i8mf2(op0, op1, op2) \
__builtin_rvv_vand_vx_i8mf2((vint8mf2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vand_vx_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (int8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vand_vx_i8mf4(op0, op1, op2) \
__builtin_rvv_vand_vx_i8mf4((vint8mf4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vand_vx_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (int8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vand_vx_i8mf8(op0, op1, op2) \
__builtin_rvv_vand_vx_i8mf8((vint8mf8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vand_vx_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (int8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vand_vx_i16m1(op0, op1, op2) \
__builtin_rvv_vand_vx_i16m1((vint16m1_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vand_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (int16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vand_vx_i16m2(op0, op1, op2) \
__builtin_rvv_vand_vx_i16m2((vint16m2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vand_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (int16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vand_vx_i16m4(op0, op1, op2) \
__builtin_rvv_vand_vx_i16m4((vint16m4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vand_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (int16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vand_vx_i16m8(op0, op1, op2) \
__builtin_rvv_vand_vx_i16m8((vint16m8_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vand_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (int16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vand_vx_i16mf2(op0, op1, op2) \
__builtin_rvv_vand_vx_i16mf2((vint16mf2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vand_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (int16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vand_vx_i16mf4(op0, op1, op2) \
__builtin_rvv_vand_vx_i16mf4((vint16mf4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vand_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (int16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vand_vx_i32m1(op0, op1, op2) \
__builtin_rvv_vand_vx_i32m1((vint32m1_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vand_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (int32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vand_vx_i32m2(op0, op1, op2) \
__builtin_rvv_vand_vx_i32m2((vint32m2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vand_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (int32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vand_vx_i32m4(op0, op1, op2) \
__builtin_rvv_vand_vx_i32m4((vint32m4_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vand_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (int32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vand_vx_i32m8(op0, op1, op2) \
__builtin_rvv_vand_vx_i32m8((vint32m8_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vand_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (int32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vand_vx_i32mf2(op0, op1, op2) \
__builtin_rvv_vand_vx_i32mf2((vint32mf2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vand_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (int32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vand_vx_i64m1(op0, op1, op2) \
__builtin_rvv_vand_vx_i64m1((vint64m1_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vand_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (int64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vand_vx_i64m2(op0, op1, op2) \
__builtin_rvv_vand_vx_i64m2((vint64m2_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vand_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (int64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vand_vx_i64m4(op0, op1, op2) \
__builtin_rvv_vand_vx_i64m4((vint64m4_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vand_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (int64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vand_vx_i64m8(op0, op1, op2) \
__builtin_rvv_vand_vx_i64m8((vint64m8_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vand_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (int64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vand_vv_u8m1(op0, op1, op2) \
__builtin_rvv_vand_vv_u8m1((vuint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vand_vv_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vand_vv_u8m2(op0, op1, op2) \
__builtin_rvv_vand_vv_u8m2((vuint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vand_vv_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vand_vv_u8m4(op0, op1, op2) \
__builtin_rvv_vand_vv_u8m4((vuint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vand_vv_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vand_vv_u8m8(op0, op1, op2) \
__builtin_rvv_vand_vv_u8m8((vuint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vand_vv_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vand_vv_u8mf2(op0, op1, op2) \
__builtin_rvv_vand_vv_u8mf2((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vand_vv_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vand_vv_u8mf4(op0, op1, op2) \
__builtin_rvv_vand_vv_u8mf4((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vand_vv_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vand_vv_u8mf8(op0, op1, op2) \
__builtin_rvv_vand_vv_u8mf8((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vand_vv_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vand_vv_u16m1(op0, op1, op2) \
__builtin_rvv_vand_vv_u16m1((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vand_vv_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vand_vv_u16m2(op0, op1, op2) \
__builtin_rvv_vand_vv_u16m2((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vand_vv_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vand_vv_u16m4(op0, op1, op2) \
__builtin_rvv_vand_vv_u16m4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vand_vv_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vand_vv_u16m8(op0, op1, op2) \
__builtin_rvv_vand_vv_u16m8((vuint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vand_vv_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vand_vv_u16mf2(op0, op1, op2) \
__builtin_rvv_vand_vv_u16mf2((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vand_vv_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vand_vv_u16mf4(op0, op1, op2) \
__builtin_rvv_vand_vv_u16mf4((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vand_vv_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vand_vv_u32m1(op0, op1, op2) \
__builtin_rvv_vand_vv_u32m1((vuint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vand_vv_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vand_vv_u32m2(op0, op1, op2) \
__builtin_rvv_vand_vv_u32m2((vuint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vand_vv_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vand_vv_u32m4(op0, op1, op2) \
__builtin_rvv_vand_vv_u32m4((vuint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vand_vv_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vand_vv_u32m8(op0, op1, op2) \
__builtin_rvv_vand_vv_u32m8((vuint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vand_vv_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vand_vv_u32mf2(op0, op1, op2) \
__builtin_rvv_vand_vv_u32mf2((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vand_vv_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vand_vv_u64m1(op0, op1, op2) \
__builtin_rvv_vand_vv_u64m1((vuint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vand_vv_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vand_vv_u64m2(op0, op1, op2) \
__builtin_rvv_vand_vv_u64m2((vuint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vand_vv_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vand_vv_u64m4(op0, op1, op2) \
__builtin_rvv_vand_vv_u64m4((vuint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vand_vv_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vand_vv_u64m8(op0, op1, op2) \
__builtin_rvv_vand_vv_u64m8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vand_vv_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vand_vx_u8m1(op0, op1, op2) \
__builtin_rvv_vand_vx_u8m1((vuint8m1_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vand_vx_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (uint8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vand_vx_u8m2(op0, op1, op2) \
__builtin_rvv_vand_vx_u8m2((vuint8m2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vand_vx_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (uint8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vand_vx_u8m4(op0, op1, op2) \
__builtin_rvv_vand_vx_u8m4((vuint8m4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vand_vx_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (uint8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vand_vx_u8m8(op0, op1, op2) \
__builtin_rvv_vand_vx_u8m8((vuint8m8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vand_vx_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (uint8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vand_vx_u8mf2(op0, op1, op2) \
__builtin_rvv_vand_vx_u8mf2((vuint8mf2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vand_vx_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (uint8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vand_vx_u8mf4(op0, op1, op2) \
__builtin_rvv_vand_vx_u8mf4((vuint8mf4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vand_vx_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (uint8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vand_vx_u8mf8(op0, op1, op2) \
__builtin_rvv_vand_vx_u8mf8((vuint8mf8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vand_vx_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (uint8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vand_vx_u16m1(op0, op1, op2) \
__builtin_rvv_vand_vx_u16m1((vuint16m1_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vand_vx_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (uint16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vand_vx_u16m2(op0, op1, op2) \
__builtin_rvv_vand_vx_u16m2((vuint16m2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vand_vx_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (uint16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vand_vx_u16m4(op0, op1, op2) \
__builtin_rvv_vand_vx_u16m4((vuint16m4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vand_vx_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (uint16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vand_vx_u16m8(op0, op1, op2) \
__builtin_rvv_vand_vx_u16m8((vuint16m8_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vand_vx_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (uint16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vand_vx_u16mf2(op0, op1, op2) \
__builtin_rvv_vand_vx_u16mf2((vuint16mf2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vand_vx_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (uint16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vand_vx_u16mf4(op0, op1, op2) \
__builtin_rvv_vand_vx_u16mf4((vuint16mf4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vand_vx_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (uint16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vand_vx_u32m1(op0, op1, op2) \
__builtin_rvv_vand_vx_u32m1((vuint32m1_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vand_vx_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (uint32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vand_vx_u32m2(op0, op1, op2) \
__builtin_rvv_vand_vx_u32m2((vuint32m2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vand_vx_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (uint32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vand_vx_u32m4(op0, op1, op2) \
__builtin_rvv_vand_vx_u32m4((vuint32m4_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vand_vx_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (uint32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vand_vx_u32m8(op0, op1, op2) \
__builtin_rvv_vand_vx_u32m8((vuint32m8_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vand_vx_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (uint32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vand_vx_u32mf2(op0, op1, op2) \
__builtin_rvv_vand_vx_u32mf2((vuint32mf2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vand_vx_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (uint32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vand_vx_u64m1(op0, op1, op2) \
__builtin_rvv_vand_vx_u64m1((vuint64m1_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vand_vx_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (uint64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vand_vx_u64m2(op0, op1, op2) \
__builtin_rvv_vand_vx_u64m2((vuint64m2_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vand_vx_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (uint64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vand_vx_u64m4(op0, op1, op2) \
__builtin_rvv_vand_vx_u64m4((vuint64m4_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vand_vx_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (uint64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vand_vx_u64m8(op0, op1, op2) \
__builtin_rvv_vand_vx_u64m8((vuint64m8_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vand_vx_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (uint64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vxor_vv_i8m1(op0, op1, op2) \
__builtin_rvv_vxor_vv_i8m1((vint8m1_t)(op0), (vint8m1_t)(op1), (size_t)(op2))
#define vxor_vv_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vxor_vv_i8m2(op0, op1, op2) \
__builtin_rvv_vxor_vv_i8m2((vint8m2_t)(op0), (vint8m2_t)(op1), (size_t)(op2))
#define vxor_vv_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vxor_vv_i8m4(op0, op1, op2) \
__builtin_rvv_vxor_vv_i8m4((vint8m4_t)(op0), (vint8m4_t)(op1), (size_t)(op2))
#define vxor_vv_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vxor_vv_i8m8(op0, op1, op2) \
__builtin_rvv_vxor_vv_i8m8((vint8m8_t)(op0), (vint8m8_t)(op1), (size_t)(op2))
#define vxor_vv_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (vint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vxor_vv_i8mf2(op0, op1, op2) \
__builtin_rvv_vxor_vv_i8mf2((vint8mf2_t)(op0), (vint8mf2_t)(op1), (size_t)(op2))
#define vxor_vv_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vxor_vv_i8mf4(op0, op1, op2) \
__builtin_rvv_vxor_vv_i8mf4((vint8mf4_t)(op0), (vint8mf4_t)(op1), (size_t)(op2))
#define vxor_vv_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vxor_vv_i8mf8(op0, op1, op2) \
__builtin_rvv_vxor_vv_i8mf8((vint8mf8_t)(op0), (vint8mf8_t)(op1), (size_t)(op2))
#define vxor_vv_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vxor_vv_i16m1(op0, op1, op2) \
__builtin_rvv_vxor_vv_i16m1((vint16m1_t)(op0), (vint16m1_t)(op1), (size_t)(op2))
#define vxor_vv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vxor_vv_i16m2(op0, op1, op2) \
__builtin_rvv_vxor_vv_i16m2((vint16m2_t)(op0), (vint16m2_t)(op1), (size_t)(op2))
#define vxor_vv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vxor_vv_i16m4(op0, op1, op2) \
__builtin_rvv_vxor_vv_i16m4((vint16m4_t)(op0), (vint16m4_t)(op1), (size_t)(op2))
#define vxor_vv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vxor_vv_i16m8(op0, op1, op2) \
__builtin_rvv_vxor_vv_i16m8((vint16m8_t)(op0), (vint16m8_t)(op1), (size_t)(op2))
#define vxor_vv_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (vint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vxor_vv_i16mf2(op0, op1, op2) \
__builtin_rvv_vxor_vv_i16mf2((vint16mf2_t)(op0), (vint16mf2_t)(op1), (size_t)(op2))
#define vxor_vv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vxor_vv_i16mf4(op0, op1, op2) \
__builtin_rvv_vxor_vv_i16mf4((vint16mf4_t)(op0), (vint16mf4_t)(op1), (size_t)(op2))
#define vxor_vv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vxor_vv_i32m1(op0, op1, op2) \
__builtin_rvv_vxor_vv_i32m1((vint32m1_t)(op0), (vint32m1_t)(op1), (size_t)(op2))
#define vxor_vv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vxor_vv_i32m2(op0, op1, op2) \
__builtin_rvv_vxor_vv_i32m2((vint32m2_t)(op0), (vint32m2_t)(op1), (size_t)(op2))
#define vxor_vv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vxor_vv_i32m4(op0, op1, op2) \
__builtin_rvv_vxor_vv_i32m4((vint32m4_t)(op0), (vint32m4_t)(op1), (size_t)(op2))
#define vxor_vv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vxor_vv_i32m8(op0, op1, op2) \
__builtin_rvv_vxor_vv_i32m8((vint32m8_t)(op0), (vint32m8_t)(op1), (size_t)(op2))
#define vxor_vv_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (vint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vxor_vv_i32mf2(op0, op1, op2) \
__builtin_rvv_vxor_vv_i32mf2((vint32mf2_t)(op0), (vint32mf2_t)(op1), (size_t)(op2))
#define vxor_vv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vxor_vv_i64m1(op0, op1, op2) \
__builtin_rvv_vxor_vv_i64m1((vint64m1_t)(op0), (vint64m1_t)(op1), (size_t)(op2))
#define vxor_vv_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vxor_vv_i64m2(op0, op1, op2) \
__builtin_rvv_vxor_vv_i64m2((vint64m2_t)(op0), (vint64m2_t)(op1), (size_t)(op2))
#define vxor_vv_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (vint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vxor_vv_i64m4(op0, op1, op2) \
__builtin_rvv_vxor_vv_i64m4((vint64m4_t)(op0), (vint64m4_t)(op1), (size_t)(op2))
#define vxor_vv_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (vint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vxor_vv_i64m8(op0, op1, op2) \
__builtin_rvv_vxor_vv_i64m8((vint64m8_t)(op0), (vint64m8_t)(op1), (size_t)(op2))
#define vxor_vv_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (vint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vxor_vx_i8m1(op0, op1, op2) \
__builtin_rvv_vxor_vx_i8m1((vint8m1_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vxor_vx_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (int8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vxor_vx_i8m2(op0, op1, op2) \
__builtin_rvv_vxor_vx_i8m2((vint8m2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vxor_vx_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (int8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vxor_vx_i8m4(op0, op1, op2) \
__builtin_rvv_vxor_vx_i8m4((vint8m4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vxor_vx_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (int8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vxor_vx_i8m8(op0, op1, op2) \
__builtin_rvv_vxor_vx_i8m8((vint8m8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vxor_vx_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (int8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vxor_vx_i8mf2(op0, op1, op2) \
__builtin_rvv_vxor_vx_i8mf2((vint8mf2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vxor_vx_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (int8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vxor_vx_i8mf4(op0, op1, op2) \
__builtin_rvv_vxor_vx_i8mf4((vint8mf4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vxor_vx_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (int8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vxor_vx_i8mf8(op0, op1, op2) \
__builtin_rvv_vxor_vx_i8mf8((vint8mf8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vxor_vx_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (int8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vxor_vx_i16m1(op0, op1, op2) \
__builtin_rvv_vxor_vx_i16m1((vint16m1_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vxor_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (int16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vxor_vx_i16m2(op0, op1, op2) \
__builtin_rvv_vxor_vx_i16m2((vint16m2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vxor_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (int16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vxor_vx_i16m4(op0, op1, op2) \
__builtin_rvv_vxor_vx_i16m4((vint16m4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vxor_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (int16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vxor_vx_i16m8(op0, op1, op2) \
__builtin_rvv_vxor_vx_i16m8((vint16m8_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vxor_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (int16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vxor_vx_i16mf2(op0, op1, op2) \
__builtin_rvv_vxor_vx_i16mf2((vint16mf2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vxor_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (int16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vxor_vx_i16mf4(op0, op1, op2) \
__builtin_rvv_vxor_vx_i16mf4((vint16mf4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vxor_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (int16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vxor_vx_i32m1(op0, op1, op2) \
__builtin_rvv_vxor_vx_i32m1((vint32m1_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vxor_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (int32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vxor_vx_i32m2(op0, op1, op2) \
__builtin_rvv_vxor_vx_i32m2((vint32m2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vxor_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (int32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vxor_vx_i32m4(op0, op1, op2) \
__builtin_rvv_vxor_vx_i32m4((vint32m4_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vxor_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (int32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vxor_vx_i32m8(op0, op1, op2) \
__builtin_rvv_vxor_vx_i32m8((vint32m8_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vxor_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (int32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vxor_vx_i32mf2(op0, op1, op2) \
__builtin_rvv_vxor_vx_i32mf2((vint32mf2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vxor_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (int32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vxor_vx_i64m1(op0, op1, op2) \
__builtin_rvv_vxor_vx_i64m1((vint64m1_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vxor_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (int64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vxor_vx_i64m2(op0, op1, op2) \
__builtin_rvv_vxor_vx_i64m2((vint64m2_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vxor_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (int64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vxor_vx_i64m4(op0, op1, op2) \
__builtin_rvv_vxor_vx_i64m4((vint64m4_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vxor_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (int64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vxor_vx_i64m8(op0, op1, op2) \
__builtin_rvv_vxor_vx_i64m8((vint64m8_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vxor_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (int64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vxor_vv_u8m1(op0, op1, op2) \
__builtin_rvv_vxor_vv_u8m1((vuint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vxor_vv_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vxor_vv_u8m2(op0, op1, op2) \
__builtin_rvv_vxor_vv_u8m2((vuint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vxor_vv_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vxor_vv_u8m4(op0, op1, op2) \
__builtin_rvv_vxor_vv_u8m4((vuint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vxor_vv_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vxor_vv_u8m8(op0, op1, op2) \
__builtin_rvv_vxor_vv_u8m8((vuint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vxor_vv_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vxor_vv_u8mf2(op0, op1, op2) \
__builtin_rvv_vxor_vv_u8mf2((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vxor_vv_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vxor_vv_u8mf4(op0, op1, op2) \
__builtin_rvv_vxor_vv_u8mf4((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vxor_vv_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vxor_vv_u8mf8(op0, op1, op2) \
__builtin_rvv_vxor_vv_u8mf8((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vxor_vv_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vxor_vv_u16m1(op0, op1, op2) \
__builtin_rvv_vxor_vv_u16m1((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vxor_vv_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vxor_vv_u16m2(op0, op1, op2) \
__builtin_rvv_vxor_vv_u16m2((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vxor_vv_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vxor_vv_u16m4(op0, op1, op2) \
__builtin_rvv_vxor_vv_u16m4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vxor_vv_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vxor_vv_u16m8(op0, op1, op2) \
__builtin_rvv_vxor_vv_u16m8((vuint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vxor_vv_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vxor_vv_u16mf2(op0, op1, op2) \
__builtin_rvv_vxor_vv_u16mf2((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vxor_vv_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vxor_vv_u16mf4(op0, op1, op2) \
__builtin_rvv_vxor_vv_u16mf4((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vxor_vv_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vxor_vv_u32m1(op0, op1, op2) \
__builtin_rvv_vxor_vv_u32m1((vuint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vxor_vv_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vxor_vv_u32m2(op0, op1, op2) \
__builtin_rvv_vxor_vv_u32m2((vuint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vxor_vv_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vxor_vv_u32m4(op0, op1, op2) \
__builtin_rvv_vxor_vv_u32m4((vuint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vxor_vv_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vxor_vv_u32m8(op0, op1, op2) \
__builtin_rvv_vxor_vv_u32m8((vuint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vxor_vv_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vxor_vv_u32mf2(op0, op1, op2) \
__builtin_rvv_vxor_vv_u32mf2((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vxor_vv_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vxor_vv_u64m1(op0, op1, op2) \
__builtin_rvv_vxor_vv_u64m1((vuint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vxor_vv_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vxor_vv_u64m2(op0, op1, op2) \
__builtin_rvv_vxor_vv_u64m2((vuint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vxor_vv_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vxor_vv_u64m4(op0, op1, op2) \
__builtin_rvv_vxor_vv_u64m4((vuint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vxor_vv_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vxor_vv_u64m8(op0, op1, op2) \
__builtin_rvv_vxor_vv_u64m8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vxor_vv_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vxor_vx_u8m1(op0, op1, op2) \
__builtin_rvv_vxor_vx_u8m1((vuint8m1_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vxor_vx_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (uint8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vxor_vx_u8m2(op0, op1, op2) \
__builtin_rvv_vxor_vx_u8m2((vuint8m2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vxor_vx_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (uint8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vxor_vx_u8m4(op0, op1, op2) \
__builtin_rvv_vxor_vx_u8m4((vuint8m4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vxor_vx_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (uint8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vxor_vx_u8m8(op0, op1, op2) \
__builtin_rvv_vxor_vx_u8m8((vuint8m8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vxor_vx_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (uint8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vxor_vx_u8mf2(op0, op1, op2) \
__builtin_rvv_vxor_vx_u8mf2((vuint8mf2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vxor_vx_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (uint8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vxor_vx_u8mf4(op0, op1, op2) \
__builtin_rvv_vxor_vx_u8mf4((vuint8mf4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vxor_vx_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (uint8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vxor_vx_u8mf8(op0, op1, op2) \
__builtin_rvv_vxor_vx_u8mf8((vuint8mf8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vxor_vx_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (uint8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vxor_vx_u16m1(op0, op1, op2) \
__builtin_rvv_vxor_vx_u16m1((vuint16m1_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vxor_vx_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (uint16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vxor_vx_u16m2(op0, op1, op2) \
__builtin_rvv_vxor_vx_u16m2((vuint16m2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vxor_vx_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (uint16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vxor_vx_u16m4(op0, op1, op2) \
__builtin_rvv_vxor_vx_u16m4((vuint16m4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vxor_vx_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (uint16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vxor_vx_u16m8(op0, op1, op2) \
__builtin_rvv_vxor_vx_u16m8((vuint16m8_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vxor_vx_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (uint16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vxor_vx_u16mf2(op0, op1, op2) \
__builtin_rvv_vxor_vx_u16mf2((vuint16mf2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vxor_vx_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (uint16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vxor_vx_u16mf4(op0, op1, op2) \
__builtin_rvv_vxor_vx_u16mf4((vuint16mf4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vxor_vx_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (uint16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vxor_vx_u32m1(op0, op1, op2) \
__builtin_rvv_vxor_vx_u32m1((vuint32m1_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vxor_vx_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (uint32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vxor_vx_u32m2(op0, op1, op2) \
__builtin_rvv_vxor_vx_u32m2((vuint32m2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vxor_vx_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (uint32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vxor_vx_u32m4(op0, op1, op2) \
__builtin_rvv_vxor_vx_u32m4((vuint32m4_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vxor_vx_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (uint32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vxor_vx_u32m8(op0, op1, op2) \
__builtin_rvv_vxor_vx_u32m8((vuint32m8_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vxor_vx_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (uint32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vxor_vx_u32mf2(op0, op1, op2) \
__builtin_rvv_vxor_vx_u32mf2((vuint32mf2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vxor_vx_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (uint32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vxor_vx_u64m1(op0, op1, op2) \
__builtin_rvv_vxor_vx_u64m1((vuint64m1_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vxor_vx_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (uint64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vxor_vx_u64m2(op0, op1, op2) \
__builtin_rvv_vxor_vx_u64m2((vuint64m2_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vxor_vx_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (uint64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vxor_vx_u64m4(op0, op1, op2) \
__builtin_rvv_vxor_vx_u64m4((vuint64m4_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vxor_vx_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (uint64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vxor_vx_u64m8(op0, op1, op2) \
__builtin_rvv_vxor_vx_u64m8((vuint64m8_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vxor_vx_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (uint64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vle16_v_u16m1(op0, op1) \
__builtin_rvv_vle16_v_u16m1((const uint16_t *)(op0), (size_t)(op1))
#define vle16_v_u16m1_m(op2, op0, op1, op3) \
__builtin_rvv_vle16_v_u16m1_m((vuint16m1_t)(op0), (const uint16_t *)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vle16_v_u16m2(op0, op1) \
__builtin_rvv_vle16_v_u16m2((const uint16_t *)(op0), (size_t)(op1))
#define vle16_v_u16m2_m(op2, op0, op1, op3) \
__builtin_rvv_vle16_v_u16m2_m((vuint16m2_t)(op0), (const uint16_t *)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vle16_v_u16m4(op0, op1) \
__builtin_rvv_vle16_v_u16m4((const uint16_t *)(op0), (size_t)(op1))
#define vle16_v_u16m4_m(op2, op0, op1, op3) \
__builtin_rvv_vle16_v_u16m4_m((vuint16m4_t)(op0), (const uint16_t *)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vle16_v_u16m8(op0, op1) \
__builtin_rvv_vle16_v_u16m8((const uint16_t *)(op0), (size_t)(op1))
#define vle16_v_u16m8_m(op2, op0, op1, op3) \
__builtin_rvv_vle16_v_u16m8_m((vuint16m8_t)(op0), (const uint16_t *)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vle16_v_u16mf2(op0, op1) \
__builtin_rvv_vle16_v_u16mf2((const uint16_t *)(op0), (size_t)(op1))
#define vle16_v_u16mf2_m(op2, op0, op1, op3) \
__builtin_rvv_vle16_v_u16mf2_m((vuint16mf2_t)(op0), (const uint16_t *)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vle16_v_u16mf4(op0, op1) \
__builtin_rvv_vle16_v_u16mf4((const uint16_t *)(op0), (size_t)(op1))
#define vle16_v_u16mf4_m(op2, op0, op1, op3) \
__builtin_rvv_vle16_v_u16mf4_m((vuint16mf4_t)(op0), (const uint16_t *)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vor_vv_i8m1(op0, op1, op2) \
__builtin_rvv_vor_vv_i8m1((vint8m1_t)(op0), (vint8m1_t)(op1), (size_t)(op2))
#define vor_vv_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vor_vv_i8m2(op0, op1, op2) \
__builtin_rvv_vor_vv_i8m2((vint8m2_t)(op0), (vint8m2_t)(op1), (size_t)(op2))
#define vor_vv_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vor_vv_i8m4(op0, op1, op2) \
__builtin_rvv_vor_vv_i8m4((vint8m4_t)(op0), (vint8m4_t)(op1), (size_t)(op2))
#define vor_vv_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vor_vv_i8m8(op0, op1, op2) \
__builtin_rvv_vor_vv_i8m8((vint8m8_t)(op0), (vint8m8_t)(op1), (size_t)(op2))
#define vor_vv_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (vint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vor_vv_i8mf2(op0, op1, op2) \
__builtin_rvv_vor_vv_i8mf2((vint8mf2_t)(op0), (vint8mf2_t)(op1), (size_t)(op2))
#define vor_vv_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vor_vv_i8mf4(op0, op1, op2) \
__builtin_rvv_vor_vv_i8mf4((vint8mf4_t)(op0), (vint8mf4_t)(op1), (size_t)(op2))
#define vor_vv_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vor_vv_i8mf8(op0, op1, op2) \
__builtin_rvv_vor_vv_i8mf8((vint8mf8_t)(op0), (vint8mf8_t)(op1), (size_t)(op2))
#define vor_vv_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vor_vv_i16m1(op0, op1, op2) \
__builtin_rvv_vor_vv_i16m1((vint16m1_t)(op0), (vint16m1_t)(op1), (size_t)(op2))
#define vor_vv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vor_vv_i16m2(op0, op1, op2) \
__builtin_rvv_vor_vv_i16m2((vint16m2_t)(op0), (vint16m2_t)(op1), (size_t)(op2))
#define vor_vv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vor_vv_i16m4(op0, op1, op2) \
__builtin_rvv_vor_vv_i16m4((vint16m4_t)(op0), (vint16m4_t)(op1), (size_t)(op2))
#define vor_vv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vor_vv_i16m8(op0, op1, op2) \
__builtin_rvv_vor_vv_i16m8((vint16m8_t)(op0), (vint16m8_t)(op1), (size_t)(op2))
#define vor_vv_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (vint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vor_vv_i16mf2(op0, op1, op2) \
__builtin_rvv_vor_vv_i16mf2((vint16mf2_t)(op0), (vint16mf2_t)(op1), (size_t)(op2))
#define vor_vv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vor_vv_i16mf4(op0, op1, op2) \
__builtin_rvv_vor_vv_i16mf4((vint16mf4_t)(op0), (vint16mf4_t)(op1), (size_t)(op2))
#define vor_vv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vor_vv_i32m1(op0, op1, op2) \
__builtin_rvv_vor_vv_i32m1((vint32m1_t)(op0), (vint32m1_t)(op1), (size_t)(op2))
#define vor_vv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vor_vv_i32m2(op0, op1, op2) \
__builtin_rvv_vor_vv_i32m2((vint32m2_t)(op0), (vint32m2_t)(op1), (size_t)(op2))
#define vor_vv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vor_vv_i32m4(op0, op1, op2) \
__builtin_rvv_vor_vv_i32m4((vint32m4_t)(op0), (vint32m4_t)(op1), (size_t)(op2))
#define vor_vv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vor_vv_i32m8(op0, op1, op2) \
__builtin_rvv_vor_vv_i32m8((vint32m8_t)(op0), (vint32m8_t)(op1), (size_t)(op2))
#define vor_vv_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (vint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vor_vv_i32mf2(op0, op1, op2) \
__builtin_rvv_vor_vv_i32mf2((vint32mf2_t)(op0), (vint32mf2_t)(op1), (size_t)(op2))
#define vor_vv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vor_vv_i64m1(op0, op1, op2) \
__builtin_rvv_vor_vv_i64m1((vint64m1_t)(op0), (vint64m1_t)(op1), (size_t)(op2))
#define vor_vv_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vor_vv_i64m2(op0, op1, op2) \
__builtin_rvv_vor_vv_i64m2((vint64m2_t)(op0), (vint64m2_t)(op1), (size_t)(op2))
#define vor_vv_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (vint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vor_vv_i64m4(op0, op1, op2) \
__builtin_rvv_vor_vv_i64m4((vint64m4_t)(op0), (vint64m4_t)(op1), (size_t)(op2))
#define vor_vv_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (vint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vor_vv_i64m8(op0, op1, op2) \
__builtin_rvv_vor_vv_i64m8((vint64m8_t)(op0), (vint64m8_t)(op1), (size_t)(op2))
#define vor_vv_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (vint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vor_vx_i8m1(op0, op1, op2) \
__builtin_rvv_vor_vx_i8m1((vint8m1_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vor_vx_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (int8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vor_vx_i8m2(op0, op1, op2) \
__builtin_rvv_vor_vx_i8m2((vint8m2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vor_vx_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (int8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vor_vx_i8m4(op0, op1, op2) \
__builtin_rvv_vor_vx_i8m4((vint8m4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vor_vx_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (int8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vor_vx_i8m8(op0, op1, op2) \
__builtin_rvv_vor_vx_i8m8((vint8m8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vor_vx_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (int8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vor_vx_i8mf2(op0, op1, op2) \
__builtin_rvv_vor_vx_i8mf2((vint8mf2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vor_vx_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (int8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vor_vx_i8mf4(op0, op1, op2) \
__builtin_rvv_vor_vx_i8mf4((vint8mf4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vor_vx_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (int8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vor_vx_i8mf8(op0, op1, op2) \
__builtin_rvv_vor_vx_i8mf8((vint8mf8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vor_vx_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (int8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vor_vx_i16m1(op0, op1, op2) \
__builtin_rvv_vor_vx_i16m1((vint16m1_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vor_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (int16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vor_vx_i16m2(op0, op1, op2) \
__builtin_rvv_vor_vx_i16m2((vint16m2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vor_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (int16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vor_vx_i16m4(op0, op1, op2) \
__builtin_rvv_vor_vx_i16m4((vint16m4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vor_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (int16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vor_vx_i16m8(op0, op1, op2) \
__builtin_rvv_vor_vx_i16m8((vint16m8_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vor_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (int16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vor_vx_i16mf2(op0, op1, op2) \
__builtin_rvv_vor_vx_i16mf2((vint16mf2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vor_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (int16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vor_vx_i16mf4(op0, op1, op2) \
__builtin_rvv_vor_vx_i16mf4((vint16mf4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vor_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (int16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vor_vx_i32m1(op0, op1, op2) \
__builtin_rvv_vor_vx_i32m1((vint32m1_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vor_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (int32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vor_vx_i32m2(op0, op1, op2) \
__builtin_rvv_vor_vx_i32m2((vint32m2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vor_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (int32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vor_vx_i32m4(op0, op1, op2) \
__builtin_rvv_vor_vx_i32m4((vint32m4_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vor_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (int32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vor_vx_i32m8(op0, op1, op2) \
__builtin_rvv_vor_vx_i32m8((vint32m8_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vor_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (int32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vor_vx_i32mf2(op0, op1, op2) \
__builtin_rvv_vor_vx_i32mf2((vint32mf2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vor_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (int32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vor_vx_i64m1(op0, op1, op2) \
__builtin_rvv_vor_vx_i64m1((vint64m1_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vor_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (int64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vor_vx_i64m2(op0, op1, op2) \
__builtin_rvv_vor_vx_i64m2((vint64m2_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vor_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (int64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vor_vx_i64m4(op0, op1, op2) \
__builtin_rvv_vor_vx_i64m4((vint64m4_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vor_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (int64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vor_vx_i64m8(op0, op1, op2) \
__builtin_rvv_vor_vx_i64m8((vint64m8_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vor_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (int64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vor_vv_u8m1(op0, op1, op2) \
__builtin_rvv_vor_vv_u8m1((vuint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vor_vv_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vor_vv_u8m2(op0, op1, op2) \
__builtin_rvv_vor_vv_u8m2((vuint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vor_vv_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vor_vv_u8m4(op0, op1, op2) \
__builtin_rvv_vor_vv_u8m4((vuint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vor_vv_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vor_vv_u8m8(op0, op1, op2) \
__builtin_rvv_vor_vv_u8m8((vuint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vor_vv_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vor_vv_u8mf2(op0, op1, op2) \
__builtin_rvv_vor_vv_u8mf2((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vor_vv_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vor_vv_u8mf4(op0, op1, op2) \
__builtin_rvv_vor_vv_u8mf4((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vor_vv_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vor_vv_u8mf8(op0, op1, op2) \
__builtin_rvv_vor_vv_u8mf8((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vor_vv_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vor_vv_u16m1(op0, op1, op2) \
__builtin_rvv_vor_vv_u16m1((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vor_vv_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vor_vv_u16m2(op0, op1, op2) \
__builtin_rvv_vor_vv_u16m2((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vor_vv_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vor_vv_u16m4(op0, op1, op2) \
__builtin_rvv_vor_vv_u16m4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vor_vv_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vor_vv_u16m8(op0, op1, op2) \
__builtin_rvv_vor_vv_u16m8((vuint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vor_vv_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vor_vv_u16mf2(op0, op1, op2) \
__builtin_rvv_vor_vv_u16mf2((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vor_vv_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vor_vv_u16mf4(op0, op1, op2) \
__builtin_rvv_vor_vv_u16mf4((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vor_vv_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vor_vv_u32m1(op0, op1, op2) \
__builtin_rvv_vor_vv_u32m1((vuint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vor_vv_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vor_vv_u32m2(op0, op1, op2) \
__builtin_rvv_vor_vv_u32m2((vuint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vor_vv_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vor_vv_u32m4(op0, op1, op2) \
__builtin_rvv_vor_vv_u32m4((vuint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vor_vv_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vor_vv_u32m8(op0, op1, op2) \
__builtin_rvv_vor_vv_u32m8((vuint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vor_vv_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vor_vv_u32mf2(op0, op1, op2) \
__builtin_rvv_vor_vv_u32mf2((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vor_vv_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vor_vv_u64m1(op0, op1, op2) \
__builtin_rvv_vor_vv_u64m1((vuint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vor_vv_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vor_vv_u64m2(op0, op1, op2) \
__builtin_rvv_vor_vv_u64m2((vuint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vor_vv_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vor_vv_u64m4(op0, op1, op2) \
__builtin_rvv_vor_vv_u64m4((vuint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vor_vv_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vor_vv_u64m8(op0, op1, op2) \
__builtin_rvv_vor_vv_u64m8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vor_vv_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vor_vx_u8m1(op0, op1, op2) \
__builtin_rvv_vor_vx_u8m1((vuint8m1_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vor_vx_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (uint8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vor_vx_u8m2(op0, op1, op2) \
__builtin_rvv_vor_vx_u8m2((vuint8m2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vor_vx_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (uint8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vor_vx_u8m4(op0, op1, op2) \
__builtin_rvv_vor_vx_u8m4((vuint8m4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vor_vx_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (uint8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vor_vx_u8m8(op0, op1, op2) \
__builtin_rvv_vor_vx_u8m8((vuint8m8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vor_vx_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (uint8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vor_vx_u8mf2(op0, op1, op2) \
__builtin_rvv_vor_vx_u8mf2((vuint8mf2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vor_vx_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (uint8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vor_vx_u8mf4(op0, op1, op2) \
__builtin_rvv_vor_vx_u8mf4((vuint8mf4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vor_vx_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (uint8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vor_vx_u8mf8(op0, op1, op2) \
__builtin_rvv_vor_vx_u8mf8((vuint8mf8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vor_vx_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (uint8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vor_vx_u16m1(op0, op1, op2) \
__builtin_rvv_vor_vx_u16m1((vuint16m1_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vor_vx_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (uint16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vor_vx_u16m2(op0, op1, op2) \
__builtin_rvv_vor_vx_u16m2((vuint16m2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vor_vx_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (uint16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vor_vx_u16m4(op0, op1, op2) \
__builtin_rvv_vor_vx_u16m4((vuint16m4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vor_vx_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (uint16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vor_vx_u16m8(op0, op1, op2) \
__builtin_rvv_vor_vx_u16m8((vuint16m8_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vor_vx_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (uint16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vor_vx_u16mf2(op0, op1, op2) \
__builtin_rvv_vor_vx_u16mf2((vuint16mf2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vor_vx_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (uint16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vor_vx_u16mf4(op0, op1, op2) \
__builtin_rvv_vor_vx_u16mf4((vuint16mf4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vor_vx_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (uint16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vor_vx_u32m1(op0, op1, op2) \
__builtin_rvv_vor_vx_u32m1((vuint32m1_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vor_vx_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (uint32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vor_vx_u32m2(op0, op1, op2) \
__builtin_rvv_vor_vx_u32m2((vuint32m2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vor_vx_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (uint32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vor_vx_u32m4(op0, op1, op2) \
__builtin_rvv_vor_vx_u32m4((vuint32m4_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vor_vx_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (uint32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vor_vx_u32m8(op0, op1, op2) \
__builtin_rvv_vor_vx_u32m8((vuint32m8_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vor_vx_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (uint32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vor_vx_u32mf2(op0, op1, op2) \
__builtin_rvv_vor_vx_u32mf2((vuint32mf2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vor_vx_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (uint32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vor_vx_u64m1(op0, op1, op2) \
__builtin_rvv_vor_vx_u64m1((vuint64m1_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vor_vx_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (uint64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vor_vx_u64m2(op0, op1, op2) \
__builtin_rvv_vor_vx_u64m2((vuint64m2_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vor_vx_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (uint64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vor_vx_u64m4(op0, op1, op2) \
__builtin_rvv_vor_vx_u64m4((vuint64m4_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vor_vx_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (uint64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vor_vx_u64m8(op0, op1, op2) \
__builtin_rvv_vor_vx_u64m8((vuint64m8_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vor_vx_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (uint64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsll_vv_i8m1(op0, op1, op2) \
__builtin_rvv_vsll_vv_i8m1((vint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vsll_vv_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsll_vv_i8m2(op0, op1, op2) \
__builtin_rvv_vsll_vv_i8m2((vint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vsll_vv_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsll_vv_i8m4(op0, op1, op2) \
__builtin_rvv_vsll_vv_i8m4((vint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vsll_vv_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsll_vv_i8m8(op0, op1, op2) \
__builtin_rvv_vsll_vv_i8m8((vint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vsll_vv_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vsll_vv_i8mf2(op0, op1, op2) \
__builtin_rvv_vsll_vv_i8mf2((vint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vsll_vv_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsll_vv_i8mf4(op0, op1, op2) \
__builtin_rvv_vsll_vv_i8mf4((vint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vsll_vv_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsll_vv_i8mf8(op0, op1, op2) \
__builtin_rvv_vsll_vv_i8mf8((vint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vsll_vv_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsll_vv_i16m1(op0, op1, op2) \
__builtin_rvv_vsll_vv_i16m1((vint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vsll_vv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsll_vv_i16m2(op0, op1, op2) \
__builtin_rvv_vsll_vv_i16m2((vint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vsll_vv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsll_vv_i16m4(op0, op1, op2) \
__builtin_rvv_vsll_vv_i16m4((vint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vsll_vv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsll_vv_i16m8(op0, op1, op2) \
__builtin_rvv_vsll_vv_i16m8((vint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vsll_vv_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsll_vv_i16mf2(op0, op1, op2) \
__builtin_rvv_vsll_vv_i16mf2((vint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vsll_vv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsll_vv_i16mf4(op0, op1, op2) \
__builtin_rvv_vsll_vv_i16mf4((vint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vsll_vv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsll_vv_i32m1(op0, op1, op2) \
__builtin_rvv_vsll_vv_i32m1((vint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vsll_vv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsll_vv_i32m2(op0, op1, op2) \
__builtin_rvv_vsll_vv_i32m2((vint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vsll_vv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsll_vv_i32m4(op0, op1, op2) \
__builtin_rvv_vsll_vv_i32m4((vint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vsll_vv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsll_vv_i32m8(op0, op1, op2) \
__builtin_rvv_vsll_vv_i32m8((vint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vsll_vv_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsll_vv_i32mf2(op0, op1, op2) \
__builtin_rvv_vsll_vv_i32mf2((vint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vsll_vv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsll_vv_i64m1(op0, op1, op2) \
__builtin_rvv_vsll_vv_i64m1((vint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vsll_vv_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsll_vv_i64m2(op0, op1, op2) \
__builtin_rvv_vsll_vv_i64m2((vint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vsll_vv_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsll_vv_i64m4(op0, op1, op2) \
__builtin_rvv_vsll_vv_i64m4((vint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vsll_vv_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsll_vv_i64m8(op0, op1, op2) \
__builtin_rvv_vsll_vv_i64m8((vint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vsll_vv_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsll_vx_i8m1(op0, op1, op2) \
__builtin_rvv_vsll_vx_i8m1((vint8m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsll_vx_i8m2(op0, op1, op2) \
__builtin_rvv_vsll_vx_i8m2((vint8m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsll_vx_i8m4(op0, op1, op2) \
__builtin_rvv_vsll_vx_i8m4((vint8m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (size_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsll_vx_i8m8(op0, op1, op2) \
__builtin_rvv_vsll_vx_i8m8((vint8m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (size_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vsll_vx_i8mf2(op0, op1, op2) \
__builtin_rvv_vsll_vx_i8mf2((vint8mf2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsll_vx_i8mf4(op0, op1, op2) \
__builtin_rvv_vsll_vx_i8mf4((vint8mf4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsll_vx_i8mf8(op0, op1, op2) \
__builtin_rvv_vsll_vx_i8mf8((vint8mf8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsll_vx_i16m1(op0, op1, op2) \
__builtin_rvv_vsll_vx_i16m1((vint16m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsll_vx_i16m2(op0, op1, op2) \
__builtin_rvv_vsll_vx_i16m2((vint16m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsll_vx_i16m4(op0, op1, op2) \
__builtin_rvv_vsll_vx_i16m4((vint16m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsll_vx_i16m8(op0, op1, op2) \
__builtin_rvv_vsll_vx_i16m8((vint16m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (size_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsll_vx_i16mf2(op0, op1, op2) \
__builtin_rvv_vsll_vx_i16mf2((vint16mf2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsll_vx_i16mf4(op0, op1, op2) \
__builtin_rvv_vsll_vx_i16mf4((vint16mf4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsll_vx_i32m1(op0, op1, op2) \
__builtin_rvv_vsll_vx_i32m1((vint32m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsll_vx_i32m2(op0, op1, op2) \
__builtin_rvv_vsll_vx_i32m2((vint32m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsll_vx_i32m4(op0, op1, op2) \
__builtin_rvv_vsll_vx_i32m4((vint32m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsll_vx_i32m8(op0, op1, op2) \
__builtin_rvv_vsll_vx_i32m8((vint32m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsll_vx_i32mf2(op0, op1, op2) \
__builtin_rvv_vsll_vx_i32mf2((vint32mf2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsll_vx_i64m1(op0, op1, op2) \
__builtin_rvv_vsll_vx_i64m1((vint64m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsll_vx_i64m2(op0, op1, op2) \
__builtin_rvv_vsll_vx_i64m2((vint64m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsll_vx_i64m4(op0, op1, op2) \
__builtin_rvv_vsll_vx_i64m4((vint64m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsll_vx_i64m8(op0, op1, op2) \
__builtin_rvv_vsll_vx_i64m8((vint64m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsll_vv_u8m1(op0, op1, op2) \
__builtin_rvv_vsll_vv_u8m1((vuint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vsll_vv_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsll_vv_u8m2(op0, op1, op2) \
__builtin_rvv_vsll_vv_u8m2((vuint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vsll_vv_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsll_vv_u8m4(op0, op1, op2) \
__builtin_rvv_vsll_vv_u8m4((vuint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vsll_vv_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsll_vv_u8m8(op0, op1, op2) \
__builtin_rvv_vsll_vv_u8m8((vuint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vsll_vv_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vsll_vv_u8mf2(op0, op1, op2) \
__builtin_rvv_vsll_vv_u8mf2((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vsll_vv_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsll_vv_u8mf4(op0, op1, op2) \
__builtin_rvv_vsll_vv_u8mf4((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vsll_vv_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsll_vv_u8mf8(op0, op1, op2) \
__builtin_rvv_vsll_vv_u8mf8((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vsll_vv_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsll_vv_u16m1(op0, op1, op2) \
__builtin_rvv_vsll_vv_u16m1((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vsll_vv_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsll_vv_u16m2(op0, op1, op2) \
__builtin_rvv_vsll_vv_u16m2((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vsll_vv_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsll_vv_u16m4(op0, op1, op2) \
__builtin_rvv_vsll_vv_u16m4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vsll_vv_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsll_vv_u16m8(op0, op1, op2) \
__builtin_rvv_vsll_vv_u16m8((vuint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vsll_vv_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsll_vv_u16mf2(op0, op1, op2) \
__builtin_rvv_vsll_vv_u16mf2((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vsll_vv_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsll_vv_u16mf4(op0, op1, op2) \
__builtin_rvv_vsll_vv_u16mf4((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vsll_vv_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsll_vv_u32m1(op0, op1, op2) \
__builtin_rvv_vsll_vv_u32m1((vuint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vsll_vv_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsll_vv_u32m2(op0, op1, op2) \
__builtin_rvv_vsll_vv_u32m2((vuint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vsll_vv_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsll_vv_u32m4(op0, op1, op2) \
__builtin_rvv_vsll_vv_u32m4((vuint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vsll_vv_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsll_vv_u32m8(op0, op1, op2) \
__builtin_rvv_vsll_vv_u32m8((vuint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vsll_vv_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsll_vv_u32mf2(op0, op1, op2) \
__builtin_rvv_vsll_vv_u32mf2((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vsll_vv_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsll_vv_u64m1(op0, op1, op2) \
__builtin_rvv_vsll_vv_u64m1((vuint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vsll_vv_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsll_vv_u64m2(op0, op1, op2) \
__builtin_rvv_vsll_vv_u64m2((vuint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vsll_vv_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsll_vv_u64m4(op0, op1, op2) \
__builtin_rvv_vsll_vv_u64m4((vuint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vsll_vv_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsll_vv_u64m8(op0, op1, op2) \
__builtin_rvv_vsll_vv_u64m8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vsll_vv_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsll_vx_u8m1(op0, op1, op2) \
__builtin_rvv_vsll_vx_u8m1((vuint8m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsll_vx_u8m2(op0, op1, op2) \
__builtin_rvv_vsll_vx_u8m2((vuint8m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsll_vx_u8m4(op0, op1, op2) \
__builtin_rvv_vsll_vx_u8m4((vuint8m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsll_vx_u8m8(op0, op1, op2) \
__builtin_rvv_vsll_vx_u8m8((vuint8m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vsll_vx_u8mf2(op0, op1, op2) \
__builtin_rvv_vsll_vx_u8mf2((vuint8mf2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsll_vx_u8mf4(op0, op1, op2) \
__builtin_rvv_vsll_vx_u8mf4((vuint8mf4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsll_vx_u8mf8(op0, op1, op2) \
__builtin_rvv_vsll_vx_u8mf8((vuint8mf8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsll_vx_u16m1(op0, op1, op2) \
__builtin_rvv_vsll_vx_u16m1((vuint16m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsll_vx_u16m2(op0, op1, op2) \
__builtin_rvv_vsll_vx_u16m2((vuint16m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsll_vx_u16m4(op0, op1, op2) \
__builtin_rvv_vsll_vx_u16m4((vuint16m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsll_vx_u16m8(op0, op1, op2) \
__builtin_rvv_vsll_vx_u16m8((vuint16m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsll_vx_u16mf2(op0, op1, op2) \
__builtin_rvv_vsll_vx_u16mf2((vuint16mf2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsll_vx_u16mf4(op0, op1, op2) \
__builtin_rvv_vsll_vx_u16mf4((vuint16mf4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsll_vx_u32m1(op0, op1, op2) \
__builtin_rvv_vsll_vx_u32m1((vuint32m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsll_vx_u32m2(op0, op1, op2) \
__builtin_rvv_vsll_vx_u32m2((vuint32m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsll_vx_u32m4(op0, op1, op2) \
__builtin_rvv_vsll_vx_u32m4((vuint32m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsll_vx_u32m8(op0, op1, op2) \
__builtin_rvv_vsll_vx_u32m8((vuint32m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsll_vx_u32mf2(op0, op1, op2) \
__builtin_rvv_vsll_vx_u32mf2((vuint32mf2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsll_vx_u64m1(op0, op1, op2) \
__builtin_rvv_vsll_vx_u64m1((vuint64m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsll_vx_u64m2(op0, op1, op2) \
__builtin_rvv_vsll_vx_u64m2((vuint64m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsll_vx_u64m4(op0, op1, op2) \
__builtin_rvv_vsll_vx_u64m4((vuint64m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsll_vx_u64m8(op0, op1, op2) \
__builtin_rvv_vsll_vx_u64m8((vuint64m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsrl_vv_u8m1(op0, op1, op2) \
__builtin_rvv_vsrl_vv_u8m1((vuint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vsrl_vv_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vv_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsrl_vv_u8m2(op0, op1, op2) \
__builtin_rvv_vsrl_vv_u8m2((vuint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vsrl_vv_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vv_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsrl_vv_u8m4(op0, op1, op2) \
__builtin_rvv_vsrl_vv_u8m4((vuint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vsrl_vv_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vv_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsrl_vv_u8m8(op0, op1, op2) \
__builtin_rvv_vsrl_vv_u8m8((vuint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vsrl_vv_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vv_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vsrl_vv_u8mf2(op0, op1, op2) \
__builtin_rvv_vsrl_vv_u8mf2((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vsrl_vv_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vv_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsrl_vv_u8mf4(op0, op1, op2) \
__builtin_rvv_vsrl_vv_u8mf4((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vsrl_vv_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vv_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsrl_vv_u8mf8(op0, op1, op2) \
__builtin_rvv_vsrl_vv_u8mf8((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vsrl_vv_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vv_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsrl_vv_u16m1(op0, op1, op2) \
__builtin_rvv_vsrl_vv_u16m1((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vsrl_vv_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vv_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsrl_vv_u16m2(op0, op1, op2) \
__builtin_rvv_vsrl_vv_u16m2((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vsrl_vv_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vv_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsrl_vv_u16m4(op0, op1, op2) \
__builtin_rvv_vsrl_vv_u16m4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vsrl_vv_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vv_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsrl_vv_u16m8(op0, op1, op2) \
__builtin_rvv_vsrl_vv_u16m8((vuint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vsrl_vv_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vv_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsrl_vv_u16mf2(op0, op1, op2) \
__builtin_rvv_vsrl_vv_u16mf2((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vsrl_vv_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vv_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsrl_vv_u16mf4(op0, op1, op2) \
__builtin_rvv_vsrl_vv_u16mf4((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vsrl_vv_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vv_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsrl_vv_u32m1(op0, op1, op2) \
__builtin_rvv_vsrl_vv_u32m1((vuint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vsrl_vv_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vv_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsrl_vv_u32m2(op0, op1, op2) \
__builtin_rvv_vsrl_vv_u32m2((vuint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vsrl_vv_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vv_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsrl_vv_u32m4(op0, op1, op2) \
__builtin_rvv_vsrl_vv_u32m4((vuint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vsrl_vv_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vv_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsrl_vv_u32m8(op0, op1, op2) \
__builtin_rvv_vsrl_vv_u32m8((vuint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vsrl_vv_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vv_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsrl_vv_u32mf2(op0, op1, op2) \
__builtin_rvv_vsrl_vv_u32mf2((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vsrl_vv_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vv_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsrl_vv_u64m1(op0, op1, op2) \
__builtin_rvv_vsrl_vv_u64m1((vuint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vsrl_vv_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vv_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsrl_vv_u64m2(op0, op1, op2) \
__builtin_rvv_vsrl_vv_u64m2((vuint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vsrl_vv_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vv_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsrl_vv_u64m4(op0, op1, op2) \
__builtin_rvv_vsrl_vv_u64m4((vuint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vsrl_vv_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vv_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsrl_vv_u64m8(op0, op1, op2) \
__builtin_rvv_vsrl_vv_u64m8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vsrl_vv_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vv_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsrl_vx_u8m1(op0, op1, op2) \
__builtin_rvv_vsrl_vx_u8m1((vuint8m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsrl_vx_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vx_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsrl_vx_u8m2(op0, op1, op2) \
__builtin_rvv_vsrl_vx_u8m2((vuint8m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsrl_vx_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vx_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsrl_vx_u8m4(op0, op1, op2) \
__builtin_rvv_vsrl_vx_u8m4((vuint8m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsrl_vx_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vx_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsrl_vx_u8m8(op0, op1, op2) \
__builtin_rvv_vsrl_vx_u8m8((vuint8m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsrl_vx_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vx_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vsrl_vx_u8mf2(op0, op1, op2) \
__builtin_rvv_vsrl_vx_u8mf2((vuint8mf2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsrl_vx_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vx_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsrl_vx_u8mf4(op0, op1, op2) \
__builtin_rvv_vsrl_vx_u8mf4((vuint8mf4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsrl_vx_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vx_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsrl_vx_u8mf8(op0, op1, op2) \
__builtin_rvv_vsrl_vx_u8mf8((vuint8mf8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsrl_vx_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vx_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsrl_vx_u16m1(op0, op1, op2) \
__builtin_rvv_vsrl_vx_u16m1((vuint16m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsrl_vx_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vx_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsrl_vx_u16m2(op0, op1, op2) \
__builtin_rvv_vsrl_vx_u16m2((vuint16m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsrl_vx_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vx_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsrl_vx_u16m4(op0, op1, op2) \
__builtin_rvv_vsrl_vx_u16m4((vuint16m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsrl_vx_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vx_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsrl_vx_u16m8(op0, op1, op2) \
__builtin_rvv_vsrl_vx_u16m8((vuint16m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsrl_vx_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vx_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsrl_vx_u16mf2(op0, op1, op2) \
__builtin_rvv_vsrl_vx_u16mf2((vuint16mf2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsrl_vx_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vx_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsrl_vx_u16mf4(op0, op1, op2) \
__builtin_rvv_vsrl_vx_u16mf4((vuint16mf4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsrl_vx_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vx_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsrl_vx_u32m1(op0, op1, op2) \
__builtin_rvv_vsrl_vx_u32m1((vuint32m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsrl_vx_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vx_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsrl_vx_u32m2(op0, op1, op2) \
__builtin_rvv_vsrl_vx_u32m2((vuint32m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsrl_vx_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vx_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsrl_vx_u32m4(op0, op1, op2) \
__builtin_rvv_vsrl_vx_u32m4((vuint32m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsrl_vx_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vx_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsrl_vx_u32m8(op0, op1, op2) \
__builtin_rvv_vsrl_vx_u32m8((vuint32m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsrl_vx_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vx_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsrl_vx_u32mf2(op0, op1, op2) \
__builtin_rvv_vsrl_vx_u32mf2((vuint32mf2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsrl_vx_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vx_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsrl_vx_u64m1(op0, op1, op2) \
__builtin_rvv_vsrl_vx_u64m1((vuint64m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsrl_vx_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vx_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsrl_vx_u64m2(op0, op1, op2) \
__builtin_rvv_vsrl_vx_u64m2((vuint64m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsrl_vx_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vx_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsrl_vx_u64m4(op0, op1, op2) \
__builtin_rvv_vsrl_vx_u64m4((vuint64m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsrl_vx_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vx_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsrl_vx_u64m8(op0, op1, op2) \
__builtin_rvv_vsrl_vx_u64m8((vuint64m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsrl_vx_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vx_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vle32_v_i32m1(op0, op1) \
__builtin_rvv_vle32_v_i32m1((const int32_t *)(op0), (size_t)(op1))
#define vle32_v_i32m1_m(op2, op0, op1, op3) \
__builtin_rvv_vle32_v_i32m1_m((vint32m1_t)(op0), (const int32_t *)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vle32_v_i32m2(op0, op1) \
__builtin_rvv_vle32_v_i32m2((const int32_t *)(op0), (size_t)(op1))
#define vle32_v_i32m2_m(op2, op0, op1, op3) \
__builtin_rvv_vle32_v_i32m2_m((vint32m2_t)(op0), (const int32_t *)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vle32_v_i32m4(op0, op1) \
__builtin_rvv_vle32_v_i32m4((const int32_t *)(op0), (size_t)(op1))
#define vle32_v_i32m4_m(op2, op0, op1, op3) \
__builtin_rvv_vle32_v_i32m4_m((vint32m4_t)(op0), (const int32_t *)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vle32_v_i32m8(op0, op1) \
__builtin_rvv_vle32_v_i32m8((const int32_t *)(op0), (size_t)(op1))
#define vle32_v_i32m8_m(op2, op0, op1, op3) \
__builtin_rvv_vle32_v_i32m8_m((vint32m8_t)(op0), (const int32_t *)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vle32_v_i32mf2(op0, op1) \
__builtin_rvv_vle32_v_i32mf2((const int32_t *)(op0), (size_t)(op1))
#define vle32_v_i32mf2_m(op2, op0, op1, op3) \
__builtin_rvv_vle32_v_i32mf2_m((vint32mf2_t)(op0), (const int32_t *)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vsra_vv_i8m1(op0, op1, op2) \
__builtin_rvv_vsra_vv_i8m1((vint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vsra_vv_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vv_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsra_vv_i8m2(op0, op1, op2) \
__builtin_rvv_vsra_vv_i8m2((vint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vsra_vv_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vv_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsra_vv_i8m4(op0, op1, op2) \
__builtin_rvv_vsra_vv_i8m4((vint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vsra_vv_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vv_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsra_vv_i8m8(op0, op1, op2) \
__builtin_rvv_vsra_vv_i8m8((vint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vsra_vv_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vv_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vsra_vv_i8mf2(op0, op1, op2) \
__builtin_rvv_vsra_vv_i8mf2((vint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vsra_vv_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vv_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsra_vv_i8mf4(op0, op1, op2) \
__builtin_rvv_vsra_vv_i8mf4((vint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vsra_vv_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vv_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsra_vv_i8mf8(op0, op1, op2) \
__builtin_rvv_vsra_vv_i8mf8((vint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vsra_vv_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vv_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsra_vv_i16m1(op0, op1, op2) \
__builtin_rvv_vsra_vv_i16m1((vint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vsra_vv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vv_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsra_vv_i16m2(op0, op1, op2) \
__builtin_rvv_vsra_vv_i16m2((vint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vsra_vv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vv_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsra_vv_i16m4(op0, op1, op2) \
__builtin_rvv_vsra_vv_i16m4((vint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vsra_vv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vv_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsra_vv_i16m8(op0, op1, op2) \
__builtin_rvv_vsra_vv_i16m8((vint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vsra_vv_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vv_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsra_vv_i16mf2(op0, op1, op2) \
__builtin_rvv_vsra_vv_i16mf2((vint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vsra_vv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vv_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsra_vv_i16mf4(op0, op1, op2) \
__builtin_rvv_vsra_vv_i16mf4((vint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vsra_vv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vv_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsra_vv_i32m1(op0, op1, op2) \
__builtin_rvv_vsra_vv_i32m1((vint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vsra_vv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vv_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsra_vv_i32m2(op0, op1, op2) \
__builtin_rvv_vsra_vv_i32m2((vint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vsra_vv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vv_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsra_vv_i32m4(op0, op1, op2) \
__builtin_rvv_vsra_vv_i32m4((vint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vsra_vv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vv_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsra_vv_i32m8(op0, op1, op2) \
__builtin_rvv_vsra_vv_i32m8((vint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vsra_vv_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vv_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsra_vv_i32mf2(op0, op1, op2) \
__builtin_rvv_vsra_vv_i32mf2((vint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vsra_vv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vv_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsra_vv_i64m1(op0, op1, op2) \
__builtin_rvv_vsra_vv_i64m1((vint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vsra_vv_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vv_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsra_vv_i64m2(op0, op1, op2) \
__builtin_rvv_vsra_vv_i64m2((vint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vsra_vv_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vv_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsra_vv_i64m4(op0, op1, op2) \
__builtin_rvv_vsra_vv_i64m4((vint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vsra_vv_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vv_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsra_vv_i64m8(op0, op1, op2) \
__builtin_rvv_vsra_vv_i64m8((vint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vsra_vv_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vv_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsra_vx_i8m1(op0, op1, op2) \
__builtin_rvv_vsra_vx_i8m1((vint8m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsra_vx_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vx_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsra_vx_i8m2(op0, op1, op2) \
__builtin_rvv_vsra_vx_i8m2((vint8m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsra_vx_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vx_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsra_vx_i8m4(op0, op1, op2) \
__builtin_rvv_vsra_vx_i8m4((vint8m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsra_vx_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vx_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (size_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsra_vx_i8m8(op0, op1, op2) \
__builtin_rvv_vsra_vx_i8m8((vint8m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsra_vx_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vx_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (size_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vsra_vx_i8mf2(op0, op1, op2) \
__builtin_rvv_vsra_vx_i8mf2((vint8mf2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsra_vx_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vx_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsra_vx_i8mf4(op0, op1, op2) \
__builtin_rvv_vsra_vx_i8mf4((vint8mf4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsra_vx_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vx_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsra_vx_i8mf8(op0, op1, op2) \
__builtin_rvv_vsra_vx_i8mf8((vint8mf8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsra_vx_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vx_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsra_vx_i16m1(op0, op1, op2) \
__builtin_rvv_vsra_vx_i16m1((vint16m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsra_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vx_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsra_vx_i16m2(op0, op1, op2) \
__builtin_rvv_vsra_vx_i16m2((vint16m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsra_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vx_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsra_vx_i16m4(op0, op1, op2) \
__builtin_rvv_vsra_vx_i16m4((vint16m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsra_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vx_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsra_vx_i16m8(op0, op1, op2) \
__builtin_rvv_vsra_vx_i16m8((vint16m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsra_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vx_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (size_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsra_vx_i16mf2(op0, op1, op2) \
__builtin_rvv_vsra_vx_i16mf2((vint16mf2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsra_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vx_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsra_vx_i16mf4(op0, op1, op2) \
__builtin_rvv_vsra_vx_i16mf4((vint16mf4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsra_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vx_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsra_vx_i32m1(op0, op1, op2) \
__builtin_rvv_vsra_vx_i32m1((vint32m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsra_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vx_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsra_vx_i32m2(op0, op1, op2) \
__builtin_rvv_vsra_vx_i32m2((vint32m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsra_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vx_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsra_vx_i32m4(op0, op1, op2) \
__builtin_rvv_vsra_vx_i32m4((vint32m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsra_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vx_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsra_vx_i32m8(op0, op1, op2) \
__builtin_rvv_vsra_vx_i32m8((vint32m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsra_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vx_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsra_vx_i32mf2(op0, op1, op2) \
__builtin_rvv_vsra_vx_i32mf2((vint32mf2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsra_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vx_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsra_vx_i64m1(op0, op1, op2) \
__builtin_rvv_vsra_vx_i64m1((vint64m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsra_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vx_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsra_vx_i64m2(op0, op1, op2) \
__builtin_rvv_vsra_vx_i64m2((vint64m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsra_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vx_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsra_vx_i64m4(op0, op1, op2) \
__builtin_rvv_vsra_vx_i64m4((vint64m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsra_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vx_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsra_vx_i64m8(op0, op1, op2) \
__builtin_rvv_vsra_vx_i64m8((vint64m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsra_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vx_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnsrl_wv_u8m1(op0, op1, op2) \
__builtin_rvv_vnsrl_wv_u8m1((vuint16m2_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vnsrl_wv_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsrl_wv_u8m1_m((vuint8m1_t)(op0), (vuint16m2_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnsrl_wv_u8m2(op0, op1, op2) \
__builtin_rvv_vnsrl_wv_u8m2((vuint16m4_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vnsrl_wv_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsrl_wv_u8m2_m((vuint8m2_t)(op0), (vuint16m4_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnsrl_wv_u8m4(op0, op1, op2) \
__builtin_rvv_vnsrl_wv_u8m4((vuint16m8_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vnsrl_wv_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsrl_wv_u8m4_m((vuint8m4_t)(op0), (vuint16m8_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vnsrl_wv_u8mf2(op0, op1, op2) \
__builtin_rvv_vnsrl_wv_u8mf2((vuint16m1_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vnsrl_wv_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsrl_wv_u8mf2_m((vuint8mf2_t)(op0), (vuint16m1_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnsrl_wv_u8mf4(op0, op1, op2) \
__builtin_rvv_vnsrl_wv_u8mf4((vuint16mf2_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vnsrl_wv_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsrl_wv_u8mf4_m((vuint8mf4_t)(op0), (vuint16mf2_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnsrl_wv_u8mf8(op0, op1, op2) \
__builtin_rvv_vnsrl_wv_u8mf8((vuint16mf4_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vnsrl_wv_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsrl_wv_u8mf8_m((vuint8mf8_t)(op0), (vuint16mf4_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnsrl_wv_u16m1(op0, op1, op2) \
__builtin_rvv_vnsrl_wv_u16m1((vuint32m2_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vnsrl_wv_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsrl_wv_u16m1_m((vuint16m1_t)(op0), (vuint32m2_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnsrl_wv_u16m2(op0, op1, op2) \
__builtin_rvv_vnsrl_wv_u16m2((vuint32m4_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vnsrl_wv_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsrl_wv_u16m2_m((vuint16m2_t)(op0), (vuint32m4_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnsrl_wv_u16m4(op0, op1, op2) \
__builtin_rvv_vnsrl_wv_u16m4((vuint32m8_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vnsrl_wv_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsrl_wv_u16m4_m((vuint16m4_t)(op0), (vuint32m8_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnsrl_wv_u16mf2(op0, op1, op2) \
__builtin_rvv_vnsrl_wv_u16mf2((vuint32m1_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vnsrl_wv_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsrl_wv_u16mf2_m((vuint16mf2_t)(op0), (vuint32m1_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnsrl_wv_u16mf4(op0, op1, op2) \
__builtin_rvv_vnsrl_wv_u16mf4((vuint32mf2_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vnsrl_wv_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsrl_wv_u16mf4_m((vuint16mf4_t)(op0), (vuint32mf2_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnsrl_wv_u32m1(op0, op1, op2) \
__builtin_rvv_vnsrl_wv_u32m1((vuint64m2_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vnsrl_wv_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsrl_wv_u32m1_m((vuint32m1_t)(op0), (vuint64m2_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnsrl_wv_u32m2(op0, op1, op2) \
__builtin_rvv_vnsrl_wv_u32m2((vuint64m4_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vnsrl_wv_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsrl_wv_u32m2_m((vuint32m2_t)(op0), (vuint64m4_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnsrl_wv_u32m4(op0, op1, op2) \
__builtin_rvv_vnsrl_wv_u32m4((vuint64m8_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vnsrl_wv_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsrl_wv_u32m4_m((vuint32m4_t)(op0), (vuint64m8_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnsrl_wv_u32mf2(op0, op1, op2) \
__builtin_rvv_vnsrl_wv_u32mf2((vuint64m1_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vnsrl_wv_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsrl_wv_u32mf2_m((vuint32mf2_t)(op0), (vuint64m1_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnsrl_wx_u8m1(op0, op1, op2) \
__builtin_rvv_vnsrl_wx_u8m1((vuint16m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnsrl_wx_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsrl_wx_u8m1_m((vuint8m1_t)(op0), (vuint16m2_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnsrl_wx_u8m2(op0, op1, op2) \
__builtin_rvv_vnsrl_wx_u8m2((vuint16m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnsrl_wx_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsrl_wx_u8m2_m((vuint8m2_t)(op0), (vuint16m4_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnsrl_wx_u8m4(op0, op1, op2) \
__builtin_rvv_vnsrl_wx_u8m4((vuint16m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnsrl_wx_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsrl_wx_u8m4_m((vuint8m4_t)(op0), (vuint16m8_t)(op1), (size_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vnsrl_wx_u8mf2(op0, op1, op2) \
__builtin_rvv_vnsrl_wx_u8mf2((vuint16m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnsrl_wx_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsrl_wx_u8mf2_m((vuint8mf2_t)(op0), (vuint16m1_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnsrl_wx_u8mf4(op0, op1, op2) \
__builtin_rvv_vnsrl_wx_u8mf4((vuint16mf2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnsrl_wx_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsrl_wx_u8mf4_m((vuint8mf4_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnsrl_wx_u8mf8(op0, op1, op2) \
__builtin_rvv_vnsrl_wx_u8mf8((vuint16mf4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnsrl_wx_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsrl_wx_u8mf8_m((vuint8mf8_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnsrl_wx_u16m1(op0, op1, op2) \
__builtin_rvv_vnsrl_wx_u16m1((vuint32m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnsrl_wx_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsrl_wx_u16m1_m((vuint16m1_t)(op0), (vuint32m2_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnsrl_wx_u16m2(op0, op1, op2) \
__builtin_rvv_vnsrl_wx_u16m2((vuint32m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnsrl_wx_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsrl_wx_u16m2_m((vuint16m2_t)(op0), (vuint32m4_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnsrl_wx_u16m4(op0, op1, op2) \
__builtin_rvv_vnsrl_wx_u16m4((vuint32m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnsrl_wx_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsrl_wx_u16m4_m((vuint16m4_t)(op0), (vuint32m8_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnsrl_wx_u16mf2(op0, op1, op2) \
__builtin_rvv_vnsrl_wx_u16mf2((vuint32m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnsrl_wx_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsrl_wx_u16mf2_m((vuint16mf2_t)(op0), (vuint32m1_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnsrl_wx_u16mf4(op0, op1, op2) \
__builtin_rvv_vnsrl_wx_u16mf4((vuint32mf2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnsrl_wx_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsrl_wx_u16mf4_m((vuint16mf4_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnsrl_wx_u32m1(op0, op1, op2) \
__builtin_rvv_vnsrl_wx_u32m1((vuint64m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnsrl_wx_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsrl_wx_u32m1_m((vuint32m1_t)(op0), (vuint64m2_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnsrl_wx_u32m2(op0, op1, op2) \
__builtin_rvv_vnsrl_wx_u32m2((vuint64m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnsrl_wx_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsrl_wx_u32m2_m((vuint32m2_t)(op0), (vuint64m4_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnsrl_wx_u32m4(op0, op1, op2) \
__builtin_rvv_vnsrl_wx_u32m4((vuint64m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnsrl_wx_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsrl_wx_u32m4_m((vuint32m4_t)(op0), (vuint64m8_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnsrl_wx_u32mf2(op0, op1, op2) \
__builtin_rvv_vnsrl_wx_u32mf2((vuint64m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnsrl_wx_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsrl_wx_u32mf2_m((vuint32mf2_t)(op0), (vuint64m1_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnsra_wv_i8m1(op0, op1, op2) \
__builtin_rvv_vnsra_wv_i8m1((vint16m2_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vnsra_wv_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsra_wv_i8m1_m((vint8m1_t)(op0), (vint16m2_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnsra_wv_i8m2(op0, op1, op2) \
__builtin_rvv_vnsra_wv_i8m2((vint16m4_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vnsra_wv_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsra_wv_i8m2_m((vint8m2_t)(op0), (vint16m4_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnsra_wv_i8m4(op0, op1, op2) \
__builtin_rvv_vnsra_wv_i8m4((vint16m8_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vnsra_wv_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsra_wv_i8m4_m((vint8m4_t)(op0), (vint16m8_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vnsra_wv_i8mf2(op0, op1, op2) \
__builtin_rvv_vnsra_wv_i8mf2((vint16m1_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vnsra_wv_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsra_wv_i8mf2_m((vint8mf2_t)(op0), (vint16m1_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnsra_wv_i8mf4(op0, op1, op2) \
__builtin_rvv_vnsra_wv_i8mf4((vint16mf2_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vnsra_wv_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsra_wv_i8mf4_m((vint8mf4_t)(op0), (vint16mf2_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnsra_wv_i8mf8(op0, op1, op2) \
__builtin_rvv_vnsra_wv_i8mf8((vint16mf4_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vnsra_wv_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsra_wv_i8mf8_m((vint8mf8_t)(op0), (vint16mf4_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnsra_wv_i16m1(op0, op1, op2) \
__builtin_rvv_vnsra_wv_i16m1((vint32m2_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vnsra_wv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsra_wv_i16m1_m((vint16m1_t)(op0), (vint32m2_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnsra_wv_i16m2(op0, op1, op2) \
__builtin_rvv_vnsra_wv_i16m2((vint32m4_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vnsra_wv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsra_wv_i16m2_m((vint16m2_t)(op0), (vint32m4_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnsra_wv_i16m4(op0, op1, op2) \
__builtin_rvv_vnsra_wv_i16m4((vint32m8_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vnsra_wv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsra_wv_i16m4_m((vint16m4_t)(op0), (vint32m8_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnsra_wv_i16mf2(op0, op1, op2) \
__builtin_rvv_vnsra_wv_i16mf2((vint32m1_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vnsra_wv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsra_wv_i16mf2_m((vint16mf2_t)(op0), (vint32m1_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnsra_wv_i16mf4(op0, op1, op2) \
__builtin_rvv_vnsra_wv_i16mf4((vint32mf2_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vnsra_wv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsra_wv_i16mf4_m((vint16mf4_t)(op0), (vint32mf2_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnsra_wv_i32m1(op0, op1, op2) \
__builtin_rvv_vnsra_wv_i32m1((vint64m2_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vnsra_wv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsra_wv_i32m1_m((vint32m1_t)(op0), (vint64m2_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnsra_wv_i32m2(op0, op1, op2) \
__builtin_rvv_vnsra_wv_i32m2((vint64m4_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vnsra_wv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsra_wv_i32m2_m((vint32m2_t)(op0), (vint64m4_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnsra_wv_i32m4(op0, op1, op2) \
__builtin_rvv_vnsra_wv_i32m4((vint64m8_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vnsra_wv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsra_wv_i32m4_m((vint32m4_t)(op0), (vint64m8_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnsra_wv_i32mf2(op0, op1, op2) \
__builtin_rvv_vnsra_wv_i32mf2((vint64m1_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vnsra_wv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsra_wv_i32mf2_m((vint32mf2_t)(op0), (vint64m1_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnsra_wx_i8m1(op0, op1, op2) \
__builtin_rvv_vnsra_wx_i8m1((vint16m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnsra_wx_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsra_wx_i8m1_m((vint8m1_t)(op0), (vint16m2_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnsra_wx_i8m2(op0, op1, op2) \
__builtin_rvv_vnsra_wx_i8m2((vint16m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnsra_wx_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsra_wx_i8m2_m((vint8m2_t)(op0), (vint16m4_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnsra_wx_i8m4(op0, op1, op2) \
__builtin_rvv_vnsra_wx_i8m4((vint16m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnsra_wx_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsra_wx_i8m4_m((vint8m4_t)(op0), (vint16m8_t)(op1), (size_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vnsra_wx_i8mf2(op0, op1, op2) \
__builtin_rvv_vnsra_wx_i8mf2((vint16m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnsra_wx_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsra_wx_i8mf2_m((vint8mf2_t)(op0), (vint16m1_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnsra_wx_i8mf4(op0, op1, op2) \
__builtin_rvv_vnsra_wx_i8mf4((vint16mf2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnsra_wx_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsra_wx_i8mf4_m((vint8mf4_t)(op0), (vint16mf2_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnsra_wx_i8mf8(op0, op1, op2) \
__builtin_rvv_vnsra_wx_i8mf8((vint16mf4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnsra_wx_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsra_wx_i8mf8_m((vint8mf8_t)(op0), (vint16mf4_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnsra_wx_i16m1(op0, op1, op2) \
__builtin_rvv_vnsra_wx_i16m1((vint32m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnsra_wx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsra_wx_i16m1_m((vint16m1_t)(op0), (vint32m2_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnsra_wx_i16m2(op0, op1, op2) \
__builtin_rvv_vnsra_wx_i16m2((vint32m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnsra_wx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsra_wx_i16m2_m((vint16m2_t)(op0), (vint32m4_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnsra_wx_i16m4(op0, op1, op2) \
__builtin_rvv_vnsra_wx_i16m4((vint32m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnsra_wx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsra_wx_i16m4_m((vint16m4_t)(op0), (vint32m8_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnsra_wx_i16mf2(op0, op1, op2) \
__builtin_rvv_vnsra_wx_i16mf2((vint32m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnsra_wx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsra_wx_i16mf2_m((vint16mf2_t)(op0), (vint32m1_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnsra_wx_i16mf4(op0, op1, op2) \
__builtin_rvv_vnsra_wx_i16mf4((vint32mf2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnsra_wx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsra_wx_i16mf4_m((vint16mf4_t)(op0), (vint32mf2_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnsra_wx_i32m1(op0, op1, op2) \
__builtin_rvv_vnsra_wx_i32m1((vint64m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnsra_wx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsra_wx_i32m1_m((vint32m1_t)(op0), (vint64m2_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnsra_wx_i32m2(op0, op1, op2) \
__builtin_rvv_vnsra_wx_i32m2((vint64m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnsra_wx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsra_wx_i32m2_m((vint32m2_t)(op0), (vint64m4_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnsra_wx_i32m4(op0, op1, op2) \
__builtin_rvv_vnsra_wx_i32m4((vint64m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnsra_wx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsra_wx_i32m4_m((vint32m4_t)(op0), (vint64m8_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnsra_wx_i32mf2(op0, op1, op2) \
__builtin_rvv_vnsra_wx_i32mf2((vint64m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnsra_wx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsra_wx_i32mf2_m((vint32mf2_t)(op0), (vint64m1_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmseq_vv_i8m1_b8(op0, op1, op2) \
__builtin_rvv_vmseq_vv_i8m1_b8((vint8m1_t)(op0), (vint8m1_t)(op1), (size_t)(op2))
#define vmseq_vv_i8m1_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_i8m1_b8_m((vbool8_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmseq_vv_i8m2_b4(op0, op1, op2) \
__builtin_rvv_vmseq_vv_i8m2_b4((vint8m2_t)(op0), (vint8m2_t)(op1), (size_t)(op2))
#define vmseq_vv_i8m2_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_i8m2_b4_m((vbool4_t)(op0), (vint8m2_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmseq_vv_i8m4_b2(op0, op1, op2) \
__builtin_rvv_vmseq_vv_i8m4_b2((vint8m4_t)(op0), (vint8m4_t)(op1), (size_t)(op2))
#define vmseq_vv_i8m4_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_i8m4_b2_m((vbool2_t)(op0), (vint8m4_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmseq_vv_i8m8_b1(op0, op1, op2) \
__builtin_rvv_vmseq_vv_i8m8_b1((vint8m8_t)(op0), (vint8m8_t)(op1), (size_t)(op2))
#define vmseq_vv_i8m8_b1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_i8m8_b1_m((vbool1_t)(op0), (vint8m8_t)(op1), (vint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmseq_vv_i8mf2_b16(op0, op1, op2) \
__builtin_rvv_vmseq_vv_i8mf2_b16((vint8mf2_t)(op0), (vint8mf2_t)(op1), (size_t)(op2))
#define vmseq_vv_i8mf2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_i8mf2_b16_m((vbool16_t)(op0), (vint8mf2_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmseq_vv_i8mf4_b32(op0, op1, op2) \
__builtin_rvv_vmseq_vv_i8mf4_b32((vint8mf4_t)(op0), (vint8mf4_t)(op1), (size_t)(op2))
#define vmseq_vv_i8mf4_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_i8mf4_b32_m((vbool32_t)(op0), (vint8mf4_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmseq_vv_i8mf8_b64(op0, op1, op2) \
__builtin_rvv_vmseq_vv_i8mf8_b64((vint8mf8_t)(op0), (vint8mf8_t)(op1), (size_t)(op2))
#define vmseq_vv_i8mf8_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_i8mf8_b64_m((vbool64_t)(op0), (vint8mf8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmseq_vv_i16m1_b16(op0, op1, op2) \
__builtin_rvv_vmseq_vv_i16m1_b16((vint16m1_t)(op0), (vint16m1_t)(op1), (size_t)(op2))
#define vmseq_vv_i16m1_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_i16m1_b16_m((vbool16_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmseq_vv_i16m2_b8(op0, op1, op2) \
__builtin_rvv_vmseq_vv_i16m2_b8((vint16m2_t)(op0), (vint16m2_t)(op1), (size_t)(op2))
#define vmseq_vv_i16m2_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_i16m2_b8_m((vbool8_t)(op0), (vint16m2_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmseq_vv_i16m4_b4(op0, op1, op2) \
__builtin_rvv_vmseq_vv_i16m4_b4((vint16m4_t)(op0), (vint16m4_t)(op1), (size_t)(op2))
#define vmseq_vv_i16m4_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_i16m4_b4_m((vbool4_t)(op0), (vint16m4_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmseq_vv_i16m8_b2(op0, op1, op2) \
__builtin_rvv_vmseq_vv_i16m8_b2((vint16m8_t)(op0), (vint16m8_t)(op1), (size_t)(op2))
#define vmseq_vv_i16m8_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_i16m8_b2_m((vbool2_t)(op0), (vint16m8_t)(op1), (vint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmseq_vv_i16mf2_b32(op0, op1, op2) \
__builtin_rvv_vmseq_vv_i16mf2_b32((vint16mf2_t)(op0), (vint16mf2_t)(op1), (size_t)(op2))
#define vmseq_vv_i16mf2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_i16mf2_b32_m((vbool32_t)(op0), (vint16mf2_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmseq_vv_i16mf4_b64(op0, op1, op2) \
__builtin_rvv_vmseq_vv_i16mf4_b64((vint16mf4_t)(op0), (vint16mf4_t)(op1), (size_t)(op2))
#define vmseq_vv_i16mf4_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_i16mf4_b64_m((vbool64_t)(op0), (vint16mf4_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmseq_vv_i32m1_b32(op0, op1, op2) \
__builtin_rvv_vmseq_vv_i32m1_b32((vint32m1_t)(op0), (vint32m1_t)(op1), (size_t)(op2))
#define vmseq_vv_i32m1_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_i32m1_b32_m((vbool32_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmseq_vv_i32m2_b16(op0, op1, op2) \
__builtin_rvv_vmseq_vv_i32m2_b16((vint32m2_t)(op0), (vint32m2_t)(op1), (size_t)(op2))
#define vmseq_vv_i32m2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_i32m2_b16_m((vbool16_t)(op0), (vint32m2_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmseq_vv_i32m4_b8(op0, op1, op2) \
__builtin_rvv_vmseq_vv_i32m4_b8((vint32m4_t)(op0), (vint32m4_t)(op1), (size_t)(op2))
#define vmseq_vv_i32m4_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_i32m4_b8_m((vbool8_t)(op0), (vint32m4_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmseq_vv_i32m8_b4(op0, op1, op2) \
__builtin_rvv_vmseq_vv_i32m8_b4((vint32m8_t)(op0), (vint32m8_t)(op1), (size_t)(op2))
#define vmseq_vv_i32m8_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_i32m8_b4_m((vbool4_t)(op0), (vint32m8_t)(op1), (vint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmseq_vv_i32mf2_b64(op0, op1, op2) \
__builtin_rvv_vmseq_vv_i32mf2_b64((vint32mf2_t)(op0), (vint32mf2_t)(op1), (size_t)(op2))
#define vmseq_vv_i32mf2_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_i32mf2_b64_m((vbool64_t)(op0), (vint32mf2_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmseq_vv_i64m1_b64(op0, op1, op2) \
__builtin_rvv_vmseq_vv_i64m1_b64((vint64m1_t)(op0), (vint64m1_t)(op1), (size_t)(op2))
#define vmseq_vv_i64m1_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_i64m1_b64_m((vbool64_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmseq_vv_i64m2_b32(op0, op1, op2) \
__builtin_rvv_vmseq_vv_i64m2_b32((vint64m2_t)(op0), (vint64m2_t)(op1), (size_t)(op2))
#define vmseq_vv_i64m2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_i64m2_b32_m((vbool32_t)(op0), (vint64m2_t)(op1), (vint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmseq_vv_i64m4_b16(op0, op1, op2) \
__builtin_rvv_vmseq_vv_i64m4_b16((vint64m4_t)(op0), (vint64m4_t)(op1), (size_t)(op2))
#define vmseq_vv_i64m4_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_i64m4_b16_m((vbool16_t)(op0), (vint64m4_t)(op1), (vint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmseq_vv_i64m8_b8(op0, op1, op2) \
__builtin_rvv_vmseq_vv_i64m8_b8((vint64m8_t)(op0), (vint64m8_t)(op1), (size_t)(op2))
#define vmseq_vv_i64m8_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_i64m8_b8_m((vbool8_t)(op0), (vint64m8_t)(op1), (vint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmseq_vx_i8m1_b8(op0, op1, op2) \
__builtin_rvv_vmseq_vx_i8m1_b8((vint8m1_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmseq_vx_i8m1_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_i8m1_b8_m((vbool8_t)(op0), (vint8m1_t)(op1), (int8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmseq_vx_i8m2_b4(op0, op1, op2) \
__builtin_rvv_vmseq_vx_i8m2_b4((vint8m2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmseq_vx_i8m2_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_i8m2_b4_m((vbool4_t)(op0), (vint8m2_t)(op1), (int8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmseq_vx_i8m4_b2(op0, op1, op2) \
__builtin_rvv_vmseq_vx_i8m4_b2((vint8m4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmseq_vx_i8m4_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_i8m4_b2_m((vbool2_t)(op0), (vint8m4_t)(op1), (int8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmseq_vx_i8m8_b1(op0, op1, op2) \
__builtin_rvv_vmseq_vx_i8m8_b1((vint8m8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmseq_vx_i8m8_b1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_i8m8_b1_m((vbool1_t)(op0), (vint8m8_t)(op1), (int8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmseq_vx_i8mf2_b16(op0, op1, op2) \
__builtin_rvv_vmseq_vx_i8mf2_b16((vint8mf2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmseq_vx_i8mf2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_i8mf2_b16_m((vbool16_t)(op0), (vint8mf2_t)(op1), (int8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmseq_vx_i8mf4_b32(op0, op1, op2) \
__builtin_rvv_vmseq_vx_i8mf4_b32((vint8mf4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmseq_vx_i8mf4_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_i8mf4_b32_m((vbool32_t)(op0), (vint8mf4_t)(op1), (int8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmseq_vx_i8mf8_b64(op0, op1, op2) \
__builtin_rvv_vmseq_vx_i8mf8_b64((vint8mf8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmseq_vx_i8mf8_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_i8mf8_b64_m((vbool64_t)(op0), (vint8mf8_t)(op1), (int8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmseq_vx_i16m1_b16(op0, op1, op2) \
__builtin_rvv_vmseq_vx_i16m1_b16((vint16m1_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmseq_vx_i16m1_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_i16m1_b16_m((vbool16_t)(op0), (vint16m1_t)(op1), (int16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmseq_vx_i16m2_b8(op0, op1, op2) \
__builtin_rvv_vmseq_vx_i16m2_b8((vint16m2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmseq_vx_i16m2_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_i16m2_b8_m((vbool8_t)(op0), (vint16m2_t)(op1), (int16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmseq_vx_i16m4_b4(op0, op1, op2) \
__builtin_rvv_vmseq_vx_i16m4_b4((vint16m4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmseq_vx_i16m4_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_i16m4_b4_m((vbool4_t)(op0), (vint16m4_t)(op1), (int16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmseq_vx_i16m8_b2(op0, op1, op2) \
__builtin_rvv_vmseq_vx_i16m8_b2((vint16m8_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmseq_vx_i16m8_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_i16m8_b2_m((vbool2_t)(op0), (vint16m8_t)(op1), (int16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmseq_vx_i16mf2_b32(op0, op1, op2) \
__builtin_rvv_vmseq_vx_i16mf2_b32((vint16mf2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmseq_vx_i16mf2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_i16mf2_b32_m((vbool32_t)(op0), (vint16mf2_t)(op1), (int16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmseq_vx_i16mf4_b64(op0, op1, op2) \
__builtin_rvv_vmseq_vx_i16mf4_b64((vint16mf4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmseq_vx_i16mf4_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_i16mf4_b64_m((vbool64_t)(op0), (vint16mf4_t)(op1), (int16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmseq_vx_i32m1_b32(op0, op1, op2) \
__builtin_rvv_vmseq_vx_i32m1_b32((vint32m1_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmseq_vx_i32m1_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_i32m1_b32_m((vbool32_t)(op0), (vint32m1_t)(op1), (int32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmseq_vx_i32m2_b16(op0, op1, op2) \
__builtin_rvv_vmseq_vx_i32m2_b16((vint32m2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmseq_vx_i32m2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_i32m2_b16_m((vbool16_t)(op0), (vint32m2_t)(op1), (int32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmseq_vx_i32m4_b8(op0, op1, op2) \
__builtin_rvv_vmseq_vx_i32m4_b8((vint32m4_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmseq_vx_i32m4_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_i32m4_b8_m((vbool8_t)(op0), (vint32m4_t)(op1), (int32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmseq_vx_i32m8_b4(op0, op1, op2) \
__builtin_rvv_vmseq_vx_i32m8_b4((vint32m8_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmseq_vx_i32m8_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_i32m8_b4_m((vbool4_t)(op0), (vint32m8_t)(op1), (int32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmseq_vx_i32mf2_b64(op0, op1, op2) \
__builtin_rvv_vmseq_vx_i32mf2_b64((vint32mf2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmseq_vx_i32mf2_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_i32mf2_b64_m((vbool64_t)(op0), (vint32mf2_t)(op1), (int32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmseq_vx_i64m1_b64(op0, op1, op2) \
__builtin_rvv_vmseq_vx_i64m1_b64((vint64m1_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmseq_vx_i64m1_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_i64m1_b64_m((vbool64_t)(op0), (vint64m1_t)(op1), (int64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmseq_vx_i64m2_b32(op0, op1, op2) \
__builtin_rvv_vmseq_vx_i64m2_b32((vint64m2_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmseq_vx_i64m2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_i64m2_b32_m((vbool32_t)(op0), (vint64m2_t)(op1), (int64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmseq_vx_i64m4_b16(op0, op1, op2) \
__builtin_rvv_vmseq_vx_i64m4_b16((vint64m4_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmseq_vx_i64m4_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_i64m4_b16_m((vbool16_t)(op0), (vint64m4_t)(op1), (int64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmseq_vx_i64m8_b8(op0, op1, op2) \
__builtin_rvv_vmseq_vx_i64m8_b8((vint64m8_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmseq_vx_i64m8_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_i64m8_b8_m((vbool8_t)(op0), (vint64m8_t)(op1), (int64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmseq_vv_u8m1_b8(op0, op1, op2) \
__builtin_rvv_vmseq_vv_u8m1_b8((vuint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vmseq_vv_u8m1_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_u8m1_b8_m((vbool8_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmseq_vv_u8m2_b4(op0, op1, op2) \
__builtin_rvv_vmseq_vv_u8m2_b4((vuint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vmseq_vv_u8m2_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_u8m2_b4_m((vbool4_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmseq_vv_u8m4_b2(op0, op1, op2) \
__builtin_rvv_vmseq_vv_u8m4_b2((vuint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vmseq_vv_u8m4_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_u8m4_b2_m((vbool2_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmseq_vv_u8m8_b1(op0, op1, op2) \
__builtin_rvv_vmseq_vv_u8m8_b1((vuint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vmseq_vv_u8m8_b1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_u8m8_b1_m((vbool1_t)(op0), (vuint8m8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmseq_vv_u8mf2_b16(op0, op1, op2) \
__builtin_rvv_vmseq_vv_u8mf2_b16((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vmseq_vv_u8mf2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_u8mf2_b16_m((vbool16_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmseq_vv_u8mf4_b32(op0, op1, op2) \
__builtin_rvv_vmseq_vv_u8mf4_b32((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vmseq_vv_u8mf4_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_u8mf4_b32_m((vbool32_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmseq_vv_u8mf8_b64(op0, op1, op2) \
__builtin_rvv_vmseq_vv_u8mf8_b64((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vmseq_vv_u8mf8_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_u8mf8_b64_m((vbool64_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmseq_vv_u16m1_b16(op0, op1, op2) \
__builtin_rvv_vmseq_vv_u16m1_b16((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vmseq_vv_u16m1_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_u16m1_b16_m((vbool16_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmseq_vv_u16m2_b8(op0, op1, op2) \
__builtin_rvv_vmseq_vv_u16m2_b8((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vmseq_vv_u16m2_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_u16m2_b8_m((vbool8_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmseq_vv_u16m4_b4(op0, op1, op2) \
__builtin_rvv_vmseq_vv_u16m4_b4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vmseq_vv_u16m4_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_u16m4_b4_m((vbool4_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmseq_vv_u16m8_b2(op0, op1, op2) \
__builtin_rvv_vmseq_vv_u16m8_b2((vuint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vmseq_vv_u16m8_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_u16m8_b2_m((vbool2_t)(op0), (vuint16m8_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmseq_vv_u16mf2_b32(op0, op1, op2) \
__builtin_rvv_vmseq_vv_u16mf2_b32((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vmseq_vv_u16mf2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_u16mf2_b32_m((vbool32_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmseq_vv_u16mf4_b64(op0, op1, op2) \
__builtin_rvv_vmseq_vv_u16mf4_b64((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vmseq_vv_u16mf4_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_u16mf4_b64_m((vbool64_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmseq_vv_u32m1_b32(op0, op1, op2) \
__builtin_rvv_vmseq_vv_u32m1_b32((vuint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vmseq_vv_u32m1_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_u32m1_b32_m((vbool32_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmseq_vv_u32m2_b16(op0, op1, op2) \
__builtin_rvv_vmseq_vv_u32m2_b16((vuint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vmseq_vv_u32m2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_u32m2_b16_m((vbool16_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmseq_vv_u32m4_b8(op0, op1, op2) \
__builtin_rvv_vmseq_vv_u32m4_b8((vuint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vmseq_vv_u32m4_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_u32m4_b8_m((vbool8_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmseq_vv_u32m8_b4(op0, op1, op2) \
__builtin_rvv_vmseq_vv_u32m8_b4((vuint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vmseq_vv_u32m8_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_u32m8_b4_m((vbool4_t)(op0), (vuint32m8_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmseq_vv_u32mf2_b64(op0, op1, op2) \
__builtin_rvv_vmseq_vv_u32mf2_b64((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vmseq_vv_u32mf2_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_u32mf2_b64_m((vbool64_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmseq_vv_u64m1_b64(op0, op1, op2) \
__builtin_rvv_vmseq_vv_u64m1_b64((vuint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vmseq_vv_u64m1_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_u64m1_b64_m((vbool64_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmseq_vv_u64m2_b32(op0, op1, op2) \
__builtin_rvv_vmseq_vv_u64m2_b32((vuint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vmseq_vv_u64m2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_u64m2_b32_m((vbool32_t)(op0), (vuint64m2_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmseq_vv_u64m4_b16(op0, op1, op2) \
__builtin_rvv_vmseq_vv_u64m4_b16((vuint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vmseq_vv_u64m4_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_u64m4_b16_m((vbool16_t)(op0), (vuint64m4_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmseq_vv_u64m8_b8(op0, op1, op2) \
__builtin_rvv_vmseq_vv_u64m8_b8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vmseq_vv_u64m8_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_u64m8_b8_m((vbool8_t)(op0), (vuint64m8_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmseq_vx_u8m1_b8(op0, op1, op2) \
__builtin_rvv_vmseq_vx_u8m1_b8((vuint8m1_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmseq_vx_u8m1_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_u8m1_b8_m((vbool8_t)(op0), (vuint8m1_t)(op1), (uint8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmseq_vx_u8m2_b4(op0, op1, op2) \
__builtin_rvv_vmseq_vx_u8m2_b4((vuint8m2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmseq_vx_u8m2_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_u8m2_b4_m((vbool4_t)(op0), (vuint8m2_t)(op1), (uint8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmseq_vx_u8m4_b2(op0, op1, op2) \
__builtin_rvv_vmseq_vx_u8m4_b2((vuint8m4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmseq_vx_u8m4_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_u8m4_b2_m((vbool2_t)(op0), (vuint8m4_t)(op1), (uint8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmseq_vx_u8m8_b1(op0, op1, op2) \
__builtin_rvv_vmseq_vx_u8m8_b1((vuint8m8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmseq_vx_u8m8_b1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_u8m8_b1_m((vbool1_t)(op0), (vuint8m8_t)(op1), (uint8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmseq_vx_u8mf2_b16(op0, op1, op2) \
__builtin_rvv_vmseq_vx_u8mf2_b16((vuint8mf2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmseq_vx_u8mf2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_u8mf2_b16_m((vbool16_t)(op0), (vuint8mf2_t)(op1), (uint8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmseq_vx_u8mf4_b32(op0, op1, op2) \
__builtin_rvv_vmseq_vx_u8mf4_b32((vuint8mf4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmseq_vx_u8mf4_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_u8mf4_b32_m((vbool32_t)(op0), (vuint8mf4_t)(op1), (uint8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmseq_vx_u8mf8_b64(op0, op1, op2) \
__builtin_rvv_vmseq_vx_u8mf8_b64((vuint8mf8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmseq_vx_u8mf8_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_u8mf8_b64_m((vbool64_t)(op0), (vuint8mf8_t)(op1), (uint8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmseq_vx_u16m1_b16(op0, op1, op2) \
__builtin_rvv_vmseq_vx_u16m1_b16((vuint16m1_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmseq_vx_u16m1_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_u16m1_b16_m((vbool16_t)(op0), (vuint16m1_t)(op1), (uint16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmseq_vx_u16m2_b8(op0, op1, op2) \
__builtin_rvv_vmseq_vx_u16m2_b8((vuint16m2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmseq_vx_u16m2_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_u16m2_b8_m((vbool8_t)(op0), (vuint16m2_t)(op1), (uint16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmseq_vx_u16m4_b4(op0, op1, op2) \
__builtin_rvv_vmseq_vx_u16m4_b4((vuint16m4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmseq_vx_u16m4_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_u16m4_b4_m((vbool4_t)(op0), (vuint16m4_t)(op1), (uint16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmseq_vx_u16m8_b2(op0, op1, op2) \
__builtin_rvv_vmseq_vx_u16m8_b2((vuint16m8_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmseq_vx_u16m8_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_u16m8_b2_m((vbool2_t)(op0), (vuint16m8_t)(op1), (uint16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmseq_vx_u16mf2_b32(op0, op1, op2) \
__builtin_rvv_vmseq_vx_u16mf2_b32((vuint16mf2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmseq_vx_u16mf2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_u16mf2_b32_m((vbool32_t)(op0), (vuint16mf2_t)(op1), (uint16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmseq_vx_u16mf4_b64(op0, op1, op2) \
__builtin_rvv_vmseq_vx_u16mf4_b64((vuint16mf4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmseq_vx_u16mf4_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_u16mf4_b64_m((vbool64_t)(op0), (vuint16mf4_t)(op1), (uint16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmseq_vx_u32m1_b32(op0, op1, op2) \
__builtin_rvv_vmseq_vx_u32m1_b32((vuint32m1_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmseq_vx_u32m1_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_u32m1_b32_m((vbool32_t)(op0), (vuint32m1_t)(op1), (uint32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmseq_vx_u32m2_b16(op0, op1, op2) \
__builtin_rvv_vmseq_vx_u32m2_b16((vuint32m2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmseq_vx_u32m2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_u32m2_b16_m((vbool16_t)(op0), (vuint32m2_t)(op1), (uint32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmseq_vx_u32m4_b8(op0, op1, op2) \
__builtin_rvv_vmseq_vx_u32m4_b8((vuint32m4_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmseq_vx_u32m4_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_u32m4_b8_m((vbool8_t)(op0), (vuint32m4_t)(op1), (uint32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmseq_vx_u32m8_b4(op0, op1, op2) \
__builtin_rvv_vmseq_vx_u32m8_b4((vuint32m8_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmseq_vx_u32m8_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_u32m8_b4_m((vbool4_t)(op0), (vuint32m8_t)(op1), (uint32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmseq_vx_u32mf2_b64(op0, op1, op2) \
__builtin_rvv_vmseq_vx_u32mf2_b64((vuint32mf2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmseq_vx_u32mf2_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_u32mf2_b64_m((vbool64_t)(op0), (vuint32mf2_t)(op1), (uint32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmseq_vx_u64m1_b64(op0, op1, op2) \
__builtin_rvv_vmseq_vx_u64m1_b64((vuint64m1_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmseq_vx_u64m1_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_u64m1_b64_m((vbool64_t)(op0), (vuint64m1_t)(op1), (uint64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmseq_vx_u64m2_b32(op0, op1, op2) \
__builtin_rvv_vmseq_vx_u64m2_b32((vuint64m2_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmseq_vx_u64m2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_u64m2_b32_m((vbool32_t)(op0), (vuint64m2_t)(op1), (uint64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmseq_vx_u64m4_b16(op0, op1, op2) \
__builtin_rvv_vmseq_vx_u64m4_b16((vuint64m4_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmseq_vx_u64m4_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_u64m4_b16_m((vbool16_t)(op0), (vuint64m4_t)(op1), (uint64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmseq_vx_u64m8_b8(op0, op1, op2) \
__builtin_rvv_vmseq_vx_u64m8_b8((vuint64m8_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmseq_vx_u64m8_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_u64m8_b8_m((vbool8_t)(op0), (vuint64m8_t)(op1), (uint64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vle32_v_u32m1(op0, op1) \
__builtin_rvv_vle32_v_u32m1((const uint32_t *)(op0), (size_t)(op1))
#define vle32_v_u32m1_m(op2, op0, op1, op3) \
__builtin_rvv_vle32_v_u32m1_m((vuint32m1_t)(op0), (const uint32_t *)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vle32_v_u32m2(op0, op1) \
__builtin_rvv_vle32_v_u32m2((const uint32_t *)(op0), (size_t)(op1))
#define vle32_v_u32m2_m(op2, op0, op1, op3) \
__builtin_rvv_vle32_v_u32m2_m((vuint32m2_t)(op0), (const uint32_t *)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vle32_v_u32m4(op0, op1) \
__builtin_rvv_vle32_v_u32m4((const uint32_t *)(op0), (size_t)(op1))
#define vle32_v_u32m4_m(op2, op0, op1, op3) \
__builtin_rvv_vle32_v_u32m4_m((vuint32m4_t)(op0), (const uint32_t *)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vle32_v_u32m8(op0, op1) \
__builtin_rvv_vle32_v_u32m8((const uint32_t *)(op0), (size_t)(op1))
#define vle32_v_u32m8_m(op2, op0, op1, op3) \
__builtin_rvv_vle32_v_u32m8_m((vuint32m8_t)(op0), (const uint32_t *)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vle32_v_u32mf2(op0, op1) \
__builtin_rvv_vle32_v_u32mf2((const uint32_t *)(op0), (size_t)(op1))
#define vle32_v_u32mf2_m(op2, op0, op1, op3) \
__builtin_rvv_vle32_v_u32mf2_m((vuint32mf2_t)(op0), (const uint32_t *)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmsne_vv_i8m1_b8(op0, op1, op2) \
__builtin_rvv_vmsne_vv_i8m1_b8((vint8m1_t)(op0), (vint8m1_t)(op1), (size_t)(op2))
#define vmsne_vv_i8m1_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_i8m1_b8_m((vbool8_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsne_vv_i8m2_b4(op0, op1, op2) \
__builtin_rvv_vmsne_vv_i8m2_b4((vint8m2_t)(op0), (vint8m2_t)(op1), (size_t)(op2))
#define vmsne_vv_i8m2_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_i8m2_b4_m((vbool4_t)(op0), (vint8m2_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsne_vv_i8m4_b2(op0, op1, op2) \
__builtin_rvv_vmsne_vv_i8m4_b2((vint8m4_t)(op0), (vint8m4_t)(op1), (size_t)(op2))
#define vmsne_vv_i8m4_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_i8m4_b2_m((vbool2_t)(op0), (vint8m4_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmsne_vv_i8m8_b1(op0, op1, op2) \
__builtin_rvv_vmsne_vv_i8m8_b1((vint8m8_t)(op0), (vint8m8_t)(op1), (size_t)(op2))
#define vmsne_vv_i8m8_b1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_i8m8_b1_m((vbool1_t)(op0), (vint8m8_t)(op1), (vint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmsne_vv_i8mf2_b16(op0, op1, op2) \
__builtin_rvv_vmsne_vv_i8mf2_b16((vint8mf2_t)(op0), (vint8mf2_t)(op1), (size_t)(op2))
#define vmsne_vv_i8mf2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_i8mf2_b16_m((vbool16_t)(op0), (vint8mf2_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsne_vv_i8mf4_b32(op0, op1, op2) \
__builtin_rvv_vmsne_vv_i8mf4_b32((vint8mf4_t)(op0), (vint8mf4_t)(op1), (size_t)(op2))
#define vmsne_vv_i8mf4_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_i8mf4_b32_m((vbool32_t)(op0), (vint8mf4_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsne_vv_i8mf8_b64(op0, op1, op2) \
__builtin_rvv_vmsne_vv_i8mf8_b64((vint8mf8_t)(op0), (vint8mf8_t)(op1), (size_t)(op2))
#define vmsne_vv_i8mf8_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_i8mf8_b64_m((vbool64_t)(op0), (vint8mf8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsne_vv_i16m1_b16(op0, op1, op2) \
__builtin_rvv_vmsne_vv_i16m1_b16((vint16m1_t)(op0), (vint16m1_t)(op1), (size_t)(op2))
#define vmsne_vv_i16m1_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_i16m1_b16_m((vbool16_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsne_vv_i16m2_b8(op0, op1, op2) \
__builtin_rvv_vmsne_vv_i16m2_b8((vint16m2_t)(op0), (vint16m2_t)(op1), (size_t)(op2))
#define vmsne_vv_i16m2_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_i16m2_b8_m((vbool8_t)(op0), (vint16m2_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsne_vv_i16m4_b4(op0, op1, op2) \
__builtin_rvv_vmsne_vv_i16m4_b4((vint16m4_t)(op0), (vint16m4_t)(op1), (size_t)(op2))
#define vmsne_vv_i16m4_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_i16m4_b4_m((vbool4_t)(op0), (vint16m4_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsne_vv_i16m8_b2(op0, op1, op2) \
__builtin_rvv_vmsne_vv_i16m8_b2((vint16m8_t)(op0), (vint16m8_t)(op1), (size_t)(op2))
#define vmsne_vv_i16m8_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_i16m8_b2_m((vbool2_t)(op0), (vint16m8_t)(op1), (vint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmsne_vv_i16mf2_b32(op0, op1, op2) \
__builtin_rvv_vmsne_vv_i16mf2_b32((vint16mf2_t)(op0), (vint16mf2_t)(op1), (size_t)(op2))
#define vmsne_vv_i16mf2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_i16mf2_b32_m((vbool32_t)(op0), (vint16mf2_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsne_vv_i16mf4_b64(op0, op1, op2) \
__builtin_rvv_vmsne_vv_i16mf4_b64((vint16mf4_t)(op0), (vint16mf4_t)(op1), (size_t)(op2))
#define vmsne_vv_i16mf4_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_i16mf4_b64_m((vbool64_t)(op0), (vint16mf4_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsne_vv_i32m1_b32(op0, op1, op2) \
__builtin_rvv_vmsne_vv_i32m1_b32((vint32m1_t)(op0), (vint32m1_t)(op1), (size_t)(op2))
#define vmsne_vv_i32m1_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_i32m1_b32_m((vbool32_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsne_vv_i32m2_b16(op0, op1, op2) \
__builtin_rvv_vmsne_vv_i32m2_b16((vint32m2_t)(op0), (vint32m2_t)(op1), (size_t)(op2))
#define vmsne_vv_i32m2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_i32m2_b16_m((vbool16_t)(op0), (vint32m2_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsne_vv_i32m4_b8(op0, op1, op2) \
__builtin_rvv_vmsne_vv_i32m4_b8((vint32m4_t)(op0), (vint32m4_t)(op1), (size_t)(op2))
#define vmsne_vv_i32m4_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_i32m4_b8_m((vbool8_t)(op0), (vint32m4_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsne_vv_i32m8_b4(op0, op1, op2) \
__builtin_rvv_vmsne_vv_i32m8_b4((vint32m8_t)(op0), (vint32m8_t)(op1), (size_t)(op2))
#define vmsne_vv_i32m8_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_i32m8_b4_m((vbool4_t)(op0), (vint32m8_t)(op1), (vint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsne_vv_i32mf2_b64(op0, op1, op2) \
__builtin_rvv_vmsne_vv_i32mf2_b64((vint32mf2_t)(op0), (vint32mf2_t)(op1), (size_t)(op2))
#define vmsne_vv_i32mf2_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_i32mf2_b64_m((vbool64_t)(op0), (vint32mf2_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsne_vv_i64m1_b64(op0, op1, op2) \
__builtin_rvv_vmsne_vv_i64m1_b64((vint64m1_t)(op0), (vint64m1_t)(op1), (size_t)(op2))
#define vmsne_vv_i64m1_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_i64m1_b64_m((vbool64_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsne_vv_i64m2_b32(op0, op1, op2) \
__builtin_rvv_vmsne_vv_i64m2_b32((vint64m2_t)(op0), (vint64m2_t)(op1), (size_t)(op2))
#define vmsne_vv_i64m2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_i64m2_b32_m((vbool32_t)(op0), (vint64m2_t)(op1), (vint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsne_vv_i64m4_b16(op0, op1, op2) \
__builtin_rvv_vmsne_vv_i64m4_b16((vint64m4_t)(op0), (vint64m4_t)(op1), (size_t)(op2))
#define vmsne_vv_i64m4_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_i64m4_b16_m((vbool16_t)(op0), (vint64m4_t)(op1), (vint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsne_vv_i64m8_b8(op0, op1, op2) \
__builtin_rvv_vmsne_vv_i64m8_b8((vint64m8_t)(op0), (vint64m8_t)(op1), (size_t)(op2))
#define vmsne_vv_i64m8_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_i64m8_b8_m((vbool8_t)(op0), (vint64m8_t)(op1), (vint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsne_vx_i8m1_b8(op0, op1, op2) \
__builtin_rvv_vmsne_vx_i8m1_b8((vint8m1_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmsne_vx_i8m1_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_i8m1_b8_m((vbool8_t)(op0), (vint8m1_t)(op1), (int8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsne_vx_i8m2_b4(op0, op1, op2) \
__builtin_rvv_vmsne_vx_i8m2_b4((vint8m2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmsne_vx_i8m2_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_i8m2_b4_m((vbool4_t)(op0), (vint8m2_t)(op1), (int8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsne_vx_i8m4_b2(op0, op1, op2) \
__builtin_rvv_vmsne_vx_i8m4_b2((vint8m4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmsne_vx_i8m4_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_i8m4_b2_m((vbool2_t)(op0), (vint8m4_t)(op1), (int8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmsne_vx_i8m8_b1(op0, op1, op2) \
__builtin_rvv_vmsne_vx_i8m8_b1((vint8m8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmsne_vx_i8m8_b1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_i8m8_b1_m((vbool1_t)(op0), (vint8m8_t)(op1), (int8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmsne_vx_i8mf2_b16(op0, op1, op2) \
__builtin_rvv_vmsne_vx_i8mf2_b16((vint8mf2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmsne_vx_i8mf2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_i8mf2_b16_m((vbool16_t)(op0), (vint8mf2_t)(op1), (int8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsne_vx_i8mf4_b32(op0, op1, op2) \
__builtin_rvv_vmsne_vx_i8mf4_b32((vint8mf4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmsne_vx_i8mf4_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_i8mf4_b32_m((vbool32_t)(op0), (vint8mf4_t)(op1), (int8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsne_vx_i8mf8_b64(op0, op1, op2) \
__builtin_rvv_vmsne_vx_i8mf8_b64((vint8mf8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmsne_vx_i8mf8_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_i8mf8_b64_m((vbool64_t)(op0), (vint8mf8_t)(op1), (int8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsne_vx_i16m1_b16(op0, op1, op2) \
__builtin_rvv_vmsne_vx_i16m1_b16((vint16m1_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmsne_vx_i16m1_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_i16m1_b16_m((vbool16_t)(op0), (vint16m1_t)(op1), (int16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsne_vx_i16m2_b8(op0, op1, op2) \
__builtin_rvv_vmsne_vx_i16m2_b8((vint16m2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmsne_vx_i16m2_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_i16m2_b8_m((vbool8_t)(op0), (vint16m2_t)(op1), (int16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsne_vx_i16m4_b4(op0, op1, op2) \
__builtin_rvv_vmsne_vx_i16m4_b4((vint16m4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmsne_vx_i16m4_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_i16m4_b4_m((vbool4_t)(op0), (vint16m4_t)(op1), (int16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsne_vx_i16m8_b2(op0, op1, op2) \
__builtin_rvv_vmsne_vx_i16m8_b2((vint16m8_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmsne_vx_i16m8_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_i16m8_b2_m((vbool2_t)(op0), (vint16m8_t)(op1), (int16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmsne_vx_i16mf2_b32(op0, op1, op2) \
__builtin_rvv_vmsne_vx_i16mf2_b32((vint16mf2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmsne_vx_i16mf2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_i16mf2_b32_m((vbool32_t)(op0), (vint16mf2_t)(op1), (int16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsne_vx_i16mf4_b64(op0, op1, op2) \
__builtin_rvv_vmsne_vx_i16mf4_b64((vint16mf4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmsne_vx_i16mf4_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_i16mf4_b64_m((vbool64_t)(op0), (vint16mf4_t)(op1), (int16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsne_vx_i32m1_b32(op0, op1, op2) \
__builtin_rvv_vmsne_vx_i32m1_b32((vint32m1_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmsne_vx_i32m1_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_i32m1_b32_m((vbool32_t)(op0), (vint32m1_t)(op1), (int32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsne_vx_i32m2_b16(op0, op1, op2) \
__builtin_rvv_vmsne_vx_i32m2_b16((vint32m2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmsne_vx_i32m2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_i32m2_b16_m((vbool16_t)(op0), (vint32m2_t)(op1), (int32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsne_vx_i32m4_b8(op0, op1, op2) \
__builtin_rvv_vmsne_vx_i32m4_b8((vint32m4_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmsne_vx_i32m4_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_i32m4_b8_m((vbool8_t)(op0), (vint32m4_t)(op1), (int32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsne_vx_i32m8_b4(op0, op1, op2) \
__builtin_rvv_vmsne_vx_i32m8_b4((vint32m8_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmsne_vx_i32m8_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_i32m8_b4_m((vbool4_t)(op0), (vint32m8_t)(op1), (int32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsne_vx_i32mf2_b64(op0, op1, op2) \
__builtin_rvv_vmsne_vx_i32mf2_b64((vint32mf2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmsne_vx_i32mf2_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_i32mf2_b64_m((vbool64_t)(op0), (vint32mf2_t)(op1), (int32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsne_vx_i64m1_b64(op0, op1, op2) \
__builtin_rvv_vmsne_vx_i64m1_b64((vint64m1_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmsne_vx_i64m1_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_i64m1_b64_m((vbool64_t)(op0), (vint64m1_t)(op1), (int64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsne_vx_i64m2_b32(op0, op1, op2) \
__builtin_rvv_vmsne_vx_i64m2_b32((vint64m2_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmsne_vx_i64m2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_i64m2_b32_m((vbool32_t)(op0), (vint64m2_t)(op1), (int64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsne_vx_i64m4_b16(op0, op1, op2) \
__builtin_rvv_vmsne_vx_i64m4_b16((vint64m4_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmsne_vx_i64m4_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_i64m4_b16_m((vbool16_t)(op0), (vint64m4_t)(op1), (int64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsne_vx_i64m8_b8(op0, op1, op2) \
__builtin_rvv_vmsne_vx_i64m8_b8((vint64m8_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmsne_vx_i64m8_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_i64m8_b8_m((vbool8_t)(op0), (vint64m8_t)(op1), (int64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsne_vv_u8m1_b8(op0, op1, op2) \
__builtin_rvv_vmsne_vv_u8m1_b8((vuint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vmsne_vv_u8m1_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_u8m1_b8_m((vbool8_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsne_vv_u8m2_b4(op0, op1, op2) \
__builtin_rvv_vmsne_vv_u8m2_b4((vuint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vmsne_vv_u8m2_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_u8m2_b4_m((vbool4_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsne_vv_u8m4_b2(op0, op1, op2) \
__builtin_rvv_vmsne_vv_u8m4_b2((vuint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vmsne_vv_u8m4_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_u8m4_b2_m((vbool2_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmsne_vv_u8m8_b1(op0, op1, op2) \
__builtin_rvv_vmsne_vv_u8m8_b1((vuint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vmsne_vv_u8m8_b1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_u8m8_b1_m((vbool1_t)(op0), (vuint8m8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmsne_vv_u8mf2_b16(op0, op1, op2) \
__builtin_rvv_vmsne_vv_u8mf2_b16((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vmsne_vv_u8mf2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_u8mf2_b16_m((vbool16_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsne_vv_u8mf4_b32(op0, op1, op2) \
__builtin_rvv_vmsne_vv_u8mf4_b32((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vmsne_vv_u8mf4_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_u8mf4_b32_m((vbool32_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsne_vv_u8mf8_b64(op0, op1, op2) \
__builtin_rvv_vmsne_vv_u8mf8_b64((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vmsne_vv_u8mf8_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_u8mf8_b64_m((vbool64_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsne_vv_u16m1_b16(op0, op1, op2) \
__builtin_rvv_vmsne_vv_u16m1_b16((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vmsne_vv_u16m1_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_u16m1_b16_m((vbool16_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsne_vv_u16m2_b8(op0, op1, op2) \
__builtin_rvv_vmsne_vv_u16m2_b8((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vmsne_vv_u16m2_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_u16m2_b8_m((vbool8_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsne_vv_u16m4_b4(op0, op1, op2) \
__builtin_rvv_vmsne_vv_u16m4_b4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vmsne_vv_u16m4_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_u16m4_b4_m((vbool4_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsne_vv_u16m8_b2(op0, op1, op2) \
__builtin_rvv_vmsne_vv_u16m8_b2((vuint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vmsne_vv_u16m8_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_u16m8_b2_m((vbool2_t)(op0), (vuint16m8_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmsne_vv_u16mf2_b32(op0, op1, op2) \
__builtin_rvv_vmsne_vv_u16mf2_b32((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vmsne_vv_u16mf2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_u16mf2_b32_m((vbool32_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsne_vv_u16mf4_b64(op0, op1, op2) \
__builtin_rvv_vmsne_vv_u16mf4_b64((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vmsne_vv_u16mf4_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_u16mf4_b64_m((vbool64_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsne_vv_u32m1_b32(op0, op1, op2) \
__builtin_rvv_vmsne_vv_u32m1_b32((vuint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vmsne_vv_u32m1_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_u32m1_b32_m((vbool32_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsne_vv_u32m2_b16(op0, op1, op2) \
__builtin_rvv_vmsne_vv_u32m2_b16((vuint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vmsne_vv_u32m2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_u32m2_b16_m((vbool16_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsne_vv_u32m4_b8(op0, op1, op2) \
__builtin_rvv_vmsne_vv_u32m4_b8((vuint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vmsne_vv_u32m4_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_u32m4_b8_m((vbool8_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsne_vv_u32m8_b4(op0, op1, op2) \
__builtin_rvv_vmsne_vv_u32m8_b4((vuint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vmsne_vv_u32m8_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_u32m8_b4_m((vbool4_t)(op0), (vuint32m8_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsne_vv_u32mf2_b64(op0, op1, op2) \
__builtin_rvv_vmsne_vv_u32mf2_b64((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vmsne_vv_u32mf2_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_u32mf2_b64_m((vbool64_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsne_vv_u64m1_b64(op0, op1, op2) \
__builtin_rvv_vmsne_vv_u64m1_b64((vuint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vmsne_vv_u64m1_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_u64m1_b64_m((vbool64_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsne_vv_u64m2_b32(op0, op1, op2) \
__builtin_rvv_vmsne_vv_u64m2_b32((vuint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vmsne_vv_u64m2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_u64m2_b32_m((vbool32_t)(op0), (vuint64m2_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsne_vv_u64m4_b16(op0, op1, op2) \
__builtin_rvv_vmsne_vv_u64m4_b16((vuint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vmsne_vv_u64m4_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_u64m4_b16_m((vbool16_t)(op0), (vuint64m4_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsne_vv_u64m8_b8(op0, op1, op2) \
__builtin_rvv_vmsne_vv_u64m8_b8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vmsne_vv_u64m8_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_u64m8_b8_m((vbool8_t)(op0), (vuint64m8_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsne_vx_u8m1_b8(op0, op1, op2) \
__builtin_rvv_vmsne_vx_u8m1_b8((vuint8m1_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsne_vx_u8m1_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_u8m1_b8_m((vbool8_t)(op0), (vuint8m1_t)(op1), (uint8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsne_vx_u8m2_b4(op0, op1, op2) \
__builtin_rvv_vmsne_vx_u8m2_b4((vuint8m2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsne_vx_u8m2_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_u8m2_b4_m((vbool4_t)(op0), (vuint8m2_t)(op1), (uint8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsne_vx_u8m4_b2(op0, op1, op2) \
__builtin_rvv_vmsne_vx_u8m4_b2((vuint8m4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsne_vx_u8m4_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_u8m4_b2_m((vbool2_t)(op0), (vuint8m4_t)(op1), (uint8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmsne_vx_u8m8_b1(op0, op1, op2) \
__builtin_rvv_vmsne_vx_u8m8_b1((vuint8m8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsne_vx_u8m8_b1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_u8m8_b1_m((vbool1_t)(op0), (vuint8m8_t)(op1), (uint8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmsne_vx_u8mf2_b16(op0, op1, op2) \
__builtin_rvv_vmsne_vx_u8mf2_b16((vuint8mf2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsne_vx_u8mf2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_u8mf2_b16_m((vbool16_t)(op0), (vuint8mf2_t)(op1), (uint8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsne_vx_u8mf4_b32(op0, op1, op2) \
__builtin_rvv_vmsne_vx_u8mf4_b32((vuint8mf4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsne_vx_u8mf4_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_u8mf4_b32_m((vbool32_t)(op0), (vuint8mf4_t)(op1), (uint8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsne_vx_u8mf8_b64(op0, op1, op2) \
__builtin_rvv_vmsne_vx_u8mf8_b64((vuint8mf8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsne_vx_u8mf8_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_u8mf8_b64_m((vbool64_t)(op0), (vuint8mf8_t)(op1), (uint8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsne_vx_u16m1_b16(op0, op1, op2) \
__builtin_rvv_vmsne_vx_u16m1_b16((vuint16m1_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmsne_vx_u16m1_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_u16m1_b16_m((vbool16_t)(op0), (vuint16m1_t)(op1), (uint16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsne_vx_u16m2_b8(op0, op1, op2) \
__builtin_rvv_vmsne_vx_u16m2_b8((vuint16m2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmsne_vx_u16m2_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_u16m2_b8_m((vbool8_t)(op0), (vuint16m2_t)(op1), (uint16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsne_vx_u16m4_b4(op0, op1, op2) \
__builtin_rvv_vmsne_vx_u16m4_b4((vuint16m4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmsne_vx_u16m4_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_u16m4_b4_m((vbool4_t)(op0), (vuint16m4_t)(op1), (uint16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsne_vx_u16m8_b2(op0, op1, op2) \
__builtin_rvv_vmsne_vx_u16m8_b2((vuint16m8_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmsne_vx_u16m8_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_u16m8_b2_m((vbool2_t)(op0), (vuint16m8_t)(op1), (uint16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmsne_vx_u16mf2_b32(op0, op1, op2) \
__builtin_rvv_vmsne_vx_u16mf2_b32((vuint16mf2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmsne_vx_u16mf2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_u16mf2_b32_m((vbool32_t)(op0), (vuint16mf2_t)(op1), (uint16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsne_vx_u16mf4_b64(op0, op1, op2) \
__builtin_rvv_vmsne_vx_u16mf4_b64((vuint16mf4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmsne_vx_u16mf4_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_u16mf4_b64_m((vbool64_t)(op0), (vuint16mf4_t)(op1), (uint16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsne_vx_u32m1_b32(op0, op1, op2) \
__builtin_rvv_vmsne_vx_u32m1_b32((vuint32m1_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmsne_vx_u32m1_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_u32m1_b32_m((vbool32_t)(op0), (vuint32m1_t)(op1), (uint32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsne_vx_u32m2_b16(op0, op1, op2) \
__builtin_rvv_vmsne_vx_u32m2_b16((vuint32m2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmsne_vx_u32m2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_u32m2_b16_m((vbool16_t)(op0), (vuint32m2_t)(op1), (uint32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsne_vx_u32m4_b8(op0, op1, op2) \
__builtin_rvv_vmsne_vx_u32m4_b8((vuint32m4_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmsne_vx_u32m4_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_u32m4_b8_m((vbool8_t)(op0), (vuint32m4_t)(op1), (uint32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsne_vx_u32m8_b4(op0, op1, op2) \
__builtin_rvv_vmsne_vx_u32m8_b4((vuint32m8_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmsne_vx_u32m8_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_u32m8_b4_m((vbool4_t)(op0), (vuint32m8_t)(op1), (uint32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsne_vx_u32mf2_b64(op0, op1, op2) \
__builtin_rvv_vmsne_vx_u32mf2_b64((vuint32mf2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmsne_vx_u32mf2_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_u32mf2_b64_m((vbool64_t)(op0), (vuint32mf2_t)(op1), (uint32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsne_vx_u64m1_b64(op0, op1, op2) \
__builtin_rvv_vmsne_vx_u64m1_b64((vuint64m1_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmsne_vx_u64m1_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_u64m1_b64_m((vbool64_t)(op0), (vuint64m1_t)(op1), (uint64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsne_vx_u64m2_b32(op0, op1, op2) \
__builtin_rvv_vmsne_vx_u64m2_b32((vuint64m2_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmsne_vx_u64m2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_u64m2_b32_m((vbool32_t)(op0), (vuint64m2_t)(op1), (uint64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsne_vx_u64m4_b16(op0, op1, op2) \
__builtin_rvv_vmsne_vx_u64m4_b16((vuint64m4_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmsne_vx_u64m4_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_u64m4_b16_m((vbool16_t)(op0), (vuint64m4_t)(op1), (uint64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsne_vx_u64m8_b8(op0, op1, op2) \
__builtin_rvv_vmsne_vx_u64m8_b8((vuint64m8_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmsne_vx_u64m8_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_u64m8_b8_m((vbool8_t)(op0), (vuint64m8_t)(op1), (uint64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsltu_vv_u8m1_b8(op0, op1, op2) \
__builtin_rvv_vmsltu_vv_u8m1_b8((vuint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vmsltu_vv_u8m1_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vv_u8m1_b8_m((vbool8_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsltu_vv_u8m2_b4(op0, op1, op2) \
__builtin_rvv_vmsltu_vv_u8m2_b4((vuint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vmsltu_vv_u8m2_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vv_u8m2_b4_m((vbool4_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsltu_vv_u8m4_b2(op0, op1, op2) \
__builtin_rvv_vmsltu_vv_u8m4_b2((vuint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vmsltu_vv_u8m4_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vv_u8m4_b2_m((vbool2_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmsltu_vv_u8m8_b1(op0, op1, op2) \
__builtin_rvv_vmsltu_vv_u8m8_b1((vuint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vmsltu_vv_u8m8_b1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vv_u8m8_b1_m((vbool1_t)(op0), (vuint8m8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmsltu_vv_u8mf2_b16(op0, op1, op2) \
__builtin_rvv_vmsltu_vv_u8mf2_b16((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vmsltu_vv_u8mf2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vv_u8mf2_b16_m((vbool16_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsltu_vv_u8mf4_b32(op0, op1, op2) \
__builtin_rvv_vmsltu_vv_u8mf4_b32((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vmsltu_vv_u8mf4_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vv_u8mf4_b32_m((vbool32_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsltu_vv_u8mf8_b64(op0, op1, op2) \
__builtin_rvv_vmsltu_vv_u8mf8_b64((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vmsltu_vv_u8mf8_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vv_u8mf8_b64_m((vbool64_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsltu_vv_u16m1_b16(op0, op1, op2) \
__builtin_rvv_vmsltu_vv_u16m1_b16((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vmsltu_vv_u16m1_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vv_u16m1_b16_m((vbool16_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsltu_vv_u16m2_b8(op0, op1, op2) \
__builtin_rvv_vmsltu_vv_u16m2_b8((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vmsltu_vv_u16m2_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vv_u16m2_b8_m((vbool8_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsltu_vv_u16m4_b4(op0, op1, op2) \
__builtin_rvv_vmsltu_vv_u16m4_b4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vmsltu_vv_u16m4_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vv_u16m4_b4_m((vbool4_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsltu_vv_u16m8_b2(op0, op1, op2) \
__builtin_rvv_vmsltu_vv_u16m8_b2((vuint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vmsltu_vv_u16m8_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vv_u16m8_b2_m((vbool2_t)(op0), (vuint16m8_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmsltu_vv_u16mf2_b32(op0, op1, op2) \
__builtin_rvv_vmsltu_vv_u16mf2_b32((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vmsltu_vv_u16mf2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vv_u16mf2_b32_m((vbool32_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsltu_vv_u16mf4_b64(op0, op1, op2) \
__builtin_rvv_vmsltu_vv_u16mf4_b64((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vmsltu_vv_u16mf4_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vv_u16mf4_b64_m((vbool64_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsltu_vv_u32m1_b32(op0, op1, op2) \
__builtin_rvv_vmsltu_vv_u32m1_b32((vuint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vmsltu_vv_u32m1_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vv_u32m1_b32_m((vbool32_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsltu_vv_u32m2_b16(op0, op1, op2) \
__builtin_rvv_vmsltu_vv_u32m2_b16((vuint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vmsltu_vv_u32m2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vv_u32m2_b16_m((vbool16_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsltu_vv_u32m4_b8(op0, op1, op2) \
__builtin_rvv_vmsltu_vv_u32m4_b8((vuint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vmsltu_vv_u32m4_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vv_u32m4_b8_m((vbool8_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsltu_vv_u32m8_b4(op0, op1, op2) \
__builtin_rvv_vmsltu_vv_u32m8_b4((vuint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vmsltu_vv_u32m8_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vv_u32m8_b4_m((vbool4_t)(op0), (vuint32m8_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsltu_vv_u32mf2_b64(op0, op1, op2) \
__builtin_rvv_vmsltu_vv_u32mf2_b64((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vmsltu_vv_u32mf2_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vv_u32mf2_b64_m((vbool64_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsltu_vv_u64m1_b64(op0, op1, op2) \
__builtin_rvv_vmsltu_vv_u64m1_b64((vuint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vmsltu_vv_u64m1_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vv_u64m1_b64_m((vbool64_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsltu_vv_u64m2_b32(op0, op1, op2) \
__builtin_rvv_vmsltu_vv_u64m2_b32((vuint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vmsltu_vv_u64m2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vv_u64m2_b32_m((vbool32_t)(op0), (vuint64m2_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsltu_vv_u64m4_b16(op0, op1, op2) \
__builtin_rvv_vmsltu_vv_u64m4_b16((vuint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vmsltu_vv_u64m4_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vv_u64m4_b16_m((vbool16_t)(op0), (vuint64m4_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsltu_vv_u64m8_b8(op0, op1, op2) \
__builtin_rvv_vmsltu_vv_u64m8_b8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vmsltu_vv_u64m8_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vv_u64m8_b8_m((vbool8_t)(op0), (vuint64m8_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsltu_vx_u8m1_b8(op0, op1, op2) \
__builtin_rvv_vmsltu_vx_u8m1_b8((vuint8m1_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsltu_vx_u8m1_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vx_u8m1_b8_m((vbool8_t)(op0), (vuint8m1_t)(op1), (uint8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsltu_vx_u8m2_b4(op0, op1, op2) \
__builtin_rvv_vmsltu_vx_u8m2_b4((vuint8m2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsltu_vx_u8m2_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vx_u8m2_b4_m((vbool4_t)(op0), (vuint8m2_t)(op1), (uint8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsltu_vx_u8m4_b2(op0, op1, op2) \
__builtin_rvv_vmsltu_vx_u8m4_b2((vuint8m4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsltu_vx_u8m4_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vx_u8m4_b2_m((vbool2_t)(op0), (vuint8m4_t)(op1), (uint8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmsltu_vx_u8m8_b1(op0, op1, op2) \
__builtin_rvv_vmsltu_vx_u8m8_b1((vuint8m8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsltu_vx_u8m8_b1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vx_u8m8_b1_m((vbool1_t)(op0), (vuint8m8_t)(op1), (uint8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmsltu_vx_u8mf2_b16(op0, op1, op2) \
__builtin_rvv_vmsltu_vx_u8mf2_b16((vuint8mf2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsltu_vx_u8mf2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vx_u8mf2_b16_m((vbool16_t)(op0), (vuint8mf2_t)(op1), (uint8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsltu_vx_u8mf4_b32(op0, op1, op2) \
__builtin_rvv_vmsltu_vx_u8mf4_b32((vuint8mf4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsltu_vx_u8mf4_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vx_u8mf4_b32_m((vbool32_t)(op0), (vuint8mf4_t)(op1), (uint8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsltu_vx_u8mf8_b64(op0, op1, op2) \
__builtin_rvv_vmsltu_vx_u8mf8_b64((vuint8mf8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsltu_vx_u8mf8_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vx_u8mf8_b64_m((vbool64_t)(op0), (vuint8mf8_t)(op1), (uint8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsltu_vx_u16m1_b16(op0, op1, op2) \
__builtin_rvv_vmsltu_vx_u16m1_b16((vuint16m1_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmsltu_vx_u16m1_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vx_u16m1_b16_m((vbool16_t)(op0), (vuint16m1_t)(op1), (uint16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsltu_vx_u16m2_b8(op0, op1, op2) \
__builtin_rvv_vmsltu_vx_u16m2_b8((vuint16m2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmsltu_vx_u16m2_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vx_u16m2_b8_m((vbool8_t)(op0), (vuint16m2_t)(op1), (uint16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsltu_vx_u16m4_b4(op0, op1, op2) \
__builtin_rvv_vmsltu_vx_u16m4_b4((vuint16m4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmsltu_vx_u16m4_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vx_u16m4_b4_m((vbool4_t)(op0), (vuint16m4_t)(op1), (uint16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsltu_vx_u16m8_b2(op0, op1, op2) \
__builtin_rvv_vmsltu_vx_u16m8_b2((vuint16m8_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmsltu_vx_u16m8_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vx_u16m8_b2_m((vbool2_t)(op0), (vuint16m8_t)(op1), (uint16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmsltu_vx_u16mf2_b32(op0, op1, op2) \
__builtin_rvv_vmsltu_vx_u16mf2_b32((vuint16mf2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmsltu_vx_u16mf2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vx_u16mf2_b32_m((vbool32_t)(op0), (vuint16mf2_t)(op1), (uint16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsltu_vx_u16mf4_b64(op0, op1, op2) \
__builtin_rvv_vmsltu_vx_u16mf4_b64((vuint16mf4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmsltu_vx_u16mf4_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vx_u16mf4_b64_m((vbool64_t)(op0), (vuint16mf4_t)(op1), (uint16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsltu_vx_u32m1_b32(op0, op1, op2) \
__builtin_rvv_vmsltu_vx_u32m1_b32((vuint32m1_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmsltu_vx_u32m1_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vx_u32m1_b32_m((vbool32_t)(op0), (vuint32m1_t)(op1), (uint32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsltu_vx_u32m2_b16(op0, op1, op2) \
__builtin_rvv_vmsltu_vx_u32m2_b16((vuint32m2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmsltu_vx_u32m2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vx_u32m2_b16_m((vbool16_t)(op0), (vuint32m2_t)(op1), (uint32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsltu_vx_u32m4_b8(op0, op1, op2) \
__builtin_rvv_vmsltu_vx_u32m4_b8((vuint32m4_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmsltu_vx_u32m4_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vx_u32m4_b8_m((vbool8_t)(op0), (vuint32m4_t)(op1), (uint32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsltu_vx_u32m8_b4(op0, op1, op2) \
__builtin_rvv_vmsltu_vx_u32m8_b4((vuint32m8_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmsltu_vx_u32m8_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vx_u32m8_b4_m((vbool4_t)(op0), (vuint32m8_t)(op1), (uint32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsltu_vx_u32mf2_b64(op0, op1, op2) \
__builtin_rvv_vmsltu_vx_u32mf2_b64((vuint32mf2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmsltu_vx_u32mf2_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vx_u32mf2_b64_m((vbool64_t)(op0), (vuint32mf2_t)(op1), (uint32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsltu_vx_u64m1_b64(op0, op1, op2) \
__builtin_rvv_vmsltu_vx_u64m1_b64((vuint64m1_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmsltu_vx_u64m1_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vx_u64m1_b64_m((vbool64_t)(op0), (vuint64m1_t)(op1), (uint64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsltu_vx_u64m2_b32(op0, op1, op2) \
__builtin_rvv_vmsltu_vx_u64m2_b32((vuint64m2_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmsltu_vx_u64m2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vx_u64m2_b32_m((vbool32_t)(op0), (vuint64m2_t)(op1), (uint64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsltu_vx_u64m4_b16(op0, op1, op2) \
__builtin_rvv_vmsltu_vx_u64m4_b16((vuint64m4_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmsltu_vx_u64m4_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vx_u64m4_b16_m((vbool16_t)(op0), (vuint64m4_t)(op1), (uint64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsltu_vx_u64m8_b8(op0, op1, op2) \
__builtin_rvv_vmsltu_vx_u64m8_b8((vuint64m8_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmsltu_vx_u64m8_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vx_u64m8_b8_m((vbool8_t)(op0), (vuint64m8_t)(op1), (uint64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmslt_vv_i8m1_b8(op0, op1, op2) \
__builtin_rvv_vmslt_vv_i8m1_b8((vint8m1_t)(op0), (vint8m1_t)(op1), (size_t)(op2))
#define vmslt_vv_i8m1_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vv_i8m1_b8_m((vbool8_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmslt_vv_i8m2_b4(op0, op1, op2) \
__builtin_rvv_vmslt_vv_i8m2_b4((vint8m2_t)(op0), (vint8m2_t)(op1), (size_t)(op2))
#define vmslt_vv_i8m2_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vv_i8m2_b4_m((vbool4_t)(op0), (vint8m2_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmslt_vv_i8m4_b2(op0, op1, op2) \
__builtin_rvv_vmslt_vv_i8m4_b2((vint8m4_t)(op0), (vint8m4_t)(op1), (size_t)(op2))
#define vmslt_vv_i8m4_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vv_i8m4_b2_m((vbool2_t)(op0), (vint8m4_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmslt_vv_i8m8_b1(op0, op1, op2) \
__builtin_rvv_vmslt_vv_i8m8_b1((vint8m8_t)(op0), (vint8m8_t)(op1), (size_t)(op2))
#define vmslt_vv_i8m8_b1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vv_i8m8_b1_m((vbool1_t)(op0), (vint8m8_t)(op1), (vint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmslt_vv_i8mf2_b16(op0, op1, op2) \
__builtin_rvv_vmslt_vv_i8mf2_b16((vint8mf2_t)(op0), (vint8mf2_t)(op1), (size_t)(op2))
#define vmslt_vv_i8mf2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vv_i8mf2_b16_m((vbool16_t)(op0), (vint8mf2_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmslt_vv_i8mf4_b32(op0, op1, op2) \
__builtin_rvv_vmslt_vv_i8mf4_b32((vint8mf4_t)(op0), (vint8mf4_t)(op1), (size_t)(op2))
#define vmslt_vv_i8mf4_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vv_i8mf4_b32_m((vbool32_t)(op0), (vint8mf4_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmslt_vv_i8mf8_b64(op0, op1, op2) \
__builtin_rvv_vmslt_vv_i8mf8_b64((vint8mf8_t)(op0), (vint8mf8_t)(op1), (size_t)(op2))
#define vmslt_vv_i8mf8_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vv_i8mf8_b64_m((vbool64_t)(op0), (vint8mf8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmslt_vv_i16m1_b16(op0, op1, op2) \
__builtin_rvv_vmslt_vv_i16m1_b16((vint16m1_t)(op0), (vint16m1_t)(op1), (size_t)(op2))
#define vmslt_vv_i16m1_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vv_i16m1_b16_m((vbool16_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmslt_vv_i16m2_b8(op0, op1, op2) \
__builtin_rvv_vmslt_vv_i16m2_b8((vint16m2_t)(op0), (vint16m2_t)(op1), (size_t)(op2))
#define vmslt_vv_i16m2_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vv_i16m2_b8_m((vbool8_t)(op0), (vint16m2_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmslt_vv_i16m4_b4(op0, op1, op2) \
__builtin_rvv_vmslt_vv_i16m4_b4((vint16m4_t)(op0), (vint16m4_t)(op1), (size_t)(op2))
#define vmslt_vv_i16m4_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vv_i16m4_b4_m((vbool4_t)(op0), (vint16m4_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmslt_vv_i16m8_b2(op0, op1, op2) \
__builtin_rvv_vmslt_vv_i16m8_b2((vint16m8_t)(op0), (vint16m8_t)(op1), (size_t)(op2))
#define vmslt_vv_i16m8_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vv_i16m8_b2_m((vbool2_t)(op0), (vint16m8_t)(op1), (vint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmslt_vv_i16mf2_b32(op0, op1, op2) \
__builtin_rvv_vmslt_vv_i16mf2_b32((vint16mf2_t)(op0), (vint16mf2_t)(op1), (size_t)(op2))
#define vmslt_vv_i16mf2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vv_i16mf2_b32_m((vbool32_t)(op0), (vint16mf2_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmslt_vv_i16mf4_b64(op0, op1, op2) \
__builtin_rvv_vmslt_vv_i16mf4_b64((vint16mf4_t)(op0), (vint16mf4_t)(op1), (size_t)(op2))
#define vmslt_vv_i16mf4_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vv_i16mf4_b64_m((vbool64_t)(op0), (vint16mf4_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmslt_vv_i32m1_b32(op0, op1, op2) \
__builtin_rvv_vmslt_vv_i32m1_b32((vint32m1_t)(op0), (vint32m1_t)(op1), (size_t)(op2))
#define vmslt_vv_i32m1_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vv_i32m1_b32_m((vbool32_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmslt_vv_i32m2_b16(op0, op1, op2) \
__builtin_rvv_vmslt_vv_i32m2_b16((vint32m2_t)(op0), (vint32m2_t)(op1), (size_t)(op2))
#define vmslt_vv_i32m2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vv_i32m2_b16_m((vbool16_t)(op0), (vint32m2_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmslt_vv_i32m4_b8(op0, op1, op2) \
__builtin_rvv_vmslt_vv_i32m4_b8((vint32m4_t)(op0), (vint32m4_t)(op1), (size_t)(op2))
#define vmslt_vv_i32m4_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vv_i32m4_b8_m((vbool8_t)(op0), (vint32m4_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmslt_vv_i32m8_b4(op0, op1, op2) \
__builtin_rvv_vmslt_vv_i32m8_b4((vint32m8_t)(op0), (vint32m8_t)(op1), (size_t)(op2))
#define vmslt_vv_i32m8_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vv_i32m8_b4_m((vbool4_t)(op0), (vint32m8_t)(op1), (vint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmslt_vv_i32mf2_b64(op0, op1, op2) \
__builtin_rvv_vmslt_vv_i32mf2_b64((vint32mf2_t)(op0), (vint32mf2_t)(op1), (size_t)(op2))
#define vmslt_vv_i32mf2_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vv_i32mf2_b64_m((vbool64_t)(op0), (vint32mf2_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmslt_vv_i64m1_b64(op0, op1, op2) \
__builtin_rvv_vmslt_vv_i64m1_b64((vint64m1_t)(op0), (vint64m1_t)(op1), (size_t)(op2))
#define vmslt_vv_i64m1_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vv_i64m1_b64_m((vbool64_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmslt_vv_i64m2_b32(op0, op1, op2) \
__builtin_rvv_vmslt_vv_i64m2_b32((vint64m2_t)(op0), (vint64m2_t)(op1), (size_t)(op2))
#define vmslt_vv_i64m2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vv_i64m2_b32_m((vbool32_t)(op0), (vint64m2_t)(op1), (vint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmslt_vv_i64m4_b16(op0, op1, op2) \
__builtin_rvv_vmslt_vv_i64m4_b16((vint64m4_t)(op0), (vint64m4_t)(op1), (size_t)(op2))
#define vmslt_vv_i64m4_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vv_i64m4_b16_m((vbool16_t)(op0), (vint64m4_t)(op1), (vint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmslt_vv_i64m8_b8(op0, op1, op2) \
__builtin_rvv_vmslt_vv_i64m8_b8((vint64m8_t)(op0), (vint64m8_t)(op1), (size_t)(op2))
#define vmslt_vv_i64m8_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vv_i64m8_b8_m((vbool8_t)(op0), (vint64m8_t)(op1), (vint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmslt_vx_i8m1_b8(op0, op1, op2) \
__builtin_rvv_vmslt_vx_i8m1_b8((vint8m1_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmslt_vx_i8m1_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vx_i8m1_b8_m((vbool8_t)(op0), (vint8m1_t)(op1), (int8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmslt_vx_i8m2_b4(op0, op1, op2) \
__builtin_rvv_vmslt_vx_i8m2_b4((vint8m2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmslt_vx_i8m2_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vx_i8m2_b4_m((vbool4_t)(op0), (vint8m2_t)(op1), (int8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmslt_vx_i8m4_b2(op0, op1, op2) \
__builtin_rvv_vmslt_vx_i8m4_b2((vint8m4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmslt_vx_i8m4_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vx_i8m4_b2_m((vbool2_t)(op0), (vint8m4_t)(op1), (int8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmslt_vx_i8m8_b1(op0, op1, op2) \
__builtin_rvv_vmslt_vx_i8m8_b1((vint8m8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmslt_vx_i8m8_b1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vx_i8m8_b1_m((vbool1_t)(op0), (vint8m8_t)(op1), (int8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmslt_vx_i8mf2_b16(op0, op1, op2) \
__builtin_rvv_vmslt_vx_i8mf2_b16((vint8mf2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmslt_vx_i8mf2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vx_i8mf2_b16_m((vbool16_t)(op0), (vint8mf2_t)(op1), (int8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmslt_vx_i8mf4_b32(op0, op1, op2) \
__builtin_rvv_vmslt_vx_i8mf4_b32((vint8mf4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmslt_vx_i8mf4_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vx_i8mf4_b32_m((vbool32_t)(op0), (vint8mf4_t)(op1), (int8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmslt_vx_i8mf8_b64(op0, op1, op2) \
__builtin_rvv_vmslt_vx_i8mf8_b64((vint8mf8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmslt_vx_i8mf8_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vx_i8mf8_b64_m((vbool64_t)(op0), (vint8mf8_t)(op1), (int8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmslt_vx_i16m1_b16(op0, op1, op2) \
__builtin_rvv_vmslt_vx_i16m1_b16((vint16m1_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmslt_vx_i16m1_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vx_i16m1_b16_m((vbool16_t)(op0), (vint16m1_t)(op1), (int16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmslt_vx_i16m2_b8(op0, op1, op2) \
__builtin_rvv_vmslt_vx_i16m2_b8((vint16m2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmslt_vx_i16m2_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vx_i16m2_b8_m((vbool8_t)(op0), (vint16m2_t)(op1), (int16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmslt_vx_i16m4_b4(op0, op1, op2) \
__builtin_rvv_vmslt_vx_i16m4_b4((vint16m4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmslt_vx_i16m4_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vx_i16m4_b4_m((vbool4_t)(op0), (vint16m4_t)(op1), (int16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmslt_vx_i16m8_b2(op0, op1, op2) \
__builtin_rvv_vmslt_vx_i16m8_b2((vint16m8_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmslt_vx_i16m8_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vx_i16m8_b2_m((vbool2_t)(op0), (vint16m8_t)(op1), (int16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmslt_vx_i16mf2_b32(op0, op1, op2) \
__builtin_rvv_vmslt_vx_i16mf2_b32((vint16mf2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmslt_vx_i16mf2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vx_i16mf2_b32_m((vbool32_t)(op0), (vint16mf2_t)(op1), (int16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmslt_vx_i16mf4_b64(op0, op1, op2) \
__builtin_rvv_vmslt_vx_i16mf4_b64((vint16mf4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmslt_vx_i16mf4_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vx_i16mf4_b64_m((vbool64_t)(op0), (vint16mf4_t)(op1), (int16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmslt_vx_i32m1_b32(op0, op1, op2) \
__builtin_rvv_vmslt_vx_i32m1_b32((vint32m1_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmslt_vx_i32m1_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vx_i32m1_b32_m((vbool32_t)(op0), (vint32m1_t)(op1), (int32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmslt_vx_i32m2_b16(op0, op1, op2) \
__builtin_rvv_vmslt_vx_i32m2_b16((vint32m2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmslt_vx_i32m2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vx_i32m2_b16_m((vbool16_t)(op0), (vint32m2_t)(op1), (int32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmslt_vx_i32m4_b8(op0, op1, op2) \
__builtin_rvv_vmslt_vx_i32m4_b8((vint32m4_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmslt_vx_i32m4_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vx_i32m4_b8_m((vbool8_t)(op0), (vint32m4_t)(op1), (int32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmslt_vx_i32m8_b4(op0, op1, op2) \
__builtin_rvv_vmslt_vx_i32m8_b4((vint32m8_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmslt_vx_i32m8_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vx_i32m8_b4_m((vbool4_t)(op0), (vint32m8_t)(op1), (int32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmslt_vx_i32mf2_b64(op0, op1, op2) \
__builtin_rvv_vmslt_vx_i32mf2_b64((vint32mf2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmslt_vx_i32mf2_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vx_i32mf2_b64_m((vbool64_t)(op0), (vint32mf2_t)(op1), (int32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmslt_vx_i64m1_b64(op0, op1, op2) \
__builtin_rvv_vmslt_vx_i64m1_b64((vint64m1_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmslt_vx_i64m1_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vx_i64m1_b64_m((vbool64_t)(op0), (vint64m1_t)(op1), (int64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmslt_vx_i64m2_b32(op0, op1, op2) \
__builtin_rvv_vmslt_vx_i64m2_b32((vint64m2_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmslt_vx_i64m2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vx_i64m2_b32_m((vbool32_t)(op0), (vint64m2_t)(op1), (int64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmslt_vx_i64m4_b16(op0, op1, op2) \
__builtin_rvv_vmslt_vx_i64m4_b16((vint64m4_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmslt_vx_i64m4_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vx_i64m4_b16_m((vbool16_t)(op0), (vint64m4_t)(op1), (int64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmslt_vx_i64m8_b8(op0, op1, op2) \
__builtin_rvv_vmslt_vx_i64m8_b8((vint64m8_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmslt_vx_i64m8_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vx_i64m8_b8_m((vbool8_t)(op0), (vint64m8_t)(op1), (int64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsleu_vv_u8m1_b8(op0, op1, op2) \
__builtin_rvv_vmsleu_vv_u8m1_b8((vuint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vmsleu_vv_u8m1_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vv_u8m1_b8_m((vbool8_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsleu_vv_u8m2_b4(op0, op1, op2) \
__builtin_rvv_vmsleu_vv_u8m2_b4((vuint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vmsleu_vv_u8m2_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vv_u8m2_b4_m((vbool4_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsleu_vv_u8m4_b2(op0, op1, op2) \
__builtin_rvv_vmsleu_vv_u8m4_b2((vuint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vmsleu_vv_u8m4_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vv_u8m4_b2_m((vbool2_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmsleu_vv_u8m8_b1(op0, op1, op2) \
__builtin_rvv_vmsleu_vv_u8m8_b1((vuint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vmsleu_vv_u8m8_b1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vv_u8m8_b1_m((vbool1_t)(op0), (vuint8m8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmsleu_vv_u8mf2_b16(op0, op1, op2) \
__builtin_rvv_vmsleu_vv_u8mf2_b16((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vmsleu_vv_u8mf2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vv_u8mf2_b16_m((vbool16_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsleu_vv_u8mf4_b32(op0, op1, op2) \
__builtin_rvv_vmsleu_vv_u8mf4_b32((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vmsleu_vv_u8mf4_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vv_u8mf4_b32_m((vbool32_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsleu_vv_u8mf8_b64(op0, op1, op2) \
__builtin_rvv_vmsleu_vv_u8mf8_b64((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vmsleu_vv_u8mf8_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vv_u8mf8_b64_m((vbool64_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsleu_vv_u16m1_b16(op0, op1, op2) \
__builtin_rvv_vmsleu_vv_u16m1_b16((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vmsleu_vv_u16m1_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vv_u16m1_b16_m((vbool16_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsleu_vv_u16m2_b8(op0, op1, op2) \
__builtin_rvv_vmsleu_vv_u16m2_b8((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vmsleu_vv_u16m2_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vv_u16m2_b8_m((vbool8_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsleu_vv_u16m4_b4(op0, op1, op2) \
__builtin_rvv_vmsleu_vv_u16m4_b4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vmsleu_vv_u16m4_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vv_u16m4_b4_m((vbool4_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsleu_vv_u16m8_b2(op0, op1, op2) \
__builtin_rvv_vmsleu_vv_u16m8_b2((vuint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vmsleu_vv_u16m8_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vv_u16m8_b2_m((vbool2_t)(op0), (vuint16m8_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmsleu_vv_u16mf2_b32(op0, op1, op2) \
__builtin_rvv_vmsleu_vv_u16mf2_b32((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vmsleu_vv_u16mf2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vv_u16mf2_b32_m((vbool32_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsleu_vv_u16mf4_b64(op0, op1, op2) \
__builtin_rvv_vmsleu_vv_u16mf4_b64((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vmsleu_vv_u16mf4_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vv_u16mf4_b64_m((vbool64_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsleu_vv_u32m1_b32(op0, op1, op2) \
__builtin_rvv_vmsleu_vv_u32m1_b32((vuint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vmsleu_vv_u32m1_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vv_u32m1_b32_m((vbool32_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsleu_vv_u32m2_b16(op0, op1, op2) \
__builtin_rvv_vmsleu_vv_u32m2_b16((vuint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vmsleu_vv_u32m2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vv_u32m2_b16_m((vbool16_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsleu_vv_u32m4_b8(op0, op1, op2) \
__builtin_rvv_vmsleu_vv_u32m4_b8((vuint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vmsleu_vv_u32m4_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vv_u32m4_b8_m((vbool8_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsleu_vv_u32m8_b4(op0, op1, op2) \
__builtin_rvv_vmsleu_vv_u32m8_b4((vuint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vmsleu_vv_u32m8_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vv_u32m8_b4_m((vbool4_t)(op0), (vuint32m8_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsleu_vv_u32mf2_b64(op0, op1, op2) \
__builtin_rvv_vmsleu_vv_u32mf2_b64((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vmsleu_vv_u32mf2_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vv_u32mf2_b64_m((vbool64_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsleu_vv_u64m1_b64(op0, op1, op2) \
__builtin_rvv_vmsleu_vv_u64m1_b64((vuint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vmsleu_vv_u64m1_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vv_u64m1_b64_m((vbool64_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsleu_vv_u64m2_b32(op0, op1, op2) \
__builtin_rvv_vmsleu_vv_u64m2_b32((vuint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vmsleu_vv_u64m2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vv_u64m2_b32_m((vbool32_t)(op0), (vuint64m2_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsleu_vv_u64m4_b16(op0, op1, op2) \
__builtin_rvv_vmsleu_vv_u64m4_b16((vuint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vmsleu_vv_u64m4_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vv_u64m4_b16_m((vbool16_t)(op0), (vuint64m4_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsleu_vv_u64m8_b8(op0, op1, op2) \
__builtin_rvv_vmsleu_vv_u64m8_b8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vmsleu_vv_u64m8_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vv_u64m8_b8_m((vbool8_t)(op0), (vuint64m8_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsleu_vx_u8m1_b8(op0, op1, op2) \
__builtin_rvv_vmsleu_vx_u8m1_b8((vuint8m1_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsleu_vx_u8m1_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vx_u8m1_b8_m((vbool8_t)(op0), (vuint8m1_t)(op1), (uint8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsleu_vx_u8m2_b4(op0, op1, op2) \
__builtin_rvv_vmsleu_vx_u8m2_b4((vuint8m2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsleu_vx_u8m2_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vx_u8m2_b4_m((vbool4_t)(op0), (vuint8m2_t)(op1), (uint8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsleu_vx_u8m4_b2(op0, op1, op2) \
__builtin_rvv_vmsleu_vx_u8m4_b2((vuint8m4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsleu_vx_u8m4_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vx_u8m4_b2_m((vbool2_t)(op0), (vuint8m4_t)(op1), (uint8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmsleu_vx_u8m8_b1(op0, op1, op2) \
__builtin_rvv_vmsleu_vx_u8m8_b1((vuint8m8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsleu_vx_u8m8_b1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vx_u8m8_b1_m((vbool1_t)(op0), (vuint8m8_t)(op1), (uint8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmsleu_vx_u8mf2_b16(op0, op1, op2) \
__builtin_rvv_vmsleu_vx_u8mf2_b16((vuint8mf2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsleu_vx_u8mf2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vx_u8mf2_b16_m((vbool16_t)(op0), (vuint8mf2_t)(op1), (uint8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsleu_vx_u8mf4_b32(op0, op1, op2) \
__builtin_rvv_vmsleu_vx_u8mf4_b32((vuint8mf4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsleu_vx_u8mf4_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vx_u8mf4_b32_m((vbool32_t)(op0), (vuint8mf4_t)(op1), (uint8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsleu_vx_u8mf8_b64(op0, op1, op2) \
__builtin_rvv_vmsleu_vx_u8mf8_b64((vuint8mf8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsleu_vx_u8mf8_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vx_u8mf8_b64_m((vbool64_t)(op0), (vuint8mf8_t)(op1), (uint8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsleu_vx_u16m1_b16(op0, op1, op2) \
__builtin_rvv_vmsleu_vx_u16m1_b16((vuint16m1_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmsleu_vx_u16m1_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vx_u16m1_b16_m((vbool16_t)(op0), (vuint16m1_t)(op1), (uint16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsleu_vx_u16m2_b8(op0, op1, op2) \
__builtin_rvv_vmsleu_vx_u16m2_b8((vuint16m2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmsleu_vx_u16m2_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vx_u16m2_b8_m((vbool8_t)(op0), (vuint16m2_t)(op1), (uint16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsleu_vx_u16m4_b4(op0, op1, op2) \
__builtin_rvv_vmsleu_vx_u16m4_b4((vuint16m4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmsleu_vx_u16m4_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vx_u16m4_b4_m((vbool4_t)(op0), (vuint16m4_t)(op1), (uint16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsleu_vx_u16m8_b2(op0, op1, op2) \
__builtin_rvv_vmsleu_vx_u16m8_b2((vuint16m8_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmsleu_vx_u16m8_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vx_u16m8_b2_m((vbool2_t)(op0), (vuint16m8_t)(op1), (uint16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmsleu_vx_u16mf2_b32(op0, op1, op2) \
__builtin_rvv_vmsleu_vx_u16mf2_b32((vuint16mf2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmsleu_vx_u16mf2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vx_u16mf2_b32_m((vbool32_t)(op0), (vuint16mf2_t)(op1), (uint16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsleu_vx_u16mf4_b64(op0, op1, op2) \
__builtin_rvv_vmsleu_vx_u16mf4_b64((vuint16mf4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmsleu_vx_u16mf4_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vx_u16mf4_b64_m((vbool64_t)(op0), (vuint16mf4_t)(op1), (uint16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsleu_vx_u32m1_b32(op0, op1, op2) \
__builtin_rvv_vmsleu_vx_u32m1_b32((vuint32m1_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmsleu_vx_u32m1_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vx_u32m1_b32_m((vbool32_t)(op0), (vuint32m1_t)(op1), (uint32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsleu_vx_u32m2_b16(op0, op1, op2) \
__builtin_rvv_vmsleu_vx_u32m2_b16((vuint32m2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmsleu_vx_u32m2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vx_u32m2_b16_m((vbool16_t)(op0), (vuint32m2_t)(op1), (uint32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsleu_vx_u32m4_b8(op0, op1, op2) \
__builtin_rvv_vmsleu_vx_u32m4_b8((vuint32m4_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmsleu_vx_u32m4_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vx_u32m4_b8_m((vbool8_t)(op0), (vuint32m4_t)(op1), (uint32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsleu_vx_u32m8_b4(op0, op1, op2) \
__builtin_rvv_vmsleu_vx_u32m8_b4((vuint32m8_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmsleu_vx_u32m8_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vx_u32m8_b4_m((vbool4_t)(op0), (vuint32m8_t)(op1), (uint32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsleu_vx_u32mf2_b64(op0, op1, op2) \
__builtin_rvv_vmsleu_vx_u32mf2_b64((vuint32mf2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmsleu_vx_u32mf2_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vx_u32mf2_b64_m((vbool64_t)(op0), (vuint32mf2_t)(op1), (uint32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsleu_vx_u64m1_b64(op0, op1, op2) \
__builtin_rvv_vmsleu_vx_u64m1_b64((vuint64m1_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmsleu_vx_u64m1_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vx_u64m1_b64_m((vbool64_t)(op0), (vuint64m1_t)(op1), (uint64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsleu_vx_u64m2_b32(op0, op1, op2) \
__builtin_rvv_vmsleu_vx_u64m2_b32((vuint64m2_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmsleu_vx_u64m2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vx_u64m2_b32_m((vbool32_t)(op0), (vuint64m2_t)(op1), (uint64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsleu_vx_u64m4_b16(op0, op1, op2) \
__builtin_rvv_vmsleu_vx_u64m4_b16((vuint64m4_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmsleu_vx_u64m4_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vx_u64m4_b16_m((vbool16_t)(op0), (vuint64m4_t)(op1), (uint64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsleu_vx_u64m8_b8(op0, op1, op2) \
__builtin_rvv_vmsleu_vx_u64m8_b8((vuint64m8_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmsleu_vx_u64m8_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vx_u64m8_b8_m((vbool8_t)(op0), (vuint64m8_t)(op1), (uint64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsle_vv_i8m1_b8(op0, op1, op2) \
__builtin_rvv_vmsle_vv_i8m1_b8((vint8m1_t)(op0), (vint8m1_t)(op1), (size_t)(op2))
#define vmsle_vv_i8m1_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vv_i8m1_b8_m((vbool8_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsle_vv_i8m2_b4(op0, op1, op2) \
__builtin_rvv_vmsle_vv_i8m2_b4((vint8m2_t)(op0), (vint8m2_t)(op1), (size_t)(op2))
#define vmsle_vv_i8m2_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vv_i8m2_b4_m((vbool4_t)(op0), (vint8m2_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsle_vv_i8m4_b2(op0, op1, op2) \
__builtin_rvv_vmsle_vv_i8m4_b2((vint8m4_t)(op0), (vint8m4_t)(op1), (size_t)(op2))
#define vmsle_vv_i8m4_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vv_i8m4_b2_m((vbool2_t)(op0), (vint8m4_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmsle_vv_i8m8_b1(op0, op1, op2) \
__builtin_rvv_vmsle_vv_i8m8_b1((vint8m8_t)(op0), (vint8m8_t)(op1), (size_t)(op2))
#define vmsle_vv_i8m8_b1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vv_i8m8_b1_m((vbool1_t)(op0), (vint8m8_t)(op1), (vint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmsle_vv_i8mf2_b16(op0, op1, op2) \
__builtin_rvv_vmsle_vv_i8mf2_b16((vint8mf2_t)(op0), (vint8mf2_t)(op1), (size_t)(op2))
#define vmsle_vv_i8mf2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vv_i8mf2_b16_m((vbool16_t)(op0), (vint8mf2_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsle_vv_i8mf4_b32(op0, op1, op2) \
__builtin_rvv_vmsle_vv_i8mf4_b32((vint8mf4_t)(op0), (vint8mf4_t)(op1), (size_t)(op2))
#define vmsle_vv_i8mf4_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vv_i8mf4_b32_m((vbool32_t)(op0), (vint8mf4_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsle_vv_i8mf8_b64(op0, op1, op2) \
__builtin_rvv_vmsle_vv_i8mf8_b64((vint8mf8_t)(op0), (vint8mf8_t)(op1), (size_t)(op2))
#define vmsle_vv_i8mf8_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vv_i8mf8_b64_m((vbool64_t)(op0), (vint8mf8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsle_vv_i16m1_b16(op0, op1, op2) \
__builtin_rvv_vmsle_vv_i16m1_b16((vint16m1_t)(op0), (vint16m1_t)(op1), (size_t)(op2))
#define vmsle_vv_i16m1_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vv_i16m1_b16_m((vbool16_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsle_vv_i16m2_b8(op0, op1, op2) \
__builtin_rvv_vmsle_vv_i16m2_b8((vint16m2_t)(op0), (vint16m2_t)(op1), (size_t)(op2))
#define vmsle_vv_i16m2_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vv_i16m2_b8_m((vbool8_t)(op0), (vint16m2_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsle_vv_i16m4_b4(op0, op1, op2) \
__builtin_rvv_vmsle_vv_i16m4_b4((vint16m4_t)(op0), (vint16m4_t)(op1), (size_t)(op2))
#define vmsle_vv_i16m4_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vv_i16m4_b4_m((vbool4_t)(op0), (vint16m4_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsle_vv_i16m8_b2(op0, op1, op2) \
__builtin_rvv_vmsle_vv_i16m8_b2((vint16m8_t)(op0), (vint16m8_t)(op1), (size_t)(op2))
#define vmsle_vv_i16m8_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vv_i16m8_b2_m((vbool2_t)(op0), (vint16m8_t)(op1), (vint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmsle_vv_i16mf2_b32(op0, op1, op2) \
__builtin_rvv_vmsle_vv_i16mf2_b32((vint16mf2_t)(op0), (vint16mf2_t)(op1), (size_t)(op2))
#define vmsle_vv_i16mf2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vv_i16mf2_b32_m((vbool32_t)(op0), (vint16mf2_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsle_vv_i16mf4_b64(op0, op1, op2) \
__builtin_rvv_vmsle_vv_i16mf4_b64((vint16mf4_t)(op0), (vint16mf4_t)(op1), (size_t)(op2))
#define vmsle_vv_i16mf4_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vv_i16mf4_b64_m((vbool64_t)(op0), (vint16mf4_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsle_vv_i32m1_b32(op0, op1, op2) \
__builtin_rvv_vmsle_vv_i32m1_b32((vint32m1_t)(op0), (vint32m1_t)(op1), (size_t)(op2))
#define vmsle_vv_i32m1_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vv_i32m1_b32_m((vbool32_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsle_vv_i32m2_b16(op0, op1, op2) \
__builtin_rvv_vmsle_vv_i32m2_b16((vint32m2_t)(op0), (vint32m2_t)(op1), (size_t)(op2))
#define vmsle_vv_i32m2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vv_i32m2_b16_m((vbool16_t)(op0), (vint32m2_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsle_vv_i32m4_b8(op0, op1, op2) \
__builtin_rvv_vmsle_vv_i32m4_b8((vint32m4_t)(op0), (vint32m4_t)(op1), (size_t)(op2))
#define vmsle_vv_i32m4_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vv_i32m4_b8_m((vbool8_t)(op0), (vint32m4_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsle_vv_i32m8_b4(op0, op1, op2) \
__builtin_rvv_vmsle_vv_i32m8_b4((vint32m8_t)(op0), (vint32m8_t)(op1), (size_t)(op2))
#define vmsle_vv_i32m8_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vv_i32m8_b4_m((vbool4_t)(op0), (vint32m8_t)(op1), (vint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsle_vv_i32mf2_b64(op0, op1, op2) \
__builtin_rvv_vmsle_vv_i32mf2_b64((vint32mf2_t)(op0), (vint32mf2_t)(op1), (size_t)(op2))
#define vmsle_vv_i32mf2_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vv_i32mf2_b64_m((vbool64_t)(op0), (vint32mf2_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsle_vv_i64m1_b64(op0, op1, op2) \
__builtin_rvv_vmsle_vv_i64m1_b64((vint64m1_t)(op0), (vint64m1_t)(op1), (size_t)(op2))
#define vmsle_vv_i64m1_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vv_i64m1_b64_m((vbool64_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsle_vv_i64m2_b32(op0, op1, op2) \
__builtin_rvv_vmsle_vv_i64m2_b32((vint64m2_t)(op0), (vint64m2_t)(op1), (size_t)(op2))
#define vmsle_vv_i64m2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vv_i64m2_b32_m((vbool32_t)(op0), (vint64m2_t)(op1), (vint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsle_vv_i64m4_b16(op0, op1, op2) \
__builtin_rvv_vmsle_vv_i64m4_b16((vint64m4_t)(op0), (vint64m4_t)(op1), (size_t)(op2))
#define vmsle_vv_i64m4_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vv_i64m4_b16_m((vbool16_t)(op0), (vint64m4_t)(op1), (vint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsle_vv_i64m8_b8(op0, op1, op2) \
__builtin_rvv_vmsle_vv_i64m8_b8((vint64m8_t)(op0), (vint64m8_t)(op1), (size_t)(op2))
#define vmsle_vv_i64m8_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vv_i64m8_b8_m((vbool8_t)(op0), (vint64m8_t)(op1), (vint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsle_vx_i8m1_b8(op0, op1, op2) \
__builtin_rvv_vmsle_vx_i8m1_b8((vint8m1_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmsle_vx_i8m1_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vx_i8m1_b8_m((vbool8_t)(op0), (vint8m1_t)(op1), (int8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsle_vx_i8m2_b4(op0, op1, op2) \
__builtin_rvv_vmsle_vx_i8m2_b4((vint8m2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmsle_vx_i8m2_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vx_i8m2_b4_m((vbool4_t)(op0), (vint8m2_t)(op1), (int8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsle_vx_i8m4_b2(op0, op1, op2) \
__builtin_rvv_vmsle_vx_i8m4_b2((vint8m4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmsle_vx_i8m4_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vx_i8m4_b2_m((vbool2_t)(op0), (vint8m4_t)(op1), (int8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmsle_vx_i8m8_b1(op0, op1, op2) \
__builtin_rvv_vmsle_vx_i8m8_b1((vint8m8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmsle_vx_i8m8_b1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vx_i8m8_b1_m((vbool1_t)(op0), (vint8m8_t)(op1), (int8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmsle_vx_i8mf2_b16(op0, op1, op2) \
__builtin_rvv_vmsle_vx_i8mf2_b16((vint8mf2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmsle_vx_i8mf2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vx_i8mf2_b16_m((vbool16_t)(op0), (vint8mf2_t)(op1), (int8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsle_vx_i8mf4_b32(op0, op1, op2) \
__builtin_rvv_vmsle_vx_i8mf4_b32((vint8mf4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmsle_vx_i8mf4_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vx_i8mf4_b32_m((vbool32_t)(op0), (vint8mf4_t)(op1), (int8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsle_vx_i8mf8_b64(op0, op1, op2) \
__builtin_rvv_vmsle_vx_i8mf8_b64((vint8mf8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmsle_vx_i8mf8_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vx_i8mf8_b64_m((vbool64_t)(op0), (vint8mf8_t)(op1), (int8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsle_vx_i16m1_b16(op0, op1, op2) \
__builtin_rvv_vmsle_vx_i16m1_b16((vint16m1_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmsle_vx_i16m1_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vx_i16m1_b16_m((vbool16_t)(op0), (vint16m1_t)(op1), (int16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsle_vx_i16m2_b8(op0, op1, op2) \
__builtin_rvv_vmsle_vx_i16m2_b8((vint16m2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmsle_vx_i16m2_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vx_i16m2_b8_m((vbool8_t)(op0), (vint16m2_t)(op1), (int16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsle_vx_i16m4_b4(op0, op1, op2) \
__builtin_rvv_vmsle_vx_i16m4_b4((vint16m4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmsle_vx_i16m4_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vx_i16m4_b4_m((vbool4_t)(op0), (vint16m4_t)(op1), (int16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsle_vx_i16m8_b2(op0, op1, op2) \
__builtin_rvv_vmsle_vx_i16m8_b2((vint16m8_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmsle_vx_i16m8_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vx_i16m8_b2_m((vbool2_t)(op0), (vint16m8_t)(op1), (int16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmsle_vx_i16mf2_b32(op0, op1, op2) \
__builtin_rvv_vmsle_vx_i16mf2_b32((vint16mf2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmsle_vx_i16mf2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vx_i16mf2_b32_m((vbool32_t)(op0), (vint16mf2_t)(op1), (int16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsle_vx_i16mf4_b64(op0, op1, op2) \
__builtin_rvv_vmsle_vx_i16mf4_b64((vint16mf4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmsle_vx_i16mf4_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vx_i16mf4_b64_m((vbool64_t)(op0), (vint16mf4_t)(op1), (int16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsle_vx_i32m1_b32(op0, op1, op2) \
__builtin_rvv_vmsle_vx_i32m1_b32((vint32m1_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmsle_vx_i32m1_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vx_i32m1_b32_m((vbool32_t)(op0), (vint32m1_t)(op1), (int32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsle_vx_i32m2_b16(op0, op1, op2) \
__builtin_rvv_vmsle_vx_i32m2_b16((vint32m2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmsle_vx_i32m2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vx_i32m2_b16_m((vbool16_t)(op0), (vint32m2_t)(op1), (int32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsle_vx_i32m4_b8(op0, op1, op2) \
__builtin_rvv_vmsle_vx_i32m4_b8((vint32m4_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmsle_vx_i32m4_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vx_i32m4_b8_m((vbool8_t)(op0), (vint32m4_t)(op1), (int32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsle_vx_i32m8_b4(op0, op1, op2) \
__builtin_rvv_vmsle_vx_i32m8_b4((vint32m8_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmsle_vx_i32m8_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vx_i32m8_b4_m((vbool4_t)(op0), (vint32m8_t)(op1), (int32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsle_vx_i32mf2_b64(op0, op1, op2) \
__builtin_rvv_vmsle_vx_i32mf2_b64((vint32mf2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmsle_vx_i32mf2_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vx_i32mf2_b64_m((vbool64_t)(op0), (vint32mf2_t)(op1), (int32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsle_vx_i64m1_b64(op0, op1, op2) \
__builtin_rvv_vmsle_vx_i64m1_b64((vint64m1_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmsle_vx_i64m1_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vx_i64m1_b64_m((vbool64_t)(op0), (vint64m1_t)(op1), (int64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsle_vx_i64m2_b32(op0, op1, op2) \
__builtin_rvv_vmsle_vx_i64m2_b32((vint64m2_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmsle_vx_i64m2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vx_i64m2_b32_m((vbool32_t)(op0), (vint64m2_t)(op1), (int64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsle_vx_i64m4_b16(op0, op1, op2) \
__builtin_rvv_vmsle_vx_i64m4_b16((vint64m4_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmsle_vx_i64m4_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vx_i64m4_b16_m((vbool16_t)(op0), (vint64m4_t)(op1), (int64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsle_vx_i64m8_b8(op0, op1, op2) \
__builtin_rvv_vmsle_vx_i64m8_b8((vint64m8_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmsle_vx_i64m8_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vx_i64m8_b8_m((vbool8_t)(op0), (vint64m8_t)(op1), (int64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsgtu_vx_u8m1_b8(op0, op1, op2) \
__builtin_rvv_vmsgtu_vx_u8m1_b8((vuint8m1_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsgtu_vx_u8m1_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgtu_vx_u8m1_b8_m((vbool8_t)(op0), (vuint8m1_t)(op1), (uint8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsgtu_vx_u8m2_b4(op0, op1, op2) \
__builtin_rvv_vmsgtu_vx_u8m2_b4((vuint8m2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsgtu_vx_u8m2_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgtu_vx_u8m2_b4_m((vbool4_t)(op0), (vuint8m2_t)(op1), (uint8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsgtu_vx_u8m4_b2(op0, op1, op2) \
__builtin_rvv_vmsgtu_vx_u8m4_b2((vuint8m4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsgtu_vx_u8m4_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgtu_vx_u8m4_b2_m((vbool2_t)(op0), (vuint8m4_t)(op1), (uint8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmsgtu_vx_u8m8_b1(op0, op1, op2) \
__builtin_rvv_vmsgtu_vx_u8m8_b1((vuint8m8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsgtu_vx_u8m8_b1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgtu_vx_u8m8_b1_m((vbool1_t)(op0), (vuint8m8_t)(op1), (uint8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmsgtu_vx_u8mf2_b16(op0, op1, op2) \
__builtin_rvv_vmsgtu_vx_u8mf2_b16((vuint8mf2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsgtu_vx_u8mf2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgtu_vx_u8mf2_b16_m((vbool16_t)(op0), (vuint8mf2_t)(op1), (uint8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsgtu_vx_u8mf4_b32(op0, op1, op2) \
__builtin_rvv_vmsgtu_vx_u8mf4_b32((vuint8mf4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsgtu_vx_u8mf4_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgtu_vx_u8mf4_b32_m((vbool32_t)(op0), (vuint8mf4_t)(op1), (uint8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsgtu_vx_u8mf8_b64(op0, op1, op2) \
__builtin_rvv_vmsgtu_vx_u8mf8_b64((vuint8mf8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsgtu_vx_u8mf8_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgtu_vx_u8mf8_b64_m((vbool64_t)(op0), (vuint8mf8_t)(op1), (uint8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsgtu_vx_u16m1_b16(op0, op1, op2) \
__builtin_rvv_vmsgtu_vx_u16m1_b16((vuint16m1_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmsgtu_vx_u16m1_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgtu_vx_u16m1_b16_m((vbool16_t)(op0), (vuint16m1_t)(op1), (uint16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsgtu_vx_u16m2_b8(op0, op1, op2) \
__builtin_rvv_vmsgtu_vx_u16m2_b8((vuint16m2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmsgtu_vx_u16m2_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgtu_vx_u16m2_b8_m((vbool8_t)(op0), (vuint16m2_t)(op1), (uint16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsgtu_vx_u16m4_b4(op0, op1, op2) \
__builtin_rvv_vmsgtu_vx_u16m4_b4((vuint16m4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmsgtu_vx_u16m4_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgtu_vx_u16m4_b4_m((vbool4_t)(op0), (vuint16m4_t)(op1), (uint16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsgtu_vx_u16m8_b2(op0, op1, op2) \
__builtin_rvv_vmsgtu_vx_u16m8_b2((vuint16m8_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmsgtu_vx_u16m8_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgtu_vx_u16m8_b2_m((vbool2_t)(op0), (vuint16m8_t)(op1), (uint16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmsgtu_vx_u16mf2_b32(op0, op1, op2) \
__builtin_rvv_vmsgtu_vx_u16mf2_b32((vuint16mf2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmsgtu_vx_u16mf2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgtu_vx_u16mf2_b32_m((vbool32_t)(op0), (vuint16mf2_t)(op1), (uint16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsgtu_vx_u16mf4_b64(op0, op1, op2) \
__builtin_rvv_vmsgtu_vx_u16mf4_b64((vuint16mf4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmsgtu_vx_u16mf4_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgtu_vx_u16mf4_b64_m((vbool64_t)(op0), (vuint16mf4_t)(op1), (uint16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsgtu_vx_u32m1_b32(op0, op1, op2) \
__builtin_rvv_vmsgtu_vx_u32m1_b32((vuint32m1_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmsgtu_vx_u32m1_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgtu_vx_u32m1_b32_m((vbool32_t)(op0), (vuint32m1_t)(op1), (uint32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsgtu_vx_u32m2_b16(op0, op1, op2) \
__builtin_rvv_vmsgtu_vx_u32m2_b16((vuint32m2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmsgtu_vx_u32m2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgtu_vx_u32m2_b16_m((vbool16_t)(op0), (vuint32m2_t)(op1), (uint32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsgtu_vx_u32m4_b8(op0, op1, op2) \
__builtin_rvv_vmsgtu_vx_u32m4_b8((vuint32m4_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmsgtu_vx_u32m4_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgtu_vx_u32m4_b8_m((vbool8_t)(op0), (vuint32m4_t)(op1), (uint32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsgtu_vx_u32m8_b4(op0, op1, op2) \
__builtin_rvv_vmsgtu_vx_u32m8_b4((vuint32m8_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmsgtu_vx_u32m8_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgtu_vx_u32m8_b4_m((vbool4_t)(op0), (vuint32m8_t)(op1), (uint32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsgtu_vx_u32mf2_b64(op0, op1, op2) \
__builtin_rvv_vmsgtu_vx_u32mf2_b64((vuint32mf2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmsgtu_vx_u32mf2_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgtu_vx_u32mf2_b64_m((vbool64_t)(op0), (vuint32mf2_t)(op1), (uint32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsgtu_vx_u64m1_b64(op0, op1, op2) \
__builtin_rvv_vmsgtu_vx_u64m1_b64((vuint64m1_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmsgtu_vx_u64m1_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgtu_vx_u64m1_b64_m((vbool64_t)(op0), (vuint64m1_t)(op1), (uint64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsgtu_vx_u64m2_b32(op0, op1, op2) \
__builtin_rvv_vmsgtu_vx_u64m2_b32((vuint64m2_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmsgtu_vx_u64m2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgtu_vx_u64m2_b32_m((vbool32_t)(op0), (vuint64m2_t)(op1), (uint64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsgtu_vx_u64m4_b16(op0, op1, op2) \
__builtin_rvv_vmsgtu_vx_u64m4_b16((vuint64m4_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmsgtu_vx_u64m4_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgtu_vx_u64m4_b16_m((vbool16_t)(op0), (vuint64m4_t)(op1), (uint64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsgtu_vx_u64m8_b8(op0, op1, op2) \
__builtin_rvv_vmsgtu_vx_u64m8_b8((vuint64m8_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmsgtu_vx_u64m8_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgtu_vx_u64m8_b8_m((vbool8_t)(op0), (vuint64m8_t)(op1), (uint64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsgt_vx_i8m1_b8(op0, op1, op2) \
__builtin_rvv_vmsgt_vx_i8m1_b8((vint8m1_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmsgt_vx_i8m1_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgt_vx_i8m1_b8_m((vbool8_t)(op0), (vint8m1_t)(op1), (int8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsgt_vx_i8m2_b4(op0, op1, op2) \
__builtin_rvv_vmsgt_vx_i8m2_b4((vint8m2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmsgt_vx_i8m2_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgt_vx_i8m2_b4_m((vbool4_t)(op0), (vint8m2_t)(op1), (int8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsgt_vx_i8m4_b2(op0, op1, op2) \
__builtin_rvv_vmsgt_vx_i8m4_b2((vint8m4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmsgt_vx_i8m4_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgt_vx_i8m4_b2_m((vbool2_t)(op0), (vint8m4_t)(op1), (int8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmsgt_vx_i8m8_b1(op0, op1, op2) \
__builtin_rvv_vmsgt_vx_i8m8_b1((vint8m8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmsgt_vx_i8m8_b1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgt_vx_i8m8_b1_m((vbool1_t)(op0), (vint8m8_t)(op1), (int8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmsgt_vx_i8mf2_b16(op0, op1, op2) \
__builtin_rvv_vmsgt_vx_i8mf2_b16((vint8mf2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmsgt_vx_i8mf2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgt_vx_i8mf2_b16_m((vbool16_t)(op0), (vint8mf2_t)(op1), (int8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsgt_vx_i8mf4_b32(op0, op1, op2) \
__builtin_rvv_vmsgt_vx_i8mf4_b32((vint8mf4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmsgt_vx_i8mf4_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgt_vx_i8mf4_b32_m((vbool32_t)(op0), (vint8mf4_t)(op1), (int8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsgt_vx_i8mf8_b64(op0, op1, op2) \
__builtin_rvv_vmsgt_vx_i8mf8_b64((vint8mf8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmsgt_vx_i8mf8_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgt_vx_i8mf8_b64_m((vbool64_t)(op0), (vint8mf8_t)(op1), (int8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsgt_vx_i16m1_b16(op0, op1, op2) \
__builtin_rvv_vmsgt_vx_i16m1_b16((vint16m1_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmsgt_vx_i16m1_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgt_vx_i16m1_b16_m((vbool16_t)(op0), (vint16m1_t)(op1), (int16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsgt_vx_i16m2_b8(op0, op1, op2) \
__builtin_rvv_vmsgt_vx_i16m2_b8((vint16m2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmsgt_vx_i16m2_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgt_vx_i16m2_b8_m((vbool8_t)(op0), (vint16m2_t)(op1), (int16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsgt_vx_i16m4_b4(op0, op1, op2) \
__builtin_rvv_vmsgt_vx_i16m4_b4((vint16m4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmsgt_vx_i16m4_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgt_vx_i16m4_b4_m((vbool4_t)(op0), (vint16m4_t)(op1), (int16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsgt_vx_i16m8_b2(op0, op1, op2) \
__builtin_rvv_vmsgt_vx_i16m8_b2((vint16m8_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmsgt_vx_i16m8_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgt_vx_i16m8_b2_m((vbool2_t)(op0), (vint16m8_t)(op1), (int16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmsgt_vx_i16mf2_b32(op0, op1, op2) \
__builtin_rvv_vmsgt_vx_i16mf2_b32((vint16mf2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmsgt_vx_i16mf2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgt_vx_i16mf2_b32_m((vbool32_t)(op0), (vint16mf2_t)(op1), (int16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsgt_vx_i16mf4_b64(op0, op1, op2) \
__builtin_rvv_vmsgt_vx_i16mf4_b64((vint16mf4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmsgt_vx_i16mf4_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgt_vx_i16mf4_b64_m((vbool64_t)(op0), (vint16mf4_t)(op1), (int16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsgt_vx_i32m1_b32(op0, op1, op2) \
__builtin_rvv_vmsgt_vx_i32m1_b32((vint32m1_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmsgt_vx_i32m1_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgt_vx_i32m1_b32_m((vbool32_t)(op0), (vint32m1_t)(op1), (int32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsgt_vx_i32m2_b16(op0, op1, op2) \
__builtin_rvv_vmsgt_vx_i32m2_b16((vint32m2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmsgt_vx_i32m2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgt_vx_i32m2_b16_m((vbool16_t)(op0), (vint32m2_t)(op1), (int32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsgt_vx_i32m4_b8(op0, op1, op2) \
__builtin_rvv_vmsgt_vx_i32m4_b8((vint32m4_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmsgt_vx_i32m4_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgt_vx_i32m4_b8_m((vbool8_t)(op0), (vint32m4_t)(op1), (int32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsgt_vx_i32m8_b4(op0, op1, op2) \
__builtin_rvv_vmsgt_vx_i32m8_b4((vint32m8_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmsgt_vx_i32m8_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgt_vx_i32m8_b4_m((vbool4_t)(op0), (vint32m8_t)(op1), (int32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsgt_vx_i32mf2_b64(op0, op1, op2) \
__builtin_rvv_vmsgt_vx_i32mf2_b64((vint32mf2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmsgt_vx_i32mf2_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgt_vx_i32mf2_b64_m((vbool64_t)(op0), (vint32mf2_t)(op1), (int32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsgt_vx_i64m1_b64(op0, op1, op2) \
__builtin_rvv_vmsgt_vx_i64m1_b64((vint64m1_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmsgt_vx_i64m1_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgt_vx_i64m1_b64_m((vbool64_t)(op0), (vint64m1_t)(op1), (int64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsgt_vx_i64m2_b32(op0, op1, op2) \
__builtin_rvv_vmsgt_vx_i64m2_b32((vint64m2_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmsgt_vx_i64m2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgt_vx_i64m2_b32_m((vbool32_t)(op0), (vint64m2_t)(op1), (int64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsgt_vx_i64m4_b16(op0, op1, op2) \
__builtin_rvv_vmsgt_vx_i64m4_b16((vint64m4_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmsgt_vx_i64m4_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgt_vx_i64m4_b16_m((vbool16_t)(op0), (vint64m4_t)(op1), (int64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsgt_vx_i64m8_b8(op0, op1, op2) \
__builtin_rvv_vmsgt_vx_i64m8_b8((vint64m8_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmsgt_vx_i64m8_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgt_vx_i64m8_b8_m((vbool8_t)(op0), (vint64m8_t)(op1), (int64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vminu_vv_u8m1(op0, op1, op2) \
__builtin_rvv_vminu_vv_u8m1((vuint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vminu_vv_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vv_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vminu_vv_u8m2(op0, op1, op2) \
__builtin_rvv_vminu_vv_u8m2((vuint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vminu_vv_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vv_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vminu_vv_u8m4(op0, op1, op2) \
__builtin_rvv_vminu_vv_u8m4((vuint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vminu_vv_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vv_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vminu_vv_u8m8(op0, op1, op2) \
__builtin_rvv_vminu_vv_u8m8((vuint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vminu_vv_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vv_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vminu_vv_u8mf2(op0, op1, op2) \
__builtin_rvv_vminu_vv_u8mf2((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vminu_vv_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vv_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vminu_vv_u8mf4(op0, op1, op2) \
__builtin_rvv_vminu_vv_u8mf4((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vminu_vv_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vv_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vminu_vv_u8mf8(op0, op1, op2) \
__builtin_rvv_vminu_vv_u8mf8((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vminu_vv_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vv_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vminu_vv_u16m1(op0, op1, op2) \
__builtin_rvv_vminu_vv_u16m1((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vminu_vv_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vv_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vminu_vv_u16m2(op0, op1, op2) \
__builtin_rvv_vminu_vv_u16m2((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vminu_vv_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vv_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vminu_vv_u16m4(op0, op1, op2) \
__builtin_rvv_vminu_vv_u16m4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vminu_vv_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vv_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vminu_vv_u16m8(op0, op1, op2) \
__builtin_rvv_vminu_vv_u16m8((vuint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vminu_vv_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vv_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vminu_vv_u16mf2(op0, op1, op2) \
__builtin_rvv_vminu_vv_u16mf2((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vminu_vv_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vv_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vminu_vv_u16mf4(op0, op1, op2) \
__builtin_rvv_vminu_vv_u16mf4((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vminu_vv_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vv_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vminu_vv_u32m1(op0, op1, op2) \
__builtin_rvv_vminu_vv_u32m1((vuint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vminu_vv_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vv_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vminu_vv_u32m2(op0, op1, op2) \
__builtin_rvv_vminu_vv_u32m2((vuint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vminu_vv_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vv_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vminu_vv_u32m4(op0, op1, op2) \
__builtin_rvv_vminu_vv_u32m4((vuint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vminu_vv_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vv_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vminu_vv_u32m8(op0, op1, op2) \
__builtin_rvv_vminu_vv_u32m8((vuint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vminu_vv_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vv_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vminu_vv_u32mf2(op0, op1, op2) \
__builtin_rvv_vminu_vv_u32mf2((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vminu_vv_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vv_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vminu_vv_u64m1(op0, op1, op2) \
__builtin_rvv_vminu_vv_u64m1((vuint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vminu_vv_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vv_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vminu_vv_u64m2(op0, op1, op2) \
__builtin_rvv_vminu_vv_u64m2((vuint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vminu_vv_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vv_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vminu_vv_u64m4(op0, op1, op2) \
__builtin_rvv_vminu_vv_u64m4((vuint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vminu_vv_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vv_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vminu_vv_u64m8(op0, op1, op2) \
__builtin_rvv_vminu_vv_u64m8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vminu_vv_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vv_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vminu_vx_u8m1(op0, op1, op2) \
__builtin_rvv_vminu_vx_u8m1((vuint8m1_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vminu_vx_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vx_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (uint8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vminu_vx_u8m2(op0, op1, op2) \
__builtin_rvv_vminu_vx_u8m2((vuint8m2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vminu_vx_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vx_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (uint8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vminu_vx_u8m4(op0, op1, op2) \
__builtin_rvv_vminu_vx_u8m4((vuint8m4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vminu_vx_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vx_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (uint8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vminu_vx_u8m8(op0, op1, op2) \
__builtin_rvv_vminu_vx_u8m8((vuint8m8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vminu_vx_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vx_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (uint8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vminu_vx_u8mf2(op0, op1, op2) \
__builtin_rvv_vminu_vx_u8mf2((vuint8mf2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vminu_vx_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vx_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (uint8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vminu_vx_u8mf4(op0, op1, op2) \
__builtin_rvv_vminu_vx_u8mf4((vuint8mf4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vminu_vx_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vx_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (uint8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vminu_vx_u8mf8(op0, op1, op2) \
__builtin_rvv_vminu_vx_u8mf8((vuint8mf8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vminu_vx_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vx_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (uint8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vminu_vx_u16m1(op0, op1, op2) \
__builtin_rvv_vminu_vx_u16m1((vuint16m1_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vminu_vx_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vx_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (uint16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vminu_vx_u16m2(op0, op1, op2) \
__builtin_rvv_vminu_vx_u16m2((vuint16m2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vminu_vx_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vx_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (uint16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vminu_vx_u16m4(op0, op1, op2) \
__builtin_rvv_vminu_vx_u16m4((vuint16m4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vminu_vx_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vx_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (uint16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vminu_vx_u16m8(op0, op1, op2) \
__builtin_rvv_vminu_vx_u16m8((vuint16m8_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vminu_vx_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vx_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (uint16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vminu_vx_u16mf2(op0, op1, op2) \
__builtin_rvv_vminu_vx_u16mf2((vuint16mf2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vminu_vx_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vx_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (uint16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vminu_vx_u16mf4(op0, op1, op2) \
__builtin_rvv_vminu_vx_u16mf4((vuint16mf4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vminu_vx_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vx_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (uint16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vminu_vx_u32m1(op0, op1, op2) \
__builtin_rvv_vminu_vx_u32m1((vuint32m1_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vminu_vx_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vx_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (uint32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vminu_vx_u32m2(op0, op1, op2) \
__builtin_rvv_vminu_vx_u32m2((vuint32m2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vminu_vx_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vx_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (uint32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vminu_vx_u32m4(op0, op1, op2) \
__builtin_rvv_vminu_vx_u32m4((vuint32m4_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vminu_vx_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vx_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (uint32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vminu_vx_u32m8(op0, op1, op2) \
__builtin_rvv_vminu_vx_u32m8((vuint32m8_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vminu_vx_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vx_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (uint32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vminu_vx_u32mf2(op0, op1, op2) \
__builtin_rvv_vminu_vx_u32mf2((vuint32mf2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vminu_vx_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vx_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (uint32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vminu_vx_u64m1(op0, op1, op2) \
__builtin_rvv_vminu_vx_u64m1((vuint64m1_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vminu_vx_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vx_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (uint64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vminu_vx_u64m2(op0, op1, op2) \
__builtin_rvv_vminu_vx_u64m2((vuint64m2_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vminu_vx_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vx_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (uint64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vminu_vx_u64m4(op0, op1, op2) \
__builtin_rvv_vminu_vx_u64m4((vuint64m4_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vminu_vx_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vx_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (uint64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vminu_vx_u64m8(op0, op1, op2) \
__builtin_rvv_vminu_vx_u64m8((vuint64m8_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vminu_vx_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vx_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (uint64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmin_vv_i8m1(op0, op1, op2) \
__builtin_rvv_vmin_vv_i8m1((vint8m1_t)(op0), (vint8m1_t)(op1), (size_t)(op2))
#define vmin_vv_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vv_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmin_vv_i8m2(op0, op1, op2) \
__builtin_rvv_vmin_vv_i8m2((vint8m2_t)(op0), (vint8m2_t)(op1), (size_t)(op2))
#define vmin_vv_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vv_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmin_vv_i8m4(op0, op1, op2) \
__builtin_rvv_vmin_vv_i8m4((vint8m4_t)(op0), (vint8m4_t)(op1), (size_t)(op2))
#define vmin_vv_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vv_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmin_vv_i8m8(op0, op1, op2) \
__builtin_rvv_vmin_vv_i8m8((vint8m8_t)(op0), (vint8m8_t)(op1), (size_t)(op2))
#define vmin_vv_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vv_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (vint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmin_vv_i8mf2(op0, op1, op2) \
__builtin_rvv_vmin_vv_i8mf2((vint8mf2_t)(op0), (vint8mf2_t)(op1), (size_t)(op2))
#define vmin_vv_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vv_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmin_vv_i8mf4(op0, op1, op2) \
__builtin_rvv_vmin_vv_i8mf4((vint8mf4_t)(op0), (vint8mf4_t)(op1), (size_t)(op2))
#define vmin_vv_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vv_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmin_vv_i8mf8(op0, op1, op2) \
__builtin_rvv_vmin_vv_i8mf8((vint8mf8_t)(op0), (vint8mf8_t)(op1), (size_t)(op2))
#define vmin_vv_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vv_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmin_vv_i16m1(op0, op1, op2) \
__builtin_rvv_vmin_vv_i16m1((vint16m1_t)(op0), (vint16m1_t)(op1), (size_t)(op2))
#define vmin_vv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vv_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmin_vv_i16m2(op0, op1, op2) \
__builtin_rvv_vmin_vv_i16m2((vint16m2_t)(op0), (vint16m2_t)(op1), (size_t)(op2))
#define vmin_vv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vv_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmin_vv_i16m4(op0, op1, op2) \
__builtin_rvv_vmin_vv_i16m4((vint16m4_t)(op0), (vint16m4_t)(op1), (size_t)(op2))
#define vmin_vv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vv_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmin_vv_i16m8(op0, op1, op2) \
__builtin_rvv_vmin_vv_i16m8((vint16m8_t)(op0), (vint16m8_t)(op1), (size_t)(op2))
#define vmin_vv_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vv_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (vint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmin_vv_i16mf2(op0, op1, op2) \
__builtin_rvv_vmin_vv_i16mf2((vint16mf2_t)(op0), (vint16mf2_t)(op1), (size_t)(op2))
#define vmin_vv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vv_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmin_vv_i16mf4(op0, op1, op2) \
__builtin_rvv_vmin_vv_i16mf4((vint16mf4_t)(op0), (vint16mf4_t)(op1), (size_t)(op2))
#define vmin_vv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vv_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmin_vv_i32m1(op0, op1, op2) \
__builtin_rvv_vmin_vv_i32m1((vint32m1_t)(op0), (vint32m1_t)(op1), (size_t)(op2))
#define vmin_vv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vv_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmin_vv_i32m2(op0, op1, op2) \
__builtin_rvv_vmin_vv_i32m2((vint32m2_t)(op0), (vint32m2_t)(op1), (size_t)(op2))
#define vmin_vv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vv_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmin_vv_i32m4(op0, op1, op2) \
__builtin_rvv_vmin_vv_i32m4((vint32m4_t)(op0), (vint32m4_t)(op1), (size_t)(op2))
#define vmin_vv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vv_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmin_vv_i32m8(op0, op1, op2) \
__builtin_rvv_vmin_vv_i32m8((vint32m8_t)(op0), (vint32m8_t)(op1), (size_t)(op2))
#define vmin_vv_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vv_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (vint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmin_vv_i32mf2(op0, op1, op2) \
__builtin_rvv_vmin_vv_i32mf2((vint32mf2_t)(op0), (vint32mf2_t)(op1), (size_t)(op2))
#define vmin_vv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vv_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmin_vv_i64m1(op0, op1, op2) \
__builtin_rvv_vmin_vv_i64m1((vint64m1_t)(op0), (vint64m1_t)(op1), (size_t)(op2))
#define vmin_vv_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vv_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmin_vv_i64m2(op0, op1, op2) \
__builtin_rvv_vmin_vv_i64m2((vint64m2_t)(op0), (vint64m2_t)(op1), (size_t)(op2))
#define vmin_vv_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vv_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (vint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmin_vv_i64m4(op0, op1, op2) \
__builtin_rvv_vmin_vv_i64m4((vint64m4_t)(op0), (vint64m4_t)(op1), (size_t)(op2))
#define vmin_vv_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vv_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (vint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmin_vv_i64m8(op0, op1, op2) \
__builtin_rvv_vmin_vv_i64m8((vint64m8_t)(op0), (vint64m8_t)(op1), (size_t)(op2))
#define vmin_vv_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vv_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (vint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmin_vx_i8m1(op0, op1, op2) \
__builtin_rvv_vmin_vx_i8m1((vint8m1_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmin_vx_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vx_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (int8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmin_vx_i8m2(op0, op1, op2) \
__builtin_rvv_vmin_vx_i8m2((vint8m2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmin_vx_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vx_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (int8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmin_vx_i8m4(op0, op1, op2) \
__builtin_rvv_vmin_vx_i8m4((vint8m4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmin_vx_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vx_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (int8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmin_vx_i8m8(op0, op1, op2) \
__builtin_rvv_vmin_vx_i8m8((vint8m8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmin_vx_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vx_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (int8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmin_vx_i8mf2(op0, op1, op2) \
__builtin_rvv_vmin_vx_i8mf2((vint8mf2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmin_vx_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vx_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (int8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmin_vx_i8mf4(op0, op1, op2) \
__builtin_rvv_vmin_vx_i8mf4((vint8mf4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmin_vx_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vx_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (int8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmin_vx_i8mf8(op0, op1, op2) \
__builtin_rvv_vmin_vx_i8mf8((vint8mf8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmin_vx_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vx_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (int8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmin_vx_i16m1(op0, op1, op2) \
__builtin_rvv_vmin_vx_i16m1((vint16m1_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmin_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vx_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (int16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmin_vx_i16m2(op0, op1, op2) \
__builtin_rvv_vmin_vx_i16m2((vint16m2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmin_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vx_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (int16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmin_vx_i16m4(op0, op1, op2) \
__builtin_rvv_vmin_vx_i16m4((vint16m4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmin_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vx_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (int16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmin_vx_i16m8(op0, op1, op2) \
__builtin_rvv_vmin_vx_i16m8((vint16m8_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmin_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vx_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (int16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmin_vx_i16mf2(op0, op1, op2) \
__builtin_rvv_vmin_vx_i16mf2((vint16mf2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmin_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vx_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (int16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmin_vx_i16mf4(op0, op1, op2) \
__builtin_rvv_vmin_vx_i16mf4((vint16mf4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmin_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vx_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (int16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmin_vx_i32m1(op0, op1, op2) \
__builtin_rvv_vmin_vx_i32m1((vint32m1_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmin_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vx_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (int32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmin_vx_i32m2(op0, op1, op2) \
__builtin_rvv_vmin_vx_i32m2((vint32m2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmin_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vx_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (int32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmin_vx_i32m4(op0, op1, op2) \
__builtin_rvv_vmin_vx_i32m4((vint32m4_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmin_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vx_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (int32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmin_vx_i32m8(op0, op1, op2) \
__builtin_rvv_vmin_vx_i32m8((vint32m8_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmin_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vx_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (int32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmin_vx_i32mf2(op0, op1, op2) \
__builtin_rvv_vmin_vx_i32mf2((vint32mf2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmin_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vx_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (int32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmin_vx_i64m1(op0, op1, op2) \
__builtin_rvv_vmin_vx_i64m1((vint64m1_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmin_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vx_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (int64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmin_vx_i64m2(op0, op1, op2) \
__builtin_rvv_vmin_vx_i64m2((vint64m2_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmin_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vx_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (int64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmin_vx_i64m4(op0, op1, op2) \
__builtin_rvv_vmin_vx_i64m4((vint64m4_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmin_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vx_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (int64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmin_vx_i64m8(op0, op1, op2) \
__builtin_rvv_vmin_vx_i64m8((vint64m8_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmin_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vx_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (int64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmaxu_vv_u8m1(op0, op1, op2) \
__builtin_rvv_vmaxu_vv_u8m1((vuint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vmaxu_vv_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vv_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmaxu_vv_u8m2(op0, op1, op2) \
__builtin_rvv_vmaxu_vv_u8m2((vuint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vmaxu_vv_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vv_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmaxu_vv_u8m4(op0, op1, op2) \
__builtin_rvv_vmaxu_vv_u8m4((vuint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vmaxu_vv_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vv_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmaxu_vv_u8m8(op0, op1, op2) \
__builtin_rvv_vmaxu_vv_u8m8((vuint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vmaxu_vv_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vv_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmaxu_vv_u8mf2(op0, op1, op2) \
__builtin_rvv_vmaxu_vv_u8mf2((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vmaxu_vv_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vv_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmaxu_vv_u8mf4(op0, op1, op2) \
__builtin_rvv_vmaxu_vv_u8mf4((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vmaxu_vv_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vv_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmaxu_vv_u8mf8(op0, op1, op2) \
__builtin_rvv_vmaxu_vv_u8mf8((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vmaxu_vv_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vv_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmaxu_vv_u16m1(op0, op1, op2) \
__builtin_rvv_vmaxu_vv_u16m1((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vmaxu_vv_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vv_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmaxu_vv_u16m2(op0, op1, op2) \
__builtin_rvv_vmaxu_vv_u16m2((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vmaxu_vv_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vv_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmaxu_vv_u16m4(op0, op1, op2) \
__builtin_rvv_vmaxu_vv_u16m4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vmaxu_vv_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vv_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmaxu_vv_u16m8(op0, op1, op2) \
__builtin_rvv_vmaxu_vv_u16m8((vuint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vmaxu_vv_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vv_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmaxu_vv_u16mf2(op0, op1, op2) \
__builtin_rvv_vmaxu_vv_u16mf2((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vmaxu_vv_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vv_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmaxu_vv_u16mf4(op0, op1, op2) \
__builtin_rvv_vmaxu_vv_u16mf4((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vmaxu_vv_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vv_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmaxu_vv_u32m1(op0, op1, op2) \
__builtin_rvv_vmaxu_vv_u32m1((vuint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vmaxu_vv_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vv_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmaxu_vv_u32m2(op0, op1, op2) \
__builtin_rvv_vmaxu_vv_u32m2((vuint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vmaxu_vv_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vv_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmaxu_vv_u32m4(op0, op1, op2) \
__builtin_rvv_vmaxu_vv_u32m4((vuint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vmaxu_vv_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vv_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmaxu_vv_u32m8(op0, op1, op2) \
__builtin_rvv_vmaxu_vv_u32m8((vuint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vmaxu_vv_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vv_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmaxu_vv_u32mf2(op0, op1, op2) \
__builtin_rvv_vmaxu_vv_u32mf2((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vmaxu_vv_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vv_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmaxu_vv_u64m1(op0, op1, op2) \
__builtin_rvv_vmaxu_vv_u64m1((vuint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vmaxu_vv_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vv_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmaxu_vv_u64m2(op0, op1, op2) \
__builtin_rvv_vmaxu_vv_u64m2((vuint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vmaxu_vv_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vv_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmaxu_vv_u64m4(op0, op1, op2) \
__builtin_rvv_vmaxu_vv_u64m4((vuint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vmaxu_vv_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vv_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmaxu_vv_u64m8(op0, op1, op2) \
__builtin_rvv_vmaxu_vv_u64m8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vmaxu_vv_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vv_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmaxu_vx_u8m1(op0, op1, op2) \
__builtin_rvv_vmaxu_vx_u8m1((vuint8m1_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmaxu_vx_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vx_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (uint8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmaxu_vx_u8m2(op0, op1, op2) \
__builtin_rvv_vmaxu_vx_u8m2((vuint8m2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmaxu_vx_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vx_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (uint8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmaxu_vx_u8m4(op0, op1, op2) \
__builtin_rvv_vmaxu_vx_u8m4((vuint8m4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmaxu_vx_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vx_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (uint8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmaxu_vx_u8m8(op0, op1, op2) \
__builtin_rvv_vmaxu_vx_u8m8((vuint8m8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmaxu_vx_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vx_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (uint8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmaxu_vx_u8mf2(op0, op1, op2) \
__builtin_rvv_vmaxu_vx_u8mf2((vuint8mf2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmaxu_vx_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vx_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (uint8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmaxu_vx_u8mf4(op0, op1, op2) \
__builtin_rvv_vmaxu_vx_u8mf4((vuint8mf4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmaxu_vx_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vx_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (uint8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmaxu_vx_u8mf8(op0, op1, op2) \
__builtin_rvv_vmaxu_vx_u8mf8((vuint8mf8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmaxu_vx_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vx_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (uint8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmaxu_vx_u16m1(op0, op1, op2) \
__builtin_rvv_vmaxu_vx_u16m1((vuint16m1_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmaxu_vx_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vx_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (uint16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmaxu_vx_u16m2(op0, op1, op2) \
__builtin_rvv_vmaxu_vx_u16m2((vuint16m2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmaxu_vx_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vx_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (uint16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmaxu_vx_u16m4(op0, op1, op2) \
__builtin_rvv_vmaxu_vx_u16m4((vuint16m4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmaxu_vx_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vx_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (uint16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmaxu_vx_u16m8(op0, op1, op2) \
__builtin_rvv_vmaxu_vx_u16m8((vuint16m8_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmaxu_vx_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vx_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (uint16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmaxu_vx_u16mf2(op0, op1, op2) \
__builtin_rvv_vmaxu_vx_u16mf2((vuint16mf2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmaxu_vx_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vx_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (uint16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmaxu_vx_u16mf4(op0, op1, op2) \
__builtin_rvv_vmaxu_vx_u16mf4((vuint16mf4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmaxu_vx_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vx_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (uint16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmaxu_vx_u32m1(op0, op1, op2) \
__builtin_rvv_vmaxu_vx_u32m1((vuint32m1_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmaxu_vx_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vx_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (uint32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmaxu_vx_u32m2(op0, op1, op2) \
__builtin_rvv_vmaxu_vx_u32m2((vuint32m2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmaxu_vx_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vx_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (uint32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmaxu_vx_u32m4(op0, op1, op2) \
__builtin_rvv_vmaxu_vx_u32m4((vuint32m4_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmaxu_vx_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vx_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (uint32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmaxu_vx_u32m8(op0, op1, op2) \
__builtin_rvv_vmaxu_vx_u32m8((vuint32m8_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmaxu_vx_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vx_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (uint32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmaxu_vx_u32mf2(op0, op1, op2) \
__builtin_rvv_vmaxu_vx_u32mf2((vuint32mf2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmaxu_vx_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vx_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (uint32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmaxu_vx_u64m1(op0, op1, op2) \
__builtin_rvv_vmaxu_vx_u64m1((vuint64m1_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmaxu_vx_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vx_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (uint64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmaxu_vx_u64m2(op0, op1, op2) \
__builtin_rvv_vmaxu_vx_u64m2((vuint64m2_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmaxu_vx_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vx_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (uint64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmaxu_vx_u64m4(op0, op1, op2) \
__builtin_rvv_vmaxu_vx_u64m4((vuint64m4_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmaxu_vx_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vx_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (uint64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmaxu_vx_u64m8(op0, op1, op2) \
__builtin_rvv_vmaxu_vx_u64m8((vuint64m8_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmaxu_vx_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vx_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (uint64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vle8_v_u8m1(op0, op1) \
__builtin_rvv_vle8_v_u8m1((const uint8_t *)(op0), (size_t)(op1))
#define vle8_v_u8m1_m(op2, op0, op1, op3) \
__builtin_rvv_vle8_v_u8m1_m((vuint8m1_t)(op0), (const uint8_t *)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vle8_v_u8m2(op0, op1) \
__builtin_rvv_vle8_v_u8m2((const uint8_t *)(op0), (size_t)(op1))
#define vle8_v_u8m2_m(op2, op0, op1, op3) \
__builtin_rvv_vle8_v_u8m2_m((vuint8m2_t)(op0), (const uint8_t *)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vle8_v_u8m4(op0, op1) \
__builtin_rvv_vle8_v_u8m4((const uint8_t *)(op0), (size_t)(op1))
#define vle8_v_u8m4_m(op2, op0, op1, op3) \
__builtin_rvv_vle8_v_u8m4_m((vuint8m4_t)(op0), (const uint8_t *)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vle8_v_u8m8(op0, op1) \
__builtin_rvv_vle8_v_u8m8((const uint8_t *)(op0), (size_t)(op1))
#define vle8_v_u8m8_m(op2, op0, op1, op3) \
__builtin_rvv_vle8_v_u8m8_m((vuint8m8_t)(op0), (const uint8_t *)(op1), (vbool1_t)(op2), (size_t)(op3))
#define vle8_v_u8mf2(op0, op1) \
__builtin_rvv_vle8_v_u8mf2((const uint8_t *)(op0), (size_t)(op1))
#define vle8_v_u8mf2_m(op2, op0, op1, op3) \
__builtin_rvv_vle8_v_u8mf2_m((vuint8mf2_t)(op0), (const uint8_t *)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vle8_v_u8mf4(op0, op1) \
__builtin_rvv_vle8_v_u8mf4((const uint8_t *)(op0), (size_t)(op1))
#define vle8_v_u8mf4_m(op2, op0, op1, op3) \
__builtin_rvv_vle8_v_u8mf4_m((vuint8mf4_t)(op0), (const uint8_t *)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vle8_v_u8mf8(op0, op1) \
__builtin_rvv_vle8_v_u8mf8((const uint8_t *)(op0), (size_t)(op1))
#define vle8_v_u8mf8_m(op2, op0, op1, op3) \
__builtin_rvv_vle8_v_u8mf8_m((vuint8mf8_t)(op0), (const uint8_t *)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vle64_v_i64m1(op0, op1) \
__builtin_rvv_vle64_v_i64m1((const int64_t *)(op0), (size_t)(op1))
#define vle64_v_i64m1_m(op2, op0, op1, op3) \
__builtin_rvv_vle64_v_i64m1_m((vint64m1_t)(op0), (const int64_t *)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vle64_v_i64m2(op0, op1) \
__builtin_rvv_vle64_v_i64m2((const int64_t *)(op0), (size_t)(op1))
#define vle64_v_i64m2_m(op2, op0, op1, op3) \
__builtin_rvv_vle64_v_i64m2_m((vint64m2_t)(op0), (const int64_t *)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vle64_v_i64m4(op0, op1) \
__builtin_rvv_vle64_v_i64m4((const int64_t *)(op0), (size_t)(op1))
#define vle64_v_i64m4_m(op2, op0, op1, op3) \
__builtin_rvv_vle64_v_i64m4_m((vint64m4_t)(op0), (const int64_t *)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vle64_v_i64m8(op0, op1) \
__builtin_rvv_vle64_v_i64m8((const int64_t *)(op0), (size_t)(op1))
#define vle64_v_i64m8_m(op2, op0, op1, op3) \
__builtin_rvv_vle64_v_i64m8_m((vint64m8_t)(op0), (const int64_t *)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmax_vv_i8m1(op0, op1, op2) \
__builtin_rvv_vmax_vv_i8m1((vint8m1_t)(op0), (vint8m1_t)(op1), (size_t)(op2))
#define vmax_vv_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vv_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmax_vv_i8m2(op0, op1, op2) \
__builtin_rvv_vmax_vv_i8m2((vint8m2_t)(op0), (vint8m2_t)(op1), (size_t)(op2))
#define vmax_vv_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vv_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmax_vv_i8m4(op0, op1, op2) \
__builtin_rvv_vmax_vv_i8m4((vint8m4_t)(op0), (vint8m4_t)(op1), (size_t)(op2))
#define vmax_vv_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vv_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmax_vv_i8m8(op0, op1, op2) \
__builtin_rvv_vmax_vv_i8m8((vint8m8_t)(op0), (vint8m8_t)(op1), (size_t)(op2))
#define vmax_vv_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vv_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (vint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmax_vv_i8mf2(op0, op1, op2) \
__builtin_rvv_vmax_vv_i8mf2((vint8mf2_t)(op0), (vint8mf2_t)(op1), (size_t)(op2))
#define vmax_vv_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vv_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmax_vv_i8mf4(op0, op1, op2) \
__builtin_rvv_vmax_vv_i8mf4((vint8mf4_t)(op0), (vint8mf4_t)(op1), (size_t)(op2))
#define vmax_vv_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vv_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmax_vv_i8mf8(op0, op1, op2) \
__builtin_rvv_vmax_vv_i8mf8((vint8mf8_t)(op0), (vint8mf8_t)(op1), (size_t)(op2))
#define vmax_vv_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vv_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmax_vv_i16m1(op0, op1, op2) \
__builtin_rvv_vmax_vv_i16m1((vint16m1_t)(op0), (vint16m1_t)(op1), (size_t)(op2))
#define vmax_vv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vv_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmax_vv_i16m2(op0, op1, op2) \
__builtin_rvv_vmax_vv_i16m2((vint16m2_t)(op0), (vint16m2_t)(op1), (size_t)(op2))
#define vmax_vv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vv_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmax_vv_i16m4(op0, op1, op2) \
__builtin_rvv_vmax_vv_i16m4((vint16m4_t)(op0), (vint16m4_t)(op1), (size_t)(op2))
#define vmax_vv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vv_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmax_vv_i16m8(op0, op1, op2) \
__builtin_rvv_vmax_vv_i16m8((vint16m8_t)(op0), (vint16m8_t)(op1), (size_t)(op2))
#define vmax_vv_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vv_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (vint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmax_vv_i16mf2(op0, op1, op2) \
__builtin_rvv_vmax_vv_i16mf2((vint16mf2_t)(op0), (vint16mf2_t)(op1), (size_t)(op2))
#define vmax_vv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vv_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmax_vv_i16mf4(op0, op1, op2) \
__builtin_rvv_vmax_vv_i16mf4((vint16mf4_t)(op0), (vint16mf4_t)(op1), (size_t)(op2))
#define vmax_vv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vv_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmax_vv_i32m1(op0, op1, op2) \
__builtin_rvv_vmax_vv_i32m1((vint32m1_t)(op0), (vint32m1_t)(op1), (size_t)(op2))
#define vmax_vv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vv_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmax_vv_i32m2(op0, op1, op2) \
__builtin_rvv_vmax_vv_i32m2((vint32m2_t)(op0), (vint32m2_t)(op1), (size_t)(op2))
#define vmax_vv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vv_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmax_vv_i32m4(op0, op1, op2) \
__builtin_rvv_vmax_vv_i32m4((vint32m4_t)(op0), (vint32m4_t)(op1), (size_t)(op2))
#define vmax_vv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vv_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmax_vv_i32m8(op0, op1, op2) \
__builtin_rvv_vmax_vv_i32m8((vint32m8_t)(op0), (vint32m8_t)(op1), (size_t)(op2))
#define vmax_vv_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vv_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (vint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmax_vv_i32mf2(op0, op1, op2) \
__builtin_rvv_vmax_vv_i32mf2((vint32mf2_t)(op0), (vint32mf2_t)(op1), (size_t)(op2))
#define vmax_vv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vv_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmax_vv_i64m1(op0, op1, op2) \
__builtin_rvv_vmax_vv_i64m1((vint64m1_t)(op0), (vint64m1_t)(op1), (size_t)(op2))
#define vmax_vv_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vv_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmax_vv_i64m2(op0, op1, op2) \
__builtin_rvv_vmax_vv_i64m2((vint64m2_t)(op0), (vint64m2_t)(op1), (size_t)(op2))
#define vmax_vv_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vv_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (vint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmax_vv_i64m4(op0, op1, op2) \
__builtin_rvv_vmax_vv_i64m4((vint64m4_t)(op0), (vint64m4_t)(op1), (size_t)(op2))
#define vmax_vv_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vv_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (vint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmax_vv_i64m8(op0, op1, op2) \
__builtin_rvv_vmax_vv_i64m8((vint64m8_t)(op0), (vint64m8_t)(op1), (size_t)(op2))
#define vmax_vv_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vv_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (vint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmax_vx_i8m1(op0, op1, op2) \
__builtin_rvv_vmax_vx_i8m1((vint8m1_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmax_vx_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vx_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (int8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmax_vx_i8m2(op0, op1, op2) \
__builtin_rvv_vmax_vx_i8m2((vint8m2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmax_vx_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vx_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (int8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmax_vx_i8m4(op0, op1, op2) \
__builtin_rvv_vmax_vx_i8m4((vint8m4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmax_vx_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vx_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (int8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmax_vx_i8m8(op0, op1, op2) \
__builtin_rvv_vmax_vx_i8m8((vint8m8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmax_vx_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vx_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (int8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmax_vx_i8mf2(op0, op1, op2) \
__builtin_rvv_vmax_vx_i8mf2((vint8mf2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmax_vx_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vx_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (int8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmax_vx_i8mf4(op0, op1, op2) \
__builtin_rvv_vmax_vx_i8mf4((vint8mf4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmax_vx_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vx_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (int8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmax_vx_i8mf8(op0, op1, op2) \
__builtin_rvv_vmax_vx_i8mf8((vint8mf8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmax_vx_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vx_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (int8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmax_vx_i16m1(op0, op1, op2) \
__builtin_rvv_vmax_vx_i16m1((vint16m1_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmax_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vx_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (int16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmax_vx_i16m2(op0, op1, op2) \
__builtin_rvv_vmax_vx_i16m2((vint16m2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmax_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vx_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (int16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmax_vx_i16m4(op0, op1, op2) \
__builtin_rvv_vmax_vx_i16m4((vint16m4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmax_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vx_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (int16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmax_vx_i16m8(op0, op1, op2) \
__builtin_rvv_vmax_vx_i16m8((vint16m8_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmax_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vx_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (int16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmax_vx_i16mf2(op0, op1, op2) \
__builtin_rvv_vmax_vx_i16mf2((vint16mf2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmax_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vx_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (int16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmax_vx_i16mf4(op0, op1, op2) \
__builtin_rvv_vmax_vx_i16mf4((vint16mf4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmax_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vx_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (int16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmax_vx_i32m1(op0, op1, op2) \
__builtin_rvv_vmax_vx_i32m1((vint32m1_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmax_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vx_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (int32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmax_vx_i32m2(op0, op1, op2) \
__builtin_rvv_vmax_vx_i32m2((vint32m2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmax_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vx_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (int32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmax_vx_i32m4(op0, op1, op2) \
__builtin_rvv_vmax_vx_i32m4((vint32m4_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmax_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vx_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (int32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmax_vx_i32m8(op0, op1, op2) \
__builtin_rvv_vmax_vx_i32m8((vint32m8_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmax_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vx_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (int32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmax_vx_i32mf2(op0, op1, op2) \
__builtin_rvv_vmax_vx_i32mf2((vint32mf2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmax_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vx_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (int32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmax_vx_i64m1(op0, op1, op2) \
__builtin_rvv_vmax_vx_i64m1((vint64m1_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmax_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vx_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (int64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmax_vx_i64m2(op0, op1, op2) \
__builtin_rvv_vmax_vx_i64m2((vint64m2_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmax_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vx_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (int64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmax_vx_i64m4(op0, op1, op2) \
__builtin_rvv_vmax_vx_i64m4((vint64m4_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmax_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vx_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (int64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmax_vx_i64m8(op0, op1, op2) \
__builtin_rvv_vmax_vx_i64m8((vint64m8_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmax_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vx_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (int64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmul_vv_i8m1(op0, op1, op2) \
__builtin_rvv_vmul_vv_i8m1((vint8m1_t)(op0), (vint8m1_t)(op1), (size_t)(op2))
#define vmul_vv_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmul_vv_i8m2(op0, op1, op2) \
__builtin_rvv_vmul_vv_i8m2((vint8m2_t)(op0), (vint8m2_t)(op1), (size_t)(op2))
#define vmul_vv_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmul_vv_i8m4(op0, op1, op2) \
__builtin_rvv_vmul_vv_i8m4((vint8m4_t)(op0), (vint8m4_t)(op1), (size_t)(op2))
#define vmul_vv_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmul_vv_i8m8(op0, op1, op2) \
__builtin_rvv_vmul_vv_i8m8((vint8m8_t)(op0), (vint8m8_t)(op1), (size_t)(op2))
#define vmul_vv_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (vint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmul_vv_i8mf2(op0, op1, op2) \
__builtin_rvv_vmul_vv_i8mf2((vint8mf2_t)(op0), (vint8mf2_t)(op1), (size_t)(op2))
#define vmul_vv_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmul_vv_i8mf4(op0, op1, op2) \
__builtin_rvv_vmul_vv_i8mf4((vint8mf4_t)(op0), (vint8mf4_t)(op1), (size_t)(op2))
#define vmul_vv_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmul_vv_i8mf8(op0, op1, op2) \
__builtin_rvv_vmul_vv_i8mf8((vint8mf8_t)(op0), (vint8mf8_t)(op1), (size_t)(op2))
#define vmul_vv_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmul_vv_i16m1(op0, op1, op2) \
__builtin_rvv_vmul_vv_i16m1((vint16m1_t)(op0), (vint16m1_t)(op1), (size_t)(op2))
#define vmul_vv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmul_vv_i16m2(op0, op1, op2) \
__builtin_rvv_vmul_vv_i16m2((vint16m2_t)(op0), (vint16m2_t)(op1), (size_t)(op2))
#define vmul_vv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmul_vv_i16m4(op0, op1, op2) \
__builtin_rvv_vmul_vv_i16m4((vint16m4_t)(op0), (vint16m4_t)(op1), (size_t)(op2))
#define vmul_vv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmul_vv_i16m8(op0, op1, op2) \
__builtin_rvv_vmul_vv_i16m8((vint16m8_t)(op0), (vint16m8_t)(op1), (size_t)(op2))
#define vmul_vv_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (vint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmul_vv_i16mf2(op0, op1, op2) \
__builtin_rvv_vmul_vv_i16mf2((vint16mf2_t)(op0), (vint16mf2_t)(op1), (size_t)(op2))
#define vmul_vv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmul_vv_i16mf4(op0, op1, op2) \
__builtin_rvv_vmul_vv_i16mf4((vint16mf4_t)(op0), (vint16mf4_t)(op1), (size_t)(op2))
#define vmul_vv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmul_vv_i32m1(op0, op1, op2) \
__builtin_rvv_vmul_vv_i32m1((vint32m1_t)(op0), (vint32m1_t)(op1), (size_t)(op2))
#define vmul_vv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmul_vv_i32m2(op0, op1, op2) \
__builtin_rvv_vmul_vv_i32m2((vint32m2_t)(op0), (vint32m2_t)(op1), (size_t)(op2))
#define vmul_vv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmul_vv_i32m4(op0, op1, op2) \
__builtin_rvv_vmul_vv_i32m4((vint32m4_t)(op0), (vint32m4_t)(op1), (size_t)(op2))
#define vmul_vv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmul_vv_i32m8(op0, op1, op2) \
__builtin_rvv_vmul_vv_i32m8((vint32m8_t)(op0), (vint32m8_t)(op1), (size_t)(op2))
#define vmul_vv_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (vint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmul_vv_i32mf2(op0, op1, op2) \
__builtin_rvv_vmul_vv_i32mf2((vint32mf2_t)(op0), (vint32mf2_t)(op1), (size_t)(op2))
#define vmul_vv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmul_vv_i64m1(op0, op1, op2) \
__builtin_rvv_vmul_vv_i64m1((vint64m1_t)(op0), (vint64m1_t)(op1), (size_t)(op2))
#define vmul_vv_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmul_vv_i64m2(op0, op1, op2) \
__builtin_rvv_vmul_vv_i64m2((vint64m2_t)(op0), (vint64m2_t)(op1), (size_t)(op2))
#define vmul_vv_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (vint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmul_vv_i64m4(op0, op1, op2) \
__builtin_rvv_vmul_vv_i64m4((vint64m4_t)(op0), (vint64m4_t)(op1), (size_t)(op2))
#define vmul_vv_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (vint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmul_vv_i64m8(op0, op1, op2) \
__builtin_rvv_vmul_vv_i64m8((vint64m8_t)(op0), (vint64m8_t)(op1), (size_t)(op2))
#define vmul_vv_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (vint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmul_vx_i8m1(op0, op1, op2) \
__builtin_rvv_vmul_vx_i8m1((vint8m1_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmul_vx_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (int8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmul_vx_i8m2(op0, op1, op2) \
__builtin_rvv_vmul_vx_i8m2((vint8m2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmul_vx_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (int8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmul_vx_i8m4(op0, op1, op2) \
__builtin_rvv_vmul_vx_i8m4((vint8m4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmul_vx_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (int8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmul_vx_i8m8(op0, op1, op2) \
__builtin_rvv_vmul_vx_i8m8((vint8m8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmul_vx_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (int8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmul_vx_i8mf2(op0, op1, op2) \
__builtin_rvv_vmul_vx_i8mf2((vint8mf2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmul_vx_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (int8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmul_vx_i8mf4(op0, op1, op2) \
__builtin_rvv_vmul_vx_i8mf4((vint8mf4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmul_vx_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (int8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmul_vx_i8mf8(op0, op1, op2) \
__builtin_rvv_vmul_vx_i8mf8((vint8mf8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmul_vx_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (int8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmul_vx_i16m1(op0, op1, op2) \
__builtin_rvv_vmul_vx_i16m1((vint16m1_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmul_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (int16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmul_vx_i16m2(op0, op1, op2) \
__builtin_rvv_vmul_vx_i16m2((vint16m2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmul_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (int16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmul_vx_i16m4(op0, op1, op2) \
__builtin_rvv_vmul_vx_i16m4((vint16m4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmul_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (int16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmul_vx_i16m8(op0, op1, op2) \
__builtin_rvv_vmul_vx_i16m8((vint16m8_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmul_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (int16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmul_vx_i16mf2(op0, op1, op2) \
__builtin_rvv_vmul_vx_i16mf2((vint16mf2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmul_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (int16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmul_vx_i16mf4(op0, op1, op2) \
__builtin_rvv_vmul_vx_i16mf4((vint16mf4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmul_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (int16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmul_vx_i32m1(op0, op1, op2) \
__builtin_rvv_vmul_vx_i32m1((vint32m1_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmul_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (int32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmul_vx_i32m2(op0, op1, op2) \
__builtin_rvv_vmul_vx_i32m2((vint32m2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmul_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (int32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmul_vx_i32m4(op0, op1, op2) \
__builtin_rvv_vmul_vx_i32m4((vint32m4_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmul_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (int32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmul_vx_i32m8(op0, op1, op2) \
__builtin_rvv_vmul_vx_i32m8((vint32m8_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmul_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (int32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmul_vx_i32mf2(op0, op1, op2) \
__builtin_rvv_vmul_vx_i32mf2((vint32mf2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmul_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (int32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmul_vx_i64m1(op0, op1, op2) \
__builtin_rvv_vmul_vx_i64m1((vint64m1_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmul_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (int64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmul_vx_i64m2(op0, op1, op2) \
__builtin_rvv_vmul_vx_i64m2((vint64m2_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmul_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (int64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmul_vx_i64m4(op0, op1, op2) \
__builtin_rvv_vmul_vx_i64m4((vint64m4_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmul_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (int64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmul_vx_i64m8(op0, op1, op2) \
__builtin_rvv_vmul_vx_i64m8((vint64m8_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmul_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (int64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmul_vv_u8m1(op0, op1, op2) \
__builtin_rvv_vmul_vv_u8m1((vuint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vmul_vv_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmul_vv_u8m2(op0, op1, op2) \
__builtin_rvv_vmul_vv_u8m2((vuint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vmul_vv_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmul_vv_u8m4(op0, op1, op2) \
__builtin_rvv_vmul_vv_u8m4((vuint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vmul_vv_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmul_vv_u8m8(op0, op1, op2) \
__builtin_rvv_vmul_vv_u8m8((vuint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vmul_vv_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmul_vv_u8mf2(op0, op1, op2) \
__builtin_rvv_vmul_vv_u8mf2((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vmul_vv_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmul_vv_u8mf4(op0, op1, op2) \
__builtin_rvv_vmul_vv_u8mf4((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vmul_vv_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmul_vv_u8mf8(op0, op1, op2) \
__builtin_rvv_vmul_vv_u8mf8((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vmul_vv_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmul_vv_u16m1(op0, op1, op2) \
__builtin_rvv_vmul_vv_u16m1((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vmul_vv_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmul_vv_u16m2(op0, op1, op2) \
__builtin_rvv_vmul_vv_u16m2((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vmul_vv_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmul_vv_u16m4(op0, op1, op2) \
__builtin_rvv_vmul_vv_u16m4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vmul_vv_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmul_vv_u16m8(op0, op1, op2) \
__builtin_rvv_vmul_vv_u16m8((vuint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vmul_vv_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmul_vv_u16mf2(op0, op1, op2) \
__builtin_rvv_vmul_vv_u16mf2((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vmul_vv_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmul_vv_u16mf4(op0, op1, op2) \
__builtin_rvv_vmul_vv_u16mf4((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vmul_vv_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmul_vv_u32m1(op0, op1, op2) \
__builtin_rvv_vmul_vv_u32m1((vuint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vmul_vv_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmul_vv_u32m2(op0, op1, op2) \
__builtin_rvv_vmul_vv_u32m2((vuint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vmul_vv_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmul_vv_u32m4(op0, op1, op2) \
__builtin_rvv_vmul_vv_u32m4((vuint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vmul_vv_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmul_vv_u32m8(op0, op1, op2) \
__builtin_rvv_vmul_vv_u32m8((vuint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vmul_vv_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmul_vv_u32mf2(op0, op1, op2) \
__builtin_rvv_vmul_vv_u32mf2((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vmul_vv_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmul_vv_u64m1(op0, op1, op2) \
__builtin_rvv_vmul_vv_u64m1((vuint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vmul_vv_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmul_vv_u64m2(op0, op1, op2) \
__builtin_rvv_vmul_vv_u64m2((vuint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vmul_vv_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmul_vv_u64m4(op0, op1, op2) \
__builtin_rvv_vmul_vv_u64m4((vuint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vmul_vv_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmul_vv_u64m8(op0, op1, op2) \
__builtin_rvv_vmul_vv_u64m8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vmul_vv_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmul_vx_u8m1(op0, op1, op2) \
__builtin_rvv_vmul_vx_u8m1((vuint8m1_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmul_vx_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (uint8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmul_vx_u8m2(op0, op1, op2) \
__builtin_rvv_vmul_vx_u8m2((vuint8m2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmul_vx_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (uint8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmul_vx_u8m4(op0, op1, op2) \
__builtin_rvv_vmul_vx_u8m4((vuint8m4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmul_vx_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (uint8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmul_vx_u8m8(op0, op1, op2) \
__builtin_rvv_vmul_vx_u8m8((vuint8m8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmul_vx_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (uint8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmul_vx_u8mf2(op0, op1, op2) \
__builtin_rvv_vmul_vx_u8mf2((vuint8mf2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmul_vx_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (uint8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmul_vx_u8mf4(op0, op1, op2) \
__builtin_rvv_vmul_vx_u8mf4((vuint8mf4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmul_vx_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (uint8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmul_vx_u8mf8(op0, op1, op2) \
__builtin_rvv_vmul_vx_u8mf8((vuint8mf8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmul_vx_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (uint8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmul_vx_u16m1(op0, op1, op2) \
__builtin_rvv_vmul_vx_u16m1((vuint16m1_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmul_vx_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (uint16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmul_vx_u16m2(op0, op1, op2) \
__builtin_rvv_vmul_vx_u16m2((vuint16m2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmul_vx_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (uint16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmul_vx_u16m4(op0, op1, op2) \
__builtin_rvv_vmul_vx_u16m4((vuint16m4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmul_vx_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (uint16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmul_vx_u16m8(op0, op1, op2) \
__builtin_rvv_vmul_vx_u16m8((vuint16m8_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmul_vx_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (uint16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmul_vx_u16mf2(op0, op1, op2) \
__builtin_rvv_vmul_vx_u16mf2((vuint16mf2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmul_vx_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (uint16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmul_vx_u16mf4(op0, op1, op2) \
__builtin_rvv_vmul_vx_u16mf4((vuint16mf4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmul_vx_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (uint16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmul_vx_u32m1(op0, op1, op2) \
__builtin_rvv_vmul_vx_u32m1((vuint32m1_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmul_vx_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (uint32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmul_vx_u32m2(op0, op1, op2) \
__builtin_rvv_vmul_vx_u32m2((vuint32m2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmul_vx_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (uint32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmul_vx_u32m4(op0, op1, op2) \
__builtin_rvv_vmul_vx_u32m4((vuint32m4_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmul_vx_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (uint32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmul_vx_u32m8(op0, op1, op2) \
__builtin_rvv_vmul_vx_u32m8((vuint32m8_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmul_vx_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (uint32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmul_vx_u32mf2(op0, op1, op2) \
__builtin_rvv_vmul_vx_u32mf2((vuint32mf2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmul_vx_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (uint32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmul_vx_u64m1(op0, op1, op2) \
__builtin_rvv_vmul_vx_u64m1((vuint64m1_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmul_vx_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (uint64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmul_vx_u64m2(op0, op1, op2) \
__builtin_rvv_vmul_vx_u64m2((vuint64m2_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmul_vx_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (uint64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmul_vx_u64m4(op0, op1, op2) \
__builtin_rvv_vmul_vx_u64m4((vuint64m4_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmul_vx_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (uint64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmul_vx_u64m8(op0, op1, op2) \
__builtin_rvv_vmul_vx_u64m8((vuint64m8_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmul_vx_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (uint64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmulh_vv_i8m1(op0, op1, op2) \
__builtin_rvv_vmulh_vv_i8m1((vint8m1_t)(op0), (vint8m1_t)(op1), (size_t)(op2))
#define vmulh_vv_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vv_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmulh_vv_i8m2(op0, op1, op2) \
__builtin_rvv_vmulh_vv_i8m2((vint8m2_t)(op0), (vint8m2_t)(op1), (size_t)(op2))
#define vmulh_vv_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vv_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmulh_vv_i8m4(op0, op1, op2) \
__builtin_rvv_vmulh_vv_i8m4((vint8m4_t)(op0), (vint8m4_t)(op1), (size_t)(op2))
#define vmulh_vv_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vv_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmulh_vv_i8m8(op0, op1, op2) \
__builtin_rvv_vmulh_vv_i8m8((vint8m8_t)(op0), (vint8m8_t)(op1), (size_t)(op2))
#define vmulh_vv_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vv_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (vint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmulh_vv_i8mf2(op0, op1, op2) \
__builtin_rvv_vmulh_vv_i8mf2((vint8mf2_t)(op0), (vint8mf2_t)(op1), (size_t)(op2))
#define vmulh_vv_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vv_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmulh_vv_i8mf4(op0, op1, op2) \
__builtin_rvv_vmulh_vv_i8mf4((vint8mf4_t)(op0), (vint8mf4_t)(op1), (size_t)(op2))
#define vmulh_vv_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vv_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmulh_vv_i8mf8(op0, op1, op2) \
__builtin_rvv_vmulh_vv_i8mf8((vint8mf8_t)(op0), (vint8mf8_t)(op1), (size_t)(op2))
#define vmulh_vv_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vv_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmulh_vv_i16m1(op0, op1, op2) \
__builtin_rvv_vmulh_vv_i16m1((vint16m1_t)(op0), (vint16m1_t)(op1), (size_t)(op2))
#define vmulh_vv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vv_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmulh_vv_i16m2(op0, op1, op2) \
__builtin_rvv_vmulh_vv_i16m2((vint16m2_t)(op0), (vint16m2_t)(op1), (size_t)(op2))
#define vmulh_vv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vv_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmulh_vv_i16m4(op0, op1, op2) \
__builtin_rvv_vmulh_vv_i16m4((vint16m4_t)(op0), (vint16m4_t)(op1), (size_t)(op2))
#define vmulh_vv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vv_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmulh_vv_i16m8(op0, op1, op2) \
__builtin_rvv_vmulh_vv_i16m8((vint16m8_t)(op0), (vint16m8_t)(op1), (size_t)(op2))
#define vmulh_vv_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vv_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (vint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmulh_vv_i16mf2(op0, op1, op2) \
__builtin_rvv_vmulh_vv_i16mf2((vint16mf2_t)(op0), (vint16mf2_t)(op1), (size_t)(op2))
#define vmulh_vv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vv_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmulh_vv_i16mf4(op0, op1, op2) \
__builtin_rvv_vmulh_vv_i16mf4((vint16mf4_t)(op0), (vint16mf4_t)(op1), (size_t)(op2))
#define vmulh_vv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vv_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmulh_vv_i32m1(op0, op1, op2) \
__builtin_rvv_vmulh_vv_i32m1((vint32m1_t)(op0), (vint32m1_t)(op1), (size_t)(op2))
#define vmulh_vv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vv_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmulh_vv_i32m2(op0, op1, op2) \
__builtin_rvv_vmulh_vv_i32m2((vint32m2_t)(op0), (vint32m2_t)(op1), (size_t)(op2))
#define vmulh_vv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vv_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmulh_vv_i32m4(op0, op1, op2) \
__builtin_rvv_vmulh_vv_i32m4((vint32m4_t)(op0), (vint32m4_t)(op1), (size_t)(op2))
#define vmulh_vv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vv_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmulh_vv_i32m8(op0, op1, op2) \
__builtin_rvv_vmulh_vv_i32m8((vint32m8_t)(op0), (vint32m8_t)(op1), (size_t)(op2))
#define vmulh_vv_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vv_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (vint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmulh_vv_i32mf2(op0, op1, op2) \
__builtin_rvv_vmulh_vv_i32mf2((vint32mf2_t)(op0), (vint32mf2_t)(op1), (size_t)(op2))
#define vmulh_vv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vv_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmulh_vv_i64m1(op0, op1, op2) \
__builtin_rvv_vmulh_vv_i64m1((vint64m1_t)(op0), (vint64m1_t)(op1), (size_t)(op2))
#define vmulh_vv_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vv_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmulh_vv_i64m2(op0, op1, op2) \
__builtin_rvv_vmulh_vv_i64m2((vint64m2_t)(op0), (vint64m2_t)(op1), (size_t)(op2))
#define vmulh_vv_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vv_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (vint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmulh_vv_i64m4(op0, op1, op2) \
__builtin_rvv_vmulh_vv_i64m4((vint64m4_t)(op0), (vint64m4_t)(op1), (size_t)(op2))
#define vmulh_vv_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vv_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (vint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmulh_vv_i64m8(op0, op1, op2) \
__builtin_rvv_vmulh_vv_i64m8((vint64m8_t)(op0), (vint64m8_t)(op1), (size_t)(op2))
#define vmulh_vv_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vv_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (vint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmulh_vx_i8m1(op0, op1, op2) \
__builtin_rvv_vmulh_vx_i8m1((vint8m1_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmulh_vx_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vx_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (int8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmulh_vx_i8m2(op0, op1, op2) \
__builtin_rvv_vmulh_vx_i8m2((vint8m2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmulh_vx_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vx_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (int8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmulh_vx_i8m4(op0, op1, op2) \
__builtin_rvv_vmulh_vx_i8m4((vint8m4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmulh_vx_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vx_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (int8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmulh_vx_i8m8(op0, op1, op2) \
__builtin_rvv_vmulh_vx_i8m8((vint8m8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmulh_vx_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vx_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (int8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmulh_vx_i8mf2(op0, op1, op2) \
__builtin_rvv_vmulh_vx_i8mf2((vint8mf2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmulh_vx_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vx_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (int8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmulh_vx_i8mf4(op0, op1, op2) \
__builtin_rvv_vmulh_vx_i8mf4((vint8mf4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmulh_vx_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vx_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (int8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmulh_vx_i8mf8(op0, op1, op2) \
__builtin_rvv_vmulh_vx_i8mf8((vint8mf8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmulh_vx_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vx_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (int8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmulh_vx_i16m1(op0, op1, op2) \
__builtin_rvv_vmulh_vx_i16m1((vint16m1_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmulh_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vx_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (int16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmulh_vx_i16m2(op0, op1, op2) \
__builtin_rvv_vmulh_vx_i16m2((vint16m2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmulh_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vx_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (int16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmulh_vx_i16m4(op0, op1, op2) \
__builtin_rvv_vmulh_vx_i16m4((vint16m4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmulh_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vx_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (int16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmulh_vx_i16m8(op0, op1, op2) \
__builtin_rvv_vmulh_vx_i16m8((vint16m8_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmulh_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vx_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (int16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmulh_vx_i16mf2(op0, op1, op2) \
__builtin_rvv_vmulh_vx_i16mf2((vint16mf2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmulh_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vx_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (int16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmulh_vx_i16mf4(op0, op1, op2) \
__builtin_rvv_vmulh_vx_i16mf4((vint16mf4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmulh_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vx_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (int16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmulh_vx_i32m1(op0, op1, op2) \
__builtin_rvv_vmulh_vx_i32m1((vint32m1_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmulh_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vx_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (int32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmulh_vx_i32m2(op0, op1, op2) \
__builtin_rvv_vmulh_vx_i32m2((vint32m2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmulh_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vx_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (int32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmulh_vx_i32m4(op0, op1, op2) \
__builtin_rvv_vmulh_vx_i32m4((vint32m4_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmulh_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vx_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (int32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmulh_vx_i32m8(op0, op1, op2) \
__builtin_rvv_vmulh_vx_i32m8((vint32m8_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmulh_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vx_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (int32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmulh_vx_i32mf2(op0, op1, op2) \
__builtin_rvv_vmulh_vx_i32mf2((vint32mf2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmulh_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vx_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (int32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmulh_vx_i64m1(op0, op1, op2) \
__builtin_rvv_vmulh_vx_i64m1((vint64m1_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmulh_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vx_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (int64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmulh_vx_i64m2(op0, op1, op2) \
__builtin_rvv_vmulh_vx_i64m2((vint64m2_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmulh_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vx_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (int64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmulh_vx_i64m4(op0, op1, op2) \
__builtin_rvv_vmulh_vx_i64m4((vint64m4_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmulh_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vx_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (int64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmulh_vx_i64m8(op0, op1, op2) \
__builtin_rvv_vmulh_vx_i64m8((vint64m8_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmulh_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vx_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (int64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmulhu_vv_u8m1(op0, op1, op2) \
__builtin_rvv_vmulhu_vv_u8m1((vuint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vmulhu_vv_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vv_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmulhu_vv_u8m2(op0, op1, op2) \
__builtin_rvv_vmulhu_vv_u8m2((vuint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vmulhu_vv_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vv_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmulhu_vv_u8m4(op0, op1, op2) \
__builtin_rvv_vmulhu_vv_u8m4((vuint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vmulhu_vv_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vv_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmulhu_vv_u8m8(op0, op1, op2) \
__builtin_rvv_vmulhu_vv_u8m8((vuint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vmulhu_vv_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vv_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmulhu_vv_u8mf2(op0, op1, op2) \
__builtin_rvv_vmulhu_vv_u8mf2((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vmulhu_vv_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vv_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmulhu_vv_u8mf4(op0, op1, op2) \
__builtin_rvv_vmulhu_vv_u8mf4((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vmulhu_vv_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vv_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmulhu_vv_u8mf8(op0, op1, op2) \
__builtin_rvv_vmulhu_vv_u8mf8((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vmulhu_vv_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vv_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmulhu_vv_u16m1(op0, op1, op2) \
__builtin_rvv_vmulhu_vv_u16m1((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vmulhu_vv_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vv_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmulhu_vv_u16m2(op0, op1, op2) \
__builtin_rvv_vmulhu_vv_u16m2((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vmulhu_vv_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vv_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmulhu_vv_u16m4(op0, op1, op2) \
__builtin_rvv_vmulhu_vv_u16m4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vmulhu_vv_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vv_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmulhu_vv_u16m8(op0, op1, op2) \
__builtin_rvv_vmulhu_vv_u16m8((vuint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vmulhu_vv_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vv_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmulhu_vv_u16mf2(op0, op1, op2) \
__builtin_rvv_vmulhu_vv_u16mf2((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vmulhu_vv_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vv_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmulhu_vv_u16mf4(op0, op1, op2) \
__builtin_rvv_vmulhu_vv_u16mf4((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vmulhu_vv_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vv_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmulhu_vv_u32m1(op0, op1, op2) \
__builtin_rvv_vmulhu_vv_u32m1((vuint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vmulhu_vv_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vv_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmulhu_vv_u32m2(op0, op1, op2) \
__builtin_rvv_vmulhu_vv_u32m2((vuint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vmulhu_vv_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vv_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmulhu_vv_u32m4(op0, op1, op2) \
__builtin_rvv_vmulhu_vv_u32m4((vuint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vmulhu_vv_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vv_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmulhu_vv_u32m8(op0, op1, op2) \
__builtin_rvv_vmulhu_vv_u32m8((vuint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vmulhu_vv_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vv_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmulhu_vv_u32mf2(op0, op1, op2) \
__builtin_rvv_vmulhu_vv_u32mf2((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vmulhu_vv_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vv_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmulhu_vv_u64m1(op0, op1, op2) \
__builtin_rvv_vmulhu_vv_u64m1((vuint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vmulhu_vv_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vv_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmulhu_vv_u64m2(op0, op1, op2) \
__builtin_rvv_vmulhu_vv_u64m2((vuint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vmulhu_vv_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vv_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmulhu_vv_u64m4(op0, op1, op2) \
__builtin_rvv_vmulhu_vv_u64m4((vuint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vmulhu_vv_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vv_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmulhu_vv_u64m8(op0, op1, op2) \
__builtin_rvv_vmulhu_vv_u64m8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vmulhu_vv_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vv_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmulhu_vx_u8m1(op0, op1, op2) \
__builtin_rvv_vmulhu_vx_u8m1((vuint8m1_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmulhu_vx_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vx_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (uint8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmulhu_vx_u8m2(op0, op1, op2) \
__builtin_rvv_vmulhu_vx_u8m2((vuint8m2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmulhu_vx_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vx_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (uint8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmulhu_vx_u8m4(op0, op1, op2) \
__builtin_rvv_vmulhu_vx_u8m4((vuint8m4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmulhu_vx_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vx_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (uint8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmulhu_vx_u8m8(op0, op1, op2) \
__builtin_rvv_vmulhu_vx_u8m8((vuint8m8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmulhu_vx_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vx_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (uint8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmulhu_vx_u8mf2(op0, op1, op2) \
__builtin_rvv_vmulhu_vx_u8mf2((vuint8mf2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmulhu_vx_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vx_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (uint8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmulhu_vx_u8mf4(op0, op1, op2) \
__builtin_rvv_vmulhu_vx_u8mf4((vuint8mf4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmulhu_vx_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vx_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (uint8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmulhu_vx_u8mf8(op0, op1, op2) \
__builtin_rvv_vmulhu_vx_u8mf8((vuint8mf8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmulhu_vx_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vx_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (uint8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmulhu_vx_u16m1(op0, op1, op2) \
__builtin_rvv_vmulhu_vx_u16m1((vuint16m1_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmulhu_vx_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vx_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (uint16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmulhu_vx_u16m2(op0, op1, op2) \
__builtin_rvv_vmulhu_vx_u16m2((vuint16m2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmulhu_vx_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vx_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (uint16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmulhu_vx_u16m4(op0, op1, op2) \
__builtin_rvv_vmulhu_vx_u16m4((vuint16m4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmulhu_vx_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vx_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (uint16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmulhu_vx_u16m8(op0, op1, op2) \
__builtin_rvv_vmulhu_vx_u16m8((vuint16m8_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmulhu_vx_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vx_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (uint16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmulhu_vx_u16mf2(op0, op1, op2) \
__builtin_rvv_vmulhu_vx_u16mf2((vuint16mf2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmulhu_vx_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vx_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (uint16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmulhu_vx_u16mf4(op0, op1, op2) \
__builtin_rvv_vmulhu_vx_u16mf4((vuint16mf4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmulhu_vx_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vx_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (uint16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmulhu_vx_u32m1(op0, op1, op2) \
__builtin_rvv_vmulhu_vx_u32m1((vuint32m1_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmulhu_vx_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vx_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (uint32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmulhu_vx_u32m2(op0, op1, op2) \
__builtin_rvv_vmulhu_vx_u32m2((vuint32m2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmulhu_vx_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vx_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (uint32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmulhu_vx_u32m4(op0, op1, op2) \
__builtin_rvv_vmulhu_vx_u32m4((vuint32m4_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmulhu_vx_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vx_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (uint32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmulhu_vx_u32m8(op0, op1, op2) \
__builtin_rvv_vmulhu_vx_u32m8((vuint32m8_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmulhu_vx_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vx_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (uint32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmulhu_vx_u32mf2(op0, op1, op2) \
__builtin_rvv_vmulhu_vx_u32mf2((vuint32mf2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmulhu_vx_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vx_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (uint32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmulhu_vx_u64m1(op0, op1, op2) \
__builtin_rvv_vmulhu_vx_u64m1((vuint64m1_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmulhu_vx_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vx_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (uint64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmulhu_vx_u64m2(op0, op1, op2) \
__builtin_rvv_vmulhu_vx_u64m2((vuint64m2_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmulhu_vx_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vx_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (uint64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmulhu_vx_u64m4(op0, op1, op2) \
__builtin_rvv_vmulhu_vx_u64m4((vuint64m4_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmulhu_vx_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vx_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (uint64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmulhu_vx_u64m8(op0, op1, op2) \
__builtin_rvv_vmulhu_vx_u64m8((vuint64m8_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmulhu_vx_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vx_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (uint64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vle64_v_u64m1(op0, op1) \
__builtin_rvv_vle64_v_u64m1((const uint64_t *)(op0), (size_t)(op1))
#define vle64_v_u64m1_m(op2, op0, op1, op3) \
__builtin_rvv_vle64_v_u64m1_m((vuint64m1_t)(op0), (const uint64_t *)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vle64_v_u64m2(op0, op1) \
__builtin_rvv_vle64_v_u64m2((const uint64_t *)(op0), (size_t)(op1))
#define vle64_v_u64m2_m(op2, op0, op1, op3) \
__builtin_rvv_vle64_v_u64m2_m((vuint64m2_t)(op0), (const uint64_t *)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vle64_v_u64m4(op0, op1) \
__builtin_rvv_vle64_v_u64m4((const uint64_t *)(op0), (size_t)(op1))
#define vle64_v_u64m4_m(op2, op0, op1, op3) \
__builtin_rvv_vle64_v_u64m4_m((vuint64m4_t)(op0), (const uint64_t *)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vle64_v_u64m8(op0, op1) \
__builtin_rvv_vle64_v_u64m8((const uint64_t *)(op0), (size_t)(op1))
#define vle64_v_u64m8_m(op2, op0, op1, op3) \
__builtin_rvv_vle64_v_u64m8_m((vuint64m8_t)(op0), (const uint64_t *)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmulhsu_vv_i8m1(op0, op1, op2) \
__builtin_rvv_vmulhsu_vv_i8m1((vint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vmulhsu_vv_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vv_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmulhsu_vv_i8m2(op0, op1, op2) \
__builtin_rvv_vmulhsu_vv_i8m2((vint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vmulhsu_vv_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vv_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmulhsu_vv_i8m4(op0, op1, op2) \
__builtin_rvv_vmulhsu_vv_i8m4((vint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vmulhsu_vv_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vv_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmulhsu_vv_i8m8(op0, op1, op2) \
__builtin_rvv_vmulhsu_vv_i8m8((vint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vmulhsu_vv_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vv_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmulhsu_vv_i8mf2(op0, op1, op2) \
__builtin_rvv_vmulhsu_vv_i8mf2((vint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vmulhsu_vv_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vv_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmulhsu_vv_i8mf4(op0, op1, op2) \
__builtin_rvv_vmulhsu_vv_i8mf4((vint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vmulhsu_vv_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vv_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmulhsu_vv_i8mf8(op0, op1, op2) \
__builtin_rvv_vmulhsu_vv_i8mf8((vint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vmulhsu_vv_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vv_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmulhsu_vv_i16m1(op0, op1, op2) \
__builtin_rvv_vmulhsu_vv_i16m1((vint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vmulhsu_vv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vv_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmulhsu_vv_i16m2(op0, op1, op2) \
__builtin_rvv_vmulhsu_vv_i16m2((vint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vmulhsu_vv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vv_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmulhsu_vv_i16m4(op0, op1, op2) \
__builtin_rvv_vmulhsu_vv_i16m4((vint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vmulhsu_vv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vv_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmulhsu_vv_i16m8(op0, op1, op2) \
__builtin_rvv_vmulhsu_vv_i16m8((vint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vmulhsu_vv_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vv_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmulhsu_vv_i16mf2(op0, op1, op2) \
__builtin_rvv_vmulhsu_vv_i16mf2((vint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vmulhsu_vv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vv_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmulhsu_vv_i16mf4(op0, op1, op2) \
__builtin_rvv_vmulhsu_vv_i16mf4((vint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vmulhsu_vv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vv_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmulhsu_vv_i32m1(op0, op1, op2) \
__builtin_rvv_vmulhsu_vv_i32m1((vint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vmulhsu_vv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vv_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmulhsu_vv_i32m2(op0, op1, op2) \
__builtin_rvv_vmulhsu_vv_i32m2((vint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vmulhsu_vv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vv_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmulhsu_vv_i32m4(op0, op1, op2) \
__builtin_rvv_vmulhsu_vv_i32m4((vint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vmulhsu_vv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vv_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmulhsu_vv_i32m8(op0, op1, op2) \
__builtin_rvv_vmulhsu_vv_i32m8((vint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vmulhsu_vv_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vv_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmulhsu_vv_i32mf2(op0, op1, op2) \
__builtin_rvv_vmulhsu_vv_i32mf2((vint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vmulhsu_vv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vv_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmulhsu_vv_i64m1(op0, op1, op2) \
__builtin_rvv_vmulhsu_vv_i64m1((vint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vmulhsu_vv_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vv_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmulhsu_vv_i64m2(op0, op1, op2) \
__builtin_rvv_vmulhsu_vv_i64m2((vint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vmulhsu_vv_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vv_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmulhsu_vv_i64m4(op0, op1, op2) \
__builtin_rvv_vmulhsu_vv_i64m4((vint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vmulhsu_vv_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vv_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmulhsu_vv_i64m8(op0, op1, op2) \
__builtin_rvv_vmulhsu_vv_i64m8((vint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vmulhsu_vv_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vv_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmulhsu_vx_i8m1(op0, op1, op2) \
__builtin_rvv_vmulhsu_vx_i8m1((vint8m1_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmulhsu_vx_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vx_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (uint8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmulhsu_vx_i8m2(op0, op1, op2) \
__builtin_rvv_vmulhsu_vx_i8m2((vint8m2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmulhsu_vx_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vx_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (uint8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmulhsu_vx_i8m4(op0, op1, op2) \
__builtin_rvv_vmulhsu_vx_i8m4((vint8m4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmulhsu_vx_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vx_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (uint8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmulhsu_vx_i8m8(op0, op1, op2) \
__builtin_rvv_vmulhsu_vx_i8m8((vint8m8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmulhsu_vx_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vx_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (uint8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmulhsu_vx_i8mf2(op0, op1, op2) \
__builtin_rvv_vmulhsu_vx_i8mf2((vint8mf2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmulhsu_vx_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vx_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (uint8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmulhsu_vx_i8mf4(op0, op1, op2) \
__builtin_rvv_vmulhsu_vx_i8mf4((vint8mf4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmulhsu_vx_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vx_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (uint8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmulhsu_vx_i8mf8(op0, op1, op2) \
__builtin_rvv_vmulhsu_vx_i8mf8((vint8mf8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmulhsu_vx_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vx_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (uint8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmulhsu_vx_i16m1(op0, op1, op2) \
__builtin_rvv_vmulhsu_vx_i16m1((vint16m1_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmulhsu_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vx_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (uint16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmulhsu_vx_i16m2(op0, op1, op2) \
__builtin_rvv_vmulhsu_vx_i16m2((vint16m2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmulhsu_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vx_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (uint16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmulhsu_vx_i16m4(op0, op1, op2) \
__builtin_rvv_vmulhsu_vx_i16m4((vint16m4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmulhsu_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vx_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (uint16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmulhsu_vx_i16m8(op0, op1, op2) \
__builtin_rvv_vmulhsu_vx_i16m8((vint16m8_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmulhsu_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vx_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (uint16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmulhsu_vx_i16mf2(op0, op1, op2) \
__builtin_rvv_vmulhsu_vx_i16mf2((vint16mf2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmulhsu_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vx_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (uint16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmulhsu_vx_i16mf4(op0, op1, op2) \
__builtin_rvv_vmulhsu_vx_i16mf4((vint16mf4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmulhsu_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vx_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (uint16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmulhsu_vx_i32m1(op0, op1, op2) \
__builtin_rvv_vmulhsu_vx_i32m1((vint32m1_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmulhsu_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vx_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (uint32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmulhsu_vx_i32m2(op0, op1, op2) \
__builtin_rvv_vmulhsu_vx_i32m2((vint32m2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmulhsu_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vx_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (uint32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmulhsu_vx_i32m4(op0, op1, op2) \
__builtin_rvv_vmulhsu_vx_i32m4((vint32m4_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmulhsu_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vx_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (uint32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmulhsu_vx_i32m8(op0, op1, op2) \
__builtin_rvv_vmulhsu_vx_i32m8((vint32m8_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmulhsu_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vx_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (uint32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmulhsu_vx_i32mf2(op0, op1, op2) \
__builtin_rvv_vmulhsu_vx_i32mf2((vint32mf2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmulhsu_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vx_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (uint32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmulhsu_vx_i64m1(op0, op1, op2) \
__builtin_rvv_vmulhsu_vx_i64m1((vint64m1_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmulhsu_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vx_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (uint64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmulhsu_vx_i64m2(op0, op1, op2) \
__builtin_rvv_vmulhsu_vx_i64m2((vint64m2_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmulhsu_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vx_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (uint64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmulhsu_vx_i64m4(op0, op1, op2) \
__builtin_rvv_vmulhsu_vx_i64m4((vint64m4_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmulhsu_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vx_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (uint64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmulhsu_vx_i64m8(op0, op1, op2) \
__builtin_rvv_vmulhsu_vx_i64m8((vint64m8_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmulhsu_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vx_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (uint64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vdivu_vv_u8m1(op0, op1, op2) \
__builtin_rvv_vdivu_vv_u8m1((vuint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vdivu_vv_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vv_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vdivu_vv_u8m2(op0, op1, op2) \
__builtin_rvv_vdivu_vv_u8m2((vuint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vdivu_vv_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vv_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vdivu_vv_u8m4(op0, op1, op2) \
__builtin_rvv_vdivu_vv_u8m4((vuint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vdivu_vv_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vv_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vdivu_vv_u8m8(op0, op1, op2) \
__builtin_rvv_vdivu_vv_u8m8((vuint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vdivu_vv_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vv_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vdivu_vv_u8mf2(op0, op1, op2) \
__builtin_rvv_vdivu_vv_u8mf2((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vdivu_vv_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vv_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vdivu_vv_u8mf4(op0, op1, op2) \
__builtin_rvv_vdivu_vv_u8mf4((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vdivu_vv_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vv_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vdivu_vv_u8mf8(op0, op1, op2) \
__builtin_rvv_vdivu_vv_u8mf8((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vdivu_vv_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vv_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vdivu_vv_u16m1(op0, op1, op2) \
__builtin_rvv_vdivu_vv_u16m1((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vdivu_vv_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vv_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vdivu_vv_u16m2(op0, op1, op2) \
__builtin_rvv_vdivu_vv_u16m2((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vdivu_vv_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vv_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vdivu_vv_u16m4(op0, op1, op2) \
__builtin_rvv_vdivu_vv_u16m4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vdivu_vv_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vv_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vdivu_vv_u16m8(op0, op1, op2) \
__builtin_rvv_vdivu_vv_u16m8((vuint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vdivu_vv_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vv_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vdivu_vv_u16mf2(op0, op1, op2) \
__builtin_rvv_vdivu_vv_u16mf2((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vdivu_vv_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vv_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vdivu_vv_u16mf4(op0, op1, op2) \
__builtin_rvv_vdivu_vv_u16mf4((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vdivu_vv_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vv_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vdivu_vv_u32m1(op0, op1, op2) \
__builtin_rvv_vdivu_vv_u32m1((vuint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vdivu_vv_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vv_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vdivu_vv_u32m2(op0, op1, op2) \
__builtin_rvv_vdivu_vv_u32m2((vuint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vdivu_vv_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vv_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vdivu_vv_u32m4(op0, op1, op2) \
__builtin_rvv_vdivu_vv_u32m4((vuint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vdivu_vv_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vv_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vdivu_vv_u32m8(op0, op1, op2) \
__builtin_rvv_vdivu_vv_u32m8((vuint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vdivu_vv_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vv_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vdivu_vv_u32mf2(op0, op1, op2) \
__builtin_rvv_vdivu_vv_u32mf2((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vdivu_vv_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vv_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vdivu_vv_u64m1(op0, op1, op2) \
__builtin_rvv_vdivu_vv_u64m1((vuint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vdivu_vv_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vv_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vdivu_vv_u64m2(op0, op1, op2) \
__builtin_rvv_vdivu_vv_u64m2((vuint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vdivu_vv_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vv_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vdivu_vv_u64m4(op0, op1, op2) \
__builtin_rvv_vdivu_vv_u64m4((vuint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vdivu_vv_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vv_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vdivu_vv_u64m8(op0, op1, op2) \
__builtin_rvv_vdivu_vv_u64m8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vdivu_vv_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vv_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vdivu_vx_u8m1(op0, op1, op2) \
__builtin_rvv_vdivu_vx_u8m1((vuint8m1_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vdivu_vx_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vx_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (uint8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vdivu_vx_u8m2(op0, op1, op2) \
__builtin_rvv_vdivu_vx_u8m2((vuint8m2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vdivu_vx_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vx_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (uint8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vdivu_vx_u8m4(op0, op1, op2) \
__builtin_rvv_vdivu_vx_u8m4((vuint8m4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vdivu_vx_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vx_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (uint8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vdivu_vx_u8m8(op0, op1, op2) \
__builtin_rvv_vdivu_vx_u8m8((vuint8m8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vdivu_vx_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vx_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (uint8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vdivu_vx_u8mf2(op0, op1, op2) \
__builtin_rvv_vdivu_vx_u8mf2((vuint8mf2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vdivu_vx_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vx_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (uint8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vdivu_vx_u8mf4(op0, op1, op2) \
__builtin_rvv_vdivu_vx_u8mf4((vuint8mf4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vdivu_vx_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vx_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (uint8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vdivu_vx_u8mf8(op0, op1, op2) \
__builtin_rvv_vdivu_vx_u8mf8((vuint8mf8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vdivu_vx_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vx_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (uint8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vdivu_vx_u16m1(op0, op1, op2) \
__builtin_rvv_vdivu_vx_u16m1((vuint16m1_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vdivu_vx_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vx_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (uint16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vdivu_vx_u16m2(op0, op1, op2) \
__builtin_rvv_vdivu_vx_u16m2((vuint16m2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vdivu_vx_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vx_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (uint16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vdivu_vx_u16m4(op0, op1, op2) \
__builtin_rvv_vdivu_vx_u16m4((vuint16m4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vdivu_vx_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vx_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (uint16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vdivu_vx_u16m8(op0, op1, op2) \
__builtin_rvv_vdivu_vx_u16m8((vuint16m8_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vdivu_vx_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vx_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (uint16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vdivu_vx_u16mf2(op0, op1, op2) \
__builtin_rvv_vdivu_vx_u16mf2((vuint16mf2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vdivu_vx_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vx_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (uint16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vdivu_vx_u16mf4(op0, op1, op2) \
__builtin_rvv_vdivu_vx_u16mf4((vuint16mf4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vdivu_vx_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vx_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (uint16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vdivu_vx_u32m1(op0, op1, op2) \
__builtin_rvv_vdivu_vx_u32m1((vuint32m1_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vdivu_vx_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vx_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (uint32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vdivu_vx_u32m2(op0, op1, op2) \
__builtin_rvv_vdivu_vx_u32m2((vuint32m2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vdivu_vx_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vx_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (uint32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vdivu_vx_u32m4(op0, op1, op2) \
__builtin_rvv_vdivu_vx_u32m4((vuint32m4_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vdivu_vx_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vx_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (uint32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vdivu_vx_u32m8(op0, op1, op2) \
__builtin_rvv_vdivu_vx_u32m8((vuint32m8_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vdivu_vx_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vx_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (uint32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vdivu_vx_u32mf2(op0, op1, op2) \
__builtin_rvv_vdivu_vx_u32mf2((vuint32mf2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vdivu_vx_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vx_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (uint32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vdivu_vx_u64m1(op0, op1, op2) \
__builtin_rvv_vdivu_vx_u64m1((vuint64m1_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vdivu_vx_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vx_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (uint64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vdivu_vx_u64m2(op0, op1, op2) \
__builtin_rvv_vdivu_vx_u64m2((vuint64m2_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vdivu_vx_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vx_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (uint64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vdivu_vx_u64m4(op0, op1, op2) \
__builtin_rvv_vdivu_vx_u64m4((vuint64m4_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vdivu_vx_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vx_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (uint64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vdivu_vx_u64m8(op0, op1, op2) \
__builtin_rvv_vdivu_vx_u64m8((vuint64m8_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vdivu_vx_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vx_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (uint64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vdiv_vv_i8m1(op0, op1, op2) \
__builtin_rvv_vdiv_vv_i8m1((vint8m1_t)(op0), (vint8m1_t)(op1), (size_t)(op2))
#define vdiv_vv_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vv_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vdiv_vv_i8m2(op0, op1, op2) \
__builtin_rvv_vdiv_vv_i8m2((vint8m2_t)(op0), (vint8m2_t)(op1), (size_t)(op2))
#define vdiv_vv_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vv_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vdiv_vv_i8m4(op0, op1, op2) \
__builtin_rvv_vdiv_vv_i8m4((vint8m4_t)(op0), (vint8m4_t)(op1), (size_t)(op2))
#define vdiv_vv_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vv_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vdiv_vv_i8m8(op0, op1, op2) \
__builtin_rvv_vdiv_vv_i8m8((vint8m8_t)(op0), (vint8m8_t)(op1), (size_t)(op2))
#define vdiv_vv_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vv_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (vint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vdiv_vv_i8mf2(op0, op1, op2) \
__builtin_rvv_vdiv_vv_i8mf2((vint8mf2_t)(op0), (vint8mf2_t)(op1), (size_t)(op2))
#define vdiv_vv_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vv_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vdiv_vv_i8mf4(op0, op1, op2) \
__builtin_rvv_vdiv_vv_i8mf4((vint8mf4_t)(op0), (vint8mf4_t)(op1), (size_t)(op2))
#define vdiv_vv_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vv_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vdiv_vv_i8mf8(op0, op1, op2) \
__builtin_rvv_vdiv_vv_i8mf8((vint8mf8_t)(op0), (vint8mf8_t)(op1), (size_t)(op2))
#define vdiv_vv_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vv_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vdiv_vv_i16m1(op0, op1, op2) \
__builtin_rvv_vdiv_vv_i16m1((vint16m1_t)(op0), (vint16m1_t)(op1), (size_t)(op2))
#define vdiv_vv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vv_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vdiv_vv_i16m2(op0, op1, op2) \
__builtin_rvv_vdiv_vv_i16m2((vint16m2_t)(op0), (vint16m2_t)(op1), (size_t)(op2))
#define vdiv_vv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vv_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vdiv_vv_i16m4(op0, op1, op2) \
__builtin_rvv_vdiv_vv_i16m4((vint16m4_t)(op0), (vint16m4_t)(op1), (size_t)(op2))
#define vdiv_vv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vv_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vdiv_vv_i16m8(op0, op1, op2) \
__builtin_rvv_vdiv_vv_i16m8((vint16m8_t)(op0), (vint16m8_t)(op1), (size_t)(op2))
#define vdiv_vv_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vv_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (vint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vdiv_vv_i16mf2(op0, op1, op2) \
__builtin_rvv_vdiv_vv_i16mf2((vint16mf2_t)(op0), (vint16mf2_t)(op1), (size_t)(op2))
#define vdiv_vv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vv_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vdiv_vv_i16mf4(op0, op1, op2) \
__builtin_rvv_vdiv_vv_i16mf4((vint16mf4_t)(op0), (vint16mf4_t)(op1), (size_t)(op2))
#define vdiv_vv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vv_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vdiv_vv_i32m1(op0, op1, op2) \
__builtin_rvv_vdiv_vv_i32m1((vint32m1_t)(op0), (vint32m1_t)(op1), (size_t)(op2))
#define vdiv_vv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vv_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vdiv_vv_i32m2(op0, op1, op2) \
__builtin_rvv_vdiv_vv_i32m2((vint32m2_t)(op0), (vint32m2_t)(op1), (size_t)(op2))
#define vdiv_vv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vv_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vdiv_vv_i32m4(op0, op1, op2) \
__builtin_rvv_vdiv_vv_i32m4((vint32m4_t)(op0), (vint32m4_t)(op1), (size_t)(op2))
#define vdiv_vv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vv_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vdiv_vv_i32m8(op0, op1, op2) \
__builtin_rvv_vdiv_vv_i32m8((vint32m8_t)(op0), (vint32m8_t)(op1), (size_t)(op2))
#define vdiv_vv_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vv_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (vint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vdiv_vv_i32mf2(op0, op1, op2) \
__builtin_rvv_vdiv_vv_i32mf2((vint32mf2_t)(op0), (vint32mf2_t)(op1), (size_t)(op2))
#define vdiv_vv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vv_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vdiv_vv_i64m1(op0, op1, op2) \
__builtin_rvv_vdiv_vv_i64m1((vint64m1_t)(op0), (vint64m1_t)(op1), (size_t)(op2))
#define vdiv_vv_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vv_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vdiv_vv_i64m2(op0, op1, op2) \
__builtin_rvv_vdiv_vv_i64m2((vint64m2_t)(op0), (vint64m2_t)(op1), (size_t)(op2))
#define vdiv_vv_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vv_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (vint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vdiv_vv_i64m4(op0, op1, op2) \
__builtin_rvv_vdiv_vv_i64m4((vint64m4_t)(op0), (vint64m4_t)(op1), (size_t)(op2))
#define vdiv_vv_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vv_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (vint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vdiv_vv_i64m8(op0, op1, op2) \
__builtin_rvv_vdiv_vv_i64m8((vint64m8_t)(op0), (vint64m8_t)(op1), (size_t)(op2))
#define vdiv_vv_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vv_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (vint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vdiv_vx_i8m1(op0, op1, op2) \
__builtin_rvv_vdiv_vx_i8m1((vint8m1_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vdiv_vx_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vx_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (int8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vdiv_vx_i8m2(op0, op1, op2) \
__builtin_rvv_vdiv_vx_i8m2((vint8m2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vdiv_vx_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vx_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (int8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vdiv_vx_i8m4(op0, op1, op2) \
__builtin_rvv_vdiv_vx_i8m4((vint8m4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vdiv_vx_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vx_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (int8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vdiv_vx_i8m8(op0, op1, op2) \
__builtin_rvv_vdiv_vx_i8m8((vint8m8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vdiv_vx_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vx_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (int8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vdiv_vx_i8mf2(op0, op1, op2) \
__builtin_rvv_vdiv_vx_i8mf2((vint8mf2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vdiv_vx_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vx_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (int8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vdiv_vx_i8mf4(op0, op1, op2) \
__builtin_rvv_vdiv_vx_i8mf4((vint8mf4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vdiv_vx_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vx_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (int8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vdiv_vx_i8mf8(op0, op1, op2) \
__builtin_rvv_vdiv_vx_i8mf8((vint8mf8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vdiv_vx_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vx_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (int8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vdiv_vx_i16m1(op0, op1, op2) \
__builtin_rvv_vdiv_vx_i16m1((vint16m1_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vdiv_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vx_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (int16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vdiv_vx_i16m2(op0, op1, op2) \
__builtin_rvv_vdiv_vx_i16m2((vint16m2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vdiv_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vx_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (int16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vdiv_vx_i16m4(op0, op1, op2) \
__builtin_rvv_vdiv_vx_i16m4((vint16m4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vdiv_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vx_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (int16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vdiv_vx_i16m8(op0, op1, op2) \
__builtin_rvv_vdiv_vx_i16m8((vint16m8_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vdiv_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vx_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (int16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vdiv_vx_i16mf2(op0, op1, op2) \
__builtin_rvv_vdiv_vx_i16mf2((vint16mf2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vdiv_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vx_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (int16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vdiv_vx_i16mf4(op0, op1, op2) \
__builtin_rvv_vdiv_vx_i16mf4((vint16mf4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vdiv_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vx_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (int16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vdiv_vx_i32m1(op0, op1, op2) \
__builtin_rvv_vdiv_vx_i32m1((vint32m1_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vdiv_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vx_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (int32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vdiv_vx_i32m2(op0, op1, op2) \
__builtin_rvv_vdiv_vx_i32m2((vint32m2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vdiv_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vx_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (int32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vdiv_vx_i32m4(op0, op1, op2) \
__builtin_rvv_vdiv_vx_i32m4((vint32m4_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vdiv_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vx_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (int32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vdiv_vx_i32m8(op0, op1, op2) \
__builtin_rvv_vdiv_vx_i32m8((vint32m8_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vdiv_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vx_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (int32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vdiv_vx_i32mf2(op0, op1, op2) \
__builtin_rvv_vdiv_vx_i32mf2((vint32mf2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vdiv_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vx_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (int32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vdiv_vx_i64m1(op0, op1, op2) \
__builtin_rvv_vdiv_vx_i64m1((vint64m1_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vdiv_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vx_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (int64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vdiv_vx_i64m2(op0, op1, op2) \
__builtin_rvv_vdiv_vx_i64m2((vint64m2_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vdiv_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vx_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (int64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vdiv_vx_i64m4(op0, op1, op2) \
__builtin_rvv_vdiv_vx_i64m4((vint64m4_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vdiv_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vx_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (int64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vdiv_vx_i64m8(op0, op1, op2) \
__builtin_rvv_vdiv_vx_i64m8((vint64m8_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vdiv_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vx_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (int64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vremu_vv_u8m1(op0, op1, op2) \
__builtin_rvv_vremu_vv_u8m1((vuint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vremu_vv_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vv_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vremu_vv_u8m2(op0, op1, op2) \
__builtin_rvv_vremu_vv_u8m2((vuint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vremu_vv_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vv_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vremu_vv_u8m4(op0, op1, op2) \
__builtin_rvv_vremu_vv_u8m4((vuint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vremu_vv_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vv_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vremu_vv_u8m8(op0, op1, op2) \
__builtin_rvv_vremu_vv_u8m8((vuint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vremu_vv_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vv_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vremu_vv_u8mf2(op0, op1, op2) \
__builtin_rvv_vremu_vv_u8mf2((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vremu_vv_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vv_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vremu_vv_u8mf4(op0, op1, op2) \
__builtin_rvv_vremu_vv_u8mf4((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vremu_vv_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vv_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vremu_vv_u8mf8(op0, op1, op2) \
__builtin_rvv_vremu_vv_u8mf8((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vremu_vv_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vv_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vremu_vv_u16m1(op0, op1, op2) \
__builtin_rvv_vremu_vv_u16m1((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vremu_vv_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vv_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vremu_vv_u16m2(op0, op1, op2) \
__builtin_rvv_vremu_vv_u16m2((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vremu_vv_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vv_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vremu_vv_u16m4(op0, op1, op2) \
__builtin_rvv_vremu_vv_u16m4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vremu_vv_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vv_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vremu_vv_u16m8(op0, op1, op2) \
__builtin_rvv_vremu_vv_u16m8((vuint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vremu_vv_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vv_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vremu_vv_u16mf2(op0, op1, op2) \
__builtin_rvv_vremu_vv_u16mf2((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vremu_vv_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vv_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vremu_vv_u16mf4(op0, op1, op2) \
__builtin_rvv_vremu_vv_u16mf4((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vremu_vv_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vv_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vremu_vv_u32m1(op0, op1, op2) \
__builtin_rvv_vremu_vv_u32m1((vuint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vremu_vv_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vv_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vremu_vv_u32m2(op0, op1, op2) \
__builtin_rvv_vremu_vv_u32m2((vuint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vremu_vv_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vv_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vremu_vv_u32m4(op0, op1, op2) \
__builtin_rvv_vremu_vv_u32m4((vuint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vremu_vv_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vv_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vremu_vv_u32m8(op0, op1, op2) \
__builtin_rvv_vremu_vv_u32m8((vuint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vremu_vv_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vv_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vremu_vv_u32mf2(op0, op1, op2) \
__builtin_rvv_vremu_vv_u32mf2((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vremu_vv_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vv_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vremu_vv_u64m1(op0, op1, op2) \
__builtin_rvv_vremu_vv_u64m1((vuint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vremu_vv_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vv_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vremu_vv_u64m2(op0, op1, op2) \
__builtin_rvv_vremu_vv_u64m2((vuint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vremu_vv_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vv_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vremu_vv_u64m4(op0, op1, op2) \
__builtin_rvv_vremu_vv_u64m4((vuint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vremu_vv_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vv_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vremu_vv_u64m8(op0, op1, op2) \
__builtin_rvv_vremu_vv_u64m8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vremu_vv_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vv_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vremu_vx_u8m1(op0, op1, op2) \
__builtin_rvv_vremu_vx_u8m1((vuint8m1_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vremu_vx_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vx_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (uint8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vremu_vx_u8m2(op0, op1, op2) \
__builtin_rvv_vremu_vx_u8m2((vuint8m2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vremu_vx_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vx_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (uint8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vremu_vx_u8m4(op0, op1, op2) \
__builtin_rvv_vremu_vx_u8m4((vuint8m4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vremu_vx_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vx_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (uint8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vremu_vx_u8m8(op0, op1, op2) \
__builtin_rvv_vremu_vx_u8m8((vuint8m8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vremu_vx_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vx_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (uint8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vremu_vx_u8mf2(op0, op1, op2) \
__builtin_rvv_vremu_vx_u8mf2((vuint8mf2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vremu_vx_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vx_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (uint8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vremu_vx_u8mf4(op0, op1, op2) \
__builtin_rvv_vremu_vx_u8mf4((vuint8mf4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vremu_vx_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vx_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (uint8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vremu_vx_u8mf8(op0, op1, op2) \
__builtin_rvv_vremu_vx_u8mf8((vuint8mf8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vremu_vx_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vx_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (uint8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vremu_vx_u16m1(op0, op1, op2) \
__builtin_rvv_vremu_vx_u16m1((vuint16m1_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vremu_vx_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vx_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (uint16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vremu_vx_u16m2(op0, op1, op2) \
__builtin_rvv_vremu_vx_u16m2((vuint16m2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vremu_vx_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vx_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (uint16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vremu_vx_u16m4(op0, op1, op2) \
__builtin_rvv_vremu_vx_u16m4((vuint16m4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vremu_vx_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vx_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (uint16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vremu_vx_u16m8(op0, op1, op2) \
__builtin_rvv_vremu_vx_u16m8((vuint16m8_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vremu_vx_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vx_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (uint16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vremu_vx_u16mf2(op0, op1, op2) \
__builtin_rvv_vremu_vx_u16mf2((vuint16mf2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vremu_vx_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vx_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (uint16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vremu_vx_u16mf4(op0, op1, op2) \
__builtin_rvv_vremu_vx_u16mf4((vuint16mf4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vremu_vx_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vx_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (uint16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vremu_vx_u32m1(op0, op1, op2) \
__builtin_rvv_vremu_vx_u32m1((vuint32m1_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vremu_vx_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vx_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (uint32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vremu_vx_u32m2(op0, op1, op2) \
__builtin_rvv_vremu_vx_u32m2((vuint32m2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vremu_vx_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vx_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (uint32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vremu_vx_u32m4(op0, op1, op2) \
__builtin_rvv_vremu_vx_u32m4((vuint32m4_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vremu_vx_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vx_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (uint32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vremu_vx_u32m8(op0, op1, op2) \
__builtin_rvv_vremu_vx_u32m8((vuint32m8_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vremu_vx_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vx_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (uint32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vremu_vx_u32mf2(op0, op1, op2) \
__builtin_rvv_vremu_vx_u32mf2((vuint32mf2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vremu_vx_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vx_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (uint32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vremu_vx_u64m1(op0, op1, op2) \
__builtin_rvv_vremu_vx_u64m1((vuint64m1_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vremu_vx_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vx_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (uint64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vremu_vx_u64m2(op0, op1, op2) \
__builtin_rvv_vremu_vx_u64m2((vuint64m2_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vremu_vx_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vx_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (uint64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vremu_vx_u64m4(op0, op1, op2) \
__builtin_rvv_vremu_vx_u64m4((vuint64m4_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vremu_vx_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vx_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (uint64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vremu_vx_u64m8(op0, op1, op2) \
__builtin_rvv_vremu_vx_u64m8((vuint64m8_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vremu_vx_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vx_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (uint64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vrem_vv_i8m1(op0, op1, op2) \
__builtin_rvv_vrem_vv_i8m1((vint8m1_t)(op0), (vint8m1_t)(op1), (size_t)(op2))
#define vrem_vv_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vv_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vrem_vv_i8m2(op0, op1, op2) \
__builtin_rvv_vrem_vv_i8m2((vint8m2_t)(op0), (vint8m2_t)(op1), (size_t)(op2))
#define vrem_vv_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vv_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vrem_vv_i8m4(op0, op1, op2) \
__builtin_rvv_vrem_vv_i8m4((vint8m4_t)(op0), (vint8m4_t)(op1), (size_t)(op2))
#define vrem_vv_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vv_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vrem_vv_i8m8(op0, op1, op2) \
__builtin_rvv_vrem_vv_i8m8((vint8m8_t)(op0), (vint8m8_t)(op1), (size_t)(op2))
#define vrem_vv_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vv_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (vint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vrem_vv_i8mf2(op0, op1, op2) \
__builtin_rvv_vrem_vv_i8mf2((vint8mf2_t)(op0), (vint8mf2_t)(op1), (size_t)(op2))
#define vrem_vv_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vv_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vrem_vv_i8mf4(op0, op1, op2) \
__builtin_rvv_vrem_vv_i8mf4((vint8mf4_t)(op0), (vint8mf4_t)(op1), (size_t)(op2))
#define vrem_vv_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vv_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vrem_vv_i8mf8(op0, op1, op2) \
__builtin_rvv_vrem_vv_i8mf8((vint8mf8_t)(op0), (vint8mf8_t)(op1), (size_t)(op2))
#define vrem_vv_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vv_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vrem_vv_i16m1(op0, op1, op2) \
__builtin_rvv_vrem_vv_i16m1((vint16m1_t)(op0), (vint16m1_t)(op1), (size_t)(op2))
#define vrem_vv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vv_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vrem_vv_i16m2(op0, op1, op2) \
__builtin_rvv_vrem_vv_i16m2((vint16m2_t)(op0), (vint16m2_t)(op1), (size_t)(op2))
#define vrem_vv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vv_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vrem_vv_i16m4(op0, op1, op2) \
__builtin_rvv_vrem_vv_i16m4((vint16m4_t)(op0), (vint16m4_t)(op1), (size_t)(op2))
#define vrem_vv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vv_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vrem_vv_i16m8(op0, op1, op2) \
__builtin_rvv_vrem_vv_i16m8((vint16m8_t)(op0), (vint16m8_t)(op1), (size_t)(op2))
#define vrem_vv_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vv_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (vint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vrem_vv_i16mf2(op0, op1, op2) \
__builtin_rvv_vrem_vv_i16mf2((vint16mf2_t)(op0), (vint16mf2_t)(op1), (size_t)(op2))
#define vrem_vv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vv_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vrem_vv_i16mf4(op0, op1, op2) \
__builtin_rvv_vrem_vv_i16mf4((vint16mf4_t)(op0), (vint16mf4_t)(op1), (size_t)(op2))
#define vrem_vv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vv_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vrem_vv_i32m1(op0, op1, op2) \
__builtin_rvv_vrem_vv_i32m1((vint32m1_t)(op0), (vint32m1_t)(op1), (size_t)(op2))
#define vrem_vv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vv_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vrem_vv_i32m2(op0, op1, op2) \
__builtin_rvv_vrem_vv_i32m2((vint32m2_t)(op0), (vint32m2_t)(op1), (size_t)(op2))
#define vrem_vv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vv_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vrem_vv_i32m4(op0, op1, op2) \
__builtin_rvv_vrem_vv_i32m4((vint32m4_t)(op0), (vint32m4_t)(op1), (size_t)(op2))
#define vrem_vv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vv_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vrem_vv_i32m8(op0, op1, op2) \
__builtin_rvv_vrem_vv_i32m8((vint32m8_t)(op0), (vint32m8_t)(op1), (size_t)(op2))
#define vrem_vv_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vv_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (vint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vrem_vv_i32mf2(op0, op1, op2) \
__builtin_rvv_vrem_vv_i32mf2((vint32mf2_t)(op0), (vint32mf2_t)(op1), (size_t)(op2))
#define vrem_vv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vv_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vrem_vv_i64m1(op0, op1, op2) \
__builtin_rvv_vrem_vv_i64m1((vint64m1_t)(op0), (vint64m1_t)(op1), (size_t)(op2))
#define vrem_vv_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vv_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vrem_vv_i64m2(op0, op1, op2) \
__builtin_rvv_vrem_vv_i64m2((vint64m2_t)(op0), (vint64m2_t)(op1), (size_t)(op2))
#define vrem_vv_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vv_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (vint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vrem_vv_i64m4(op0, op1, op2) \
__builtin_rvv_vrem_vv_i64m4((vint64m4_t)(op0), (vint64m4_t)(op1), (size_t)(op2))
#define vrem_vv_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vv_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (vint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vrem_vv_i64m8(op0, op1, op2) \
__builtin_rvv_vrem_vv_i64m8((vint64m8_t)(op0), (vint64m8_t)(op1), (size_t)(op2))
#define vrem_vv_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vv_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (vint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vrem_vx_i8m1(op0, op1, op2) \
__builtin_rvv_vrem_vx_i8m1((vint8m1_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vrem_vx_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vx_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (int8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vrem_vx_i8m2(op0, op1, op2) \
__builtin_rvv_vrem_vx_i8m2((vint8m2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vrem_vx_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vx_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (int8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vrem_vx_i8m4(op0, op1, op2) \
__builtin_rvv_vrem_vx_i8m4((vint8m4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vrem_vx_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vx_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (int8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vrem_vx_i8m8(op0, op1, op2) \
__builtin_rvv_vrem_vx_i8m8((vint8m8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vrem_vx_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vx_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (int8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vrem_vx_i8mf2(op0, op1, op2) \
__builtin_rvv_vrem_vx_i8mf2((vint8mf2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vrem_vx_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vx_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (int8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vrem_vx_i8mf4(op0, op1, op2) \
__builtin_rvv_vrem_vx_i8mf4((vint8mf4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vrem_vx_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vx_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (int8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vrem_vx_i8mf8(op0, op1, op2) \
__builtin_rvv_vrem_vx_i8mf8((vint8mf8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vrem_vx_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vx_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (int8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vrem_vx_i16m1(op0, op1, op2) \
__builtin_rvv_vrem_vx_i16m1((vint16m1_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vrem_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vx_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (int16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vrem_vx_i16m2(op0, op1, op2) \
__builtin_rvv_vrem_vx_i16m2((vint16m2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vrem_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vx_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (int16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vrem_vx_i16m4(op0, op1, op2) \
__builtin_rvv_vrem_vx_i16m4((vint16m4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vrem_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vx_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (int16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vrem_vx_i16m8(op0, op1, op2) \
__builtin_rvv_vrem_vx_i16m8((vint16m8_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vrem_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vx_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (int16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vrem_vx_i16mf2(op0, op1, op2) \
__builtin_rvv_vrem_vx_i16mf2((vint16mf2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vrem_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vx_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (int16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vrem_vx_i16mf4(op0, op1, op2) \
__builtin_rvv_vrem_vx_i16mf4((vint16mf4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vrem_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vx_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (int16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vrem_vx_i32m1(op0, op1, op2) \
__builtin_rvv_vrem_vx_i32m1((vint32m1_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vrem_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vx_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (int32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vrem_vx_i32m2(op0, op1, op2) \
__builtin_rvv_vrem_vx_i32m2((vint32m2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vrem_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vx_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (int32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vrem_vx_i32m4(op0, op1, op2) \
__builtin_rvv_vrem_vx_i32m4((vint32m4_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vrem_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vx_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (int32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vrem_vx_i32m8(op0, op1, op2) \
__builtin_rvv_vrem_vx_i32m8((vint32m8_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vrem_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vx_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (int32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vrem_vx_i32mf2(op0, op1, op2) \
__builtin_rvv_vrem_vx_i32mf2((vint32mf2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vrem_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vx_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (int32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vrem_vx_i64m1(op0, op1, op2) \
__builtin_rvv_vrem_vx_i64m1((vint64m1_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vrem_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vx_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (int64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vrem_vx_i64m2(op0, op1, op2) \
__builtin_rvv_vrem_vx_i64m2((vint64m2_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vrem_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vx_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (int64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vrem_vx_i64m4(op0, op1, op2) \
__builtin_rvv_vrem_vx_i64m4((vint64m4_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vrem_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vx_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (int64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vrem_vx_i64m8(op0, op1, op2) \
__builtin_rvv_vrem_vx_i64m8((vint64m8_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vrem_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vx_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (int64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmul_vv_i16mf4(op0, op1, op2) \
__builtin_rvv_vwmul_vv_i16mf4((vint8mf8_t)(op0), (vint8mf8_t)(op1), (size_t)(op2))
#define vwmul_vv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmul_vv_i16mf4_m((vint16mf4_t)(op0), (vint8mf8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmul_vv_i16mf2(op0, op1, op2) \
__builtin_rvv_vwmul_vv_i16mf2((vint8mf4_t)(op0), (vint8mf4_t)(op1), (size_t)(op2))
#define vwmul_vv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmul_vv_i16mf2_m((vint16mf2_t)(op0), (vint8mf4_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmul_vv_i16m1(op0, op1, op2) \
__builtin_rvv_vwmul_vv_i16m1((vint8mf2_t)(op0), (vint8mf2_t)(op1), (size_t)(op2))
#define vwmul_vv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmul_vv_i16m1_m((vint16m1_t)(op0), (vint8mf2_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmul_vv_i16m2(op0, op1, op2) \
__builtin_rvv_vwmul_vv_i16m2((vint8m1_t)(op0), (vint8m1_t)(op1), (size_t)(op2))
#define vwmul_vv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmul_vv_i16m2_m((vint16m2_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmul_vv_i16m4(op0, op1, op2) \
__builtin_rvv_vwmul_vv_i16m4((vint8m2_t)(op0), (vint8m2_t)(op1), (size_t)(op2))
#define vwmul_vv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmul_vv_i16m4_m((vint16m4_t)(op0), (vint8m2_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwmul_vv_i16m8(op0, op1, op2) \
__builtin_rvv_vwmul_vv_i16m8((vint8m4_t)(op0), (vint8m4_t)(op1), (size_t)(op2))
#define vwmul_vv_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmul_vv_i16m8_m((vint16m8_t)(op0), (vint8m4_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vwmul_vv_i32mf2(op0, op1, op2) \
__builtin_rvv_vwmul_vv_i32mf2((vint16mf4_t)(op0), (vint16mf4_t)(op1), (size_t)(op2))
#define vwmul_vv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmul_vv_i32mf2_m((vint32mf2_t)(op0), (vint16mf4_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmul_vv_i32m1(op0, op1, op2) \
__builtin_rvv_vwmul_vv_i32m1((vint16mf2_t)(op0), (vint16mf2_t)(op1), (size_t)(op2))
#define vwmul_vv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmul_vv_i32m1_m((vint32m1_t)(op0), (vint16mf2_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmul_vv_i32m2(op0, op1, op2) \
__builtin_rvv_vwmul_vv_i32m2((vint16m1_t)(op0), (vint16m1_t)(op1), (size_t)(op2))
#define vwmul_vv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmul_vv_i32m2_m((vint32m2_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmul_vv_i32m4(op0, op1, op2) \
__builtin_rvv_vwmul_vv_i32m4((vint16m2_t)(op0), (vint16m2_t)(op1), (size_t)(op2))
#define vwmul_vv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmul_vv_i32m4_m((vint32m4_t)(op0), (vint16m2_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmul_vv_i32m8(op0, op1, op2) \
__builtin_rvv_vwmul_vv_i32m8((vint16m4_t)(op0), (vint16m4_t)(op1), (size_t)(op2))
#define vwmul_vv_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmul_vv_i32m8_m((vint32m8_t)(op0), (vint16m4_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwmul_vv_i64m1(op0, op1, op2) \
__builtin_rvv_vwmul_vv_i64m1((vint32mf2_t)(op0), (vint32mf2_t)(op1), (size_t)(op2))
#define vwmul_vv_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmul_vv_i64m1_m((vint64m1_t)(op0), (vint32mf2_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmul_vv_i64m2(op0, op1, op2) \
__builtin_rvv_vwmul_vv_i64m2((vint32m1_t)(op0), (vint32m1_t)(op1), (size_t)(op2))
#define vwmul_vv_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmul_vv_i64m2_m((vint64m2_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmul_vv_i64m4(op0, op1, op2) \
__builtin_rvv_vwmul_vv_i64m4((vint32m2_t)(op0), (vint32m2_t)(op1), (size_t)(op2))
#define vwmul_vv_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmul_vv_i64m4_m((vint64m4_t)(op0), (vint32m2_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmul_vv_i64m8(op0, op1, op2) \
__builtin_rvv_vwmul_vv_i64m8((vint32m4_t)(op0), (vint32m4_t)(op1), (size_t)(op2))
#define vwmul_vv_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmul_vv_i64m8_m((vint64m8_t)(op0), (vint32m4_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmul_vx_i16mf4(op0, op1, op2) \
__builtin_rvv_vwmul_vx_i16mf4((vint8mf8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vwmul_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmul_vx_i16mf4_m((vint16mf4_t)(op0), (vint8mf8_t)(op1), (int8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmul_vx_i16mf2(op0, op1, op2) \
__builtin_rvv_vwmul_vx_i16mf2((vint8mf4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vwmul_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmul_vx_i16mf2_m((vint16mf2_t)(op0), (vint8mf4_t)(op1), (int8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmul_vx_i16m1(op0, op1, op2) \
__builtin_rvv_vwmul_vx_i16m1((vint8mf2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vwmul_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmul_vx_i16m1_m((vint16m1_t)(op0), (vint8mf2_t)(op1), (int8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmul_vx_i16m2(op0, op1, op2) \
__builtin_rvv_vwmul_vx_i16m2((vint8m1_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vwmul_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmul_vx_i16m2_m((vint16m2_t)(op0), (vint8m1_t)(op1), (int8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmul_vx_i16m4(op0, op1, op2) \
__builtin_rvv_vwmul_vx_i16m4((vint8m2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vwmul_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmul_vx_i16m4_m((vint16m4_t)(op0), (vint8m2_t)(op1), (int8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwmul_vx_i16m8(op0, op1, op2) \
__builtin_rvv_vwmul_vx_i16m8((vint8m4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vwmul_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmul_vx_i16m8_m((vint16m8_t)(op0), (vint8m4_t)(op1), (int8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vwmul_vx_i32mf2(op0, op1, op2) \
__builtin_rvv_vwmul_vx_i32mf2((vint16mf4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vwmul_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmul_vx_i32mf2_m((vint32mf2_t)(op0), (vint16mf4_t)(op1), (int16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmul_vx_i32m1(op0, op1, op2) \
__builtin_rvv_vwmul_vx_i32m1((vint16mf2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vwmul_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmul_vx_i32m1_m((vint32m1_t)(op0), (vint16mf2_t)(op1), (int16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmul_vx_i32m2(op0, op1, op2) \
__builtin_rvv_vwmul_vx_i32m2((vint16m1_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vwmul_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmul_vx_i32m2_m((vint32m2_t)(op0), (vint16m1_t)(op1), (int16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmul_vx_i32m4(op0, op1, op2) \
__builtin_rvv_vwmul_vx_i32m4((vint16m2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vwmul_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmul_vx_i32m4_m((vint32m4_t)(op0), (vint16m2_t)(op1), (int16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmul_vx_i32m8(op0, op1, op2) \
__builtin_rvv_vwmul_vx_i32m8((vint16m4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vwmul_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmul_vx_i32m8_m((vint32m8_t)(op0), (vint16m4_t)(op1), (int16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwmul_vx_i64m1(op0, op1, op2) \
__builtin_rvv_vwmul_vx_i64m1((vint32mf2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vwmul_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmul_vx_i64m1_m((vint64m1_t)(op0), (vint32mf2_t)(op1), (int32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmul_vx_i64m2(op0, op1, op2) \
__builtin_rvv_vwmul_vx_i64m2((vint32m1_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vwmul_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmul_vx_i64m2_m((vint64m2_t)(op0), (vint32m1_t)(op1), (int32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmul_vx_i64m4(op0, op1, op2) \
__builtin_rvv_vwmul_vx_i64m4((vint32m2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vwmul_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmul_vx_i64m4_m((vint64m4_t)(op0), (vint32m2_t)(op1), (int32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmul_vx_i64m8(op0, op1, op2) \
__builtin_rvv_vwmul_vx_i64m8((vint32m4_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vwmul_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmul_vx_i64m8_m((vint64m8_t)(op0), (vint32m4_t)(op1), (int32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmulu_vv_u16mf4(op0, op1, op2) \
__builtin_rvv_vwmulu_vv_u16mf4((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vwmulu_vv_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulu_vv_u16mf4_m((vuint16mf4_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmulu_vv_u16mf2(op0, op1, op2) \
__builtin_rvv_vwmulu_vv_u16mf2((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vwmulu_vv_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulu_vv_u16mf2_m((vuint16mf2_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmulu_vv_u16m1(op0, op1, op2) \
__builtin_rvv_vwmulu_vv_u16m1((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vwmulu_vv_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulu_vv_u16m1_m((vuint16m1_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmulu_vv_u16m2(op0, op1, op2) \
__builtin_rvv_vwmulu_vv_u16m2((vuint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vwmulu_vv_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulu_vv_u16m2_m((vuint16m2_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmulu_vv_u16m4(op0, op1, op2) \
__builtin_rvv_vwmulu_vv_u16m4((vuint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vwmulu_vv_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulu_vv_u16m4_m((vuint16m4_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwmulu_vv_u16m8(op0, op1, op2) \
__builtin_rvv_vwmulu_vv_u16m8((vuint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vwmulu_vv_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulu_vv_u16m8_m((vuint16m8_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vwmulu_vv_u32mf2(op0, op1, op2) \
__builtin_rvv_vwmulu_vv_u32mf2((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vwmulu_vv_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulu_vv_u32mf2_m((vuint32mf2_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmulu_vv_u32m1(op0, op1, op2) \
__builtin_rvv_vwmulu_vv_u32m1((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vwmulu_vv_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulu_vv_u32m1_m((vuint32m1_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmulu_vv_u32m2(op0, op1, op2) \
__builtin_rvv_vwmulu_vv_u32m2((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vwmulu_vv_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulu_vv_u32m2_m((vuint32m2_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmulu_vv_u32m4(op0, op1, op2) \
__builtin_rvv_vwmulu_vv_u32m4((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vwmulu_vv_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulu_vv_u32m4_m((vuint32m4_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmulu_vv_u32m8(op0, op1, op2) \
__builtin_rvv_vwmulu_vv_u32m8((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vwmulu_vv_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulu_vv_u32m8_m((vuint32m8_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwmulu_vv_u64m1(op0, op1, op2) \
__builtin_rvv_vwmulu_vv_u64m1((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vwmulu_vv_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulu_vv_u64m1_m((vuint64m1_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmulu_vv_u64m2(op0, op1, op2) \
__builtin_rvv_vwmulu_vv_u64m2((vuint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vwmulu_vv_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulu_vv_u64m2_m((vuint64m2_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmulu_vv_u64m4(op0, op1, op2) \
__builtin_rvv_vwmulu_vv_u64m4((vuint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vwmulu_vv_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulu_vv_u64m4_m((vuint64m4_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmulu_vv_u64m8(op0, op1, op2) \
__builtin_rvv_vwmulu_vv_u64m8((vuint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vwmulu_vv_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulu_vv_u64m8_m((vuint64m8_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmulu_vx_u16mf4(op0, op1, op2) \
__builtin_rvv_vwmulu_vx_u16mf4((vuint8mf8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vwmulu_vx_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulu_vx_u16mf4_m((vuint16mf4_t)(op0), (vuint8mf8_t)(op1), (uint8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmulu_vx_u16mf2(op0, op1, op2) \
__builtin_rvv_vwmulu_vx_u16mf2((vuint8mf4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vwmulu_vx_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulu_vx_u16mf2_m((vuint16mf2_t)(op0), (vuint8mf4_t)(op1), (uint8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmulu_vx_u16m1(op0, op1, op2) \
__builtin_rvv_vwmulu_vx_u16m1((vuint8mf2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vwmulu_vx_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulu_vx_u16m1_m((vuint16m1_t)(op0), (vuint8mf2_t)(op1), (uint8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmulu_vx_u16m2(op0, op1, op2) \
__builtin_rvv_vwmulu_vx_u16m2((vuint8m1_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vwmulu_vx_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulu_vx_u16m2_m((vuint16m2_t)(op0), (vuint8m1_t)(op1), (uint8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmulu_vx_u16m4(op0, op1, op2) \
__builtin_rvv_vwmulu_vx_u16m4((vuint8m2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vwmulu_vx_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulu_vx_u16m4_m((vuint16m4_t)(op0), (vuint8m2_t)(op1), (uint8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwmulu_vx_u16m8(op0, op1, op2) \
__builtin_rvv_vwmulu_vx_u16m8((vuint8m4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vwmulu_vx_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulu_vx_u16m8_m((vuint16m8_t)(op0), (vuint8m4_t)(op1), (uint8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vwmulu_vx_u32mf2(op0, op1, op2) \
__builtin_rvv_vwmulu_vx_u32mf2((vuint16mf4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vwmulu_vx_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulu_vx_u32mf2_m((vuint32mf2_t)(op0), (vuint16mf4_t)(op1), (uint16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmulu_vx_u32m1(op0, op1, op2) \
__builtin_rvv_vwmulu_vx_u32m1((vuint16mf2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vwmulu_vx_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulu_vx_u32m1_m((vuint32m1_t)(op0), (vuint16mf2_t)(op1), (uint16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmulu_vx_u32m2(op0, op1, op2) \
__builtin_rvv_vwmulu_vx_u32m2((vuint16m1_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vwmulu_vx_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulu_vx_u32m2_m((vuint32m2_t)(op0), (vuint16m1_t)(op1), (uint16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmulu_vx_u32m4(op0, op1, op2) \
__builtin_rvv_vwmulu_vx_u32m4((vuint16m2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vwmulu_vx_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulu_vx_u32m4_m((vuint32m4_t)(op0), (vuint16m2_t)(op1), (uint16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmulu_vx_u32m8(op0, op1, op2) \
__builtin_rvv_vwmulu_vx_u32m8((vuint16m4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vwmulu_vx_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulu_vx_u32m8_m((vuint32m8_t)(op0), (vuint16m4_t)(op1), (uint16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwmulu_vx_u64m1(op0, op1, op2) \
__builtin_rvv_vwmulu_vx_u64m1((vuint32mf2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vwmulu_vx_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulu_vx_u64m1_m((vuint64m1_t)(op0), (vuint32mf2_t)(op1), (uint32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmulu_vx_u64m2(op0, op1, op2) \
__builtin_rvv_vwmulu_vx_u64m2((vuint32m1_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vwmulu_vx_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulu_vx_u64m2_m((vuint64m2_t)(op0), (vuint32m1_t)(op1), (uint32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmulu_vx_u64m4(op0, op1, op2) \
__builtin_rvv_vwmulu_vx_u64m4((vuint32m2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vwmulu_vx_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulu_vx_u64m4_m((vuint64m4_t)(op0), (vuint32m2_t)(op1), (uint32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmulu_vx_u64m8(op0, op1, op2) \
__builtin_rvv_vwmulu_vx_u64m8((vuint32m4_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vwmulu_vx_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulu_vx_u64m8_m((vuint64m8_t)(op0), (vuint32m4_t)(op1), (uint32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmulsu_vv_i16mf4(op0, op1, op2) \
__builtin_rvv_vwmulsu_vv_i16mf4((vint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vwmulsu_vv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulsu_vv_i16mf4_m((vint16mf4_t)(op0), (vint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmulsu_vv_i16mf2(op0, op1, op2) \
__builtin_rvv_vwmulsu_vv_i16mf2((vint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vwmulsu_vv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulsu_vv_i16mf2_m((vint16mf2_t)(op0), (vint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmulsu_vv_i16m1(op0, op1, op2) \
__builtin_rvv_vwmulsu_vv_i16m1((vint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vwmulsu_vv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulsu_vv_i16m1_m((vint16m1_t)(op0), (vint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmulsu_vv_i16m2(op0, op1, op2) \
__builtin_rvv_vwmulsu_vv_i16m2((vint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vwmulsu_vv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulsu_vv_i16m2_m((vint16m2_t)(op0), (vint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmulsu_vv_i16m4(op0, op1, op2) \
__builtin_rvv_vwmulsu_vv_i16m4((vint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vwmulsu_vv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulsu_vv_i16m4_m((vint16m4_t)(op0), (vint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwmulsu_vv_i16m8(op0, op1, op2) \
__builtin_rvv_vwmulsu_vv_i16m8((vint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vwmulsu_vv_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulsu_vv_i16m8_m((vint16m8_t)(op0), (vint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vwmulsu_vv_i32mf2(op0, op1, op2) \
__builtin_rvv_vwmulsu_vv_i32mf2((vint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vwmulsu_vv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulsu_vv_i32mf2_m((vint32mf2_t)(op0), (vint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmulsu_vv_i32m1(op0, op1, op2) \
__builtin_rvv_vwmulsu_vv_i32m1((vint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vwmulsu_vv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulsu_vv_i32m1_m((vint32m1_t)(op0), (vint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmulsu_vv_i32m2(op0, op1, op2) \
__builtin_rvv_vwmulsu_vv_i32m2((vint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vwmulsu_vv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulsu_vv_i32m2_m((vint32m2_t)(op0), (vint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmulsu_vv_i32m4(op0, op1, op2) \
__builtin_rvv_vwmulsu_vv_i32m4((vint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vwmulsu_vv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulsu_vv_i32m4_m((vint32m4_t)(op0), (vint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmulsu_vv_i32m8(op0, op1, op2) \
__builtin_rvv_vwmulsu_vv_i32m8((vint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vwmulsu_vv_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulsu_vv_i32m8_m((vint32m8_t)(op0), (vint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwmulsu_vv_i64m1(op0, op1, op2) \
__builtin_rvv_vwmulsu_vv_i64m1((vint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vwmulsu_vv_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulsu_vv_i64m1_m((vint64m1_t)(op0), (vint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmulsu_vv_i64m2(op0, op1, op2) \
__builtin_rvv_vwmulsu_vv_i64m2((vint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vwmulsu_vv_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulsu_vv_i64m2_m((vint64m2_t)(op0), (vint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmulsu_vv_i64m4(op0, op1, op2) \
__builtin_rvv_vwmulsu_vv_i64m4((vint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vwmulsu_vv_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulsu_vv_i64m4_m((vint64m4_t)(op0), (vint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmulsu_vv_i64m8(op0, op1, op2) \
__builtin_rvv_vwmulsu_vv_i64m8((vint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vwmulsu_vv_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulsu_vv_i64m8_m((vint64m8_t)(op0), (vint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmulsu_vx_i16mf4(op0, op1, op2) \
__builtin_rvv_vwmulsu_vx_i16mf4((vint8mf8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vwmulsu_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulsu_vx_i16mf4_m((vint16mf4_t)(op0), (vint8mf8_t)(op1), (uint8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmulsu_vx_i16mf2(op0, op1, op2) \
__builtin_rvv_vwmulsu_vx_i16mf2((vint8mf4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vwmulsu_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulsu_vx_i16mf2_m((vint16mf2_t)(op0), (vint8mf4_t)(op1), (uint8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmulsu_vx_i16m1(op0, op1, op2) \
__builtin_rvv_vwmulsu_vx_i16m1((vint8mf2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vwmulsu_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulsu_vx_i16m1_m((vint16m1_t)(op0), (vint8mf2_t)(op1), (uint8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmulsu_vx_i16m2(op0, op1, op2) \
__builtin_rvv_vwmulsu_vx_i16m2((vint8m1_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vwmulsu_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulsu_vx_i16m2_m((vint16m2_t)(op0), (vint8m1_t)(op1), (uint8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmulsu_vx_i16m4(op0, op1, op2) \
__builtin_rvv_vwmulsu_vx_i16m4((vint8m2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vwmulsu_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulsu_vx_i16m4_m((vint16m4_t)(op0), (vint8m2_t)(op1), (uint8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwmulsu_vx_i16m8(op0, op1, op2) \
__builtin_rvv_vwmulsu_vx_i16m8((vint8m4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vwmulsu_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulsu_vx_i16m8_m((vint16m8_t)(op0), (vint8m4_t)(op1), (uint8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vwmulsu_vx_i32mf2(op0, op1, op2) \
__builtin_rvv_vwmulsu_vx_i32mf2((vint16mf4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vwmulsu_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulsu_vx_i32mf2_m((vint32mf2_t)(op0), (vint16mf4_t)(op1), (uint16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmulsu_vx_i32m1(op0, op1, op2) \
__builtin_rvv_vwmulsu_vx_i32m1((vint16mf2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vwmulsu_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulsu_vx_i32m1_m((vint32m1_t)(op0), (vint16mf2_t)(op1), (uint16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmulsu_vx_i32m2(op0, op1, op2) \
__builtin_rvv_vwmulsu_vx_i32m2((vint16m1_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vwmulsu_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulsu_vx_i32m2_m((vint32m2_t)(op0), (vint16m1_t)(op1), (uint16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmulsu_vx_i32m4(op0, op1, op2) \
__builtin_rvv_vwmulsu_vx_i32m4((vint16m2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vwmulsu_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulsu_vx_i32m4_m((vint32m4_t)(op0), (vint16m2_t)(op1), (uint16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmulsu_vx_i32m8(op0, op1, op2) \
__builtin_rvv_vwmulsu_vx_i32m8((vint16m4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vwmulsu_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulsu_vx_i32m8_m((vint32m8_t)(op0), (vint16m4_t)(op1), (uint16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwmulsu_vx_i64m1(op0, op1, op2) \
__builtin_rvv_vwmulsu_vx_i64m1((vint32mf2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vwmulsu_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulsu_vx_i64m1_m((vint64m1_t)(op0), (vint32mf2_t)(op1), (uint32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmulsu_vx_i64m2(op0, op1, op2) \
__builtin_rvv_vwmulsu_vx_i64m2((vint32m1_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vwmulsu_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulsu_vx_i64m2_m((vint64m2_t)(op0), (vint32m1_t)(op1), (uint32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmulsu_vx_i64m4(op0, op1, op2) \
__builtin_rvv_vwmulsu_vx_i64m4((vint32m2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vwmulsu_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulsu_vx_i64m4_m((vint64m4_t)(op0), (vint32m2_t)(op1), (uint32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmulsu_vx_i64m8(op0, op1, op2) \
__builtin_rvv_vwmulsu_vx_i64m8((vint32m4_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vwmulsu_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulsu_vx_i64m8_m((vint64m8_t)(op0), (vint32m4_t)(op1), (uint32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmacc_vv_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_i8m1((vint8m1_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (size_t)(op3))
#define vmacc_vv_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmacc_vv_i8m2(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_i8m2((vint8m2_t)(op0), (vint8m2_t)(op1), (vint8m2_t)(op2), (size_t)(op3))
#define vmacc_vv_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmacc_vv_i8m4(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_i8m4((vint8m4_t)(op0), (vint8m4_t)(op1), (vint8m4_t)(op2), (size_t)(op3))
#define vmacc_vv_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmacc_vv_i8m8(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_i8m8((vint8m8_t)(op0), (vint8m8_t)(op1), (vint8m8_t)(op2), (size_t)(op3))
#define vmacc_vv_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (vint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmacc_vv_i8mf2(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_i8mf2((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vint8mf2_t)(op2), (size_t)(op3))
#define vmacc_vv_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmacc_vv_i8mf4(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_i8mf4((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vint8mf4_t)(op2), (size_t)(op3))
#define vmacc_vv_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmacc_vv_i8mf8(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_i8mf8((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vint8mf8_t)(op2), (size_t)(op3))
#define vmacc_vv_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmacc_vv_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_i16m1((vint16m1_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vmacc_vv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmacc_vv_i16m2(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_i16m2((vint16m2_t)(op0), (vint16m2_t)(op1), (vint16m2_t)(op2), (size_t)(op3))
#define vmacc_vv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmacc_vv_i16m4(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_i16m4((vint16m4_t)(op0), (vint16m4_t)(op1), (vint16m4_t)(op2), (size_t)(op3))
#define vmacc_vv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmacc_vv_i16m8(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_i16m8((vint16m8_t)(op0), (vint16m8_t)(op1), (vint16m8_t)(op2), (size_t)(op3))
#define vmacc_vv_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (vint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmacc_vv_i16mf2(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_i16mf2((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vint16mf2_t)(op2), (size_t)(op3))
#define vmacc_vv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmacc_vv_i16mf4(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_i16mf4((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vint16mf4_t)(op2), (size_t)(op3))
#define vmacc_vv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmacc_vv_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_i32m1((vint32m1_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (size_t)(op3))
#define vmacc_vv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmacc_vv_i32m2(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_i32m2((vint32m2_t)(op0), (vint32m2_t)(op1), (vint32m2_t)(op2), (size_t)(op3))
#define vmacc_vv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmacc_vv_i32m4(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_i32m4((vint32m4_t)(op0), (vint32m4_t)(op1), (vint32m4_t)(op2), (size_t)(op3))
#define vmacc_vv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmacc_vv_i32m8(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_i32m8((vint32m8_t)(op0), (vint32m8_t)(op1), (vint32m8_t)(op2), (size_t)(op3))
#define vmacc_vv_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (vint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmacc_vv_i32mf2(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_i32mf2((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vint32mf2_t)(op2), (size_t)(op3))
#define vmacc_vv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmacc_vv_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_i64m1((vint64m1_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (size_t)(op3))
#define vmacc_vv_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmacc_vv_i64m2(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_i64m2((vint64m2_t)(op0), (vint64m2_t)(op1), (vint64m2_t)(op2), (size_t)(op3))
#define vmacc_vv_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (vint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmacc_vv_i64m4(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_i64m4((vint64m4_t)(op0), (vint64m4_t)(op1), (vint64m4_t)(op2), (size_t)(op3))
#define vmacc_vv_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (vint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmacc_vv_i64m8(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_i64m8((vint64m8_t)(op0), (vint64m8_t)(op1), (vint64m8_t)(op2), (size_t)(op3))
#define vmacc_vv_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (vint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmacc_vx_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_i8m1((vint8m1_t)(op0), (int8_t)(op1), (vint8m1_t)(op2), (size_t)(op3))
#define vmacc_vx_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_i8m1_m((vint8m1_t)(op0), (int8_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmacc_vx_i8m2(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_i8m2((vint8m2_t)(op0), (int8_t)(op1), (vint8m2_t)(op2), (size_t)(op3))
#define vmacc_vx_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_i8m2_m((vint8m2_t)(op0), (int8_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmacc_vx_i8m4(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_i8m4((vint8m4_t)(op0), (int8_t)(op1), (vint8m4_t)(op2), (size_t)(op3))
#define vmacc_vx_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_i8m4_m((vint8m4_t)(op0), (int8_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmacc_vx_i8m8(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_i8m8((vint8m8_t)(op0), (int8_t)(op1), (vint8m8_t)(op2), (size_t)(op3))
#define vmacc_vx_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_i8m8_m((vint8m8_t)(op0), (int8_t)(op1), (vint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmacc_vx_i8mf2(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_i8mf2((vint8mf2_t)(op0), (int8_t)(op1), (vint8mf2_t)(op2), (size_t)(op3))
#define vmacc_vx_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_i8mf2_m((vint8mf2_t)(op0), (int8_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmacc_vx_i8mf4(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_i8mf4((vint8mf4_t)(op0), (int8_t)(op1), (vint8mf4_t)(op2), (size_t)(op3))
#define vmacc_vx_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_i8mf4_m((vint8mf4_t)(op0), (int8_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmacc_vx_i8mf8(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_i8mf8((vint8mf8_t)(op0), (int8_t)(op1), (vint8mf8_t)(op2), (size_t)(op3))
#define vmacc_vx_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_i8mf8_m((vint8mf8_t)(op0), (int8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmacc_vx_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_i16m1((vint16m1_t)(op0), (int16_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vmacc_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_i16m1_m((vint16m1_t)(op0), (int16_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmacc_vx_i16m2(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_i16m2((vint16m2_t)(op0), (int16_t)(op1), (vint16m2_t)(op2), (size_t)(op3))
#define vmacc_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_i16m2_m((vint16m2_t)(op0), (int16_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmacc_vx_i16m4(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_i16m4((vint16m4_t)(op0), (int16_t)(op1), (vint16m4_t)(op2), (size_t)(op3))
#define vmacc_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_i16m4_m((vint16m4_t)(op0), (int16_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmacc_vx_i16m8(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_i16m8((vint16m8_t)(op0), (int16_t)(op1), (vint16m8_t)(op2), (size_t)(op3))
#define vmacc_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_i16m8_m((vint16m8_t)(op0), (int16_t)(op1), (vint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmacc_vx_i16mf2(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_i16mf2((vint16mf2_t)(op0), (int16_t)(op1), (vint16mf2_t)(op2), (size_t)(op3))
#define vmacc_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_i16mf2_m((vint16mf2_t)(op0), (int16_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmacc_vx_i16mf4(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_i16mf4((vint16mf4_t)(op0), (int16_t)(op1), (vint16mf4_t)(op2), (size_t)(op3))
#define vmacc_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_i16mf4_m((vint16mf4_t)(op0), (int16_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmacc_vx_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_i32m1((vint32m1_t)(op0), (int32_t)(op1), (vint32m1_t)(op2), (size_t)(op3))
#define vmacc_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_i32m1_m((vint32m1_t)(op0), (int32_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmacc_vx_i32m2(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_i32m2((vint32m2_t)(op0), (int32_t)(op1), (vint32m2_t)(op2), (size_t)(op3))
#define vmacc_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_i32m2_m((vint32m2_t)(op0), (int32_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmacc_vx_i32m4(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_i32m4((vint32m4_t)(op0), (int32_t)(op1), (vint32m4_t)(op2), (size_t)(op3))
#define vmacc_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_i32m4_m((vint32m4_t)(op0), (int32_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmacc_vx_i32m8(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_i32m8((vint32m8_t)(op0), (int32_t)(op1), (vint32m8_t)(op2), (size_t)(op3))
#define vmacc_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_i32m8_m((vint32m8_t)(op0), (int32_t)(op1), (vint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmacc_vx_i32mf2(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_i32mf2((vint32mf2_t)(op0), (int32_t)(op1), (vint32mf2_t)(op2), (size_t)(op3))
#define vmacc_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_i32mf2_m((vint32mf2_t)(op0), (int32_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmacc_vx_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_i64m1((vint64m1_t)(op0), (int64_t)(op1), (vint64m1_t)(op2), (size_t)(op3))
#define vmacc_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_i64m1_m((vint64m1_t)(op0), (int64_t)(op1), (vint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmacc_vx_i64m2(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_i64m2((vint64m2_t)(op0), (int64_t)(op1), (vint64m2_t)(op2), (size_t)(op3))
#define vmacc_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_i64m2_m((vint64m2_t)(op0), (int64_t)(op1), (vint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmacc_vx_i64m4(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_i64m4((vint64m4_t)(op0), (int64_t)(op1), (vint64m4_t)(op2), (size_t)(op3))
#define vmacc_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_i64m4_m((vint64m4_t)(op0), (int64_t)(op1), (vint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmacc_vx_i64m8(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_i64m8((vint64m8_t)(op0), (int64_t)(op1), (vint64m8_t)(op2), (size_t)(op3))
#define vmacc_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_i64m8_m((vint64m8_t)(op0), (int64_t)(op1), (vint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmacc_vv_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_u8m1((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vmacc_vv_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmacc_vv_u8m2(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_u8m2((vuint8m2_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (size_t)(op3))
#define vmacc_vv_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmacc_vv_u8m4(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_u8m4((vuint8m4_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (size_t)(op3))
#define vmacc_vv_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmacc_vv_u8m8(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_u8m8((vuint8m8_t)(op0), (vuint8m8_t)(op1), (vuint8m8_t)(op2), (size_t)(op3))
#define vmacc_vv_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmacc_vv_u8mf2(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_u8mf2((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (size_t)(op3))
#define vmacc_vv_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmacc_vv_u8mf4(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_u8mf4((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (size_t)(op3))
#define vmacc_vv_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmacc_vv_u8mf8(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_u8mf8((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (size_t)(op3))
#define vmacc_vv_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmacc_vv_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_u16m1((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vmacc_vv_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmacc_vv_u16m2(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_u16m2((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (size_t)(op3))
#define vmacc_vv_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmacc_vv_u16m4(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_u16m4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (size_t)(op3))
#define vmacc_vv_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmacc_vv_u16m8(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_u16m8((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vuint16m8_t)(op2), (size_t)(op3))
#define vmacc_vv_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmacc_vv_u16mf2(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_u16mf2((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (size_t)(op3))
#define vmacc_vv_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmacc_vv_u16mf4(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_u16mf4((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (size_t)(op3))
#define vmacc_vv_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmacc_vv_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_u32m1((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vmacc_vv_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmacc_vv_u32m2(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_u32m2((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (size_t)(op3))
#define vmacc_vv_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmacc_vv_u32m4(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_u32m4((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (size_t)(op3))
#define vmacc_vv_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmacc_vv_u32m8(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_u32m8((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vuint32m8_t)(op2), (size_t)(op3))
#define vmacc_vv_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmacc_vv_u32mf2(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_u32mf2((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (size_t)(op3))
#define vmacc_vv_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmacc_vv_u64m1(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_u64m1((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vmacc_vv_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmacc_vv_u64m2(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_u64m2((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vuint64m2_t)(op2), (size_t)(op3))
#define vmacc_vv_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmacc_vv_u64m4(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_u64m4((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vuint64m4_t)(op2), (size_t)(op3))
#define vmacc_vv_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmacc_vv_u64m8(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_u64m8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vuint64m8_t)(op2), (size_t)(op3))
#define vmacc_vv_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmacc_vx_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_u8m1((vuint8m1_t)(op0), (uint8_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vmacc_vx_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_u8m1_m((vuint8m1_t)(op0), (uint8_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmacc_vx_u8m2(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_u8m2((vuint8m2_t)(op0), (uint8_t)(op1), (vuint8m2_t)(op2), (size_t)(op3))
#define vmacc_vx_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_u8m2_m((vuint8m2_t)(op0), (uint8_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmacc_vx_u8m4(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_u8m4((vuint8m4_t)(op0), (uint8_t)(op1), (vuint8m4_t)(op2), (size_t)(op3))
#define vmacc_vx_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_u8m4_m((vuint8m4_t)(op0), (uint8_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmacc_vx_u8m8(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_u8m8((vuint8m8_t)(op0), (uint8_t)(op1), (vuint8m8_t)(op2), (size_t)(op3))
#define vmacc_vx_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_u8m8_m((vuint8m8_t)(op0), (uint8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmacc_vx_u8mf2(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_u8mf2((vuint8mf2_t)(op0), (uint8_t)(op1), (vuint8mf2_t)(op2), (size_t)(op3))
#define vmacc_vx_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_u8mf2_m((vuint8mf2_t)(op0), (uint8_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmacc_vx_u8mf4(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_u8mf4((vuint8mf4_t)(op0), (uint8_t)(op1), (vuint8mf4_t)(op2), (size_t)(op3))
#define vmacc_vx_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_u8mf4_m((vuint8mf4_t)(op0), (uint8_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmacc_vx_u8mf8(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_u8mf8((vuint8mf8_t)(op0), (uint8_t)(op1), (vuint8mf8_t)(op2), (size_t)(op3))
#define vmacc_vx_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_u8mf8_m((vuint8mf8_t)(op0), (uint8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmacc_vx_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_u16m1((vuint16m1_t)(op0), (uint16_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vmacc_vx_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_u16m1_m((vuint16m1_t)(op0), (uint16_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmacc_vx_u16m2(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_u16m2((vuint16m2_t)(op0), (uint16_t)(op1), (vuint16m2_t)(op2), (size_t)(op3))
#define vmacc_vx_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_u16m2_m((vuint16m2_t)(op0), (uint16_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmacc_vx_u16m4(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_u16m4((vuint16m4_t)(op0), (uint16_t)(op1), (vuint16m4_t)(op2), (size_t)(op3))
#define vmacc_vx_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_u16m4_m((vuint16m4_t)(op0), (uint16_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmacc_vx_u16m8(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_u16m8((vuint16m8_t)(op0), (uint16_t)(op1), (vuint16m8_t)(op2), (size_t)(op3))
#define vmacc_vx_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_u16m8_m((vuint16m8_t)(op0), (uint16_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmacc_vx_u16mf2(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_u16mf2((vuint16mf2_t)(op0), (uint16_t)(op1), (vuint16mf2_t)(op2), (size_t)(op3))
#define vmacc_vx_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_u16mf2_m((vuint16mf2_t)(op0), (uint16_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmacc_vx_u16mf4(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_u16mf4((vuint16mf4_t)(op0), (uint16_t)(op1), (vuint16mf4_t)(op2), (size_t)(op3))
#define vmacc_vx_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_u16mf4_m((vuint16mf4_t)(op0), (uint16_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmacc_vx_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_u32m1((vuint32m1_t)(op0), (uint32_t)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vmacc_vx_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_u32m1_m((vuint32m1_t)(op0), (uint32_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmacc_vx_u32m2(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_u32m2((vuint32m2_t)(op0), (uint32_t)(op1), (vuint32m2_t)(op2), (size_t)(op3))
#define vmacc_vx_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_u32m2_m((vuint32m2_t)(op0), (uint32_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmacc_vx_u32m4(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_u32m4((vuint32m4_t)(op0), (uint32_t)(op1), (vuint32m4_t)(op2), (size_t)(op3))
#define vmacc_vx_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_u32m4_m((vuint32m4_t)(op0), (uint32_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmacc_vx_u32m8(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_u32m8((vuint32m8_t)(op0), (uint32_t)(op1), (vuint32m8_t)(op2), (size_t)(op3))
#define vmacc_vx_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_u32m8_m((vuint32m8_t)(op0), (uint32_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmacc_vx_u32mf2(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_u32mf2((vuint32mf2_t)(op0), (uint32_t)(op1), (vuint32mf2_t)(op2), (size_t)(op3))
#define vmacc_vx_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_u32mf2_m((vuint32mf2_t)(op0), (uint32_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmacc_vx_u64m1(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_u64m1((vuint64m1_t)(op0), (uint64_t)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vmacc_vx_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_u64m1_m((vuint64m1_t)(op0), (uint64_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmacc_vx_u64m2(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_u64m2((vuint64m2_t)(op0), (uint64_t)(op1), (vuint64m2_t)(op2), (size_t)(op3))
#define vmacc_vx_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_u64m2_m((vuint64m2_t)(op0), (uint64_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmacc_vx_u64m4(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_u64m4((vuint64m4_t)(op0), (uint64_t)(op1), (vuint64m4_t)(op2), (size_t)(op3))
#define vmacc_vx_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_u64m4_m((vuint64m4_t)(op0), (uint64_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmacc_vx_u64m8(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_u64m8((vuint64m8_t)(op0), (uint64_t)(op1), (vuint64m8_t)(op2), (size_t)(op3))
#define vmacc_vx_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_u64m8_m((vuint64m8_t)(op0), (uint64_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vle16ff_v_i16m1(op0, op1, op2) \
__builtin_rvv_vle16ff_v_i16m1((const int16_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle16ff_v_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle16ff_v_i16m1_m((vint16m1_t)(op0), (const int16_t *)(op1), (size_t *)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vle16ff_v_i16m2(op0, op1, op2) \
__builtin_rvv_vle16ff_v_i16m2((const int16_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle16ff_v_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle16ff_v_i16m2_m((vint16m2_t)(op0), (const int16_t *)(op1), (size_t *)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vle16ff_v_i16m4(op0, op1, op2) \
__builtin_rvv_vle16ff_v_i16m4((const int16_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle16ff_v_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle16ff_v_i16m4_m((vint16m4_t)(op0), (const int16_t *)(op1), (size_t *)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vle16ff_v_i16m8(op0, op1, op2) \
__builtin_rvv_vle16ff_v_i16m8((const int16_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle16ff_v_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle16ff_v_i16m8_m((vint16m8_t)(op0), (const int16_t *)(op1), (size_t *)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vle16ff_v_i16mf2(op0, op1, op2) \
__builtin_rvv_vle16ff_v_i16mf2((const int16_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle16ff_v_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle16ff_v_i16mf2_m((vint16mf2_t)(op0), (const int16_t *)(op1), (size_t *)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vle16ff_v_i16mf4(op0, op1, op2) \
__builtin_rvv_vle16ff_v_i16mf4((const int16_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle16ff_v_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle16ff_v_i16mf4_m((vint16mf4_t)(op0), (const int16_t *)(op1), (size_t *)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsac_vv_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_i8m1((vint8m1_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (size_t)(op3))
#define vnmsac_vv_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnmsac_vv_i8m2(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_i8m2((vint8m2_t)(op0), (vint8m2_t)(op1), (vint8m2_t)(op2), (size_t)(op3))
#define vnmsac_vv_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnmsac_vv_i8m4(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_i8m4((vint8m4_t)(op0), (vint8m4_t)(op1), (vint8m4_t)(op2), (size_t)(op3))
#define vnmsac_vv_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vnmsac_vv_i8m8(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_i8m8((vint8m8_t)(op0), (vint8m8_t)(op1), (vint8m8_t)(op2), (size_t)(op3))
#define vnmsac_vv_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (vint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vnmsac_vv_i8mf2(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_i8mf2((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vint8mf2_t)(op2), (size_t)(op3))
#define vnmsac_vv_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnmsac_vv_i8mf4(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_i8mf4((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vint8mf4_t)(op2), (size_t)(op3))
#define vnmsac_vv_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnmsac_vv_i8mf8(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_i8mf8((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vint8mf8_t)(op2), (size_t)(op3))
#define vnmsac_vv_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsac_vv_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_i16m1((vint16m1_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vnmsac_vv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnmsac_vv_i16m2(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_i16m2((vint16m2_t)(op0), (vint16m2_t)(op1), (vint16m2_t)(op2), (size_t)(op3))
#define vnmsac_vv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnmsac_vv_i16m4(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_i16m4((vint16m4_t)(op0), (vint16m4_t)(op1), (vint16m4_t)(op2), (size_t)(op3))
#define vnmsac_vv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnmsac_vv_i16m8(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_i16m8((vint16m8_t)(op0), (vint16m8_t)(op1), (vint16m8_t)(op2), (size_t)(op3))
#define vnmsac_vv_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (vint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vnmsac_vv_i16mf2(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_i16mf2((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vint16mf2_t)(op2), (size_t)(op3))
#define vnmsac_vv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnmsac_vv_i16mf4(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_i16mf4((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vint16mf4_t)(op2), (size_t)(op3))
#define vnmsac_vv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsac_vv_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_i32m1((vint32m1_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (size_t)(op3))
#define vnmsac_vv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnmsac_vv_i32m2(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_i32m2((vint32m2_t)(op0), (vint32m2_t)(op1), (vint32m2_t)(op2), (size_t)(op3))
#define vnmsac_vv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnmsac_vv_i32m4(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_i32m4((vint32m4_t)(op0), (vint32m4_t)(op1), (vint32m4_t)(op2), (size_t)(op3))
#define vnmsac_vv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnmsac_vv_i32m8(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_i32m8((vint32m8_t)(op0), (vint32m8_t)(op1), (vint32m8_t)(op2), (size_t)(op3))
#define vnmsac_vv_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (vint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnmsac_vv_i32mf2(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_i32mf2((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vint32mf2_t)(op2), (size_t)(op3))
#define vnmsac_vv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsac_vv_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_i64m1((vint64m1_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (size_t)(op3))
#define vnmsac_vv_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsac_vv_i64m2(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_i64m2((vint64m2_t)(op0), (vint64m2_t)(op1), (vint64m2_t)(op2), (size_t)(op3))
#define vnmsac_vv_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (vint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnmsac_vv_i64m4(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_i64m4((vint64m4_t)(op0), (vint64m4_t)(op1), (vint64m4_t)(op2), (size_t)(op3))
#define vnmsac_vv_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (vint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnmsac_vv_i64m8(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_i64m8((vint64m8_t)(op0), (vint64m8_t)(op1), (vint64m8_t)(op2), (size_t)(op3))
#define vnmsac_vv_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (vint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnmsac_vx_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_i8m1((vint8m1_t)(op0), (int8_t)(op1), (vint8m1_t)(op2), (size_t)(op3))
#define vnmsac_vx_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_i8m1_m((vint8m1_t)(op0), (int8_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnmsac_vx_i8m2(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_i8m2((vint8m2_t)(op0), (int8_t)(op1), (vint8m2_t)(op2), (size_t)(op3))
#define vnmsac_vx_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_i8m2_m((vint8m2_t)(op0), (int8_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnmsac_vx_i8m4(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_i8m4((vint8m4_t)(op0), (int8_t)(op1), (vint8m4_t)(op2), (size_t)(op3))
#define vnmsac_vx_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_i8m4_m((vint8m4_t)(op0), (int8_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vnmsac_vx_i8m8(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_i8m8((vint8m8_t)(op0), (int8_t)(op1), (vint8m8_t)(op2), (size_t)(op3))
#define vnmsac_vx_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_i8m8_m((vint8m8_t)(op0), (int8_t)(op1), (vint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vnmsac_vx_i8mf2(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_i8mf2((vint8mf2_t)(op0), (int8_t)(op1), (vint8mf2_t)(op2), (size_t)(op3))
#define vnmsac_vx_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_i8mf2_m((vint8mf2_t)(op0), (int8_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnmsac_vx_i8mf4(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_i8mf4((vint8mf4_t)(op0), (int8_t)(op1), (vint8mf4_t)(op2), (size_t)(op3))
#define vnmsac_vx_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_i8mf4_m((vint8mf4_t)(op0), (int8_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnmsac_vx_i8mf8(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_i8mf8((vint8mf8_t)(op0), (int8_t)(op1), (vint8mf8_t)(op2), (size_t)(op3))
#define vnmsac_vx_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_i8mf8_m((vint8mf8_t)(op0), (int8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsac_vx_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_i16m1((vint16m1_t)(op0), (int16_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vnmsac_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_i16m1_m((vint16m1_t)(op0), (int16_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnmsac_vx_i16m2(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_i16m2((vint16m2_t)(op0), (int16_t)(op1), (vint16m2_t)(op2), (size_t)(op3))
#define vnmsac_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_i16m2_m((vint16m2_t)(op0), (int16_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnmsac_vx_i16m4(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_i16m4((vint16m4_t)(op0), (int16_t)(op1), (vint16m4_t)(op2), (size_t)(op3))
#define vnmsac_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_i16m4_m((vint16m4_t)(op0), (int16_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnmsac_vx_i16m8(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_i16m8((vint16m8_t)(op0), (int16_t)(op1), (vint16m8_t)(op2), (size_t)(op3))
#define vnmsac_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_i16m8_m((vint16m8_t)(op0), (int16_t)(op1), (vint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vnmsac_vx_i16mf2(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_i16mf2((vint16mf2_t)(op0), (int16_t)(op1), (vint16mf2_t)(op2), (size_t)(op3))
#define vnmsac_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_i16mf2_m((vint16mf2_t)(op0), (int16_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnmsac_vx_i16mf4(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_i16mf4((vint16mf4_t)(op0), (int16_t)(op1), (vint16mf4_t)(op2), (size_t)(op3))
#define vnmsac_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_i16mf4_m((vint16mf4_t)(op0), (int16_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsac_vx_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_i32m1((vint32m1_t)(op0), (int32_t)(op1), (vint32m1_t)(op2), (size_t)(op3))
#define vnmsac_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_i32m1_m((vint32m1_t)(op0), (int32_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnmsac_vx_i32m2(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_i32m2((vint32m2_t)(op0), (int32_t)(op1), (vint32m2_t)(op2), (size_t)(op3))
#define vnmsac_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_i32m2_m((vint32m2_t)(op0), (int32_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnmsac_vx_i32m4(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_i32m4((vint32m4_t)(op0), (int32_t)(op1), (vint32m4_t)(op2), (size_t)(op3))
#define vnmsac_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_i32m4_m((vint32m4_t)(op0), (int32_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnmsac_vx_i32m8(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_i32m8((vint32m8_t)(op0), (int32_t)(op1), (vint32m8_t)(op2), (size_t)(op3))
#define vnmsac_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_i32m8_m((vint32m8_t)(op0), (int32_t)(op1), (vint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnmsac_vx_i32mf2(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_i32mf2((vint32mf2_t)(op0), (int32_t)(op1), (vint32mf2_t)(op2), (size_t)(op3))
#define vnmsac_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_i32mf2_m((vint32mf2_t)(op0), (int32_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsac_vx_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_i64m1((vint64m1_t)(op0), (int64_t)(op1), (vint64m1_t)(op2), (size_t)(op3))
#define vnmsac_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_i64m1_m((vint64m1_t)(op0), (int64_t)(op1), (vint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsac_vx_i64m2(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_i64m2((vint64m2_t)(op0), (int64_t)(op1), (vint64m2_t)(op2), (size_t)(op3))
#define vnmsac_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_i64m2_m((vint64m2_t)(op0), (int64_t)(op1), (vint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnmsac_vx_i64m4(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_i64m4((vint64m4_t)(op0), (int64_t)(op1), (vint64m4_t)(op2), (size_t)(op3))
#define vnmsac_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_i64m4_m((vint64m4_t)(op0), (int64_t)(op1), (vint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnmsac_vx_i64m8(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_i64m8((vint64m8_t)(op0), (int64_t)(op1), (vint64m8_t)(op2), (size_t)(op3))
#define vnmsac_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_i64m8_m((vint64m8_t)(op0), (int64_t)(op1), (vint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnmsac_vv_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_u8m1((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vnmsac_vv_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnmsac_vv_u8m2(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_u8m2((vuint8m2_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (size_t)(op3))
#define vnmsac_vv_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnmsac_vv_u8m4(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_u8m4((vuint8m4_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (size_t)(op3))
#define vnmsac_vv_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vnmsac_vv_u8m8(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_u8m8((vuint8m8_t)(op0), (vuint8m8_t)(op1), (vuint8m8_t)(op2), (size_t)(op3))
#define vnmsac_vv_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vnmsac_vv_u8mf2(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_u8mf2((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (size_t)(op3))
#define vnmsac_vv_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnmsac_vv_u8mf4(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_u8mf4((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (size_t)(op3))
#define vnmsac_vv_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnmsac_vv_u8mf8(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_u8mf8((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (size_t)(op3))
#define vnmsac_vv_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsac_vv_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_u16m1((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vnmsac_vv_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnmsac_vv_u16m2(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_u16m2((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (size_t)(op3))
#define vnmsac_vv_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnmsac_vv_u16m4(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_u16m4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (size_t)(op3))
#define vnmsac_vv_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnmsac_vv_u16m8(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_u16m8((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vuint16m8_t)(op2), (size_t)(op3))
#define vnmsac_vv_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vnmsac_vv_u16mf2(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_u16mf2((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (size_t)(op3))
#define vnmsac_vv_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnmsac_vv_u16mf4(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_u16mf4((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (size_t)(op3))
#define vnmsac_vv_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsac_vv_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_u32m1((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vnmsac_vv_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnmsac_vv_u32m2(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_u32m2((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (size_t)(op3))
#define vnmsac_vv_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnmsac_vv_u32m4(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_u32m4((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (size_t)(op3))
#define vnmsac_vv_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnmsac_vv_u32m8(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_u32m8((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vuint32m8_t)(op2), (size_t)(op3))
#define vnmsac_vv_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnmsac_vv_u32mf2(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_u32mf2((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (size_t)(op3))
#define vnmsac_vv_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsac_vv_u64m1(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_u64m1((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vnmsac_vv_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsac_vv_u64m2(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_u64m2((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vuint64m2_t)(op2), (size_t)(op3))
#define vnmsac_vv_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnmsac_vv_u64m4(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_u64m4((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vuint64m4_t)(op2), (size_t)(op3))
#define vnmsac_vv_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnmsac_vv_u64m8(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_u64m8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vuint64m8_t)(op2), (size_t)(op3))
#define vnmsac_vv_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnmsac_vx_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_u8m1((vuint8m1_t)(op0), (uint8_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vnmsac_vx_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_u8m1_m((vuint8m1_t)(op0), (uint8_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnmsac_vx_u8m2(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_u8m2((vuint8m2_t)(op0), (uint8_t)(op1), (vuint8m2_t)(op2), (size_t)(op3))
#define vnmsac_vx_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_u8m2_m((vuint8m2_t)(op0), (uint8_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnmsac_vx_u8m4(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_u8m4((vuint8m4_t)(op0), (uint8_t)(op1), (vuint8m4_t)(op2), (size_t)(op3))
#define vnmsac_vx_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_u8m4_m((vuint8m4_t)(op0), (uint8_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vnmsac_vx_u8m8(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_u8m8((vuint8m8_t)(op0), (uint8_t)(op1), (vuint8m8_t)(op2), (size_t)(op3))
#define vnmsac_vx_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_u8m8_m((vuint8m8_t)(op0), (uint8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vnmsac_vx_u8mf2(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_u8mf2((vuint8mf2_t)(op0), (uint8_t)(op1), (vuint8mf2_t)(op2), (size_t)(op3))
#define vnmsac_vx_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_u8mf2_m((vuint8mf2_t)(op0), (uint8_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnmsac_vx_u8mf4(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_u8mf4((vuint8mf4_t)(op0), (uint8_t)(op1), (vuint8mf4_t)(op2), (size_t)(op3))
#define vnmsac_vx_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_u8mf4_m((vuint8mf4_t)(op0), (uint8_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnmsac_vx_u8mf8(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_u8mf8((vuint8mf8_t)(op0), (uint8_t)(op1), (vuint8mf8_t)(op2), (size_t)(op3))
#define vnmsac_vx_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_u8mf8_m((vuint8mf8_t)(op0), (uint8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsac_vx_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_u16m1((vuint16m1_t)(op0), (uint16_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vnmsac_vx_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_u16m1_m((vuint16m1_t)(op0), (uint16_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnmsac_vx_u16m2(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_u16m2((vuint16m2_t)(op0), (uint16_t)(op1), (vuint16m2_t)(op2), (size_t)(op3))
#define vnmsac_vx_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_u16m2_m((vuint16m2_t)(op0), (uint16_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnmsac_vx_u16m4(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_u16m4((vuint16m4_t)(op0), (uint16_t)(op1), (vuint16m4_t)(op2), (size_t)(op3))
#define vnmsac_vx_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_u16m4_m((vuint16m4_t)(op0), (uint16_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnmsac_vx_u16m8(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_u16m8((vuint16m8_t)(op0), (uint16_t)(op1), (vuint16m8_t)(op2), (size_t)(op3))
#define vnmsac_vx_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_u16m8_m((vuint16m8_t)(op0), (uint16_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vnmsac_vx_u16mf2(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_u16mf2((vuint16mf2_t)(op0), (uint16_t)(op1), (vuint16mf2_t)(op2), (size_t)(op3))
#define vnmsac_vx_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_u16mf2_m((vuint16mf2_t)(op0), (uint16_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnmsac_vx_u16mf4(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_u16mf4((vuint16mf4_t)(op0), (uint16_t)(op1), (vuint16mf4_t)(op2), (size_t)(op3))
#define vnmsac_vx_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_u16mf4_m((vuint16mf4_t)(op0), (uint16_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsac_vx_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_u32m1((vuint32m1_t)(op0), (uint32_t)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vnmsac_vx_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_u32m1_m((vuint32m1_t)(op0), (uint32_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnmsac_vx_u32m2(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_u32m2((vuint32m2_t)(op0), (uint32_t)(op1), (vuint32m2_t)(op2), (size_t)(op3))
#define vnmsac_vx_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_u32m2_m((vuint32m2_t)(op0), (uint32_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnmsac_vx_u32m4(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_u32m4((vuint32m4_t)(op0), (uint32_t)(op1), (vuint32m4_t)(op2), (size_t)(op3))
#define vnmsac_vx_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_u32m4_m((vuint32m4_t)(op0), (uint32_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnmsac_vx_u32m8(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_u32m8((vuint32m8_t)(op0), (uint32_t)(op1), (vuint32m8_t)(op2), (size_t)(op3))
#define vnmsac_vx_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_u32m8_m((vuint32m8_t)(op0), (uint32_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnmsac_vx_u32mf2(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_u32mf2((vuint32mf2_t)(op0), (uint32_t)(op1), (vuint32mf2_t)(op2), (size_t)(op3))
#define vnmsac_vx_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_u32mf2_m((vuint32mf2_t)(op0), (uint32_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsac_vx_u64m1(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_u64m1((vuint64m1_t)(op0), (uint64_t)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vnmsac_vx_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_u64m1_m((vuint64m1_t)(op0), (uint64_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsac_vx_u64m2(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_u64m2((vuint64m2_t)(op0), (uint64_t)(op1), (vuint64m2_t)(op2), (size_t)(op3))
#define vnmsac_vx_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_u64m2_m((vuint64m2_t)(op0), (uint64_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnmsac_vx_u64m4(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_u64m4((vuint64m4_t)(op0), (uint64_t)(op1), (vuint64m4_t)(op2), (size_t)(op3))
#define vnmsac_vx_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_u64m4_m((vuint64m4_t)(op0), (uint64_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnmsac_vx_u64m8(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_u64m8((vuint64m8_t)(op0), (uint64_t)(op1), (vuint64m8_t)(op2), (size_t)(op3))
#define vnmsac_vx_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_u64m8_m((vuint64m8_t)(op0), (uint64_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmadd_vv_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_i8m1((vint8m1_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (size_t)(op3))
#define vmadd_vv_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmadd_vv_i8m2(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_i8m2((vint8m2_t)(op0), (vint8m2_t)(op1), (vint8m2_t)(op2), (size_t)(op3))
#define vmadd_vv_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmadd_vv_i8m4(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_i8m4((vint8m4_t)(op0), (vint8m4_t)(op1), (vint8m4_t)(op2), (size_t)(op3))
#define vmadd_vv_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmadd_vv_i8m8(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_i8m8((vint8m8_t)(op0), (vint8m8_t)(op1), (vint8m8_t)(op2), (size_t)(op3))
#define vmadd_vv_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (vint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmadd_vv_i8mf2(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_i8mf2((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vint8mf2_t)(op2), (size_t)(op3))
#define vmadd_vv_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmadd_vv_i8mf4(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_i8mf4((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vint8mf4_t)(op2), (size_t)(op3))
#define vmadd_vv_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmadd_vv_i8mf8(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_i8mf8((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vint8mf8_t)(op2), (size_t)(op3))
#define vmadd_vv_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmadd_vv_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_i16m1((vint16m1_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vmadd_vv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmadd_vv_i16m2(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_i16m2((vint16m2_t)(op0), (vint16m2_t)(op1), (vint16m2_t)(op2), (size_t)(op3))
#define vmadd_vv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmadd_vv_i16m4(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_i16m4((vint16m4_t)(op0), (vint16m4_t)(op1), (vint16m4_t)(op2), (size_t)(op3))
#define vmadd_vv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmadd_vv_i16m8(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_i16m8((vint16m8_t)(op0), (vint16m8_t)(op1), (vint16m8_t)(op2), (size_t)(op3))
#define vmadd_vv_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (vint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmadd_vv_i16mf2(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_i16mf2((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vint16mf2_t)(op2), (size_t)(op3))
#define vmadd_vv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmadd_vv_i16mf4(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_i16mf4((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vint16mf4_t)(op2), (size_t)(op3))
#define vmadd_vv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmadd_vv_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_i32m1((vint32m1_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (size_t)(op3))
#define vmadd_vv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmadd_vv_i32m2(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_i32m2((vint32m2_t)(op0), (vint32m2_t)(op1), (vint32m2_t)(op2), (size_t)(op3))
#define vmadd_vv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmadd_vv_i32m4(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_i32m4((vint32m4_t)(op0), (vint32m4_t)(op1), (vint32m4_t)(op2), (size_t)(op3))
#define vmadd_vv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmadd_vv_i32m8(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_i32m8((vint32m8_t)(op0), (vint32m8_t)(op1), (vint32m8_t)(op2), (size_t)(op3))
#define vmadd_vv_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (vint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmadd_vv_i32mf2(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_i32mf2((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vint32mf2_t)(op2), (size_t)(op3))
#define vmadd_vv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmadd_vv_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_i64m1((vint64m1_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (size_t)(op3))
#define vmadd_vv_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmadd_vv_i64m2(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_i64m2((vint64m2_t)(op0), (vint64m2_t)(op1), (vint64m2_t)(op2), (size_t)(op3))
#define vmadd_vv_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (vint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmadd_vv_i64m4(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_i64m4((vint64m4_t)(op0), (vint64m4_t)(op1), (vint64m4_t)(op2), (size_t)(op3))
#define vmadd_vv_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (vint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmadd_vv_i64m8(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_i64m8((vint64m8_t)(op0), (vint64m8_t)(op1), (vint64m8_t)(op2), (size_t)(op3))
#define vmadd_vv_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (vint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmadd_vx_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_i8m1((vint8m1_t)(op0), (int8_t)(op1), (vint8m1_t)(op2), (size_t)(op3))
#define vmadd_vx_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_i8m1_m((vint8m1_t)(op0), (int8_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmadd_vx_i8m2(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_i8m2((vint8m2_t)(op0), (int8_t)(op1), (vint8m2_t)(op2), (size_t)(op3))
#define vmadd_vx_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_i8m2_m((vint8m2_t)(op0), (int8_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmadd_vx_i8m4(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_i8m4((vint8m4_t)(op0), (int8_t)(op1), (vint8m4_t)(op2), (size_t)(op3))
#define vmadd_vx_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_i8m4_m((vint8m4_t)(op0), (int8_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmadd_vx_i8m8(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_i8m8((vint8m8_t)(op0), (int8_t)(op1), (vint8m8_t)(op2), (size_t)(op3))
#define vmadd_vx_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_i8m8_m((vint8m8_t)(op0), (int8_t)(op1), (vint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmadd_vx_i8mf2(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_i8mf2((vint8mf2_t)(op0), (int8_t)(op1), (vint8mf2_t)(op2), (size_t)(op3))
#define vmadd_vx_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_i8mf2_m((vint8mf2_t)(op0), (int8_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmadd_vx_i8mf4(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_i8mf4((vint8mf4_t)(op0), (int8_t)(op1), (vint8mf4_t)(op2), (size_t)(op3))
#define vmadd_vx_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_i8mf4_m((vint8mf4_t)(op0), (int8_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmadd_vx_i8mf8(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_i8mf8((vint8mf8_t)(op0), (int8_t)(op1), (vint8mf8_t)(op2), (size_t)(op3))
#define vmadd_vx_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_i8mf8_m((vint8mf8_t)(op0), (int8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmadd_vx_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_i16m1((vint16m1_t)(op0), (int16_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vmadd_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_i16m1_m((vint16m1_t)(op0), (int16_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmadd_vx_i16m2(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_i16m2((vint16m2_t)(op0), (int16_t)(op1), (vint16m2_t)(op2), (size_t)(op3))
#define vmadd_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_i16m2_m((vint16m2_t)(op0), (int16_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmadd_vx_i16m4(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_i16m4((vint16m4_t)(op0), (int16_t)(op1), (vint16m4_t)(op2), (size_t)(op3))
#define vmadd_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_i16m4_m((vint16m4_t)(op0), (int16_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmadd_vx_i16m8(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_i16m8((vint16m8_t)(op0), (int16_t)(op1), (vint16m8_t)(op2), (size_t)(op3))
#define vmadd_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_i16m8_m((vint16m8_t)(op0), (int16_t)(op1), (vint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmadd_vx_i16mf2(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_i16mf2((vint16mf2_t)(op0), (int16_t)(op1), (vint16mf2_t)(op2), (size_t)(op3))
#define vmadd_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_i16mf2_m((vint16mf2_t)(op0), (int16_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmadd_vx_i16mf4(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_i16mf4((vint16mf4_t)(op0), (int16_t)(op1), (vint16mf4_t)(op2), (size_t)(op3))
#define vmadd_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_i16mf4_m((vint16mf4_t)(op0), (int16_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmadd_vx_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_i32m1((vint32m1_t)(op0), (int32_t)(op1), (vint32m1_t)(op2), (size_t)(op3))
#define vmadd_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_i32m1_m((vint32m1_t)(op0), (int32_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmadd_vx_i32m2(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_i32m2((vint32m2_t)(op0), (int32_t)(op1), (vint32m2_t)(op2), (size_t)(op3))
#define vmadd_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_i32m2_m((vint32m2_t)(op0), (int32_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmadd_vx_i32m4(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_i32m4((vint32m4_t)(op0), (int32_t)(op1), (vint32m4_t)(op2), (size_t)(op3))
#define vmadd_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_i32m4_m((vint32m4_t)(op0), (int32_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmadd_vx_i32m8(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_i32m8((vint32m8_t)(op0), (int32_t)(op1), (vint32m8_t)(op2), (size_t)(op3))
#define vmadd_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_i32m8_m((vint32m8_t)(op0), (int32_t)(op1), (vint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmadd_vx_i32mf2(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_i32mf2((vint32mf2_t)(op0), (int32_t)(op1), (vint32mf2_t)(op2), (size_t)(op3))
#define vmadd_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_i32mf2_m((vint32mf2_t)(op0), (int32_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmadd_vx_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_i64m1((vint64m1_t)(op0), (int64_t)(op1), (vint64m1_t)(op2), (size_t)(op3))
#define vmadd_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_i64m1_m((vint64m1_t)(op0), (int64_t)(op1), (vint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmadd_vx_i64m2(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_i64m2((vint64m2_t)(op0), (int64_t)(op1), (vint64m2_t)(op2), (size_t)(op3))
#define vmadd_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_i64m2_m((vint64m2_t)(op0), (int64_t)(op1), (vint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmadd_vx_i64m4(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_i64m4((vint64m4_t)(op0), (int64_t)(op1), (vint64m4_t)(op2), (size_t)(op3))
#define vmadd_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_i64m4_m((vint64m4_t)(op0), (int64_t)(op1), (vint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmadd_vx_i64m8(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_i64m8((vint64m8_t)(op0), (int64_t)(op1), (vint64m8_t)(op2), (size_t)(op3))
#define vmadd_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_i64m8_m((vint64m8_t)(op0), (int64_t)(op1), (vint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmadd_vv_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_u8m1((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vmadd_vv_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmadd_vv_u8m2(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_u8m2((vuint8m2_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (size_t)(op3))
#define vmadd_vv_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmadd_vv_u8m4(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_u8m4((vuint8m4_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (size_t)(op3))
#define vmadd_vv_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmadd_vv_u8m8(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_u8m8((vuint8m8_t)(op0), (vuint8m8_t)(op1), (vuint8m8_t)(op2), (size_t)(op3))
#define vmadd_vv_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmadd_vv_u8mf2(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_u8mf2((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (size_t)(op3))
#define vmadd_vv_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmadd_vv_u8mf4(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_u8mf4((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (size_t)(op3))
#define vmadd_vv_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmadd_vv_u8mf8(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_u8mf8((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (size_t)(op3))
#define vmadd_vv_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmadd_vv_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_u16m1((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vmadd_vv_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmadd_vv_u16m2(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_u16m2((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (size_t)(op3))
#define vmadd_vv_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmadd_vv_u16m4(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_u16m4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (size_t)(op3))
#define vmadd_vv_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmadd_vv_u16m8(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_u16m8((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vuint16m8_t)(op2), (size_t)(op3))
#define vmadd_vv_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmadd_vv_u16mf2(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_u16mf2((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (size_t)(op3))
#define vmadd_vv_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmadd_vv_u16mf4(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_u16mf4((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (size_t)(op3))
#define vmadd_vv_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmadd_vv_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_u32m1((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vmadd_vv_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmadd_vv_u32m2(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_u32m2((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (size_t)(op3))
#define vmadd_vv_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmadd_vv_u32m4(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_u32m4((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (size_t)(op3))
#define vmadd_vv_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmadd_vv_u32m8(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_u32m8((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vuint32m8_t)(op2), (size_t)(op3))
#define vmadd_vv_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmadd_vv_u32mf2(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_u32mf2((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (size_t)(op3))
#define vmadd_vv_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmadd_vv_u64m1(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_u64m1((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vmadd_vv_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmadd_vv_u64m2(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_u64m2((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vuint64m2_t)(op2), (size_t)(op3))
#define vmadd_vv_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmadd_vv_u64m4(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_u64m4((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vuint64m4_t)(op2), (size_t)(op3))
#define vmadd_vv_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmadd_vv_u64m8(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_u64m8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vuint64m8_t)(op2), (size_t)(op3))
#define vmadd_vv_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmadd_vx_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_u8m1((vuint8m1_t)(op0), (uint8_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vmadd_vx_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_u8m1_m((vuint8m1_t)(op0), (uint8_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmadd_vx_u8m2(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_u8m2((vuint8m2_t)(op0), (uint8_t)(op1), (vuint8m2_t)(op2), (size_t)(op3))
#define vmadd_vx_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_u8m2_m((vuint8m2_t)(op0), (uint8_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmadd_vx_u8m4(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_u8m4((vuint8m4_t)(op0), (uint8_t)(op1), (vuint8m4_t)(op2), (size_t)(op3))
#define vmadd_vx_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_u8m4_m((vuint8m4_t)(op0), (uint8_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmadd_vx_u8m8(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_u8m8((vuint8m8_t)(op0), (uint8_t)(op1), (vuint8m8_t)(op2), (size_t)(op3))
#define vmadd_vx_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_u8m8_m((vuint8m8_t)(op0), (uint8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmadd_vx_u8mf2(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_u8mf2((vuint8mf2_t)(op0), (uint8_t)(op1), (vuint8mf2_t)(op2), (size_t)(op3))
#define vmadd_vx_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_u8mf2_m((vuint8mf2_t)(op0), (uint8_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmadd_vx_u8mf4(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_u8mf4((vuint8mf4_t)(op0), (uint8_t)(op1), (vuint8mf4_t)(op2), (size_t)(op3))
#define vmadd_vx_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_u8mf4_m((vuint8mf4_t)(op0), (uint8_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmadd_vx_u8mf8(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_u8mf8((vuint8mf8_t)(op0), (uint8_t)(op1), (vuint8mf8_t)(op2), (size_t)(op3))
#define vmadd_vx_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_u8mf8_m((vuint8mf8_t)(op0), (uint8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmadd_vx_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_u16m1((vuint16m1_t)(op0), (uint16_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vmadd_vx_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_u16m1_m((vuint16m1_t)(op0), (uint16_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmadd_vx_u16m2(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_u16m2((vuint16m2_t)(op0), (uint16_t)(op1), (vuint16m2_t)(op2), (size_t)(op3))
#define vmadd_vx_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_u16m2_m((vuint16m2_t)(op0), (uint16_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmadd_vx_u16m4(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_u16m4((vuint16m4_t)(op0), (uint16_t)(op1), (vuint16m4_t)(op2), (size_t)(op3))
#define vmadd_vx_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_u16m4_m((vuint16m4_t)(op0), (uint16_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmadd_vx_u16m8(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_u16m8((vuint16m8_t)(op0), (uint16_t)(op1), (vuint16m8_t)(op2), (size_t)(op3))
#define vmadd_vx_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_u16m8_m((vuint16m8_t)(op0), (uint16_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmadd_vx_u16mf2(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_u16mf2((vuint16mf2_t)(op0), (uint16_t)(op1), (vuint16mf2_t)(op2), (size_t)(op3))
#define vmadd_vx_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_u16mf2_m((vuint16mf2_t)(op0), (uint16_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmadd_vx_u16mf4(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_u16mf4((vuint16mf4_t)(op0), (uint16_t)(op1), (vuint16mf4_t)(op2), (size_t)(op3))
#define vmadd_vx_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_u16mf4_m((vuint16mf4_t)(op0), (uint16_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmadd_vx_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_u32m1((vuint32m1_t)(op0), (uint32_t)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vmadd_vx_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_u32m1_m((vuint32m1_t)(op0), (uint32_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmadd_vx_u32m2(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_u32m2((vuint32m2_t)(op0), (uint32_t)(op1), (vuint32m2_t)(op2), (size_t)(op3))
#define vmadd_vx_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_u32m2_m((vuint32m2_t)(op0), (uint32_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmadd_vx_u32m4(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_u32m4((vuint32m4_t)(op0), (uint32_t)(op1), (vuint32m4_t)(op2), (size_t)(op3))
#define vmadd_vx_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_u32m4_m((vuint32m4_t)(op0), (uint32_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmadd_vx_u32m8(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_u32m8((vuint32m8_t)(op0), (uint32_t)(op1), (vuint32m8_t)(op2), (size_t)(op3))
#define vmadd_vx_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_u32m8_m((vuint32m8_t)(op0), (uint32_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmadd_vx_u32mf2(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_u32mf2((vuint32mf2_t)(op0), (uint32_t)(op1), (vuint32mf2_t)(op2), (size_t)(op3))
#define vmadd_vx_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_u32mf2_m((vuint32mf2_t)(op0), (uint32_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmadd_vx_u64m1(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_u64m1((vuint64m1_t)(op0), (uint64_t)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vmadd_vx_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_u64m1_m((vuint64m1_t)(op0), (uint64_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmadd_vx_u64m2(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_u64m2((vuint64m2_t)(op0), (uint64_t)(op1), (vuint64m2_t)(op2), (size_t)(op3))
#define vmadd_vx_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_u64m2_m((vuint64m2_t)(op0), (uint64_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmadd_vx_u64m4(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_u64m4((vuint64m4_t)(op0), (uint64_t)(op1), (vuint64m4_t)(op2), (size_t)(op3))
#define vmadd_vx_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_u64m4_m((vuint64m4_t)(op0), (uint64_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmadd_vx_u64m8(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_u64m8((vuint64m8_t)(op0), (uint64_t)(op1), (vuint64m8_t)(op2), (size_t)(op3))
#define vmadd_vx_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_u64m8_m((vuint64m8_t)(op0), (uint64_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnmsub_vv_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_i8m1((vint8m1_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (size_t)(op3))
#define vnmsub_vv_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnmsub_vv_i8m2(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_i8m2((vint8m2_t)(op0), (vint8m2_t)(op1), (vint8m2_t)(op2), (size_t)(op3))
#define vnmsub_vv_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnmsub_vv_i8m4(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_i8m4((vint8m4_t)(op0), (vint8m4_t)(op1), (vint8m4_t)(op2), (size_t)(op3))
#define vnmsub_vv_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vnmsub_vv_i8m8(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_i8m8((vint8m8_t)(op0), (vint8m8_t)(op1), (vint8m8_t)(op2), (size_t)(op3))
#define vnmsub_vv_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (vint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vnmsub_vv_i8mf2(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_i8mf2((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vint8mf2_t)(op2), (size_t)(op3))
#define vnmsub_vv_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnmsub_vv_i8mf4(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_i8mf4((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vint8mf4_t)(op2), (size_t)(op3))
#define vnmsub_vv_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnmsub_vv_i8mf8(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_i8mf8((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vint8mf8_t)(op2), (size_t)(op3))
#define vnmsub_vv_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsub_vv_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_i16m1((vint16m1_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vnmsub_vv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnmsub_vv_i16m2(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_i16m2((vint16m2_t)(op0), (vint16m2_t)(op1), (vint16m2_t)(op2), (size_t)(op3))
#define vnmsub_vv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnmsub_vv_i16m4(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_i16m4((vint16m4_t)(op0), (vint16m4_t)(op1), (vint16m4_t)(op2), (size_t)(op3))
#define vnmsub_vv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnmsub_vv_i16m8(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_i16m8((vint16m8_t)(op0), (vint16m8_t)(op1), (vint16m8_t)(op2), (size_t)(op3))
#define vnmsub_vv_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (vint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vnmsub_vv_i16mf2(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_i16mf2((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vint16mf2_t)(op2), (size_t)(op3))
#define vnmsub_vv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnmsub_vv_i16mf4(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_i16mf4((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vint16mf4_t)(op2), (size_t)(op3))
#define vnmsub_vv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsub_vv_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_i32m1((vint32m1_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (size_t)(op3))
#define vnmsub_vv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnmsub_vv_i32m2(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_i32m2((vint32m2_t)(op0), (vint32m2_t)(op1), (vint32m2_t)(op2), (size_t)(op3))
#define vnmsub_vv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnmsub_vv_i32m4(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_i32m4((vint32m4_t)(op0), (vint32m4_t)(op1), (vint32m4_t)(op2), (size_t)(op3))
#define vnmsub_vv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnmsub_vv_i32m8(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_i32m8((vint32m8_t)(op0), (vint32m8_t)(op1), (vint32m8_t)(op2), (size_t)(op3))
#define vnmsub_vv_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (vint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnmsub_vv_i32mf2(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_i32mf2((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vint32mf2_t)(op2), (size_t)(op3))
#define vnmsub_vv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsub_vv_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_i64m1((vint64m1_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (size_t)(op3))
#define vnmsub_vv_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsub_vv_i64m2(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_i64m2((vint64m2_t)(op0), (vint64m2_t)(op1), (vint64m2_t)(op2), (size_t)(op3))
#define vnmsub_vv_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (vint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnmsub_vv_i64m4(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_i64m4((vint64m4_t)(op0), (vint64m4_t)(op1), (vint64m4_t)(op2), (size_t)(op3))
#define vnmsub_vv_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (vint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnmsub_vv_i64m8(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_i64m8((vint64m8_t)(op0), (vint64m8_t)(op1), (vint64m8_t)(op2), (size_t)(op3))
#define vnmsub_vv_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (vint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnmsub_vx_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_i8m1((vint8m1_t)(op0), (int8_t)(op1), (vint8m1_t)(op2), (size_t)(op3))
#define vnmsub_vx_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_i8m1_m((vint8m1_t)(op0), (int8_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnmsub_vx_i8m2(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_i8m2((vint8m2_t)(op0), (int8_t)(op1), (vint8m2_t)(op2), (size_t)(op3))
#define vnmsub_vx_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_i8m2_m((vint8m2_t)(op0), (int8_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnmsub_vx_i8m4(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_i8m4((vint8m4_t)(op0), (int8_t)(op1), (vint8m4_t)(op2), (size_t)(op3))
#define vnmsub_vx_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_i8m4_m((vint8m4_t)(op0), (int8_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vnmsub_vx_i8m8(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_i8m8((vint8m8_t)(op0), (int8_t)(op1), (vint8m8_t)(op2), (size_t)(op3))
#define vnmsub_vx_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_i8m8_m((vint8m8_t)(op0), (int8_t)(op1), (vint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vnmsub_vx_i8mf2(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_i8mf2((vint8mf2_t)(op0), (int8_t)(op1), (vint8mf2_t)(op2), (size_t)(op3))
#define vnmsub_vx_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_i8mf2_m((vint8mf2_t)(op0), (int8_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnmsub_vx_i8mf4(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_i8mf4((vint8mf4_t)(op0), (int8_t)(op1), (vint8mf4_t)(op2), (size_t)(op3))
#define vnmsub_vx_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_i8mf4_m((vint8mf4_t)(op0), (int8_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnmsub_vx_i8mf8(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_i8mf8((vint8mf8_t)(op0), (int8_t)(op1), (vint8mf8_t)(op2), (size_t)(op3))
#define vnmsub_vx_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_i8mf8_m((vint8mf8_t)(op0), (int8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsub_vx_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_i16m1((vint16m1_t)(op0), (int16_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vnmsub_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_i16m1_m((vint16m1_t)(op0), (int16_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnmsub_vx_i16m2(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_i16m2((vint16m2_t)(op0), (int16_t)(op1), (vint16m2_t)(op2), (size_t)(op3))
#define vnmsub_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_i16m2_m((vint16m2_t)(op0), (int16_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnmsub_vx_i16m4(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_i16m4((vint16m4_t)(op0), (int16_t)(op1), (vint16m4_t)(op2), (size_t)(op3))
#define vnmsub_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_i16m4_m((vint16m4_t)(op0), (int16_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnmsub_vx_i16m8(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_i16m8((vint16m8_t)(op0), (int16_t)(op1), (vint16m8_t)(op2), (size_t)(op3))
#define vnmsub_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_i16m8_m((vint16m8_t)(op0), (int16_t)(op1), (vint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vnmsub_vx_i16mf2(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_i16mf2((vint16mf2_t)(op0), (int16_t)(op1), (vint16mf2_t)(op2), (size_t)(op3))
#define vnmsub_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_i16mf2_m((vint16mf2_t)(op0), (int16_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnmsub_vx_i16mf4(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_i16mf4((vint16mf4_t)(op0), (int16_t)(op1), (vint16mf4_t)(op2), (size_t)(op3))
#define vnmsub_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_i16mf4_m((vint16mf4_t)(op0), (int16_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsub_vx_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_i32m1((vint32m1_t)(op0), (int32_t)(op1), (vint32m1_t)(op2), (size_t)(op3))
#define vnmsub_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_i32m1_m((vint32m1_t)(op0), (int32_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnmsub_vx_i32m2(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_i32m2((vint32m2_t)(op0), (int32_t)(op1), (vint32m2_t)(op2), (size_t)(op3))
#define vnmsub_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_i32m2_m((vint32m2_t)(op0), (int32_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnmsub_vx_i32m4(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_i32m4((vint32m4_t)(op0), (int32_t)(op1), (vint32m4_t)(op2), (size_t)(op3))
#define vnmsub_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_i32m4_m((vint32m4_t)(op0), (int32_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnmsub_vx_i32m8(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_i32m8((vint32m8_t)(op0), (int32_t)(op1), (vint32m8_t)(op2), (size_t)(op3))
#define vnmsub_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_i32m8_m((vint32m8_t)(op0), (int32_t)(op1), (vint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnmsub_vx_i32mf2(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_i32mf2((vint32mf2_t)(op0), (int32_t)(op1), (vint32mf2_t)(op2), (size_t)(op3))
#define vnmsub_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_i32mf2_m((vint32mf2_t)(op0), (int32_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsub_vx_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_i64m1((vint64m1_t)(op0), (int64_t)(op1), (vint64m1_t)(op2), (size_t)(op3))
#define vnmsub_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_i64m1_m((vint64m1_t)(op0), (int64_t)(op1), (vint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsub_vx_i64m2(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_i64m2((vint64m2_t)(op0), (int64_t)(op1), (vint64m2_t)(op2), (size_t)(op3))
#define vnmsub_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_i64m2_m((vint64m2_t)(op0), (int64_t)(op1), (vint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnmsub_vx_i64m4(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_i64m4((vint64m4_t)(op0), (int64_t)(op1), (vint64m4_t)(op2), (size_t)(op3))
#define vnmsub_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_i64m4_m((vint64m4_t)(op0), (int64_t)(op1), (vint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnmsub_vx_i64m8(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_i64m8((vint64m8_t)(op0), (int64_t)(op1), (vint64m8_t)(op2), (size_t)(op3))
#define vnmsub_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_i64m8_m((vint64m8_t)(op0), (int64_t)(op1), (vint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vle16ff_v_u16m1(op0, op1, op2) \
__builtin_rvv_vle16ff_v_u16m1((const uint16_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle16ff_v_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle16ff_v_u16m1_m((vuint16m1_t)(op0), (const uint16_t *)(op1), (size_t *)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vle16ff_v_u16m2(op0, op1, op2) \
__builtin_rvv_vle16ff_v_u16m2((const uint16_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle16ff_v_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle16ff_v_u16m2_m((vuint16m2_t)(op0), (const uint16_t *)(op1), (size_t *)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vle16ff_v_u16m4(op0, op1, op2) \
__builtin_rvv_vle16ff_v_u16m4((const uint16_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle16ff_v_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle16ff_v_u16m4_m((vuint16m4_t)(op0), (const uint16_t *)(op1), (size_t *)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vle16ff_v_u16m8(op0, op1, op2) \
__builtin_rvv_vle16ff_v_u16m8((const uint16_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle16ff_v_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle16ff_v_u16m8_m((vuint16m8_t)(op0), (const uint16_t *)(op1), (size_t *)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vle16ff_v_u16mf2(op0, op1, op2) \
__builtin_rvv_vle16ff_v_u16mf2((const uint16_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle16ff_v_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle16ff_v_u16mf2_m((vuint16mf2_t)(op0), (const uint16_t *)(op1), (size_t *)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vle16ff_v_u16mf4(op0, op1, op2) \
__builtin_rvv_vle16ff_v_u16mf4((const uint16_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle16ff_v_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle16ff_v_u16mf4_m((vuint16mf4_t)(op0), (const uint16_t *)(op1), (size_t *)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsub_vv_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_u8m1((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vnmsub_vv_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnmsub_vv_u8m2(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_u8m2((vuint8m2_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (size_t)(op3))
#define vnmsub_vv_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnmsub_vv_u8m4(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_u8m4((vuint8m4_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (size_t)(op3))
#define vnmsub_vv_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vnmsub_vv_u8m8(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_u8m8((vuint8m8_t)(op0), (vuint8m8_t)(op1), (vuint8m8_t)(op2), (size_t)(op3))
#define vnmsub_vv_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vnmsub_vv_u8mf2(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_u8mf2((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (size_t)(op3))
#define vnmsub_vv_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnmsub_vv_u8mf4(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_u8mf4((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (size_t)(op3))
#define vnmsub_vv_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnmsub_vv_u8mf8(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_u8mf8((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (size_t)(op3))
#define vnmsub_vv_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsub_vv_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_u16m1((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vnmsub_vv_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnmsub_vv_u16m2(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_u16m2((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (size_t)(op3))
#define vnmsub_vv_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnmsub_vv_u16m4(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_u16m4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (size_t)(op3))
#define vnmsub_vv_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnmsub_vv_u16m8(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_u16m8((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vuint16m8_t)(op2), (size_t)(op3))
#define vnmsub_vv_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vnmsub_vv_u16mf2(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_u16mf2((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (size_t)(op3))
#define vnmsub_vv_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnmsub_vv_u16mf4(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_u16mf4((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (size_t)(op3))
#define vnmsub_vv_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsub_vv_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_u32m1((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vnmsub_vv_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnmsub_vv_u32m2(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_u32m2((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (size_t)(op3))
#define vnmsub_vv_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnmsub_vv_u32m4(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_u32m4((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (size_t)(op3))
#define vnmsub_vv_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnmsub_vv_u32m8(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_u32m8((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vuint32m8_t)(op2), (size_t)(op3))
#define vnmsub_vv_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnmsub_vv_u32mf2(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_u32mf2((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (size_t)(op3))
#define vnmsub_vv_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsub_vv_u64m1(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_u64m1((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vnmsub_vv_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsub_vv_u64m2(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_u64m2((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vuint64m2_t)(op2), (size_t)(op3))
#define vnmsub_vv_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnmsub_vv_u64m4(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_u64m4((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vuint64m4_t)(op2), (size_t)(op3))
#define vnmsub_vv_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnmsub_vv_u64m8(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_u64m8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vuint64m8_t)(op2), (size_t)(op3))
#define vnmsub_vv_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnmsub_vx_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_u8m1((vuint8m1_t)(op0), (uint8_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vnmsub_vx_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_u8m1_m((vuint8m1_t)(op0), (uint8_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnmsub_vx_u8m2(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_u8m2((vuint8m2_t)(op0), (uint8_t)(op1), (vuint8m2_t)(op2), (size_t)(op3))
#define vnmsub_vx_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_u8m2_m((vuint8m2_t)(op0), (uint8_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnmsub_vx_u8m4(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_u8m4((vuint8m4_t)(op0), (uint8_t)(op1), (vuint8m4_t)(op2), (size_t)(op3))
#define vnmsub_vx_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_u8m4_m((vuint8m4_t)(op0), (uint8_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vnmsub_vx_u8m8(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_u8m8((vuint8m8_t)(op0), (uint8_t)(op1), (vuint8m8_t)(op2), (size_t)(op3))
#define vnmsub_vx_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_u8m8_m((vuint8m8_t)(op0), (uint8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vnmsub_vx_u8mf2(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_u8mf2((vuint8mf2_t)(op0), (uint8_t)(op1), (vuint8mf2_t)(op2), (size_t)(op3))
#define vnmsub_vx_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_u8mf2_m((vuint8mf2_t)(op0), (uint8_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnmsub_vx_u8mf4(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_u8mf4((vuint8mf4_t)(op0), (uint8_t)(op1), (vuint8mf4_t)(op2), (size_t)(op3))
#define vnmsub_vx_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_u8mf4_m((vuint8mf4_t)(op0), (uint8_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnmsub_vx_u8mf8(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_u8mf8((vuint8mf8_t)(op0), (uint8_t)(op1), (vuint8mf8_t)(op2), (size_t)(op3))
#define vnmsub_vx_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_u8mf8_m((vuint8mf8_t)(op0), (uint8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsub_vx_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_u16m1((vuint16m1_t)(op0), (uint16_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vnmsub_vx_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_u16m1_m((vuint16m1_t)(op0), (uint16_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnmsub_vx_u16m2(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_u16m2((vuint16m2_t)(op0), (uint16_t)(op1), (vuint16m2_t)(op2), (size_t)(op3))
#define vnmsub_vx_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_u16m2_m((vuint16m2_t)(op0), (uint16_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnmsub_vx_u16m4(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_u16m4((vuint16m4_t)(op0), (uint16_t)(op1), (vuint16m4_t)(op2), (size_t)(op3))
#define vnmsub_vx_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_u16m4_m((vuint16m4_t)(op0), (uint16_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnmsub_vx_u16m8(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_u16m8((vuint16m8_t)(op0), (uint16_t)(op1), (vuint16m8_t)(op2), (size_t)(op3))
#define vnmsub_vx_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_u16m8_m((vuint16m8_t)(op0), (uint16_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vnmsub_vx_u16mf2(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_u16mf2((vuint16mf2_t)(op0), (uint16_t)(op1), (vuint16mf2_t)(op2), (size_t)(op3))
#define vnmsub_vx_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_u16mf2_m((vuint16mf2_t)(op0), (uint16_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnmsub_vx_u16mf4(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_u16mf4((vuint16mf4_t)(op0), (uint16_t)(op1), (vuint16mf4_t)(op2), (size_t)(op3))
#define vnmsub_vx_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_u16mf4_m((vuint16mf4_t)(op0), (uint16_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsub_vx_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_u32m1((vuint32m1_t)(op0), (uint32_t)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vnmsub_vx_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_u32m1_m((vuint32m1_t)(op0), (uint32_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnmsub_vx_u32m2(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_u32m2((vuint32m2_t)(op0), (uint32_t)(op1), (vuint32m2_t)(op2), (size_t)(op3))
#define vnmsub_vx_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_u32m2_m((vuint32m2_t)(op0), (uint32_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnmsub_vx_u32m4(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_u32m4((vuint32m4_t)(op0), (uint32_t)(op1), (vuint32m4_t)(op2), (size_t)(op3))
#define vnmsub_vx_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_u32m4_m((vuint32m4_t)(op0), (uint32_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnmsub_vx_u32m8(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_u32m8((vuint32m8_t)(op0), (uint32_t)(op1), (vuint32m8_t)(op2), (size_t)(op3))
#define vnmsub_vx_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_u32m8_m((vuint32m8_t)(op0), (uint32_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnmsub_vx_u32mf2(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_u32mf2((vuint32mf2_t)(op0), (uint32_t)(op1), (vuint32mf2_t)(op2), (size_t)(op3))
#define vnmsub_vx_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_u32mf2_m((vuint32mf2_t)(op0), (uint32_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsub_vx_u64m1(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_u64m1((vuint64m1_t)(op0), (uint64_t)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vnmsub_vx_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_u64m1_m((vuint64m1_t)(op0), (uint64_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsub_vx_u64m2(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_u64m2((vuint64m2_t)(op0), (uint64_t)(op1), (vuint64m2_t)(op2), (size_t)(op3))
#define vnmsub_vx_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_u64m2_m((vuint64m2_t)(op0), (uint64_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnmsub_vx_u64m4(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_u64m4((vuint64m4_t)(op0), (uint64_t)(op1), (vuint64m4_t)(op2), (size_t)(op3))
#define vnmsub_vx_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_u64m4_m((vuint64m4_t)(op0), (uint64_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnmsub_vx_u64m8(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_u64m8((vuint64m8_t)(op0), (uint64_t)(op1), (vuint64m8_t)(op2), (size_t)(op3))
#define vnmsub_vx_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_u64m8_m((vuint64m8_t)(op0), (uint64_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmaccu_vv_u16mf4(op0, op1, op2, op3) \
__builtin_rvv_vwmaccu_vv_u16mf4((vuint16mf4_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (size_t)(op3))
#define vwmaccu_vv_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccu_vv_u16mf4_m((vuint16mf4_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmaccu_vv_u16mf2(op0, op1, op2, op3) \
__builtin_rvv_vwmaccu_vv_u16mf2((vuint16mf2_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (size_t)(op3))
#define vwmaccu_vv_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccu_vv_u16mf2_m((vuint16mf2_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmaccu_vv_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vwmaccu_vv_u16m1((vuint16m1_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (size_t)(op3))
#define vwmaccu_vv_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccu_vv_u16m1_m((vuint16m1_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmaccu_vv_u16m2(op0, op1, op2, op3) \
__builtin_rvv_vwmaccu_vv_u16m2((vuint16m2_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vwmaccu_vv_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccu_vv_u16m2_m((vuint16m2_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmaccu_vv_u16m4(op0, op1, op2, op3) \
__builtin_rvv_vwmaccu_vv_u16m4((vuint16m4_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (size_t)(op3))
#define vwmaccu_vv_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccu_vv_u16m4_m((vuint16m4_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwmaccu_vv_u16m8(op0, op1, op2, op3) \
__builtin_rvv_vwmaccu_vv_u16m8((vuint16m8_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (size_t)(op3))
#define vwmaccu_vv_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccu_vv_u16m8_m((vuint16m8_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vwmaccu_vv_u32mf2(op0, op1, op2, op3) \
__builtin_rvv_vwmaccu_vv_u32mf2((vuint32mf2_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (size_t)(op3))
#define vwmaccu_vv_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccu_vv_u32mf2_m((vuint32mf2_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmaccu_vv_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vwmaccu_vv_u32m1((vuint32m1_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (size_t)(op3))
#define vwmaccu_vv_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccu_vv_u32m1_m((vuint32m1_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmaccu_vv_u32m2(op0, op1, op2, op3) \
__builtin_rvv_vwmaccu_vv_u32m2((vuint32m2_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vwmaccu_vv_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccu_vv_u32m2_m((vuint32m2_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmaccu_vv_u32m4(op0, op1, op2, op3) \
__builtin_rvv_vwmaccu_vv_u32m4((vuint32m4_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (size_t)(op3))
#define vwmaccu_vv_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccu_vv_u32m4_m((vuint32m4_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmaccu_vv_u32m8(op0, op1, op2, op3) \
__builtin_rvv_vwmaccu_vv_u32m8((vuint32m8_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (size_t)(op3))
#define vwmaccu_vv_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccu_vv_u32m8_m((vuint32m8_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwmaccu_vv_u64m1(op0, op1, op2, op3) \
__builtin_rvv_vwmaccu_vv_u64m1((vuint64m1_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (size_t)(op3))
#define vwmaccu_vv_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccu_vv_u64m1_m((vuint64m1_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmaccu_vv_u64m2(op0, op1, op2, op3) \
__builtin_rvv_vwmaccu_vv_u64m2((vuint64m2_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vwmaccu_vv_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccu_vv_u64m2_m((vuint64m2_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmaccu_vv_u64m4(op0, op1, op2, op3) \
__builtin_rvv_vwmaccu_vv_u64m4((vuint64m4_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (size_t)(op3))
#define vwmaccu_vv_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccu_vv_u64m4_m((vuint64m4_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmaccu_vv_u64m8(op0, op1, op2, op3) \
__builtin_rvv_vwmaccu_vv_u64m8((vuint64m8_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (size_t)(op3))
#define vwmaccu_vv_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccu_vv_u64m8_m((vuint64m8_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmaccu_vx_u16mf4(op0, op1, op2, op3) \
__builtin_rvv_vwmaccu_vx_u16mf4((vuint16mf4_t)(op0), (uint8_t)(op1), (vuint8mf8_t)(op2), (size_t)(op3))
#define vwmaccu_vx_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccu_vx_u16mf4_m((vuint16mf4_t)(op0), (uint8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmaccu_vx_u16mf2(op0, op1, op2, op3) \
__builtin_rvv_vwmaccu_vx_u16mf2((vuint16mf2_t)(op0), (uint8_t)(op1), (vuint8mf4_t)(op2), (size_t)(op3))
#define vwmaccu_vx_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccu_vx_u16mf2_m((vuint16mf2_t)(op0), (uint8_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmaccu_vx_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vwmaccu_vx_u16m1((vuint16m1_t)(op0), (uint8_t)(op1), (vuint8mf2_t)(op2), (size_t)(op3))
#define vwmaccu_vx_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccu_vx_u16m1_m((vuint16m1_t)(op0), (uint8_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmaccu_vx_u16m2(op0, op1, op2, op3) \
__builtin_rvv_vwmaccu_vx_u16m2((vuint16m2_t)(op0), (uint8_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vwmaccu_vx_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccu_vx_u16m2_m((vuint16m2_t)(op0), (uint8_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmaccu_vx_u16m4(op0, op1, op2, op3) \
__builtin_rvv_vwmaccu_vx_u16m4((vuint16m4_t)(op0), (uint8_t)(op1), (vuint8m2_t)(op2), (size_t)(op3))
#define vwmaccu_vx_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccu_vx_u16m4_m((vuint16m4_t)(op0), (uint8_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwmaccu_vx_u16m8(op0, op1, op2, op3) \
__builtin_rvv_vwmaccu_vx_u16m8((vuint16m8_t)(op0), (uint8_t)(op1), (vuint8m4_t)(op2), (size_t)(op3))
#define vwmaccu_vx_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccu_vx_u16m8_m((vuint16m8_t)(op0), (uint8_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vwmaccu_vx_u32mf2(op0, op1, op2, op3) \
__builtin_rvv_vwmaccu_vx_u32mf2((vuint32mf2_t)(op0), (uint16_t)(op1), (vuint16mf4_t)(op2), (size_t)(op3))
#define vwmaccu_vx_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccu_vx_u32mf2_m((vuint32mf2_t)(op0), (uint16_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmaccu_vx_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vwmaccu_vx_u32m1((vuint32m1_t)(op0), (uint16_t)(op1), (vuint16mf2_t)(op2), (size_t)(op3))
#define vwmaccu_vx_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccu_vx_u32m1_m((vuint32m1_t)(op0), (uint16_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmaccu_vx_u32m2(op0, op1, op2, op3) \
__builtin_rvv_vwmaccu_vx_u32m2((vuint32m2_t)(op0), (uint16_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vwmaccu_vx_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccu_vx_u32m2_m((vuint32m2_t)(op0), (uint16_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmaccu_vx_u32m4(op0, op1, op2, op3) \
__builtin_rvv_vwmaccu_vx_u32m4((vuint32m4_t)(op0), (uint16_t)(op1), (vuint16m2_t)(op2), (size_t)(op3))
#define vwmaccu_vx_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccu_vx_u32m4_m((vuint32m4_t)(op0), (uint16_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmaccu_vx_u32m8(op0, op1, op2, op3) \
__builtin_rvv_vwmaccu_vx_u32m8((vuint32m8_t)(op0), (uint16_t)(op1), (vuint16m4_t)(op2), (size_t)(op3))
#define vwmaccu_vx_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccu_vx_u32m8_m((vuint32m8_t)(op0), (uint16_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwmaccu_vx_u64m1(op0, op1, op2, op3) \
__builtin_rvv_vwmaccu_vx_u64m1((vuint64m1_t)(op0), (uint32_t)(op1), (vuint32mf2_t)(op2), (size_t)(op3))
#define vwmaccu_vx_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccu_vx_u64m1_m((vuint64m1_t)(op0), (uint32_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmaccu_vx_u64m2(op0, op1, op2, op3) \
__builtin_rvv_vwmaccu_vx_u64m2((vuint64m2_t)(op0), (uint32_t)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vwmaccu_vx_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccu_vx_u64m2_m((vuint64m2_t)(op0), (uint32_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmaccu_vx_u64m4(op0, op1, op2, op3) \
__builtin_rvv_vwmaccu_vx_u64m4((vuint64m4_t)(op0), (uint32_t)(op1), (vuint32m2_t)(op2), (size_t)(op3))
#define vwmaccu_vx_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccu_vx_u64m4_m((vuint64m4_t)(op0), (uint32_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmaccu_vx_u64m8(op0, op1, op2, op3) \
__builtin_rvv_vwmaccu_vx_u64m8((vuint64m8_t)(op0), (uint32_t)(op1), (vuint32m4_t)(op2), (size_t)(op3))
#define vwmaccu_vx_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccu_vx_u64m8_m((vuint64m8_t)(op0), (uint32_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmacc_vv_i16mf4(op0, op1, op2, op3) \
__builtin_rvv_vwmacc_vv_i16mf4((vint16mf4_t)(op0), (vint8mf8_t)(op1), (vint8mf8_t)(op2), (size_t)(op3))
#define vwmacc_vv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmacc_vv_i16mf4_m((vint16mf4_t)(op0), (vint8mf8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmacc_vv_i16mf2(op0, op1, op2, op3) \
__builtin_rvv_vwmacc_vv_i16mf2((vint16mf2_t)(op0), (vint8mf4_t)(op1), (vint8mf4_t)(op2), (size_t)(op3))
#define vwmacc_vv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmacc_vv_i16mf2_m((vint16mf2_t)(op0), (vint8mf4_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmacc_vv_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vwmacc_vv_i16m1((vint16m1_t)(op0), (vint8mf2_t)(op1), (vint8mf2_t)(op2), (size_t)(op3))
#define vwmacc_vv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmacc_vv_i16m1_m((vint16m1_t)(op0), (vint8mf2_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmacc_vv_i16m2(op0, op1, op2, op3) \
__builtin_rvv_vwmacc_vv_i16m2((vint16m2_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (size_t)(op3))
#define vwmacc_vv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmacc_vv_i16m2_m((vint16m2_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmacc_vv_i16m4(op0, op1, op2, op3) \
__builtin_rvv_vwmacc_vv_i16m4((vint16m4_t)(op0), (vint8m2_t)(op1), (vint8m2_t)(op2), (size_t)(op3))
#define vwmacc_vv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmacc_vv_i16m4_m((vint16m4_t)(op0), (vint8m2_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwmacc_vv_i16m8(op0, op1, op2, op3) \
__builtin_rvv_vwmacc_vv_i16m8((vint16m8_t)(op0), (vint8m4_t)(op1), (vint8m4_t)(op2), (size_t)(op3))
#define vwmacc_vv_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmacc_vv_i16m8_m((vint16m8_t)(op0), (vint8m4_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vwmacc_vv_i32mf2(op0, op1, op2, op3) \
__builtin_rvv_vwmacc_vv_i32mf2((vint32mf2_t)(op0), (vint16mf4_t)(op1), (vint16mf4_t)(op2), (size_t)(op3))
#define vwmacc_vv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmacc_vv_i32mf2_m((vint32mf2_t)(op0), (vint16mf4_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmacc_vv_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vwmacc_vv_i32m1((vint32m1_t)(op0), (vint16mf2_t)(op1), (vint16mf2_t)(op2), (size_t)(op3))
#define vwmacc_vv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmacc_vv_i32m1_m((vint32m1_t)(op0), (vint16mf2_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmacc_vv_i32m2(op0, op1, op2, op3) \
__builtin_rvv_vwmacc_vv_i32m2((vint32m2_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vwmacc_vv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmacc_vv_i32m2_m((vint32m2_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmacc_vv_i32m4(op0, op1, op2, op3) \
__builtin_rvv_vwmacc_vv_i32m4((vint32m4_t)(op0), (vint16m2_t)(op1), (vint16m2_t)(op2), (size_t)(op3))
#define vwmacc_vv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmacc_vv_i32m4_m((vint32m4_t)(op0), (vint16m2_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmacc_vv_i32m8(op0, op1, op2, op3) \
__builtin_rvv_vwmacc_vv_i32m8((vint32m8_t)(op0), (vint16m4_t)(op1), (vint16m4_t)(op2), (size_t)(op3))
#define vwmacc_vv_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmacc_vv_i32m8_m((vint32m8_t)(op0), (vint16m4_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwmacc_vv_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vwmacc_vv_i64m1((vint64m1_t)(op0), (vint32mf2_t)(op1), (vint32mf2_t)(op2), (size_t)(op3))
#define vwmacc_vv_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmacc_vv_i64m1_m((vint64m1_t)(op0), (vint32mf2_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmacc_vv_i64m2(op0, op1, op2, op3) \
__builtin_rvv_vwmacc_vv_i64m2((vint64m2_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (size_t)(op3))
#define vwmacc_vv_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmacc_vv_i64m2_m((vint64m2_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmacc_vv_i64m4(op0, op1, op2, op3) \
__builtin_rvv_vwmacc_vv_i64m4((vint64m4_t)(op0), (vint32m2_t)(op1), (vint32m2_t)(op2), (size_t)(op3))
#define vwmacc_vv_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmacc_vv_i64m4_m((vint64m4_t)(op0), (vint32m2_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmacc_vv_i64m8(op0, op1, op2, op3) \
__builtin_rvv_vwmacc_vv_i64m8((vint64m8_t)(op0), (vint32m4_t)(op1), (vint32m4_t)(op2), (size_t)(op3))
#define vwmacc_vv_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmacc_vv_i64m8_m((vint64m8_t)(op0), (vint32m4_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmacc_vx_i16mf4(op0, op1, op2, op3) \
__builtin_rvv_vwmacc_vx_i16mf4((vint16mf4_t)(op0), (int8_t)(op1), (vint8mf8_t)(op2), (size_t)(op3))
#define vwmacc_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmacc_vx_i16mf4_m((vint16mf4_t)(op0), (int8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmacc_vx_i16mf2(op0, op1, op2, op3) \
__builtin_rvv_vwmacc_vx_i16mf2((vint16mf2_t)(op0), (int8_t)(op1), (vint8mf4_t)(op2), (size_t)(op3))
#define vwmacc_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmacc_vx_i16mf2_m((vint16mf2_t)(op0), (int8_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmacc_vx_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vwmacc_vx_i16m1((vint16m1_t)(op0), (int8_t)(op1), (vint8mf2_t)(op2), (size_t)(op3))
#define vwmacc_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmacc_vx_i16m1_m((vint16m1_t)(op0), (int8_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmacc_vx_i16m2(op0, op1, op2, op3) \
__builtin_rvv_vwmacc_vx_i16m2((vint16m2_t)(op0), (int8_t)(op1), (vint8m1_t)(op2), (size_t)(op3))
#define vwmacc_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmacc_vx_i16m2_m((vint16m2_t)(op0), (int8_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmacc_vx_i16m4(op0, op1, op2, op3) \
__builtin_rvv_vwmacc_vx_i16m4((vint16m4_t)(op0), (int8_t)(op1), (vint8m2_t)(op2), (size_t)(op3))
#define vwmacc_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmacc_vx_i16m4_m((vint16m4_t)(op0), (int8_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwmacc_vx_i16m8(op0, op1, op2, op3) \
__builtin_rvv_vwmacc_vx_i16m8((vint16m8_t)(op0), (int8_t)(op1), (vint8m4_t)(op2), (size_t)(op3))
#define vwmacc_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmacc_vx_i16m8_m((vint16m8_t)(op0), (int8_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vwmacc_vx_i32mf2(op0, op1, op2, op3) \
__builtin_rvv_vwmacc_vx_i32mf2((vint32mf2_t)(op0), (int16_t)(op1), (vint16mf4_t)(op2), (size_t)(op3))
#define vwmacc_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmacc_vx_i32mf2_m((vint32mf2_t)(op0), (int16_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmacc_vx_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vwmacc_vx_i32m1((vint32m1_t)(op0), (int16_t)(op1), (vint16mf2_t)(op2), (size_t)(op3))
#define vwmacc_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmacc_vx_i32m1_m((vint32m1_t)(op0), (int16_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmacc_vx_i32m2(op0, op1, op2, op3) \
__builtin_rvv_vwmacc_vx_i32m2((vint32m2_t)(op0), (int16_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vwmacc_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmacc_vx_i32m2_m((vint32m2_t)(op0), (int16_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmacc_vx_i32m4(op0, op1, op2, op3) \
__builtin_rvv_vwmacc_vx_i32m4((vint32m4_t)(op0), (int16_t)(op1), (vint16m2_t)(op2), (size_t)(op3))
#define vwmacc_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmacc_vx_i32m4_m((vint32m4_t)(op0), (int16_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmacc_vx_i32m8(op0, op1, op2, op3) \
__builtin_rvv_vwmacc_vx_i32m8((vint32m8_t)(op0), (int16_t)(op1), (vint16m4_t)(op2), (size_t)(op3))
#define vwmacc_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmacc_vx_i32m8_m((vint32m8_t)(op0), (int16_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwmacc_vx_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vwmacc_vx_i64m1((vint64m1_t)(op0), (int32_t)(op1), (vint32mf2_t)(op2), (size_t)(op3))
#define vwmacc_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmacc_vx_i64m1_m((vint64m1_t)(op0), (int32_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmacc_vx_i64m2(op0, op1, op2, op3) \
__builtin_rvv_vwmacc_vx_i64m2((vint64m2_t)(op0), (int32_t)(op1), (vint32m1_t)(op2), (size_t)(op3))
#define vwmacc_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmacc_vx_i64m2_m((vint64m2_t)(op0), (int32_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmacc_vx_i64m4(op0, op1, op2, op3) \
__builtin_rvv_vwmacc_vx_i64m4((vint64m4_t)(op0), (int32_t)(op1), (vint32m2_t)(op2), (size_t)(op3))
#define vwmacc_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmacc_vx_i64m4_m((vint64m4_t)(op0), (int32_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmacc_vx_i64m8(op0, op1, op2, op3) \
__builtin_rvv_vwmacc_vx_i64m8((vint64m8_t)(op0), (int32_t)(op1), (vint32m4_t)(op2), (size_t)(op3))
#define vwmacc_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmacc_vx_i64m8_m((vint64m8_t)(op0), (int32_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmaccsu_vv_i16mf4(op0, op1, op2, op3) \
__builtin_rvv_vwmaccsu_vv_i16mf4((vint16mf4_t)(op0), (vint8mf8_t)(op1), (vuint8mf8_t)(op2), (size_t)(op3))
#define vwmaccsu_vv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccsu_vv_i16mf4_m((vint16mf4_t)(op0), (vint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmaccsu_vv_i16mf2(op0, op1, op2, op3) \
__builtin_rvv_vwmaccsu_vv_i16mf2((vint16mf2_t)(op0), (vint8mf4_t)(op1), (vuint8mf4_t)(op2), (size_t)(op3))
#define vwmaccsu_vv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccsu_vv_i16mf2_m((vint16mf2_t)(op0), (vint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmaccsu_vv_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vwmaccsu_vv_i16m1((vint16m1_t)(op0), (vint8mf2_t)(op1), (vuint8mf2_t)(op2), (size_t)(op3))
#define vwmaccsu_vv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccsu_vv_i16m1_m((vint16m1_t)(op0), (vint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmaccsu_vv_i16m2(op0, op1, op2, op3) \
__builtin_rvv_vwmaccsu_vv_i16m2((vint16m2_t)(op0), (vint8m1_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vwmaccsu_vv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccsu_vv_i16m2_m((vint16m2_t)(op0), (vint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmaccsu_vv_i16m4(op0, op1, op2, op3) \
__builtin_rvv_vwmaccsu_vv_i16m4((vint16m4_t)(op0), (vint8m2_t)(op1), (vuint8m2_t)(op2), (size_t)(op3))
#define vwmaccsu_vv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccsu_vv_i16m4_m((vint16m4_t)(op0), (vint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwmaccsu_vv_i16m8(op0, op1, op2, op3) \
__builtin_rvv_vwmaccsu_vv_i16m8((vint16m8_t)(op0), (vint8m4_t)(op1), (vuint8m4_t)(op2), (size_t)(op3))
#define vwmaccsu_vv_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccsu_vv_i16m8_m((vint16m8_t)(op0), (vint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vwmaccsu_vv_i32mf2(op0, op1, op2, op3) \
__builtin_rvv_vwmaccsu_vv_i32mf2((vint32mf2_t)(op0), (vint16mf4_t)(op1), (vuint16mf4_t)(op2), (size_t)(op3))
#define vwmaccsu_vv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccsu_vv_i32mf2_m((vint32mf2_t)(op0), (vint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmaccsu_vv_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vwmaccsu_vv_i32m1((vint32m1_t)(op0), (vint16mf2_t)(op1), (vuint16mf2_t)(op2), (size_t)(op3))
#define vwmaccsu_vv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccsu_vv_i32m1_m((vint32m1_t)(op0), (vint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmaccsu_vv_i32m2(op0, op1, op2, op3) \
__builtin_rvv_vwmaccsu_vv_i32m2((vint32m2_t)(op0), (vint16m1_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vwmaccsu_vv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccsu_vv_i32m2_m((vint32m2_t)(op0), (vint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmaccsu_vv_i32m4(op0, op1, op2, op3) \
__builtin_rvv_vwmaccsu_vv_i32m4((vint32m4_t)(op0), (vint16m2_t)(op1), (vuint16m2_t)(op2), (size_t)(op3))
#define vwmaccsu_vv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccsu_vv_i32m4_m((vint32m4_t)(op0), (vint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmaccsu_vv_i32m8(op0, op1, op2, op3) \
__builtin_rvv_vwmaccsu_vv_i32m8((vint32m8_t)(op0), (vint16m4_t)(op1), (vuint16m4_t)(op2), (size_t)(op3))
#define vwmaccsu_vv_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccsu_vv_i32m8_m((vint32m8_t)(op0), (vint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwmaccsu_vv_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vwmaccsu_vv_i64m1((vint64m1_t)(op0), (vint32mf2_t)(op1), (vuint32mf2_t)(op2), (size_t)(op3))
#define vwmaccsu_vv_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccsu_vv_i64m1_m((vint64m1_t)(op0), (vint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmaccsu_vv_i64m2(op0, op1, op2, op3) \
__builtin_rvv_vwmaccsu_vv_i64m2((vint64m2_t)(op0), (vint32m1_t)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vwmaccsu_vv_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccsu_vv_i64m2_m((vint64m2_t)(op0), (vint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmaccsu_vv_i64m4(op0, op1, op2, op3) \
__builtin_rvv_vwmaccsu_vv_i64m4((vint64m4_t)(op0), (vint32m2_t)(op1), (vuint32m2_t)(op2), (size_t)(op3))
#define vwmaccsu_vv_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccsu_vv_i64m4_m((vint64m4_t)(op0), (vint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmaccsu_vv_i64m8(op0, op1, op2, op3) \
__builtin_rvv_vwmaccsu_vv_i64m8((vint64m8_t)(op0), (vint32m4_t)(op1), (vuint32m4_t)(op2), (size_t)(op3))
#define vwmaccsu_vv_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccsu_vv_i64m8_m((vint64m8_t)(op0), (vint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmaccsu_vx_i16mf4(op0, op1, op2, op3) \
__builtin_rvv_vwmaccsu_vx_i16mf4((vint16mf4_t)(op0), (int8_t)(op1), (vuint8mf8_t)(op2), (size_t)(op3))
#define vwmaccsu_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccsu_vx_i16mf4_m((vint16mf4_t)(op0), (int8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmaccsu_vx_i16mf2(op0, op1, op2, op3) \
__builtin_rvv_vwmaccsu_vx_i16mf2((vint16mf2_t)(op0), (int8_t)(op1), (vuint8mf4_t)(op2), (size_t)(op3))
#define vwmaccsu_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccsu_vx_i16mf2_m((vint16mf2_t)(op0), (int8_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmaccsu_vx_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vwmaccsu_vx_i16m1((vint16m1_t)(op0), (int8_t)(op1), (vuint8mf2_t)(op2), (size_t)(op3))
#define vwmaccsu_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccsu_vx_i16m1_m((vint16m1_t)(op0), (int8_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmaccsu_vx_i16m2(op0, op1, op2, op3) \
__builtin_rvv_vwmaccsu_vx_i16m2((vint16m2_t)(op0), (int8_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vwmaccsu_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccsu_vx_i16m2_m((vint16m2_t)(op0), (int8_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmaccsu_vx_i16m4(op0, op1, op2, op3) \
__builtin_rvv_vwmaccsu_vx_i16m4((vint16m4_t)(op0), (int8_t)(op1), (vuint8m2_t)(op2), (size_t)(op3))
#define vwmaccsu_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccsu_vx_i16m4_m((vint16m4_t)(op0), (int8_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwmaccsu_vx_i16m8(op0, op1, op2, op3) \
__builtin_rvv_vwmaccsu_vx_i16m8((vint16m8_t)(op0), (int8_t)(op1), (vuint8m4_t)(op2), (size_t)(op3))
#define vwmaccsu_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccsu_vx_i16m8_m((vint16m8_t)(op0), (int8_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vwmaccsu_vx_i32mf2(op0, op1, op2, op3) \
__builtin_rvv_vwmaccsu_vx_i32mf2((vint32mf2_t)(op0), (int16_t)(op1), (vuint16mf4_t)(op2), (size_t)(op3))
#define vwmaccsu_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccsu_vx_i32mf2_m((vint32mf2_t)(op0), (int16_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmaccsu_vx_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vwmaccsu_vx_i32m1((vint32m1_t)(op0), (int16_t)(op1), (vuint16mf2_t)(op2), (size_t)(op3))
#define vwmaccsu_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccsu_vx_i32m1_m((vint32m1_t)(op0), (int16_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmaccsu_vx_i32m2(op0, op1, op2, op3) \
__builtin_rvv_vwmaccsu_vx_i32m2((vint32m2_t)(op0), (int16_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vwmaccsu_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccsu_vx_i32m2_m((vint32m2_t)(op0), (int16_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmaccsu_vx_i32m4(op0, op1, op2, op3) \
__builtin_rvv_vwmaccsu_vx_i32m4((vint32m4_t)(op0), (int16_t)(op1), (vuint16m2_t)(op2), (size_t)(op3))
#define vwmaccsu_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccsu_vx_i32m4_m((vint32m4_t)(op0), (int16_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmaccsu_vx_i32m8(op0, op1, op2, op3) \
__builtin_rvv_vwmaccsu_vx_i32m8((vint32m8_t)(op0), (int16_t)(op1), (vuint16m4_t)(op2), (size_t)(op3))
#define vwmaccsu_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccsu_vx_i32m8_m((vint32m8_t)(op0), (int16_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwmaccsu_vx_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vwmaccsu_vx_i64m1((vint64m1_t)(op0), (int32_t)(op1), (vuint32mf2_t)(op2), (size_t)(op3))
#define vwmaccsu_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccsu_vx_i64m1_m((vint64m1_t)(op0), (int32_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmaccsu_vx_i64m2(op0, op1, op2, op3) \
__builtin_rvv_vwmaccsu_vx_i64m2((vint64m2_t)(op0), (int32_t)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vwmaccsu_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccsu_vx_i64m2_m((vint64m2_t)(op0), (int32_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmaccsu_vx_i64m4(op0, op1, op2, op3) \
__builtin_rvv_vwmaccsu_vx_i64m4((vint64m4_t)(op0), (int32_t)(op1), (vuint32m2_t)(op2), (size_t)(op3))
#define vwmaccsu_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccsu_vx_i64m4_m((vint64m4_t)(op0), (int32_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmaccsu_vx_i64m8(op0, op1, op2, op3) \
__builtin_rvv_vwmaccsu_vx_i64m8((vint64m8_t)(op0), (int32_t)(op1), (vuint32m4_t)(op2), (size_t)(op3))
#define vwmaccsu_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccsu_vx_i64m8_m((vint64m8_t)(op0), (int32_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmaccus_vx_i16mf4(op0, op1, op2, op3) \
__builtin_rvv_vwmaccus_vx_i16mf4((vint16mf4_t)(op0), (uint8_t)(op1), (vint8mf8_t)(op2), (size_t)(op3))
#define vwmaccus_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccus_vx_i16mf4_m((vint16mf4_t)(op0), (uint8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmaccus_vx_i16mf2(op0, op1, op2, op3) \
__builtin_rvv_vwmaccus_vx_i16mf2((vint16mf2_t)(op0), (uint8_t)(op1), (vint8mf4_t)(op2), (size_t)(op3))
#define vwmaccus_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccus_vx_i16mf2_m((vint16mf2_t)(op0), (uint8_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmaccus_vx_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vwmaccus_vx_i16m1((vint16m1_t)(op0), (uint8_t)(op1), (vint8mf2_t)(op2), (size_t)(op3))
#define vwmaccus_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccus_vx_i16m1_m((vint16m1_t)(op0), (uint8_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmaccus_vx_i16m2(op0, op1, op2, op3) \
__builtin_rvv_vwmaccus_vx_i16m2((vint16m2_t)(op0), (uint8_t)(op1), (vint8m1_t)(op2), (size_t)(op3))
#define vwmaccus_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccus_vx_i16m2_m((vint16m2_t)(op0), (uint8_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmaccus_vx_i16m4(op0, op1, op2, op3) \
__builtin_rvv_vwmaccus_vx_i16m4((vint16m4_t)(op0), (uint8_t)(op1), (vint8m2_t)(op2), (size_t)(op3))
#define vwmaccus_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccus_vx_i16m4_m((vint16m4_t)(op0), (uint8_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwmaccus_vx_i16m8(op0, op1, op2, op3) \
__builtin_rvv_vwmaccus_vx_i16m8((vint16m8_t)(op0), (uint8_t)(op1), (vint8m4_t)(op2), (size_t)(op3))
#define vwmaccus_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccus_vx_i16m8_m((vint16m8_t)(op0), (uint8_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vwmaccus_vx_i32mf2(op0, op1, op2, op3) \
__builtin_rvv_vwmaccus_vx_i32mf2((vint32mf2_t)(op0), (uint16_t)(op1), (vint16mf4_t)(op2), (size_t)(op3))
#define vwmaccus_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccus_vx_i32mf2_m((vint32mf2_t)(op0), (uint16_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmaccus_vx_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vwmaccus_vx_i32m1((vint32m1_t)(op0), (uint16_t)(op1), (vint16mf2_t)(op2), (size_t)(op3))
#define vwmaccus_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccus_vx_i32m1_m((vint32m1_t)(op0), (uint16_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmaccus_vx_i32m2(op0, op1, op2, op3) \
__builtin_rvv_vwmaccus_vx_i32m2((vint32m2_t)(op0), (uint16_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vwmaccus_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccus_vx_i32m2_m((vint32m2_t)(op0), (uint16_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmaccus_vx_i32m4(op0, op1, op2, op3) \
__builtin_rvv_vwmaccus_vx_i32m4((vint32m4_t)(op0), (uint16_t)(op1), (vint16m2_t)(op2), (size_t)(op3))
#define vwmaccus_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccus_vx_i32m4_m((vint32m4_t)(op0), (uint16_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmaccus_vx_i32m8(op0, op1, op2, op3) \
__builtin_rvv_vwmaccus_vx_i32m8((vint32m8_t)(op0), (uint16_t)(op1), (vint16m4_t)(op2), (size_t)(op3))
#define vwmaccus_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccus_vx_i32m8_m((vint32m8_t)(op0), (uint16_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwmaccus_vx_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vwmaccus_vx_i64m1((vint64m1_t)(op0), (uint32_t)(op1), (vint32mf2_t)(op2), (size_t)(op3))
#define vwmaccus_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccus_vx_i64m1_m((vint64m1_t)(op0), (uint32_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmaccus_vx_i64m2(op0, op1, op2, op3) \
__builtin_rvv_vwmaccus_vx_i64m2((vint64m2_t)(op0), (uint32_t)(op1), (vint32m1_t)(op2), (size_t)(op3))
#define vwmaccus_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccus_vx_i64m2_m((vint64m2_t)(op0), (uint32_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmaccus_vx_i64m4(op0, op1, op2, op3) \
__builtin_rvv_vwmaccus_vx_i64m4((vint64m4_t)(op0), (uint32_t)(op1), (vint32m2_t)(op2), (size_t)(op3))
#define vwmaccus_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccus_vx_i64m4_m((vint64m4_t)(op0), (uint32_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmaccus_vx_i64m8(op0, op1, op2, op3) \
__builtin_rvv_vwmaccus_vx_i64m8((vint64m8_t)(op0), (uint32_t)(op1), (vint32m4_t)(op2), (size_t)(op3))
#define vwmaccus_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccus_vx_i64m8_m((vint64m8_t)(op0), (uint32_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsaddu_vv_u8m1(op0, op1, op2) \
__builtin_rvv_vsaddu_vv_u8m1((vuint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vsaddu_vv_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vv_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsaddu_vv_u8m2(op0, op1, op2) \
__builtin_rvv_vsaddu_vv_u8m2((vuint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vsaddu_vv_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vv_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsaddu_vv_u8m4(op0, op1, op2) \
__builtin_rvv_vsaddu_vv_u8m4((vuint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vsaddu_vv_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vv_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsaddu_vv_u8m8(op0, op1, op2) \
__builtin_rvv_vsaddu_vv_u8m8((vuint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vsaddu_vv_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vv_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vsaddu_vv_u8mf2(op0, op1, op2) \
__builtin_rvv_vsaddu_vv_u8mf2((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vsaddu_vv_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vv_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsaddu_vv_u8mf4(op0, op1, op2) \
__builtin_rvv_vsaddu_vv_u8mf4((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vsaddu_vv_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vv_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsaddu_vv_u8mf8(op0, op1, op2) \
__builtin_rvv_vsaddu_vv_u8mf8((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vsaddu_vv_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vv_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsaddu_vv_u16m1(op0, op1, op2) \
__builtin_rvv_vsaddu_vv_u16m1((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vsaddu_vv_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vv_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsaddu_vv_u16m2(op0, op1, op2) \
__builtin_rvv_vsaddu_vv_u16m2((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vsaddu_vv_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vv_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsaddu_vv_u16m4(op0, op1, op2) \
__builtin_rvv_vsaddu_vv_u16m4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vsaddu_vv_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vv_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsaddu_vv_u16m8(op0, op1, op2) \
__builtin_rvv_vsaddu_vv_u16m8((vuint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vsaddu_vv_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vv_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsaddu_vv_u16mf2(op0, op1, op2) \
__builtin_rvv_vsaddu_vv_u16mf2((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vsaddu_vv_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vv_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsaddu_vv_u16mf4(op0, op1, op2) \
__builtin_rvv_vsaddu_vv_u16mf4((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vsaddu_vv_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vv_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsaddu_vv_u32m1(op0, op1, op2) \
__builtin_rvv_vsaddu_vv_u32m1((vuint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vsaddu_vv_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vv_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsaddu_vv_u32m2(op0, op1, op2) \
__builtin_rvv_vsaddu_vv_u32m2((vuint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vsaddu_vv_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vv_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsaddu_vv_u32m4(op0, op1, op2) \
__builtin_rvv_vsaddu_vv_u32m4((vuint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vsaddu_vv_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vv_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsaddu_vv_u32m8(op0, op1, op2) \
__builtin_rvv_vsaddu_vv_u32m8((vuint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vsaddu_vv_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vv_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsaddu_vv_u32mf2(op0, op1, op2) \
__builtin_rvv_vsaddu_vv_u32mf2((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vsaddu_vv_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vv_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsaddu_vv_u64m1(op0, op1, op2) \
__builtin_rvv_vsaddu_vv_u64m1((vuint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vsaddu_vv_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vv_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsaddu_vv_u64m2(op0, op1, op2) \
__builtin_rvv_vsaddu_vv_u64m2((vuint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vsaddu_vv_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vv_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsaddu_vv_u64m4(op0, op1, op2) \
__builtin_rvv_vsaddu_vv_u64m4((vuint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vsaddu_vv_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vv_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsaddu_vv_u64m8(op0, op1, op2) \
__builtin_rvv_vsaddu_vv_u64m8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vsaddu_vv_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vv_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vle32ff_v_i32m1(op0, op1, op2) \
__builtin_rvv_vle32ff_v_i32m1((const int32_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle32ff_v_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle32ff_v_i32m1_m((vint32m1_t)(op0), (const int32_t *)(op1), (size_t *)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vle32ff_v_i32m2(op0, op1, op2) \
__builtin_rvv_vle32ff_v_i32m2((const int32_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle32ff_v_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle32ff_v_i32m2_m((vint32m2_t)(op0), (const int32_t *)(op1), (size_t *)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vle32ff_v_i32m4(op0, op1, op2) \
__builtin_rvv_vle32ff_v_i32m4((const int32_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle32ff_v_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle32ff_v_i32m4_m((vint32m4_t)(op0), (const int32_t *)(op1), (size_t *)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vle32ff_v_i32m8(op0, op1, op2) \
__builtin_rvv_vle32ff_v_i32m8((const int32_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle32ff_v_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle32ff_v_i32m8_m((vint32m8_t)(op0), (const int32_t *)(op1), (size_t *)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vle32ff_v_i32mf2(op0, op1, op2) \
__builtin_rvv_vle32ff_v_i32mf2((const int32_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle32ff_v_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle32ff_v_i32mf2_m((vint32mf2_t)(op0), (const int32_t *)(op1), (size_t *)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsaddu_vx_u8m1(op0, op1, op2) \
__builtin_rvv_vsaddu_vx_u8m1((vuint8m1_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vsaddu_vx_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vx_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (uint8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsaddu_vx_u8m2(op0, op1, op2) \
__builtin_rvv_vsaddu_vx_u8m2((vuint8m2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vsaddu_vx_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vx_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (uint8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsaddu_vx_u8m4(op0, op1, op2) \
__builtin_rvv_vsaddu_vx_u8m4((vuint8m4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vsaddu_vx_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vx_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (uint8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsaddu_vx_u8m8(op0, op1, op2) \
__builtin_rvv_vsaddu_vx_u8m8((vuint8m8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vsaddu_vx_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vx_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (uint8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vsaddu_vx_u8mf2(op0, op1, op2) \
__builtin_rvv_vsaddu_vx_u8mf2((vuint8mf2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vsaddu_vx_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vx_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (uint8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsaddu_vx_u8mf4(op0, op1, op2) \
__builtin_rvv_vsaddu_vx_u8mf4((vuint8mf4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vsaddu_vx_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vx_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (uint8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsaddu_vx_u8mf8(op0, op1, op2) \
__builtin_rvv_vsaddu_vx_u8mf8((vuint8mf8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vsaddu_vx_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vx_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (uint8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsaddu_vx_u16m1(op0, op1, op2) \
__builtin_rvv_vsaddu_vx_u16m1((vuint16m1_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vsaddu_vx_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vx_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (uint16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsaddu_vx_u16m2(op0, op1, op2) \
__builtin_rvv_vsaddu_vx_u16m2((vuint16m2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vsaddu_vx_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vx_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (uint16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsaddu_vx_u16m4(op0, op1, op2) \
__builtin_rvv_vsaddu_vx_u16m4((vuint16m4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vsaddu_vx_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vx_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (uint16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsaddu_vx_u16m8(op0, op1, op2) \
__builtin_rvv_vsaddu_vx_u16m8((vuint16m8_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vsaddu_vx_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vx_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (uint16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsaddu_vx_u16mf2(op0, op1, op2) \
__builtin_rvv_vsaddu_vx_u16mf2((vuint16mf2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vsaddu_vx_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vx_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (uint16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsaddu_vx_u16mf4(op0, op1, op2) \
__builtin_rvv_vsaddu_vx_u16mf4((vuint16mf4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vsaddu_vx_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vx_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (uint16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsaddu_vx_u32m1(op0, op1, op2) \
__builtin_rvv_vsaddu_vx_u32m1((vuint32m1_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vsaddu_vx_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vx_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (uint32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsaddu_vx_u32m2(op0, op1, op2) \
__builtin_rvv_vsaddu_vx_u32m2((vuint32m2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vsaddu_vx_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vx_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (uint32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsaddu_vx_u32m4(op0, op1, op2) \
__builtin_rvv_vsaddu_vx_u32m4((vuint32m4_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vsaddu_vx_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vx_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (uint32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsaddu_vx_u32m8(op0, op1, op2) \
__builtin_rvv_vsaddu_vx_u32m8((vuint32m8_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vsaddu_vx_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vx_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (uint32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsaddu_vx_u32mf2(op0, op1, op2) \
__builtin_rvv_vsaddu_vx_u32mf2((vuint32mf2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vsaddu_vx_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vx_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (uint32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsaddu_vx_u64m1(op0, op1, op2) \
__builtin_rvv_vsaddu_vx_u64m1((vuint64m1_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vsaddu_vx_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vx_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (uint64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsaddu_vx_u64m2(op0, op1, op2) \
__builtin_rvv_vsaddu_vx_u64m2((vuint64m2_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vsaddu_vx_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vx_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (uint64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsaddu_vx_u64m4(op0, op1, op2) \
__builtin_rvv_vsaddu_vx_u64m4((vuint64m4_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vsaddu_vx_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vx_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (uint64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsaddu_vx_u64m8(op0, op1, op2) \
__builtin_rvv_vsaddu_vx_u64m8((vuint64m8_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vsaddu_vx_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vx_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (uint64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsadd_vv_i8m1(op0, op1, op2) \
__builtin_rvv_vsadd_vv_i8m1((vint8m1_t)(op0), (vint8m1_t)(op1), (size_t)(op2))
#define vsadd_vv_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vv_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsadd_vv_i8m2(op0, op1, op2) \
__builtin_rvv_vsadd_vv_i8m2((vint8m2_t)(op0), (vint8m2_t)(op1), (size_t)(op2))
#define vsadd_vv_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vv_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsadd_vv_i8m4(op0, op1, op2) \
__builtin_rvv_vsadd_vv_i8m4((vint8m4_t)(op0), (vint8m4_t)(op1), (size_t)(op2))
#define vsadd_vv_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vv_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsadd_vv_i8m8(op0, op1, op2) \
__builtin_rvv_vsadd_vv_i8m8((vint8m8_t)(op0), (vint8m8_t)(op1), (size_t)(op2))
#define vsadd_vv_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vv_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (vint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vsadd_vv_i8mf2(op0, op1, op2) \
__builtin_rvv_vsadd_vv_i8mf2((vint8mf2_t)(op0), (vint8mf2_t)(op1), (size_t)(op2))
#define vsadd_vv_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vv_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsadd_vv_i8mf4(op0, op1, op2) \
__builtin_rvv_vsadd_vv_i8mf4((vint8mf4_t)(op0), (vint8mf4_t)(op1), (size_t)(op2))
#define vsadd_vv_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vv_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsadd_vv_i8mf8(op0, op1, op2) \
__builtin_rvv_vsadd_vv_i8mf8((vint8mf8_t)(op0), (vint8mf8_t)(op1), (size_t)(op2))
#define vsadd_vv_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vv_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsadd_vv_i16m1(op0, op1, op2) \
__builtin_rvv_vsadd_vv_i16m1((vint16m1_t)(op0), (vint16m1_t)(op1), (size_t)(op2))
#define vsadd_vv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vv_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsadd_vv_i16m2(op0, op1, op2) \
__builtin_rvv_vsadd_vv_i16m2((vint16m2_t)(op0), (vint16m2_t)(op1), (size_t)(op2))
#define vsadd_vv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vv_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsadd_vv_i16m4(op0, op1, op2) \
__builtin_rvv_vsadd_vv_i16m4((vint16m4_t)(op0), (vint16m4_t)(op1), (size_t)(op2))
#define vsadd_vv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vv_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsadd_vv_i16m8(op0, op1, op2) \
__builtin_rvv_vsadd_vv_i16m8((vint16m8_t)(op0), (vint16m8_t)(op1), (size_t)(op2))
#define vsadd_vv_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vv_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (vint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsadd_vv_i16mf2(op0, op1, op2) \
__builtin_rvv_vsadd_vv_i16mf2((vint16mf2_t)(op0), (vint16mf2_t)(op1), (size_t)(op2))
#define vsadd_vv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vv_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsadd_vv_i16mf4(op0, op1, op2) \
__builtin_rvv_vsadd_vv_i16mf4((vint16mf4_t)(op0), (vint16mf4_t)(op1), (size_t)(op2))
#define vsadd_vv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vv_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsadd_vv_i32m1(op0, op1, op2) \
__builtin_rvv_vsadd_vv_i32m1((vint32m1_t)(op0), (vint32m1_t)(op1), (size_t)(op2))
#define vsadd_vv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vv_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsadd_vv_i32m2(op0, op1, op2) \
__builtin_rvv_vsadd_vv_i32m2((vint32m2_t)(op0), (vint32m2_t)(op1), (size_t)(op2))
#define vsadd_vv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vv_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsadd_vv_i32m4(op0, op1, op2) \
__builtin_rvv_vsadd_vv_i32m4((vint32m4_t)(op0), (vint32m4_t)(op1), (size_t)(op2))
#define vsadd_vv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vv_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsadd_vv_i32m8(op0, op1, op2) \
__builtin_rvv_vsadd_vv_i32m8((vint32m8_t)(op0), (vint32m8_t)(op1), (size_t)(op2))
#define vsadd_vv_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vv_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (vint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsadd_vv_i32mf2(op0, op1, op2) \
__builtin_rvv_vsadd_vv_i32mf2((vint32mf2_t)(op0), (vint32mf2_t)(op1), (size_t)(op2))
#define vsadd_vv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vv_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsadd_vv_i64m1(op0, op1, op2) \
__builtin_rvv_vsadd_vv_i64m1((vint64m1_t)(op0), (vint64m1_t)(op1), (size_t)(op2))
#define vsadd_vv_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vv_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsadd_vv_i64m2(op0, op1, op2) \
__builtin_rvv_vsadd_vv_i64m2((vint64m2_t)(op0), (vint64m2_t)(op1), (size_t)(op2))
#define vsadd_vv_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vv_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (vint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsadd_vv_i64m4(op0, op1, op2) \
__builtin_rvv_vsadd_vv_i64m4((vint64m4_t)(op0), (vint64m4_t)(op1), (size_t)(op2))
#define vsadd_vv_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vv_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (vint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsadd_vv_i64m8(op0, op1, op2) \
__builtin_rvv_vsadd_vv_i64m8((vint64m8_t)(op0), (vint64m8_t)(op1), (size_t)(op2))
#define vsadd_vv_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vv_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (vint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsadd_vx_i8m1(op0, op1, op2) \
__builtin_rvv_vsadd_vx_i8m1((vint8m1_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vsadd_vx_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vx_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (int8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsadd_vx_i8m2(op0, op1, op2) \
__builtin_rvv_vsadd_vx_i8m2((vint8m2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vsadd_vx_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vx_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (int8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsadd_vx_i8m4(op0, op1, op2) \
__builtin_rvv_vsadd_vx_i8m4((vint8m4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vsadd_vx_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vx_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (int8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsadd_vx_i8m8(op0, op1, op2) \
__builtin_rvv_vsadd_vx_i8m8((vint8m8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vsadd_vx_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vx_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (int8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vsadd_vx_i8mf2(op0, op1, op2) \
__builtin_rvv_vsadd_vx_i8mf2((vint8mf2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vsadd_vx_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vx_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (int8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsadd_vx_i8mf4(op0, op1, op2) \
__builtin_rvv_vsadd_vx_i8mf4((vint8mf4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vsadd_vx_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vx_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (int8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsadd_vx_i8mf8(op0, op1, op2) \
__builtin_rvv_vsadd_vx_i8mf8((vint8mf8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vsadd_vx_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vx_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (int8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsadd_vx_i16m1(op0, op1, op2) \
__builtin_rvv_vsadd_vx_i16m1((vint16m1_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vsadd_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vx_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (int16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsadd_vx_i16m2(op0, op1, op2) \
__builtin_rvv_vsadd_vx_i16m2((vint16m2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vsadd_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vx_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (int16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsadd_vx_i16m4(op0, op1, op2) \
__builtin_rvv_vsadd_vx_i16m4((vint16m4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vsadd_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vx_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (int16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsadd_vx_i16m8(op0, op1, op2) \
__builtin_rvv_vsadd_vx_i16m8((vint16m8_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vsadd_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vx_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (int16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsadd_vx_i16mf2(op0, op1, op2) \
__builtin_rvv_vsadd_vx_i16mf2((vint16mf2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vsadd_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vx_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (int16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsadd_vx_i16mf4(op0, op1, op2) \
__builtin_rvv_vsadd_vx_i16mf4((vint16mf4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vsadd_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vx_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (int16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsadd_vx_i32m1(op0, op1, op2) \
__builtin_rvv_vsadd_vx_i32m1((vint32m1_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vsadd_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vx_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (int32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsadd_vx_i32m2(op0, op1, op2) \
__builtin_rvv_vsadd_vx_i32m2((vint32m2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vsadd_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vx_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (int32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsadd_vx_i32m4(op0, op1, op2) \
__builtin_rvv_vsadd_vx_i32m4((vint32m4_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vsadd_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vx_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (int32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsadd_vx_i32m8(op0, op1, op2) \
__builtin_rvv_vsadd_vx_i32m8((vint32m8_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vsadd_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vx_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (int32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsadd_vx_i32mf2(op0, op1, op2) \
__builtin_rvv_vsadd_vx_i32mf2((vint32mf2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vsadd_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vx_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (int32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsadd_vx_i64m1(op0, op1, op2) \
__builtin_rvv_vsadd_vx_i64m1((vint64m1_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vsadd_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vx_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (int64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsadd_vx_i64m2(op0, op1, op2) \
__builtin_rvv_vsadd_vx_i64m2((vint64m2_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vsadd_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vx_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (int64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsadd_vx_i64m4(op0, op1, op2) \
__builtin_rvv_vsadd_vx_i64m4((vint64m4_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vsadd_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vx_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (int64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsadd_vx_i64m8(op0, op1, op2) \
__builtin_rvv_vsadd_vx_i64m8((vint64m8_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vsadd_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vx_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (int64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vssubu_vv_u8m1(op0, op1, op2) \
__builtin_rvv_vssubu_vv_u8m1((vuint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vssubu_vv_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vv_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vssubu_vv_u8m2(op0, op1, op2) \
__builtin_rvv_vssubu_vv_u8m2((vuint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vssubu_vv_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vv_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vssubu_vv_u8m4(op0, op1, op2) \
__builtin_rvv_vssubu_vv_u8m4((vuint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vssubu_vv_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vv_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vssubu_vv_u8m8(op0, op1, op2) \
__builtin_rvv_vssubu_vv_u8m8((vuint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vssubu_vv_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vv_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vssubu_vv_u8mf2(op0, op1, op2) \
__builtin_rvv_vssubu_vv_u8mf2((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vssubu_vv_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vv_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vssubu_vv_u8mf4(op0, op1, op2) \
__builtin_rvv_vssubu_vv_u8mf4((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vssubu_vv_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vv_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vssubu_vv_u8mf8(op0, op1, op2) \
__builtin_rvv_vssubu_vv_u8mf8((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vssubu_vv_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vv_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssubu_vv_u16m1(op0, op1, op2) \
__builtin_rvv_vssubu_vv_u16m1((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vssubu_vv_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vv_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vssubu_vv_u16m2(op0, op1, op2) \
__builtin_rvv_vssubu_vv_u16m2((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vssubu_vv_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vv_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vssubu_vv_u16m4(op0, op1, op2) \
__builtin_rvv_vssubu_vv_u16m4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vssubu_vv_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vv_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vssubu_vv_u16m8(op0, op1, op2) \
__builtin_rvv_vssubu_vv_u16m8((vuint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vssubu_vv_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vv_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vssubu_vv_u16mf2(op0, op1, op2) \
__builtin_rvv_vssubu_vv_u16mf2((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vssubu_vv_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vv_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vssubu_vv_u16mf4(op0, op1, op2) \
__builtin_rvv_vssubu_vv_u16mf4((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vssubu_vv_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vv_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssubu_vv_u32m1(op0, op1, op2) \
__builtin_rvv_vssubu_vv_u32m1((vuint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vssubu_vv_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vv_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vssubu_vv_u32m2(op0, op1, op2) \
__builtin_rvv_vssubu_vv_u32m2((vuint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vssubu_vv_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vv_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vssubu_vv_u32m4(op0, op1, op2) \
__builtin_rvv_vssubu_vv_u32m4((vuint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vssubu_vv_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vv_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vssubu_vv_u32m8(op0, op1, op2) \
__builtin_rvv_vssubu_vv_u32m8((vuint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vssubu_vv_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vv_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vssubu_vv_u32mf2(op0, op1, op2) \
__builtin_rvv_vssubu_vv_u32mf2((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vssubu_vv_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vv_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssubu_vv_u64m1(op0, op1, op2) \
__builtin_rvv_vssubu_vv_u64m1((vuint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vssubu_vv_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vv_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssubu_vv_u64m2(op0, op1, op2) \
__builtin_rvv_vssubu_vv_u64m2((vuint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vssubu_vv_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vv_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vssubu_vv_u64m4(op0, op1, op2) \
__builtin_rvv_vssubu_vv_u64m4((vuint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vssubu_vv_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vv_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vssubu_vv_u64m8(op0, op1, op2) \
__builtin_rvv_vssubu_vv_u64m8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vssubu_vv_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vv_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vssubu_vx_u8m1(op0, op1, op2) \
__builtin_rvv_vssubu_vx_u8m1((vuint8m1_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vssubu_vx_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vx_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (uint8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vssubu_vx_u8m2(op0, op1, op2) \
__builtin_rvv_vssubu_vx_u8m2((vuint8m2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vssubu_vx_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vx_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (uint8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vssubu_vx_u8m4(op0, op1, op2) \
__builtin_rvv_vssubu_vx_u8m4((vuint8m4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vssubu_vx_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vx_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (uint8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vssubu_vx_u8m8(op0, op1, op2) \
__builtin_rvv_vssubu_vx_u8m8((vuint8m8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vssubu_vx_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vx_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (uint8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vssubu_vx_u8mf2(op0, op1, op2) \
__builtin_rvv_vssubu_vx_u8mf2((vuint8mf2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vssubu_vx_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vx_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (uint8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vssubu_vx_u8mf4(op0, op1, op2) \
__builtin_rvv_vssubu_vx_u8mf4((vuint8mf4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vssubu_vx_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vx_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (uint8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vssubu_vx_u8mf8(op0, op1, op2) \
__builtin_rvv_vssubu_vx_u8mf8((vuint8mf8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vssubu_vx_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vx_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (uint8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssubu_vx_u16m1(op0, op1, op2) \
__builtin_rvv_vssubu_vx_u16m1((vuint16m1_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vssubu_vx_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vx_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (uint16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vssubu_vx_u16m2(op0, op1, op2) \
__builtin_rvv_vssubu_vx_u16m2((vuint16m2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vssubu_vx_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vx_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (uint16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vssubu_vx_u16m4(op0, op1, op2) \
__builtin_rvv_vssubu_vx_u16m4((vuint16m4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vssubu_vx_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vx_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (uint16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vssubu_vx_u16m8(op0, op1, op2) \
__builtin_rvv_vssubu_vx_u16m8((vuint16m8_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vssubu_vx_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vx_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (uint16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vssubu_vx_u16mf2(op0, op1, op2) \
__builtin_rvv_vssubu_vx_u16mf2((vuint16mf2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vssubu_vx_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vx_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (uint16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vssubu_vx_u16mf4(op0, op1, op2) \
__builtin_rvv_vssubu_vx_u16mf4((vuint16mf4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vssubu_vx_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vx_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (uint16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssubu_vx_u32m1(op0, op1, op2) \
__builtin_rvv_vssubu_vx_u32m1((vuint32m1_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vssubu_vx_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vx_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (uint32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vssubu_vx_u32m2(op0, op1, op2) \
__builtin_rvv_vssubu_vx_u32m2((vuint32m2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vssubu_vx_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vx_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (uint32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vssubu_vx_u32m4(op0, op1, op2) \
__builtin_rvv_vssubu_vx_u32m4((vuint32m4_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vssubu_vx_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vx_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (uint32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vssubu_vx_u32m8(op0, op1, op2) \
__builtin_rvv_vssubu_vx_u32m8((vuint32m8_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vssubu_vx_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vx_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (uint32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vssubu_vx_u32mf2(op0, op1, op2) \
__builtin_rvv_vssubu_vx_u32mf2((vuint32mf2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vssubu_vx_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vx_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (uint32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssubu_vx_u64m1(op0, op1, op2) \
__builtin_rvv_vssubu_vx_u64m1((vuint64m1_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vssubu_vx_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vx_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (uint64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssubu_vx_u64m2(op0, op1, op2) \
__builtin_rvv_vssubu_vx_u64m2((vuint64m2_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vssubu_vx_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vx_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (uint64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vssubu_vx_u64m4(op0, op1, op2) \
__builtin_rvv_vssubu_vx_u64m4((vuint64m4_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vssubu_vx_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vx_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (uint64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vssubu_vx_u64m8(op0, op1, op2) \
__builtin_rvv_vssubu_vx_u64m8((vuint64m8_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vssubu_vx_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vx_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (uint64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vssub_vv_i8m1(op0, op1, op2) \
__builtin_rvv_vssub_vv_i8m1((vint8m1_t)(op0), (vint8m1_t)(op1), (size_t)(op2))
#define vssub_vv_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vv_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vssub_vv_i8m2(op0, op1, op2) \
__builtin_rvv_vssub_vv_i8m2((vint8m2_t)(op0), (vint8m2_t)(op1), (size_t)(op2))
#define vssub_vv_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vv_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vssub_vv_i8m4(op0, op1, op2) \
__builtin_rvv_vssub_vv_i8m4((vint8m4_t)(op0), (vint8m4_t)(op1), (size_t)(op2))
#define vssub_vv_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vv_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vssub_vv_i8m8(op0, op1, op2) \
__builtin_rvv_vssub_vv_i8m8((vint8m8_t)(op0), (vint8m8_t)(op1), (size_t)(op2))
#define vssub_vv_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vv_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (vint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vssub_vv_i8mf2(op0, op1, op2) \
__builtin_rvv_vssub_vv_i8mf2((vint8mf2_t)(op0), (vint8mf2_t)(op1), (size_t)(op2))
#define vssub_vv_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vv_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vssub_vv_i8mf4(op0, op1, op2) \
__builtin_rvv_vssub_vv_i8mf4((vint8mf4_t)(op0), (vint8mf4_t)(op1), (size_t)(op2))
#define vssub_vv_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vv_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vssub_vv_i8mf8(op0, op1, op2) \
__builtin_rvv_vssub_vv_i8mf8((vint8mf8_t)(op0), (vint8mf8_t)(op1), (size_t)(op2))
#define vssub_vv_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vv_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssub_vv_i16m1(op0, op1, op2) \
__builtin_rvv_vssub_vv_i16m1((vint16m1_t)(op0), (vint16m1_t)(op1), (size_t)(op2))
#define vssub_vv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vv_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vssub_vv_i16m2(op0, op1, op2) \
__builtin_rvv_vssub_vv_i16m2((vint16m2_t)(op0), (vint16m2_t)(op1), (size_t)(op2))
#define vssub_vv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vv_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vssub_vv_i16m4(op0, op1, op2) \
__builtin_rvv_vssub_vv_i16m4((vint16m4_t)(op0), (vint16m4_t)(op1), (size_t)(op2))
#define vssub_vv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vv_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vssub_vv_i16m8(op0, op1, op2) \
__builtin_rvv_vssub_vv_i16m8((vint16m8_t)(op0), (vint16m8_t)(op1), (size_t)(op2))
#define vssub_vv_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vv_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (vint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vssub_vv_i16mf2(op0, op1, op2) \
__builtin_rvv_vssub_vv_i16mf2((vint16mf2_t)(op0), (vint16mf2_t)(op1), (size_t)(op2))
#define vssub_vv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vv_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vssub_vv_i16mf4(op0, op1, op2) \
__builtin_rvv_vssub_vv_i16mf4((vint16mf4_t)(op0), (vint16mf4_t)(op1), (size_t)(op2))
#define vssub_vv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vv_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssub_vv_i32m1(op0, op1, op2) \
__builtin_rvv_vssub_vv_i32m1((vint32m1_t)(op0), (vint32m1_t)(op1), (size_t)(op2))
#define vssub_vv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vv_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vssub_vv_i32m2(op0, op1, op2) \
__builtin_rvv_vssub_vv_i32m2((vint32m2_t)(op0), (vint32m2_t)(op1), (size_t)(op2))
#define vssub_vv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vv_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vssub_vv_i32m4(op0, op1, op2) \
__builtin_rvv_vssub_vv_i32m4((vint32m4_t)(op0), (vint32m4_t)(op1), (size_t)(op2))
#define vssub_vv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vv_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vssub_vv_i32m8(op0, op1, op2) \
__builtin_rvv_vssub_vv_i32m8((vint32m8_t)(op0), (vint32m8_t)(op1), (size_t)(op2))
#define vssub_vv_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vv_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (vint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vssub_vv_i32mf2(op0, op1, op2) \
__builtin_rvv_vssub_vv_i32mf2((vint32mf2_t)(op0), (vint32mf2_t)(op1), (size_t)(op2))
#define vssub_vv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vv_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssub_vv_i64m1(op0, op1, op2) \
__builtin_rvv_vssub_vv_i64m1((vint64m1_t)(op0), (vint64m1_t)(op1), (size_t)(op2))
#define vssub_vv_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vv_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssub_vv_i64m2(op0, op1, op2) \
__builtin_rvv_vssub_vv_i64m2((vint64m2_t)(op0), (vint64m2_t)(op1), (size_t)(op2))
#define vssub_vv_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vv_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (vint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vssub_vv_i64m4(op0, op1, op2) \
__builtin_rvv_vssub_vv_i64m4((vint64m4_t)(op0), (vint64m4_t)(op1), (size_t)(op2))
#define vssub_vv_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vv_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (vint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vssub_vv_i64m8(op0, op1, op2) \
__builtin_rvv_vssub_vv_i64m8((vint64m8_t)(op0), (vint64m8_t)(op1), (size_t)(op2))
#define vssub_vv_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vv_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (vint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vssub_vx_i8m1(op0, op1, op2) \
__builtin_rvv_vssub_vx_i8m1((vint8m1_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vssub_vx_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vx_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (int8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vssub_vx_i8m2(op0, op1, op2) \
__builtin_rvv_vssub_vx_i8m2((vint8m2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vssub_vx_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vx_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (int8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vssub_vx_i8m4(op0, op1, op2) \
__builtin_rvv_vssub_vx_i8m4((vint8m4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vssub_vx_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vx_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (int8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vssub_vx_i8m8(op0, op1, op2) \
__builtin_rvv_vssub_vx_i8m8((vint8m8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vssub_vx_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vx_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (int8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vssub_vx_i8mf2(op0, op1, op2) \
__builtin_rvv_vssub_vx_i8mf2((vint8mf2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vssub_vx_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vx_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (int8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vssub_vx_i8mf4(op0, op1, op2) \
__builtin_rvv_vssub_vx_i8mf4((vint8mf4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vssub_vx_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vx_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (int8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vssub_vx_i8mf8(op0, op1, op2) \
__builtin_rvv_vssub_vx_i8mf8((vint8mf8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vssub_vx_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vx_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (int8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssub_vx_i16m1(op0, op1, op2) \
__builtin_rvv_vssub_vx_i16m1((vint16m1_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vssub_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vx_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (int16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vssub_vx_i16m2(op0, op1, op2) \
__builtin_rvv_vssub_vx_i16m2((vint16m2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vssub_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vx_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (int16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vssub_vx_i16m4(op0, op1, op2) \
__builtin_rvv_vssub_vx_i16m4((vint16m4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vssub_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vx_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (int16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vssub_vx_i16m8(op0, op1, op2) \
__builtin_rvv_vssub_vx_i16m8((vint16m8_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vssub_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vx_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (int16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vssub_vx_i16mf2(op0, op1, op2) \
__builtin_rvv_vssub_vx_i16mf2((vint16mf2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vssub_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vx_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (int16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vssub_vx_i16mf4(op0, op1, op2) \
__builtin_rvv_vssub_vx_i16mf4((vint16mf4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vssub_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vx_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (int16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssub_vx_i32m1(op0, op1, op2) \
__builtin_rvv_vssub_vx_i32m1((vint32m1_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vssub_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vx_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (int32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vssub_vx_i32m2(op0, op1, op2) \
__builtin_rvv_vssub_vx_i32m2((vint32m2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vssub_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vx_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (int32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vssub_vx_i32m4(op0, op1, op2) \
__builtin_rvv_vssub_vx_i32m4((vint32m4_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vssub_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vx_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (int32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vssub_vx_i32m8(op0, op1, op2) \
__builtin_rvv_vssub_vx_i32m8((vint32m8_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vssub_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vx_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (int32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vssub_vx_i32mf2(op0, op1, op2) \
__builtin_rvv_vssub_vx_i32mf2((vint32mf2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vssub_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vx_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (int32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssub_vx_i64m1(op0, op1, op2) \
__builtin_rvv_vssub_vx_i64m1((vint64m1_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vssub_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vx_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (int64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssub_vx_i64m2(op0, op1, op2) \
__builtin_rvv_vssub_vx_i64m2((vint64m2_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vssub_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vx_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (int64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vssub_vx_i64m4(op0, op1, op2) \
__builtin_rvv_vssub_vx_i64m4((vint64m4_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vssub_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vx_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (int64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vssub_vx_i64m8(op0, op1, op2) \
__builtin_rvv_vssub_vx_i64m8((vint64m8_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vssub_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vx_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (int64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vaaddu_vv_u8m1(op0, op1, op2) \
__builtin_rvv_vaaddu_vv_u8m1((vuint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vaaddu_vv_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vv_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vaaddu_vv_u8m2(op0, op1, op2) \
__builtin_rvv_vaaddu_vv_u8m2((vuint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vaaddu_vv_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vv_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vaaddu_vv_u8m4(op0, op1, op2) \
__builtin_rvv_vaaddu_vv_u8m4((vuint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vaaddu_vv_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vv_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vaaddu_vv_u8m8(op0, op1, op2) \
__builtin_rvv_vaaddu_vv_u8m8((vuint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vaaddu_vv_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vv_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vaaddu_vv_u8mf2(op0, op1, op2) \
__builtin_rvv_vaaddu_vv_u8mf2((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vaaddu_vv_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vv_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vaaddu_vv_u8mf4(op0, op1, op2) \
__builtin_rvv_vaaddu_vv_u8mf4((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vaaddu_vv_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vv_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vaaddu_vv_u8mf8(op0, op1, op2) \
__builtin_rvv_vaaddu_vv_u8mf8((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vaaddu_vv_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vv_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vaaddu_vv_u16m1(op0, op1, op2) \
__builtin_rvv_vaaddu_vv_u16m1((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vaaddu_vv_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vv_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vaaddu_vv_u16m2(op0, op1, op2) \
__builtin_rvv_vaaddu_vv_u16m2((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vaaddu_vv_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vv_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vaaddu_vv_u16m4(op0, op1, op2) \
__builtin_rvv_vaaddu_vv_u16m4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vaaddu_vv_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vv_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vaaddu_vv_u16m8(op0, op1, op2) \
__builtin_rvv_vaaddu_vv_u16m8((vuint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vaaddu_vv_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vv_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vaaddu_vv_u16mf2(op0, op1, op2) \
__builtin_rvv_vaaddu_vv_u16mf2((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vaaddu_vv_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vv_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vaaddu_vv_u16mf4(op0, op1, op2) \
__builtin_rvv_vaaddu_vv_u16mf4((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vaaddu_vv_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vv_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vaaddu_vv_u32m1(op0, op1, op2) \
__builtin_rvv_vaaddu_vv_u32m1((vuint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vaaddu_vv_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vv_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vaaddu_vv_u32m2(op0, op1, op2) \
__builtin_rvv_vaaddu_vv_u32m2((vuint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vaaddu_vv_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vv_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vaaddu_vv_u32m4(op0, op1, op2) \
__builtin_rvv_vaaddu_vv_u32m4((vuint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vaaddu_vv_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vv_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vaaddu_vv_u32m8(op0, op1, op2) \
__builtin_rvv_vaaddu_vv_u32m8((vuint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vaaddu_vv_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vv_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vaaddu_vv_u32mf2(op0, op1, op2) \
__builtin_rvv_vaaddu_vv_u32mf2((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vaaddu_vv_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vv_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vaaddu_vv_u64m1(op0, op1, op2) \
__builtin_rvv_vaaddu_vv_u64m1((vuint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vaaddu_vv_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vv_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vaaddu_vv_u64m2(op0, op1, op2) \
__builtin_rvv_vaaddu_vv_u64m2((vuint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vaaddu_vv_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vv_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vaaddu_vv_u64m4(op0, op1, op2) \
__builtin_rvv_vaaddu_vv_u64m4((vuint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vaaddu_vv_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vv_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vaaddu_vv_u64m8(op0, op1, op2) \
__builtin_rvv_vaaddu_vv_u64m8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vaaddu_vv_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vv_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vaaddu_vx_u8m1(op0, op1, op2) \
__builtin_rvv_vaaddu_vx_u8m1((vuint8m1_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vaaddu_vx_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vx_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (uint8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vaaddu_vx_u8m2(op0, op1, op2) \
__builtin_rvv_vaaddu_vx_u8m2((vuint8m2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vaaddu_vx_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vx_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (uint8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vaaddu_vx_u8m4(op0, op1, op2) \
__builtin_rvv_vaaddu_vx_u8m4((vuint8m4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vaaddu_vx_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vx_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (uint8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vaaddu_vx_u8m8(op0, op1, op2) \
__builtin_rvv_vaaddu_vx_u8m8((vuint8m8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vaaddu_vx_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vx_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (uint8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vaaddu_vx_u8mf2(op0, op1, op2) \
__builtin_rvv_vaaddu_vx_u8mf2((vuint8mf2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vaaddu_vx_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vx_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (uint8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vaaddu_vx_u8mf4(op0, op1, op2) \
__builtin_rvv_vaaddu_vx_u8mf4((vuint8mf4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vaaddu_vx_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vx_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (uint8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vaaddu_vx_u8mf8(op0, op1, op2) \
__builtin_rvv_vaaddu_vx_u8mf8((vuint8mf8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vaaddu_vx_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vx_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (uint8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vaaddu_vx_u16m1(op0, op1, op2) \
__builtin_rvv_vaaddu_vx_u16m1((vuint16m1_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vaaddu_vx_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vx_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (uint16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vaaddu_vx_u16m2(op0, op1, op2) \
__builtin_rvv_vaaddu_vx_u16m2((vuint16m2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vaaddu_vx_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vx_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (uint16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vaaddu_vx_u16m4(op0, op1, op2) \
__builtin_rvv_vaaddu_vx_u16m4((vuint16m4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vaaddu_vx_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vx_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (uint16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vaaddu_vx_u16m8(op0, op1, op2) \
__builtin_rvv_vaaddu_vx_u16m8((vuint16m8_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vaaddu_vx_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vx_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (uint16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vaaddu_vx_u16mf2(op0, op1, op2) \
__builtin_rvv_vaaddu_vx_u16mf2((vuint16mf2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vaaddu_vx_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vx_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (uint16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vaaddu_vx_u16mf4(op0, op1, op2) \
__builtin_rvv_vaaddu_vx_u16mf4((vuint16mf4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vaaddu_vx_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vx_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (uint16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vaaddu_vx_u32m1(op0, op1, op2) \
__builtin_rvv_vaaddu_vx_u32m1((vuint32m1_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vaaddu_vx_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vx_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (uint32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vaaddu_vx_u32m2(op0, op1, op2) \
__builtin_rvv_vaaddu_vx_u32m2((vuint32m2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vaaddu_vx_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vx_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (uint32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vaaddu_vx_u32m4(op0, op1, op2) \
__builtin_rvv_vaaddu_vx_u32m4((vuint32m4_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vaaddu_vx_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vx_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (uint32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vaaddu_vx_u32m8(op0, op1, op2) \
__builtin_rvv_vaaddu_vx_u32m8((vuint32m8_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vaaddu_vx_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vx_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (uint32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vaaddu_vx_u32mf2(op0, op1, op2) \
__builtin_rvv_vaaddu_vx_u32mf2((vuint32mf2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vaaddu_vx_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vx_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (uint32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vaaddu_vx_u64m1(op0, op1, op2) \
__builtin_rvv_vaaddu_vx_u64m1((vuint64m1_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vaaddu_vx_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vx_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (uint64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vaaddu_vx_u64m2(op0, op1, op2) \
__builtin_rvv_vaaddu_vx_u64m2((vuint64m2_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vaaddu_vx_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vx_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (uint64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vaaddu_vx_u64m4(op0, op1, op2) \
__builtin_rvv_vaaddu_vx_u64m4((vuint64m4_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vaaddu_vx_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vx_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (uint64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vaaddu_vx_u64m8(op0, op1, op2) \
__builtin_rvv_vaaddu_vx_u64m8((vuint64m8_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vaaddu_vx_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vx_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (uint64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vaadd_vv_i8m1(op0, op1, op2) \
__builtin_rvv_vaadd_vv_i8m1((vint8m1_t)(op0), (vint8m1_t)(op1), (size_t)(op2))
#define vaadd_vv_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vv_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vaadd_vv_i8m2(op0, op1, op2) \
__builtin_rvv_vaadd_vv_i8m2((vint8m2_t)(op0), (vint8m2_t)(op1), (size_t)(op2))
#define vaadd_vv_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vv_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vaadd_vv_i8m4(op0, op1, op2) \
__builtin_rvv_vaadd_vv_i8m4((vint8m4_t)(op0), (vint8m4_t)(op1), (size_t)(op2))
#define vaadd_vv_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vv_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vaadd_vv_i8m8(op0, op1, op2) \
__builtin_rvv_vaadd_vv_i8m8((vint8m8_t)(op0), (vint8m8_t)(op1), (size_t)(op2))
#define vaadd_vv_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vv_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (vint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vaadd_vv_i8mf2(op0, op1, op2) \
__builtin_rvv_vaadd_vv_i8mf2((vint8mf2_t)(op0), (vint8mf2_t)(op1), (size_t)(op2))
#define vaadd_vv_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vv_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vaadd_vv_i8mf4(op0, op1, op2) \
__builtin_rvv_vaadd_vv_i8mf4((vint8mf4_t)(op0), (vint8mf4_t)(op1), (size_t)(op2))
#define vaadd_vv_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vv_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vaadd_vv_i8mf8(op0, op1, op2) \
__builtin_rvv_vaadd_vv_i8mf8((vint8mf8_t)(op0), (vint8mf8_t)(op1), (size_t)(op2))
#define vaadd_vv_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vv_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vaadd_vv_i16m1(op0, op1, op2) \
__builtin_rvv_vaadd_vv_i16m1((vint16m1_t)(op0), (vint16m1_t)(op1), (size_t)(op2))
#define vaadd_vv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vv_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vaadd_vv_i16m2(op0, op1, op2) \
__builtin_rvv_vaadd_vv_i16m2((vint16m2_t)(op0), (vint16m2_t)(op1), (size_t)(op2))
#define vaadd_vv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vv_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vaadd_vv_i16m4(op0, op1, op2) \
__builtin_rvv_vaadd_vv_i16m4((vint16m4_t)(op0), (vint16m4_t)(op1), (size_t)(op2))
#define vaadd_vv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vv_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vaadd_vv_i16m8(op0, op1, op2) \
__builtin_rvv_vaadd_vv_i16m8((vint16m8_t)(op0), (vint16m8_t)(op1), (size_t)(op2))
#define vaadd_vv_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vv_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (vint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vaadd_vv_i16mf2(op0, op1, op2) \
__builtin_rvv_vaadd_vv_i16mf2((vint16mf2_t)(op0), (vint16mf2_t)(op1), (size_t)(op2))
#define vaadd_vv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vv_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vaadd_vv_i16mf4(op0, op1, op2) \
__builtin_rvv_vaadd_vv_i16mf4((vint16mf4_t)(op0), (vint16mf4_t)(op1), (size_t)(op2))
#define vaadd_vv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vv_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vaadd_vv_i32m1(op0, op1, op2) \
__builtin_rvv_vaadd_vv_i32m1((vint32m1_t)(op0), (vint32m1_t)(op1), (size_t)(op2))
#define vaadd_vv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vv_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vaadd_vv_i32m2(op0, op1, op2) \
__builtin_rvv_vaadd_vv_i32m2((vint32m2_t)(op0), (vint32m2_t)(op1), (size_t)(op2))
#define vaadd_vv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vv_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vaadd_vv_i32m4(op0, op1, op2) \
__builtin_rvv_vaadd_vv_i32m4((vint32m4_t)(op0), (vint32m4_t)(op1), (size_t)(op2))
#define vaadd_vv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vv_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vaadd_vv_i32m8(op0, op1, op2) \
__builtin_rvv_vaadd_vv_i32m8((vint32m8_t)(op0), (vint32m8_t)(op1), (size_t)(op2))
#define vaadd_vv_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vv_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (vint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vaadd_vv_i32mf2(op0, op1, op2) \
__builtin_rvv_vaadd_vv_i32mf2((vint32mf2_t)(op0), (vint32mf2_t)(op1), (size_t)(op2))
#define vaadd_vv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vv_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vaadd_vv_i64m1(op0, op1, op2) \
__builtin_rvv_vaadd_vv_i64m1((vint64m1_t)(op0), (vint64m1_t)(op1), (size_t)(op2))
#define vaadd_vv_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vv_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vaadd_vv_i64m2(op0, op1, op2) \
__builtin_rvv_vaadd_vv_i64m2((vint64m2_t)(op0), (vint64m2_t)(op1), (size_t)(op2))
#define vaadd_vv_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vv_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (vint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vaadd_vv_i64m4(op0, op1, op2) \
__builtin_rvv_vaadd_vv_i64m4((vint64m4_t)(op0), (vint64m4_t)(op1), (size_t)(op2))
#define vaadd_vv_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vv_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (vint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vaadd_vv_i64m8(op0, op1, op2) \
__builtin_rvv_vaadd_vv_i64m8((vint64m8_t)(op0), (vint64m8_t)(op1), (size_t)(op2))
#define vaadd_vv_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vv_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (vint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vle32ff_v_u32m1(op0, op1, op2) \
__builtin_rvv_vle32ff_v_u32m1((const uint32_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle32ff_v_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle32ff_v_u32m1_m((vuint32m1_t)(op0), (const uint32_t *)(op1), (size_t *)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vle32ff_v_u32m2(op0, op1, op2) \
__builtin_rvv_vle32ff_v_u32m2((const uint32_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle32ff_v_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle32ff_v_u32m2_m((vuint32m2_t)(op0), (const uint32_t *)(op1), (size_t *)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vle32ff_v_u32m4(op0, op1, op2) \
__builtin_rvv_vle32ff_v_u32m4((const uint32_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle32ff_v_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle32ff_v_u32m4_m((vuint32m4_t)(op0), (const uint32_t *)(op1), (size_t *)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vle32ff_v_u32m8(op0, op1, op2) \
__builtin_rvv_vle32ff_v_u32m8((const uint32_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle32ff_v_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle32ff_v_u32m8_m((vuint32m8_t)(op0), (const uint32_t *)(op1), (size_t *)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vle32ff_v_u32mf2(op0, op1, op2) \
__builtin_rvv_vle32ff_v_u32mf2((const uint32_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle32ff_v_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle32ff_v_u32mf2_m((vuint32mf2_t)(op0), (const uint32_t *)(op1), (size_t *)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vaadd_vx_i8m1(op0, op1, op2) \
__builtin_rvv_vaadd_vx_i8m1((vint8m1_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vaadd_vx_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vx_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (int8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vaadd_vx_i8m2(op0, op1, op2) \
__builtin_rvv_vaadd_vx_i8m2((vint8m2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vaadd_vx_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vx_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (int8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vaadd_vx_i8m4(op0, op1, op2) \
__builtin_rvv_vaadd_vx_i8m4((vint8m4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vaadd_vx_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vx_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (int8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vaadd_vx_i8m8(op0, op1, op2) \
__builtin_rvv_vaadd_vx_i8m8((vint8m8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vaadd_vx_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vx_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (int8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vaadd_vx_i8mf2(op0, op1, op2) \
__builtin_rvv_vaadd_vx_i8mf2((vint8mf2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vaadd_vx_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vx_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (int8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vaadd_vx_i8mf4(op0, op1, op2) \
__builtin_rvv_vaadd_vx_i8mf4((vint8mf4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vaadd_vx_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vx_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (int8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vaadd_vx_i8mf8(op0, op1, op2) \
__builtin_rvv_vaadd_vx_i8mf8((vint8mf8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vaadd_vx_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vx_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (int8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vaadd_vx_i16m1(op0, op1, op2) \
__builtin_rvv_vaadd_vx_i16m1((vint16m1_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vaadd_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vx_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (int16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vaadd_vx_i16m2(op0, op1, op2) \
__builtin_rvv_vaadd_vx_i16m2((vint16m2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vaadd_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vx_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (int16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vaadd_vx_i16m4(op0, op1, op2) \
__builtin_rvv_vaadd_vx_i16m4((vint16m4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vaadd_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vx_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (int16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vaadd_vx_i16m8(op0, op1, op2) \
__builtin_rvv_vaadd_vx_i16m8((vint16m8_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vaadd_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vx_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (int16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vaadd_vx_i16mf2(op0, op1, op2) \
__builtin_rvv_vaadd_vx_i16mf2((vint16mf2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vaadd_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vx_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (int16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vaadd_vx_i16mf4(op0, op1, op2) \
__builtin_rvv_vaadd_vx_i16mf4((vint16mf4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vaadd_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vx_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (int16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vaadd_vx_i32m1(op0, op1, op2) \
__builtin_rvv_vaadd_vx_i32m1((vint32m1_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vaadd_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vx_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (int32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vaadd_vx_i32m2(op0, op1, op2) \
__builtin_rvv_vaadd_vx_i32m2((vint32m2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vaadd_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vx_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (int32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vaadd_vx_i32m4(op0, op1, op2) \
__builtin_rvv_vaadd_vx_i32m4((vint32m4_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vaadd_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vx_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (int32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vaadd_vx_i32m8(op0, op1, op2) \
__builtin_rvv_vaadd_vx_i32m8((vint32m8_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vaadd_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vx_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (int32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vaadd_vx_i32mf2(op0, op1, op2) \
__builtin_rvv_vaadd_vx_i32mf2((vint32mf2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vaadd_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vx_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (int32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vaadd_vx_i64m1(op0, op1, op2) \
__builtin_rvv_vaadd_vx_i64m1((vint64m1_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vaadd_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vx_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (int64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vaadd_vx_i64m2(op0, op1, op2) \
__builtin_rvv_vaadd_vx_i64m2((vint64m2_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vaadd_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vx_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (int64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vaadd_vx_i64m4(op0, op1, op2) \
__builtin_rvv_vaadd_vx_i64m4((vint64m4_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vaadd_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vx_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (int64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vaadd_vx_i64m8(op0, op1, op2) \
__builtin_rvv_vaadd_vx_i64m8((vint64m8_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vaadd_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vx_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (int64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vasubu_vv_u8m1(op0, op1, op2) \
__builtin_rvv_vasubu_vv_u8m1((vuint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vasubu_vv_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vv_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vasubu_vv_u8m2(op0, op1, op2) \
__builtin_rvv_vasubu_vv_u8m2((vuint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vasubu_vv_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vv_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vasubu_vv_u8m4(op0, op1, op2) \
__builtin_rvv_vasubu_vv_u8m4((vuint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vasubu_vv_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vv_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vasubu_vv_u8m8(op0, op1, op2) \
__builtin_rvv_vasubu_vv_u8m8((vuint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vasubu_vv_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vv_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vasubu_vv_u8mf2(op0, op1, op2) \
__builtin_rvv_vasubu_vv_u8mf2((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vasubu_vv_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vv_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vasubu_vv_u8mf4(op0, op1, op2) \
__builtin_rvv_vasubu_vv_u8mf4((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vasubu_vv_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vv_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vasubu_vv_u8mf8(op0, op1, op2) \
__builtin_rvv_vasubu_vv_u8mf8((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vasubu_vv_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vv_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vasubu_vv_u16m1(op0, op1, op2) \
__builtin_rvv_vasubu_vv_u16m1((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vasubu_vv_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vv_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vasubu_vv_u16m2(op0, op1, op2) \
__builtin_rvv_vasubu_vv_u16m2((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vasubu_vv_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vv_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vasubu_vv_u16m4(op0, op1, op2) \
__builtin_rvv_vasubu_vv_u16m4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vasubu_vv_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vv_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vasubu_vv_u16m8(op0, op1, op2) \
__builtin_rvv_vasubu_vv_u16m8((vuint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vasubu_vv_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vv_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vasubu_vv_u16mf2(op0, op1, op2) \
__builtin_rvv_vasubu_vv_u16mf2((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vasubu_vv_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vv_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vasubu_vv_u16mf4(op0, op1, op2) \
__builtin_rvv_vasubu_vv_u16mf4((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vasubu_vv_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vv_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vasubu_vv_u32m1(op0, op1, op2) \
__builtin_rvv_vasubu_vv_u32m1((vuint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vasubu_vv_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vv_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vasubu_vv_u32m2(op0, op1, op2) \
__builtin_rvv_vasubu_vv_u32m2((vuint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vasubu_vv_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vv_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vasubu_vv_u32m4(op0, op1, op2) \
__builtin_rvv_vasubu_vv_u32m4((vuint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vasubu_vv_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vv_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vasubu_vv_u32m8(op0, op1, op2) \
__builtin_rvv_vasubu_vv_u32m8((vuint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vasubu_vv_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vv_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vasubu_vv_u32mf2(op0, op1, op2) \
__builtin_rvv_vasubu_vv_u32mf2((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vasubu_vv_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vv_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vasubu_vv_u64m1(op0, op1, op2) \
__builtin_rvv_vasubu_vv_u64m1((vuint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vasubu_vv_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vv_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vasubu_vv_u64m2(op0, op1, op2) \
__builtin_rvv_vasubu_vv_u64m2((vuint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vasubu_vv_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vv_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vasubu_vv_u64m4(op0, op1, op2) \
__builtin_rvv_vasubu_vv_u64m4((vuint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vasubu_vv_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vv_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vasubu_vv_u64m8(op0, op1, op2) \
__builtin_rvv_vasubu_vv_u64m8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vasubu_vv_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vv_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vasubu_vx_u8m1(op0, op1, op2) \
__builtin_rvv_vasubu_vx_u8m1((vuint8m1_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vasubu_vx_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vx_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (uint8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vasubu_vx_u8m2(op0, op1, op2) \
__builtin_rvv_vasubu_vx_u8m2((vuint8m2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vasubu_vx_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vx_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (uint8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vasubu_vx_u8m4(op0, op1, op2) \
__builtin_rvv_vasubu_vx_u8m4((vuint8m4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vasubu_vx_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vx_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (uint8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vasubu_vx_u8m8(op0, op1, op2) \
__builtin_rvv_vasubu_vx_u8m8((vuint8m8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vasubu_vx_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vx_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (uint8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vasubu_vx_u8mf2(op0, op1, op2) \
__builtin_rvv_vasubu_vx_u8mf2((vuint8mf2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vasubu_vx_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vx_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (uint8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vasubu_vx_u8mf4(op0, op1, op2) \
__builtin_rvv_vasubu_vx_u8mf4((vuint8mf4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vasubu_vx_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vx_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (uint8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vasubu_vx_u8mf8(op0, op1, op2) \
__builtin_rvv_vasubu_vx_u8mf8((vuint8mf8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vasubu_vx_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vx_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (uint8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vasubu_vx_u16m1(op0, op1, op2) \
__builtin_rvv_vasubu_vx_u16m1((vuint16m1_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vasubu_vx_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vx_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (uint16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vasubu_vx_u16m2(op0, op1, op2) \
__builtin_rvv_vasubu_vx_u16m2((vuint16m2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vasubu_vx_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vx_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (uint16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vasubu_vx_u16m4(op0, op1, op2) \
__builtin_rvv_vasubu_vx_u16m4((vuint16m4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vasubu_vx_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vx_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (uint16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vasubu_vx_u16m8(op0, op1, op2) \
__builtin_rvv_vasubu_vx_u16m8((vuint16m8_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vasubu_vx_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vx_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (uint16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vasubu_vx_u16mf2(op0, op1, op2) \
__builtin_rvv_vasubu_vx_u16mf2((vuint16mf2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vasubu_vx_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vx_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (uint16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vasubu_vx_u16mf4(op0, op1, op2) \
__builtin_rvv_vasubu_vx_u16mf4((vuint16mf4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vasubu_vx_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vx_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (uint16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vasubu_vx_u32m1(op0, op1, op2) \
__builtin_rvv_vasubu_vx_u32m1((vuint32m1_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vasubu_vx_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vx_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (uint32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vasubu_vx_u32m2(op0, op1, op2) \
__builtin_rvv_vasubu_vx_u32m2((vuint32m2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vasubu_vx_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vx_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (uint32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vasubu_vx_u32m4(op0, op1, op2) \
__builtin_rvv_vasubu_vx_u32m4((vuint32m4_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vasubu_vx_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vx_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (uint32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vasubu_vx_u32m8(op0, op1, op2) \
__builtin_rvv_vasubu_vx_u32m8((vuint32m8_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vasubu_vx_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vx_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (uint32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vasubu_vx_u32mf2(op0, op1, op2) \
__builtin_rvv_vasubu_vx_u32mf2((vuint32mf2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vasubu_vx_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vx_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (uint32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vasubu_vx_u64m1(op0, op1, op2) \
__builtin_rvv_vasubu_vx_u64m1((vuint64m1_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vasubu_vx_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vx_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (uint64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vasubu_vx_u64m2(op0, op1, op2) \
__builtin_rvv_vasubu_vx_u64m2((vuint64m2_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vasubu_vx_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vx_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (uint64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vasubu_vx_u64m4(op0, op1, op2) \
__builtin_rvv_vasubu_vx_u64m4((vuint64m4_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vasubu_vx_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vx_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (uint64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vasubu_vx_u64m8(op0, op1, op2) \
__builtin_rvv_vasubu_vx_u64m8((vuint64m8_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vasubu_vx_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vx_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (uint64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vasub_vv_i8m1(op0, op1, op2) \
__builtin_rvv_vasub_vv_i8m1((vint8m1_t)(op0), (vint8m1_t)(op1), (size_t)(op2))
#define vasub_vv_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vv_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vasub_vv_i8m2(op0, op1, op2) \
__builtin_rvv_vasub_vv_i8m2((vint8m2_t)(op0), (vint8m2_t)(op1), (size_t)(op2))
#define vasub_vv_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vv_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vasub_vv_i8m4(op0, op1, op2) \
__builtin_rvv_vasub_vv_i8m4((vint8m4_t)(op0), (vint8m4_t)(op1), (size_t)(op2))
#define vasub_vv_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vv_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vasub_vv_i8m8(op0, op1, op2) \
__builtin_rvv_vasub_vv_i8m8((vint8m8_t)(op0), (vint8m8_t)(op1), (size_t)(op2))
#define vasub_vv_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vv_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (vint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vasub_vv_i8mf2(op0, op1, op2) \
__builtin_rvv_vasub_vv_i8mf2((vint8mf2_t)(op0), (vint8mf2_t)(op1), (size_t)(op2))
#define vasub_vv_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vv_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vasub_vv_i8mf4(op0, op1, op2) \
__builtin_rvv_vasub_vv_i8mf4((vint8mf4_t)(op0), (vint8mf4_t)(op1), (size_t)(op2))
#define vasub_vv_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vv_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vasub_vv_i8mf8(op0, op1, op2) \
__builtin_rvv_vasub_vv_i8mf8((vint8mf8_t)(op0), (vint8mf8_t)(op1), (size_t)(op2))
#define vasub_vv_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vv_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vasub_vv_i16m1(op0, op1, op2) \
__builtin_rvv_vasub_vv_i16m1((vint16m1_t)(op0), (vint16m1_t)(op1), (size_t)(op2))
#define vasub_vv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vv_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vasub_vv_i16m2(op0, op1, op2) \
__builtin_rvv_vasub_vv_i16m2((vint16m2_t)(op0), (vint16m2_t)(op1), (size_t)(op2))
#define vasub_vv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vv_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vasub_vv_i16m4(op0, op1, op2) \
__builtin_rvv_vasub_vv_i16m4((vint16m4_t)(op0), (vint16m4_t)(op1), (size_t)(op2))
#define vasub_vv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vv_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vasub_vv_i16m8(op0, op1, op2) \
__builtin_rvv_vasub_vv_i16m8((vint16m8_t)(op0), (vint16m8_t)(op1), (size_t)(op2))
#define vasub_vv_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vv_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (vint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vasub_vv_i16mf2(op0, op1, op2) \
__builtin_rvv_vasub_vv_i16mf2((vint16mf2_t)(op0), (vint16mf2_t)(op1), (size_t)(op2))
#define vasub_vv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vv_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vasub_vv_i16mf4(op0, op1, op2) \
__builtin_rvv_vasub_vv_i16mf4((vint16mf4_t)(op0), (vint16mf4_t)(op1), (size_t)(op2))
#define vasub_vv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vv_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vasub_vv_i32m1(op0, op1, op2) \
__builtin_rvv_vasub_vv_i32m1((vint32m1_t)(op0), (vint32m1_t)(op1), (size_t)(op2))
#define vasub_vv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vv_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vasub_vv_i32m2(op0, op1, op2) \
__builtin_rvv_vasub_vv_i32m2((vint32m2_t)(op0), (vint32m2_t)(op1), (size_t)(op2))
#define vasub_vv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vv_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vasub_vv_i32m4(op0, op1, op2) \
__builtin_rvv_vasub_vv_i32m4((vint32m4_t)(op0), (vint32m4_t)(op1), (size_t)(op2))
#define vasub_vv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vv_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vasub_vv_i32m8(op0, op1, op2) \
__builtin_rvv_vasub_vv_i32m8((vint32m8_t)(op0), (vint32m8_t)(op1), (size_t)(op2))
#define vasub_vv_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vv_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (vint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vasub_vv_i32mf2(op0, op1, op2) \
__builtin_rvv_vasub_vv_i32mf2((vint32mf2_t)(op0), (vint32mf2_t)(op1), (size_t)(op2))
#define vasub_vv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vv_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vasub_vv_i64m1(op0, op1, op2) \
__builtin_rvv_vasub_vv_i64m1((vint64m1_t)(op0), (vint64m1_t)(op1), (size_t)(op2))
#define vasub_vv_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vv_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vasub_vv_i64m2(op0, op1, op2) \
__builtin_rvv_vasub_vv_i64m2((vint64m2_t)(op0), (vint64m2_t)(op1), (size_t)(op2))
#define vasub_vv_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vv_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (vint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vasub_vv_i64m4(op0, op1, op2) \
__builtin_rvv_vasub_vv_i64m4((vint64m4_t)(op0), (vint64m4_t)(op1), (size_t)(op2))
#define vasub_vv_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vv_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (vint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vasub_vv_i64m8(op0, op1, op2) \
__builtin_rvv_vasub_vv_i64m8((vint64m8_t)(op0), (vint64m8_t)(op1), (size_t)(op2))
#define vasub_vv_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vv_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (vint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vasub_vx_i8m1(op0, op1, op2) \
__builtin_rvv_vasub_vx_i8m1((vint8m1_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vasub_vx_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vx_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (int8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vasub_vx_i8m2(op0, op1, op2) \
__builtin_rvv_vasub_vx_i8m2((vint8m2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vasub_vx_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vx_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (int8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vasub_vx_i8m4(op0, op1, op2) \
__builtin_rvv_vasub_vx_i8m4((vint8m4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vasub_vx_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vx_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (int8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vasub_vx_i8m8(op0, op1, op2) \
__builtin_rvv_vasub_vx_i8m8((vint8m8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vasub_vx_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vx_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (int8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vasub_vx_i8mf2(op0, op1, op2) \
__builtin_rvv_vasub_vx_i8mf2((vint8mf2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vasub_vx_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vx_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (int8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vasub_vx_i8mf4(op0, op1, op2) \
__builtin_rvv_vasub_vx_i8mf4((vint8mf4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vasub_vx_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vx_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (int8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vasub_vx_i8mf8(op0, op1, op2) \
__builtin_rvv_vasub_vx_i8mf8((vint8mf8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vasub_vx_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vx_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (int8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vasub_vx_i16m1(op0, op1, op2) \
__builtin_rvv_vasub_vx_i16m1((vint16m1_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vasub_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vx_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (int16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vasub_vx_i16m2(op0, op1, op2) \
__builtin_rvv_vasub_vx_i16m2((vint16m2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vasub_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vx_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (int16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vasub_vx_i16m4(op0, op1, op2) \
__builtin_rvv_vasub_vx_i16m4((vint16m4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vasub_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vx_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (int16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vasub_vx_i16m8(op0, op1, op2) \
__builtin_rvv_vasub_vx_i16m8((vint16m8_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vasub_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vx_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (int16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vasub_vx_i16mf2(op0, op1, op2) \
__builtin_rvv_vasub_vx_i16mf2((vint16mf2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vasub_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vx_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (int16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vasub_vx_i16mf4(op0, op1, op2) \
__builtin_rvv_vasub_vx_i16mf4((vint16mf4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vasub_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vx_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (int16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vasub_vx_i32m1(op0, op1, op2) \
__builtin_rvv_vasub_vx_i32m1((vint32m1_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vasub_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vx_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (int32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vasub_vx_i32m2(op0, op1, op2) \
__builtin_rvv_vasub_vx_i32m2((vint32m2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vasub_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vx_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (int32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vasub_vx_i32m4(op0, op1, op2) \
__builtin_rvv_vasub_vx_i32m4((vint32m4_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vasub_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vx_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (int32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vasub_vx_i32m8(op0, op1, op2) \
__builtin_rvv_vasub_vx_i32m8((vint32m8_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vasub_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vx_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (int32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vasub_vx_i32mf2(op0, op1, op2) \
__builtin_rvv_vasub_vx_i32mf2((vint32mf2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vasub_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vx_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (int32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vasub_vx_i64m1(op0, op1, op2) \
__builtin_rvv_vasub_vx_i64m1((vint64m1_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vasub_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vx_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (int64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vasub_vx_i64m2(op0, op1, op2) \
__builtin_rvv_vasub_vx_i64m2((vint64m2_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vasub_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vx_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (int64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vasub_vx_i64m4(op0, op1, op2) \
__builtin_rvv_vasub_vx_i64m4((vint64m4_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vasub_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vx_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (int64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vasub_vx_i64m8(op0, op1, op2) \
__builtin_rvv_vasub_vx_i64m8((vint64m8_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vasub_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vx_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (int64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsmul_vv_i8m1(op0, op1, op2) \
__builtin_rvv_vsmul_vv_i8m1((vint8m1_t)(op0), (vint8m1_t)(op1), (size_t)(op2))
#define vsmul_vv_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vv_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsmul_vv_i8m2(op0, op1, op2) \
__builtin_rvv_vsmul_vv_i8m2((vint8m2_t)(op0), (vint8m2_t)(op1), (size_t)(op2))
#define vsmul_vv_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vv_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsmul_vv_i8m4(op0, op1, op2) \
__builtin_rvv_vsmul_vv_i8m4((vint8m4_t)(op0), (vint8m4_t)(op1), (size_t)(op2))
#define vsmul_vv_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vv_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsmul_vv_i8m8(op0, op1, op2) \
__builtin_rvv_vsmul_vv_i8m8((vint8m8_t)(op0), (vint8m8_t)(op1), (size_t)(op2))
#define vsmul_vv_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vv_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (vint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vsmul_vv_i8mf2(op0, op1, op2) \
__builtin_rvv_vsmul_vv_i8mf2((vint8mf2_t)(op0), (vint8mf2_t)(op1), (size_t)(op2))
#define vsmul_vv_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vv_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsmul_vv_i8mf4(op0, op1, op2) \
__builtin_rvv_vsmul_vv_i8mf4((vint8mf4_t)(op0), (vint8mf4_t)(op1), (size_t)(op2))
#define vsmul_vv_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vv_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsmul_vv_i8mf8(op0, op1, op2) \
__builtin_rvv_vsmul_vv_i8mf8((vint8mf8_t)(op0), (vint8mf8_t)(op1), (size_t)(op2))
#define vsmul_vv_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vv_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsmul_vv_i16m1(op0, op1, op2) \
__builtin_rvv_vsmul_vv_i16m1((vint16m1_t)(op0), (vint16m1_t)(op1), (size_t)(op2))
#define vsmul_vv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vv_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsmul_vv_i16m2(op0, op1, op2) \
__builtin_rvv_vsmul_vv_i16m2((vint16m2_t)(op0), (vint16m2_t)(op1), (size_t)(op2))
#define vsmul_vv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vv_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsmul_vv_i16m4(op0, op1, op2) \
__builtin_rvv_vsmul_vv_i16m4((vint16m4_t)(op0), (vint16m4_t)(op1), (size_t)(op2))
#define vsmul_vv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vv_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsmul_vv_i16m8(op0, op1, op2) \
__builtin_rvv_vsmul_vv_i16m8((vint16m8_t)(op0), (vint16m8_t)(op1), (size_t)(op2))
#define vsmul_vv_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vv_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (vint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsmul_vv_i16mf2(op0, op1, op2) \
__builtin_rvv_vsmul_vv_i16mf2((vint16mf2_t)(op0), (vint16mf2_t)(op1), (size_t)(op2))
#define vsmul_vv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vv_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsmul_vv_i16mf4(op0, op1, op2) \
__builtin_rvv_vsmul_vv_i16mf4((vint16mf4_t)(op0), (vint16mf4_t)(op1), (size_t)(op2))
#define vsmul_vv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vv_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsmul_vv_i32m1(op0, op1, op2) \
__builtin_rvv_vsmul_vv_i32m1((vint32m1_t)(op0), (vint32m1_t)(op1), (size_t)(op2))
#define vsmul_vv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vv_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsmul_vv_i32m2(op0, op1, op2) \
__builtin_rvv_vsmul_vv_i32m2((vint32m2_t)(op0), (vint32m2_t)(op1), (size_t)(op2))
#define vsmul_vv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vv_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsmul_vv_i32m4(op0, op1, op2) \
__builtin_rvv_vsmul_vv_i32m4((vint32m4_t)(op0), (vint32m4_t)(op1), (size_t)(op2))
#define vsmul_vv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vv_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsmul_vv_i32m8(op0, op1, op2) \
__builtin_rvv_vsmul_vv_i32m8((vint32m8_t)(op0), (vint32m8_t)(op1), (size_t)(op2))
#define vsmul_vv_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vv_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (vint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsmul_vv_i32mf2(op0, op1, op2) \
__builtin_rvv_vsmul_vv_i32mf2((vint32mf2_t)(op0), (vint32mf2_t)(op1), (size_t)(op2))
#define vsmul_vv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vv_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsmul_vv_i64m1(op0, op1, op2) \
__builtin_rvv_vsmul_vv_i64m1((vint64m1_t)(op0), (vint64m1_t)(op1), (size_t)(op2))
#define vsmul_vv_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vv_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsmul_vv_i64m2(op0, op1, op2) \
__builtin_rvv_vsmul_vv_i64m2((vint64m2_t)(op0), (vint64m2_t)(op1), (size_t)(op2))
#define vsmul_vv_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vv_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (vint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsmul_vv_i64m4(op0, op1, op2) \
__builtin_rvv_vsmul_vv_i64m4((vint64m4_t)(op0), (vint64m4_t)(op1), (size_t)(op2))
#define vsmul_vv_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vv_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (vint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsmul_vv_i64m8(op0, op1, op2) \
__builtin_rvv_vsmul_vv_i64m8((vint64m8_t)(op0), (vint64m8_t)(op1), (size_t)(op2))
#define vsmul_vv_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vv_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (vint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsmul_vx_i8m1(op0, op1, op2) \
__builtin_rvv_vsmul_vx_i8m1((vint8m1_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vsmul_vx_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vx_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (int8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsmul_vx_i8m2(op0, op1, op2) \
__builtin_rvv_vsmul_vx_i8m2((vint8m2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vsmul_vx_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vx_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (int8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsmul_vx_i8m4(op0, op1, op2) \
__builtin_rvv_vsmul_vx_i8m4((vint8m4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vsmul_vx_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vx_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (int8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsmul_vx_i8m8(op0, op1, op2) \
__builtin_rvv_vsmul_vx_i8m8((vint8m8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vsmul_vx_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vx_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (int8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vsmul_vx_i8mf2(op0, op1, op2) \
__builtin_rvv_vsmul_vx_i8mf2((vint8mf2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vsmul_vx_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vx_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (int8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsmul_vx_i8mf4(op0, op1, op2) \
__builtin_rvv_vsmul_vx_i8mf4((vint8mf4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vsmul_vx_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vx_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (int8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsmul_vx_i8mf8(op0, op1, op2) \
__builtin_rvv_vsmul_vx_i8mf8((vint8mf8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vsmul_vx_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vx_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (int8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsmul_vx_i16m1(op0, op1, op2) \
__builtin_rvv_vsmul_vx_i16m1((vint16m1_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vsmul_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vx_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (int16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsmul_vx_i16m2(op0, op1, op2) \
__builtin_rvv_vsmul_vx_i16m2((vint16m2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vsmul_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vx_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (int16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsmul_vx_i16m4(op0, op1, op2) \
__builtin_rvv_vsmul_vx_i16m4((vint16m4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vsmul_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vx_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (int16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsmul_vx_i16m8(op0, op1, op2) \
__builtin_rvv_vsmul_vx_i16m8((vint16m8_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vsmul_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vx_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (int16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsmul_vx_i16mf2(op0, op1, op2) \
__builtin_rvv_vsmul_vx_i16mf2((vint16mf2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vsmul_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vx_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (int16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsmul_vx_i16mf4(op0, op1, op2) \
__builtin_rvv_vsmul_vx_i16mf4((vint16mf4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vsmul_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vx_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (int16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsmul_vx_i32m1(op0, op1, op2) \
__builtin_rvv_vsmul_vx_i32m1((vint32m1_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vsmul_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vx_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (int32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsmul_vx_i32m2(op0, op1, op2) \
__builtin_rvv_vsmul_vx_i32m2((vint32m2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vsmul_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vx_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (int32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsmul_vx_i32m4(op0, op1, op2) \
__builtin_rvv_vsmul_vx_i32m4((vint32m4_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vsmul_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vx_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (int32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsmul_vx_i32m8(op0, op1, op2) \
__builtin_rvv_vsmul_vx_i32m8((vint32m8_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vsmul_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vx_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (int32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsmul_vx_i32mf2(op0, op1, op2) \
__builtin_rvv_vsmul_vx_i32mf2((vint32mf2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vsmul_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vx_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (int32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsmul_vx_i64m1(op0, op1, op2) \
__builtin_rvv_vsmul_vx_i64m1((vint64m1_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vsmul_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vx_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (int64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsmul_vx_i64m2(op0, op1, op2) \
__builtin_rvv_vsmul_vx_i64m2((vint64m2_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vsmul_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vx_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (int64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsmul_vx_i64m4(op0, op1, op2) \
__builtin_rvv_vsmul_vx_i64m4((vint64m4_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vsmul_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vx_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (int64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsmul_vx_i64m8(op0, op1, op2) \
__builtin_rvv_vsmul_vx_i64m8((vint64m8_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vsmul_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vx_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (int64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vssrl_vv_u8m1(op0, op1, op2) \
__builtin_rvv_vssrl_vv_u8m1((vuint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vssrl_vv_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vv_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vssrl_vv_u8m2(op0, op1, op2) \
__builtin_rvv_vssrl_vv_u8m2((vuint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vssrl_vv_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vv_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vssrl_vv_u8m4(op0, op1, op2) \
__builtin_rvv_vssrl_vv_u8m4((vuint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vssrl_vv_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vv_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vssrl_vv_u8m8(op0, op1, op2) \
__builtin_rvv_vssrl_vv_u8m8((vuint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vssrl_vv_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vv_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vssrl_vv_u8mf2(op0, op1, op2) \
__builtin_rvv_vssrl_vv_u8mf2((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vssrl_vv_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vv_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vssrl_vv_u8mf4(op0, op1, op2) \
__builtin_rvv_vssrl_vv_u8mf4((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vssrl_vv_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vv_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vssrl_vv_u8mf8(op0, op1, op2) \
__builtin_rvv_vssrl_vv_u8mf8((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vssrl_vv_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vv_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssrl_vv_u16m1(op0, op1, op2) \
__builtin_rvv_vssrl_vv_u16m1((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vssrl_vv_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vv_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vssrl_vv_u16m2(op0, op1, op2) \
__builtin_rvv_vssrl_vv_u16m2((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vssrl_vv_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vv_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vssrl_vv_u16m4(op0, op1, op2) \
__builtin_rvv_vssrl_vv_u16m4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vssrl_vv_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vv_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vssrl_vv_u16m8(op0, op1, op2) \
__builtin_rvv_vssrl_vv_u16m8((vuint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vssrl_vv_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vv_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vssrl_vv_u16mf2(op0, op1, op2) \
__builtin_rvv_vssrl_vv_u16mf2((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vssrl_vv_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vv_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vssrl_vv_u16mf4(op0, op1, op2) \
__builtin_rvv_vssrl_vv_u16mf4((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vssrl_vv_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vv_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssrl_vv_u32m1(op0, op1, op2) \
__builtin_rvv_vssrl_vv_u32m1((vuint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vssrl_vv_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vv_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vssrl_vv_u32m2(op0, op1, op2) \
__builtin_rvv_vssrl_vv_u32m2((vuint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vssrl_vv_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vv_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vssrl_vv_u32m4(op0, op1, op2) \
__builtin_rvv_vssrl_vv_u32m4((vuint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vssrl_vv_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vv_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vssrl_vv_u32m8(op0, op1, op2) \
__builtin_rvv_vssrl_vv_u32m8((vuint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vssrl_vv_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vv_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vssrl_vv_u32mf2(op0, op1, op2) \
__builtin_rvv_vssrl_vv_u32mf2((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vssrl_vv_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vv_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssrl_vv_u64m1(op0, op1, op2) \
__builtin_rvv_vssrl_vv_u64m1((vuint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vssrl_vv_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vv_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssrl_vv_u64m2(op0, op1, op2) \
__builtin_rvv_vssrl_vv_u64m2((vuint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vssrl_vv_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vv_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vssrl_vv_u64m4(op0, op1, op2) \
__builtin_rvv_vssrl_vv_u64m4((vuint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vssrl_vv_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vv_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vssrl_vv_u64m8(op0, op1, op2) \
__builtin_rvv_vssrl_vv_u64m8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vssrl_vv_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vv_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vssrl_vx_u8m1(op0, op1, op2) \
__builtin_rvv_vssrl_vx_u8m1((vuint8m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssrl_vx_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vx_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vssrl_vx_u8m2(op0, op1, op2) \
__builtin_rvv_vssrl_vx_u8m2((vuint8m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssrl_vx_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vx_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vssrl_vx_u8m4(op0, op1, op2) \
__builtin_rvv_vssrl_vx_u8m4((vuint8m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssrl_vx_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vx_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vssrl_vx_u8m8(op0, op1, op2) \
__builtin_rvv_vssrl_vx_u8m8((vuint8m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssrl_vx_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vx_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vssrl_vx_u8mf2(op0, op1, op2) \
__builtin_rvv_vssrl_vx_u8mf2((vuint8mf2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssrl_vx_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vx_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vssrl_vx_u8mf4(op0, op1, op2) \
__builtin_rvv_vssrl_vx_u8mf4((vuint8mf4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssrl_vx_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vx_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vssrl_vx_u8mf8(op0, op1, op2) \
__builtin_rvv_vssrl_vx_u8mf8((vuint8mf8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssrl_vx_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vx_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssrl_vx_u16m1(op0, op1, op2) \
__builtin_rvv_vssrl_vx_u16m1((vuint16m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssrl_vx_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vx_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vssrl_vx_u16m2(op0, op1, op2) \
__builtin_rvv_vssrl_vx_u16m2((vuint16m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssrl_vx_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vx_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vssrl_vx_u16m4(op0, op1, op2) \
__builtin_rvv_vssrl_vx_u16m4((vuint16m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssrl_vx_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vx_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vssrl_vx_u16m8(op0, op1, op2) \
__builtin_rvv_vssrl_vx_u16m8((vuint16m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssrl_vx_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vx_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vssrl_vx_u16mf2(op0, op1, op2) \
__builtin_rvv_vssrl_vx_u16mf2((vuint16mf2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssrl_vx_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vx_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vssrl_vx_u16mf4(op0, op1, op2) \
__builtin_rvv_vssrl_vx_u16mf4((vuint16mf4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssrl_vx_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vx_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssrl_vx_u32m1(op0, op1, op2) \
__builtin_rvv_vssrl_vx_u32m1((vuint32m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssrl_vx_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vx_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vssrl_vx_u32m2(op0, op1, op2) \
__builtin_rvv_vssrl_vx_u32m2((vuint32m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssrl_vx_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vx_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vssrl_vx_u32m4(op0, op1, op2) \
__builtin_rvv_vssrl_vx_u32m4((vuint32m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssrl_vx_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vx_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vssrl_vx_u32m8(op0, op1, op2) \
__builtin_rvv_vssrl_vx_u32m8((vuint32m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssrl_vx_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vx_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vssrl_vx_u32mf2(op0, op1, op2) \
__builtin_rvv_vssrl_vx_u32mf2((vuint32mf2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssrl_vx_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vx_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssrl_vx_u64m1(op0, op1, op2) \
__builtin_rvv_vssrl_vx_u64m1((vuint64m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssrl_vx_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vx_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssrl_vx_u64m2(op0, op1, op2) \
__builtin_rvv_vssrl_vx_u64m2((vuint64m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssrl_vx_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vx_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vssrl_vx_u64m4(op0, op1, op2) \
__builtin_rvv_vssrl_vx_u64m4((vuint64m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssrl_vx_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vx_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vssrl_vx_u64m8(op0, op1, op2) \
__builtin_rvv_vssrl_vx_u64m8((vuint64m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssrl_vx_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vx_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vssra_vv_i8m1(op0, op1, op2) \
__builtin_rvv_vssra_vv_i8m1((vint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vssra_vv_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vv_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vssra_vv_i8m2(op0, op1, op2) \
__builtin_rvv_vssra_vv_i8m2((vint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vssra_vv_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vv_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vssra_vv_i8m4(op0, op1, op2) \
__builtin_rvv_vssra_vv_i8m4((vint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vssra_vv_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vv_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vssra_vv_i8m8(op0, op1, op2) \
__builtin_rvv_vssra_vv_i8m8((vint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vssra_vv_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vv_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vssra_vv_i8mf2(op0, op1, op2) \
__builtin_rvv_vssra_vv_i8mf2((vint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vssra_vv_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vv_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vssra_vv_i8mf4(op0, op1, op2) \
__builtin_rvv_vssra_vv_i8mf4((vint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vssra_vv_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vv_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vssra_vv_i8mf8(op0, op1, op2) \
__builtin_rvv_vssra_vv_i8mf8((vint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vssra_vv_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vv_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssra_vv_i16m1(op0, op1, op2) \
__builtin_rvv_vssra_vv_i16m1((vint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vssra_vv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vv_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vssra_vv_i16m2(op0, op1, op2) \
__builtin_rvv_vssra_vv_i16m2((vint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vssra_vv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vv_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vssra_vv_i16m4(op0, op1, op2) \
__builtin_rvv_vssra_vv_i16m4((vint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vssra_vv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vv_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vssra_vv_i16m8(op0, op1, op2) \
__builtin_rvv_vssra_vv_i16m8((vint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vssra_vv_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vv_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vssra_vv_i16mf2(op0, op1, op2) \
__builtin_rvv_vssra_vv_i16mf2((vint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vssra_vv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vv_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vssra_vv_i16mf4(op0, op1, op2) \
__builtin_rvv_vssra_vv_i16mf4((vint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vssra_vv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vv_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssra_vv_i32m1(op0, op1, op2) \
__builtin_rvv_vssra_vv_i32m1((vint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vssra_vv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vv_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vssra_vv_i32m2(op0, op1, op2) \
__builtin_rvv_vssra_vv_i32m2((vint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vssra_vv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vv_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vssra_vv_i32m4(op0, op1, op2) \
__builtin_rvv_vssra_vv_i32m4((vint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vssra_vv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vv_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vssra_vv_i32m8(op0, op1, op2) \
__builtin_rvv_vssra_vv_i32m8((vint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vssra_vv_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vv_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vssra_vv_i32mf2(op0, op1, op2) \
__builtin_rvv_vssra_vv_i32mf2((vint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vssra_vv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vv_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssra_vv_i64m1(op0, op1, op2) \
__builtin_rvv_vssra_vv_i64m1((vint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vssra_vv_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vv_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssra_vv_i64m2(op0, op1, op2) \
__builtin_rvv_vssra_vv_i64m2((vint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vssra_vv_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vv_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vssra_vv_i64m4(op0, op1, op2) \
__builtin_rvv_vssra_vv_i64m4((vint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vssra_vv_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vv_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vssra_vv_i64m8(op0, op1, op2) \
__builtin_rvv_vssra_vv_i64m8((vint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vssra_vv_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vv_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vssra_vx_i8m1(op0, op1, op2) \
__builtin_rvv_vssra_vx_i8m1((vint8m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssra_vx_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vx_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vssra_vx_i8m2(op0, op1, op2) \
__builtin_rvv_vssra_vx_i8m2((vint8m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssra_vx_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vx_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vssra_vx_i8m4(op0, op1, op2) \
__builtin_rvv_vssra_vx_i8m4((vint8m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssra_vx_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vx_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (size_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vssra_vx_i8m8(op0, op1, op2) \
__builtin_rvv_vssra_vx_i8m8((vint8m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssra_vx_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vx_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (size_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vssra_vx_i8mf2(op0, op1, op2) \
__builtin_rvv_vssra_vx_i8mf2((vint8mf2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssra_vx_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vx_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vssra_vx_i8mf4(op0, op1, op2) \
__builtin_rvv_vssra_vx_i8mf4((vint8mf4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssra_vx_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vx_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vssra_vx_i8mf8(op0, op1, op2) \
__builtin_rvv_vssra_vx_i8mf8((vint8mf8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssra_vx_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vx_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssra_vx_i16m1(op0, op1, op2) \
__builtin_rvv_vssra_vx_i16m1((vint16m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssra_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vx_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vssra_vx_i16m2(op0, op1, op2) \
__builtin_rvv_vssra_vx_i16m2((vint16m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssra_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vx_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vssra_vx_i16m4(op0, op1, op2) \
__builtin_rvv_vssra_vx_i16m4((vint16m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssra_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vx_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vssra_vx_i16m8(op0, op1, op2) \
__builtin_rvv_vssra_vx_i16m8((vint16m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssra_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vx_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (size_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vssra_vx_i16mf2(op0, op1, op2) \
__builtin_rvv_vssra_vx_i16mf2((vint16mf2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssra_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vx_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vssra_vx_i16mf4(op0, op1, op2) \
__builtin_rvv_vssra_vx_i16mf4((vint16mf4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssra_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vx_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssra_vx_i32m1(op0, op1, op2) \
__builtin_rvv_vssra_vx_i32m1((vint32m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssra_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vx_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vssra_vx_i32m2(op0, op1, op2) \
__builtin_rvv_vssra_vx_i32m2((vint32m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssra_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vx_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vssra_vx_i32m4(op0, op1, op2) \
__builtin_rvv_vssra_vx_i32m4((vint32m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssra_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vx_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vssra_vx_i32m8(op0, op1, op2) \
__builtin_rvv_vssra_vx_i32m8((vint32m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssra_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vx_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vssra_vx_i32mf2(op0, op1, op2) \
__builtin_rvv_vssra_vx_i32mf2((vint32mf2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssra_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vx_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssra_vx_i64m1(op0, op1, op2) \
__builtin_rvv_vssra_vx_i64m1((vint64m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssra_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vx_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssra_vx_i64m2(op0, op1, op2) \
__builtin_rvv_vssra_vx_i64m2((vint64m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssra_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vx_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vssra_vx_i64m4(op0, op1, op2) \
__builtin_rvv_vssra_vx_i64m4((vint64m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssra_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vx_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vssra_vx_i64m8(op0, op1, op2) \
__builtin_rvv_vssra_vx_i64m8((vint64m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssra_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vx_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnclipu_wv_u8m1(op0, op1, op2) \
__builtin_rvv_vnclipu_wv_u8m1((vuint16m2_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vnclipu_wv_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclipu_wv_u8m1_m((vuint8m1_t)(op0), (vuint16m2_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnclipu_wv_u8m2(op0, op1, op2) \
__builtin_rvv_vnclipu_wv_u8m2((vuint16m4_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vnclipu_wv_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclipu_wv_u8m2_m((vuint8m2_t)(op0), (vuint16m4_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnclipu_wv_u8m4(op0, op1, op2) \
__builtin_rvv_vnclipu_wv_u8m4((vuint16m8_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vnclipu_wv_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclipu_wv_u8m4_m((vuint8m4_t)(op0), (vuint16m8_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vnclipu_wv_u8mf2(op0, op1, op2) \
__builtin_rvv_vnclipu_wv_u8mf2((vuint16m1_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vnclipu_wv_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclipu_wv_u8mf2_m((vuint8mf2_t)(op0), (vuint16m1_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnclipu_wv_u8mf4(op0, op1, op2) \
__builtin_rvv_vnclipu_wv_u8mf4((vuint16mf2_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vnclipu_wv_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclipu_wv_u8mf4_m((vuint8mf4_t)(op0), (vuint16mf2_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnclipu_wv_u8mf8(op0, op1, op2) \
__builtin_rvv_vnclipu_wv_u8mf8((vuint16mf4_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vnclipu_wv_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclipu_wv_u8mf8_m((vuint8mf8_t)(op0), (vuint16mf4_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnclipu_wv_u16m1(op0, op1, op2) \
__builtin_rvv_vnclipu_wv_u16m1((vuint32m2_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vnclipu_wv_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclipu_wv_u16m1_m((vuint16m1_t)(op0), (vuint32m2_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnclipu_wv_u16m2(op0, op1, op2) \
__builtin_rvv_vnclipu_wv_u16m2((vuint32m4_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vnclipu_wv_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclipu_wv_u16m2_m((vuint16m2_t)(op0), (vuint32m4_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnclipu_wv_u16m4(op0, op1, op2) \
__builtin_rvv_vnclipu_wv_u16m4((vuint32m8_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vnclipu_wv_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclipu_wv_u16m4_m((vuint16m4_t)(op0), (vuint32m8_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnclipu_wv_u16mf2(op0, op1, op2) \
__builtin_rvv_vnclipu_wv_u16mf2((vuint32m1_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vnclipu_wv_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclipu_wv_u16mf2_m((vuint16mf2_t)(op0), (vuint32m1_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnclipu_wv_u16mf4(op0, op1, op2) \
__builtin_rvv_vnclipu_wv_u16mf4((vuint32mf2_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vnclipu_wv_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclipu_wv_u16mf4_m((vuint16mf4_t)(op0), (vuint32mf2_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnclipu_wv_u32m1(op0, op1, op2) \
__builtin_rvv_vnclipu_wv_u32m1((vuint64m2_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vnclipu_wv_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclipu_wv_u32m1_m((vuint32m1_t)(op0), (vuint64m2_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnclipu_wv_u32m2(op0, op1, op2) \
__builtin_rvv_vnclipu_wv_u32m2((vuint64m4_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vnclipu_wv_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclipu_wv_u32m2_m((vuint32m2_t)(op0), (vuint64m4_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnclipu_wv_u32m4(op0, op1, op2) \
__builtin_rvv_vnclipu_wv_u32m4((vuint64m8_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vnclipu_wv_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclipu_wv_u32m4_m((vuint32m4_t)(op0), (vuint64m8_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnclipu_wv_u32mf2(op0, op1, op2) \
__builtin_rvv_vnclipu_wv_u32mf2((vuint64m1_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vnclipu_wv_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclipu_wv_u32mf2_m((vuint32mf2_t)(op0), (vuint64m1_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnclipu_wx_u8m1(op0, op1, op2) \
__builtin_rvv_vnclipu_wx_u8m1((vuint16m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnclipu_wx_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclipu_wx_u8m1_m((vuint8m1_t)(op0), (vuint16m2_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnclipu_wx_u8m2(op0, op1, op2) \
__builtin_rvv_vnclipu_wx_u8m2((vuint16m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnclipu_wx_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclipu_wx_u8m2_m((vuint8m2_t)(op0), (vuint16m4_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnclipu_wx_u8m4(op0, op1, op2) \
__builtin_rvv_vnclipu_wx_u8m4((vuint16m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnclipu_wx_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclipu_wx_u8m4_m((vuint8m4_t)(op0), (vuint16m8_t)(op1), (size_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vnclipu_wx_u8mf2(op0, op1, op2) \
__builtin_rvv_vnclipu_wx_u8mf2((vuint16m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnclipu_wx_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclipu_wx_u8mf2_m((vuint8mf2_t)(op0), (vuint16m1_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnclipu_wx_u8mf4(op0, op1, op2) \
__builtin_rvv_vnclipu_wx_u8mf4((vuint16mf2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnclipu_wx_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclipu_wx_u8mf4_m((vuint8mf4_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnclipu_wx_u8mf8(op0, op1, op2) \
__builtin_rvv_vnclipu_wx_u8mf8((vuint16mf4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnclipu_wx_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclipu_wx_u8mf8_m((vuint8mf8_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnclipu_wx_u16m1(op0, op1, op2) \
__builtin_rvv_vnclipu_wx_u16m1((vuint32m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnclipu_wx_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclipu_wx_u16m1_m((vuint16m1_t)(op0), (vuint32m2_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnclipu_wx_u16m2(op0, op1, op2) \
__builtin_rvv_vnclipu_wx_u16m2((vuint32m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnclipu_wx_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclipu_wx_u16m2_m((vuint16m2_t)(op0), (vuint32m4_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnclipu_wx_u16m4(op0, op1, op2) \
__builtin_rvv_vnclipu_wx_u16m4((vuint32m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnclipu_wx_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclipu_wx_u16m4_m((vuint16m4_t)(op0), (vuint32m8_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnclipu_wx_u16mf2(op0, op1, op2) \
__builtin_rvv_vnclipu_wx_u16mf2((vuint32m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnclipu_wx_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclipu_wx_u16mf2_m((vuint16mf2_t)(op0), (vuint32m1_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnclipu_wx_u16mf4(op0, op1, op2) \
__builtin_rvv_vnclipu_wx_u16mf4((vuint32mf2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnclipu_wx_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclipu_wx_u16mf4_m((vuint16mf4_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnclipu_wx_u32m1(op0, op1, op2) \
__builtin_rvv_vnclipu_wx_u32m1((vuint64m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnclipu_wx_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclipu_wx_u32m1_m((vuint32m1_t)(op0), (vuint64m2_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnclipu_wx_u32m2(op0, op1, op2) \
__builtin_rvv_vnclipu_wx_u32m2((vuint64m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnclipu_wx_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclipu_wx_u32m2_m((vuint32m2_t)(op0), (vuint64m4_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnclipu_wx_u32m4(op0, op1, op2) \
__builtin_rvv_vnclipu_wx_u32m4((vuint64m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnclipu_wx_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclipu_wx_u32m4_m((vuint32m4_t)(op0), (vuint64m8_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnclipu_wx_u32mf2(op0, op1, op2) \
__builtin_rvv_vnclipu_wx_u32mf2((vuint64m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnclipu_wx_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclipu_wx_u32mf2_m((vuint32mf2_t)(op0), (vuint64m1_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnclip_wv_i8m1(op0, op1, op2) \
__builtin_rvv_vnclip_wv_i8m1((vint16m2_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vnclip_wv_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclip_wv_i8m1_m((vint8m1_t)(op0), (vint16m2_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnclip_wv_i8m2(op0, op1, op2) \
__builtin_rvv_vnclip_wv_i8m2((vint16m4_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vnclip_wv_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclip_wv_i8m2_m((vint8m2_t)(op0), (vint16m4_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnclip_wv_i8m4(op0, op1, op2) \
__builtin_rvv_vnclip_wv_i8m4((vint16m8_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vnclip_wv_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclip_wv_i8m4_m((vint8m4_t)(op0), (vint16m8_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vnclip_wv_i8mf2(op0, op1, op2) \
__builtin_rvv_vnclip_wv_i8mf2((vint16m1_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vnclip_wv_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclip_wv_i8mf2_m((vint8mf2_t)(op0), (vint16m1_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnclip_wv_i8mf4(op0, op1, op2) \
__builtin_rvv_vnclip_wv_i8mf4((vint16mf2_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vnclip_wv_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclip_wv_i8mf4_m((vint8mf4_t)(op0), (vint16mf2_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnclip_wv_i8mf8(op0, op1, op2) \
__builtin_rvv_vnclip_wv_i8mf8((vint16mf4_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vnclip_wv_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclip_wv_i8mf8_m((vint8mf8_t)(op0), (vint16mf4_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnclip_wv_i16m1(op0, op1, op2) \
__builtin_rvv_vnclip_wv_i16m1((vint32m2_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vnclip_wv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclip_wv_i16m1_m((vint16m1_t)(op0), (vint32m2_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnclip_wv_i16m2(op0, op1, op2) \
__builtin_rvv_vnclip_wv_i16m2((vint32m4_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vnclip_wv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclip_wv_i16m2_m((vint16m2_t)(op0), (vint32m4_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnclip_wv_i16m4(op0, op1, op2) \
__builtin_rvv_vnclip_wv_i16m4((vint32m8_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vnclip_wv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclip_wv_i16m4_m((vint16m4_t)(op0), (vint32m8_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnclip_wv_i16mf2(op0, op1, op2) \
__builtin_rvv_vnclip_wv_i16mf2((vint32m1_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vnclip_wv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclip_wv_i16mf2_m((vint16mf2_t)(op0), (vint32m1_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnclip_wv_i16mf4(op0, op1, op2) \
__builtin_rvv_vnclip_wv_i16mf4((vint32mf2_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vnclip_wv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclip_wv_i16mf4_m((vint16mf4_t)(op0), (vint32mf2_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnclip_wv_i32m1(op0, op1, op2) \
__builtin_rvv_vnclip_wv_i32m1((vint64m2_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vnclip_wv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclip_wv_i32m1_m((vint32m1_t)(op0), (vint64m2_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnclip_wv_i32m2(op0, op1, op2) \
__builtin_rvv_vnclip_wv_i32m2((vint64m4_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vnclip_wv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclip_wv_i32m2_m((vint32m2_t)(op0), (vint64m4_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnclip_wv_i32m4(op0, op1, op2) \
__builtin_rvv_vnclip_wv_i32m4((vint64m8_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vnclip_wv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclip_wv_i32m4_m((vint32m4_t)(op0), (vint64m8_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnclip_wv_i32mf2(op0, op1, op2) \
__builtin_rvv_vnclip_wv_i32mf2((vint64m1_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vnclip_wv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclip_wv_i32mf2_m((vint32mf2_t)(op0), (vint64m1_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnclip_wx_i8m1(op0, op1, op2) \
__builtin_rvv_vnclip_wx_i8m1((vint16m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnclip_wx_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclip_wx_i8m1_m((vint8m1_t)(op0), (vint16m2_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnclip_wx_i8m2(op0, op1, op2) \
__builtin_rvv_vnclip_wx_i8m2((vint16m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnclip_wx_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclip_wx_i8m2_m((vint8m2_t)(op0), (vint16m4_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnclip_wx_i8m4(op0, op1, op2) \
__builtin_rvv_vnclip_wx_i8m4((vint16m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnclip_wx_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclip_wx_i8m4_m((vint8m4_t)(op0), (vint16m8_t)(op1), (size_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vnclip_wx_i8mf2(op0, op1, op2) \
__builtin_rvv_vnclip_wx_i8mf2((vint16m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnclip_wx_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclip_wx_i8mf2_m((vint8mf2_t)(op0), (vint16m1_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnclip_wx_i8mf4(op0, op1, op2) \
__builtin_rvv_vnclip_wx_i8mf4((vint16mf2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnclip_wx_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclip_wx_i8mf4_m((vint8mf4_t)(op0), (vint16mf2_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnclip_wx_i8mf8(op0, op1, op2) \
__builtin_rvv_vnclip_wx_i8mf8((vint16mf4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnclip_wx_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclip_wx_i8mf8_m((vint8mf8_t)(op0), (vint16mf4_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnclip_wx_i16m1(op0, op1, op2) \
__builtin_rvv_vnclip_wx_i16m1((vint32m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnclip_wx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclip_wx_i16m1_m((vint16m1_t)(op0), (vint32m2_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnclip_wx_i16m2(op0, op1, op2) \
__builtin_rvv_vnclip_wx_i16m2((vint32m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnclip_wx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclip_wx_i16m2_m((vint16m2_t)(op0), (vint32m4_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnclip_wx_i16m4(op0, op1, op2) \
__builtin_rvv_vnclip_wx_i16m4((vint32m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnclip_wx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclip_wx_i16m4_m((vint16m4_t)(op0), (vint32m8_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnclip_wx_i16mf2(op0, op1, op2) \
__builtin_rvv_vnclip_wx_i16mf2((vint32m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnclip_wx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclip_wx_i16mf2_m((vint16mf2_t)(op0), (vint32m1_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnclip_wx_i16mf4(op0, op1, op2) \
__builtin_rvv_vnclip_wx_i16mf4((vint32mf2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnclip_wx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclip_wx_i16mf4_m((vint16mf4_t)(op0), (vint32mf2_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnclip_wx_i32m1(op0, op1, op2) \
__builtin_rvv_vnclip_wx_i32m1((vint64m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnclip_wx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclip_wx_i32m1_m((vint32m1_t)(op0), (vint64m2_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnclip_wx_i32m2(op0, op1, op2) \
__builtin_rvv_vnclip_wx_i32m2((vint64m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnclip_wx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclip_wx_i32m2_m((vint32m2_t)(op0), (vint64m4_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnclip_wx_i32m4(op0, op1, op2) \
__builtin_rvv_vnclip_wx_i32m4((vint64m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnclip_wx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclip_wx_i32m4_m((vint32m4_t)(op0), (vint64m8_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnclip_wx_i32mf2(op0, op1, op2) \
__builtin_rvv_vnclip_wx_i32mf2((vint64m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnclip_wx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclip_wx_i32mf2_m((vint32mf2_t)(op0), (vint64m1_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vle64ff_v_i64m1(op0, op1, op2) \
__builtin_rvv_vle64ff_v_i64m1((const int64_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle64ff_v_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle64ff_v_i64m1_m((vint64m1_t)(op0), (const int64_t *)(op1), (size_t *)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vle64ff_v_i64m2(op0, op1, op2) \
__builtin_rvv_vle64ff_v_i64m2((const int64_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle64ff_v_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle64ff_v_i64m2_m((vint64m2_t)(op0), (const int64_t *)(op1), (size_t *)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vle64ff_v_i64m4(op0, op1, op2) \
__builtin_rvv_vle64ff_v_i64m4((const int64_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle64ff_v_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle64ff_v_i64m4_m((vint64m4_t)(op0), (const int64_t *)(op1), (size_t *)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vle64ff_v_i64m8(op0, op1, op2) \
__builtin_rvv_vle64ff_v_i64m8((const int64_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle64ff_v_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle64ff_v_i64m8_m((vint64m8_t)(op0), (const int64_t *)(op1), (size_t *)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vle64ff_v_u64m1(op0, op1, op2) \
__builtin_rvv_vle64ff_v_u64m1((const uint64_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle64ff_v_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle64ff_v_u64m1_m((vuint64m1_t)(op0), (const uint64_t *)(op1), (size_t *)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vle64ff_v_u64m2(op0, op1, op2) \
__builtin_rvv_vle64ff_v_u64m2((const uint64_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle64ff_v_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle64ff_v_u64m2_m((vuint64m2_t)(op0), (const uint64_t *)(op1), (size_t *)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vle64ff_v_u64m4(op0, op1, op2) \
__builtin_rvv_vle64ff_v_u64m4((const uint64_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle64ff_v_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle64ff_v_u64m4_m((vuint64m4_t)(op0), (const uint64_t *)(op1), (size_t *)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vle64ff_v_u64m8(op0, op1, op2) \
__builtin_rvv_vle64ff_v_u64m8((const uint64_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle64ff_v_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle64ff_v_u64m8_m((vuint64m8_t)(op0), (const uint64_t *)(op1), (size_t *)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei8_v_i8m1(op0, op1, op2) \
__builtin_rvv_vluxei8_v_i8m1((const int8_t *)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vluxei8_v_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_i8m1_m((vint8m1_t)(op0), (const int8_t *)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei8_v_i8m2(op0, op1, op2) \
__builtin_rvv_vluxei8_v_i8m2((const int8_t *)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vluxei8_v_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_i8m2_m((vint8m2_t)(op0), (const int8_t *)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vluxei8_v_i8m4(op0, op1, op2) \
__builtin_rvv_vluxei8_v_i8m4((const int8_t *)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vluxei8_v_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_i8m4_m((vint8m4_t)(op0), (const int8_t *)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vluxei8_v_i8m8(op0, op1, op2) \
__builtin_rvv_vluxei8_v_i8m8((const int8_t *)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vluxei8_v_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_i8m8_m((vint8m8_t)(op0), (const int8_t *)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vluxei8_v_i8mf2(op0, op1, op2) \
__builtin_rvv_vluxei8_v_i8mf2((const int8_t *)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vluxei8_v_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_i8mf2_m((vint8mf2_t)(op0), (const int8_t *)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei8_v_i8mf4(op0, op1, op2) \
__builtin_rvv_vluxei8_v_i8mf4((const int8_t *)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vluxei8_v_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_i8mf4_m((vint8mf4_t)(op0), (const int8_t *)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei8_v_i8mf8(op0, op1, op2) \
__builtin_rvv_vluxei8_v_i8mf8((const int8_t *)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vluxei8_v_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_i8mf8_m((vint8mf8_t)(op0), (const int8_t *)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vse16_v_i16m1(op1, op0, op2) \
__builtin_rvv_vse16_v_i16m1((vint16m1_t)(op0), (int16_t *)(op1), (size_t)(op2))
#define vse16_v_i16m1_m(op2, op1, op0, op3) \
__builtin_rvv_vse16_v_i16m1_m((vint16m1_t)(op0), (int16_t *)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vse16_v_i16m2(op1, op0, op2) \
__builtin_rvv_vse16_v_i16m2((vint16m2_t)(op0), (int16_t *)(op1), (size_t)(op2))
#define vse16_v_i16m2_m(op2, op1, op0, op3) \
__builtin_rvv_vse16_v_i16m2_m((vint16m2_t)(op0), (int16_t *)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vse16_v_i16m4(op1, op0, op2) \
__builtin_rvv_vse16_v_i16m4((vint16m4_t)(op0), (int16_t *)(op1), (size_t)(op2))
#define vse16_v_i16m4_m(op2, op1, op0, op3) \
__builtin_rvv_vse16_v_i16m4_m((vint16m4_t)(op0), (int16_t *)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vse16_v_i16m8(op1, op0, op2) \
__builtin_rvv_vse16_v_i16m8((vint16m8_t)(op0), (int16_t *)(op1), (size_t)(op2))
#define vse16_v_i16m8_m(op2, op1, op0, op3) \
__builtin_rvv_vse16_v_i16m8_m((vint16m8_t)(op0), (int16_t *)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vse16_v_i16mf2(op1, op0, op2) \
__builtin_rvv_vse16_v_i16mf2((vint16mf2_t)(op0), (int16_t *)(op1), (size_t)(op2))
#define vse16_v_i16mf2_m(op2, op1, op0, op3) \
__builtin_rvv_vse16_v_i16mf2_m((vint16mf2_t)(op0), (int16_t *)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vse16_v_i16mf4(op1, op0, op2) \
__builtin_rvv_vse16_v_i16mf4((vint16mf4_t)(op0), (int16_t *)(op1), (size_t)(op2))
#define vse16_v_i16mf4_m(op2, op1, op0, op3) \
__builtin_rvv_vse16_v_i16mf4_m((vint16mf4_t)(op0), (int16_t *)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vse16_v_u16m1(op1, op0, op2) \
__builtin_rvv_vse16_v_u16m1((vuint16m1_t)(op0), (uint16_t *)(op1), (size_t)(op2))
#define vse16_v_u16m1_m(op2, op1, op0, op3) \
__builtin_rvv_vse16_v_u16m1_m((vuint16m1_t)(op0), (uint16_t *)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vse16_v_u16m2(op1, op0, op2) \
__builtin_rvv_vse16_v_u16m2((vuint16m2_t)(op0), (uint16_t *)(op1), (size_t)(op2))
#define vse16_v_u16m2_m(op2, op1, op0, op3) \
__builtin_rvv_vse16_v_u16m2_m((vuint16m2_t)(op0), (uint16_t *)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vse16_v_u16m4(op1, op0, op2) \
__builtin_rvv_vse16_v_u16m4((vuint16m4_t)(op0), (uint16_t *)(op1), (size_t)(op2))
#define vse16_v_u16m4_m(op2, op1, op0, op3) \
__builtin_rvv_vse16_v_u16m4_m((vuint16m4_t)(op0), (uint16_t *)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vse16_v_u16m8(op1, op0, op2) \
__builtin_rvv_vse16_v_u16m8((vuint16m8_t)(op0), (uint16_t *)(op1), (size_t)(op2))
#define vse16_v_u16m8_m(op2, op1, op0, op3) \
__builtin_rvv_vse16_v_u16m8_m((vuint16m8_t)(op0), (uint16_t *)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vse16_v_u16mf2(op1, op0, op2) \
__builtin_rvv_vse16_v_u16mf2((vuint16mf2_t)(op0), (uint16_t *)(op1), (size_t)(op2))
#define vse16_v_u16mf2_m(op2, op1, op0, op3) \
__builtin_rvv_vse16_v_u16mf2_m((vuint16mf2_t)(op0), (uint16_t *)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vse16_v_u16mf4(op1, op0, op2) \
__builtin_rvv_vse16_v_u16mf4((vuint16mf4_t)(op0), (uint16_t *)(op1), (size_t)(op2))
#define vse16_v_u16mf4_m(op2, op1, op0, op3) \
__builtin_rvv_vse16_v_u16mf4_m((vuint16mf4_t)(op0), (uint16_t *)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vse32_v_i32m1(op1, op0, op2) \
__builtin_rvv_vse32_v_i32m1((vint32m1_t)(op0), (int32_t *)(op1), (size_t)(op2))
#define vse32_v_i32m1_m(op2, op1, op0, op3) \
__builtin_rvv_vse32_v_i32m1_m((vint32m1_t)(op0), (int32_t *)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vse32_v_i32m2(op1, op0, op2) \
__builtin_rvv_vse32_v_i32m2((vint32m2_t)(op0), (int32_t *)(op1), (size_t)(op2))
#define vse32_v_i32m2_m(op2, op1, op0, op3) \
__builtin_rvv_vse32_v_i32m2_m((vint32m2_t)(op0), (int32_t *)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vse32_v_i32m4(op1, op0, op2) \
__builtin_rvv_vse32_v_i32m4((vint32m4_t)(op0), (int32_t *)(op1), (size_t)(op2))
#define vse32_v_i32m4_m(op2, op1, op0, op3) \
__builtin_rvv_vse32_v_i32m4_m((vint32m4_t)(op0), (int32_t *)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vse32_v_i32m8(op1, op0, op2) \
__builtin_rvv_vse32_v_i32m8((vint32m8_t)(op0), (int32_t *)(op1), (size_t)(op2))
#define vse32_v_i32m8_m(op2, op1, op0, op3) \
__builtin_rvv_vse32_v_i32m8_m((vint32m8_t)(op0), (int32_t *)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vse32_v_i32mf2(op1, op0, op2) \
__builtin_rvv_vse32_v_i32mf2((vint32mf2_t)(op0), (int32_t *)(op1), (size_t)(op2))
#define vse32_v_i32mf2_m(op2, op1, op0, op3) \
__builtin_rvv_vse32_v_i32mf2_m((vint32mf2_t)(op0), (int32_t *)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vse32_v_u32m1(op1, op0, op2) \
__builtin_rvv_vse32_v_u32m1((vuint32m1_t)(op0), (uint32_t *)(op1), (size_t)(op2))
#define vse32_v_u32m1_m(op2, op1, op0, op3) \
__builtin_rvv_vse32_v_u32m1_m((vuint32m1_t)(op0), (uint32_t *)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vse32_v_u32m2(op1, op0, op2) \
__builtin_rvv_vse32_v_u32m2((vuint32m2_t)(op0), (uint32_t *)(op1), (size_t)(op2))
#define vse32_v_u32m2_m(op2, op1, op0, op3) \
__builtin_rvv_vse32_v_u32m2_m((vuint32m2_t)(op0), (uint32_t *)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vse32_v_u32m4(op1, op0, op2) \
__builtin_rvv_vse32_v_u32m4((vuint32m4_t)(op0), (uint32_t *)(op1), (size_t)(op2))
#define vse32_v_u32m4_m(op2, op1, op0, op3) \
__builtin_rvv_vse32_v_u32m4_m((vuint32m4_t)(op0), (uint32_t *)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vse32_v_u32m8(op1, op0, op2) \
__builtin_rvv_vse32_v_u32m8((vuint32m8_t)(op0), (uint32_t *)(op1), (size_t)(op2))
#define vse32_v_u32m8_m(op2, op1, op0, op3) \
__builtin_rvv_vse32_v_u32m8_m((vuint32m8_t)(op0), (uint32_t *)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vse32_v_u32mf2(op1, op0, op2) \
__builtin_rvv_vse32_v_u32mf2((vuint32mf2_t)(op0), (uint32_t *)(op1), (size_t)(op2))
#define vse32_v_u32mf2_m(op2, op1, op0, op3) \
__builtin_rvv_vse32_v_u32mf2_m((vuint32mf2_t)(op0), (uint32_t *)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vse64_v_i64m1(op1, op0, op2) \
__builtin_rvv_vse64_v_i64m1((vint64m1_t)(op0), (int64_t *)(op1), (size_t)(op2))
#define vse64_v_i64m1_m(op2, op1, op0, op3) \
__builtin_rvv_vse64_v_i64m1_m((vint64m1_t)(op0), (int64_t *)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vse64_v_i64m2(op1, op0, op2) \
__builtin_rvv_vse64_v_i64m2((vint64m2_t)(op0), (int64_t *)(op1), (size_t)(op2))
#define vse64_v_i64m2_m(op2, op1, op0, op3) \
__builtin_rvv_vse64_v_i64m2_m((vint64m2_t)(op0), (int64_t *)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vse64_v_i64m4(op1, op0, op2) \
__builtin_rvv_vse64_v_i64m4((vint64m4_t)(op0), (int64_t *)(op1), (size_t)(op2))
#define vse64_v_i64m4_m(op2, op1, op0, op3) \
__builtin_rvv_vse64_v_i64m4_m((vint64m4_t)(op0), (int64_t *)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vse64_v_i64m8(op1, op0, op2) \
__builtin_rvv_vse64_v_i64m8((vint64m8_t)(op0), (int64_t *)(op1), (size_t)(op2))
#define vse64_v_i64m8_m(op2, op1, op0, op3) \
__builtin_rvv_vse64_v_i64m8_m((vint64m8_t)(op0), (int64_t *)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vse64_v_u64m1(op1, op0, op2) \
__builtin_rvv_vse64_v_u64m1((vuint64m1_t)(op0), (uint64_t *)(op1), (size_t)(op2))
#define vse64_v_u64m1_m(op2, op1, op0, op3) \
__builtin_rvv_vse64_v_u64m1_m((vuint64m1_t)(op0), (uint64_t *)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vse64_v_u64m2(op1, op0, op2) \
__builtin_rvv_vse64_v_u64m2((vuint64m2_t)(op0), (uint64_t *)(op1), (size_t)(op2))
#define vse64_v_u64m2_m(op2, op1, op0, op3) \
__builtin_rvv_vse64_v_u64m2_m((vuint64m2_t)(op0), (uint64_t *)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vse64_v_u64m4(op1, op0, op2) \
__builtin_rvv_vse64_v_u64m4((vuint64m4_t)(op0), (uint64_t *)(op1), (size_t)(op2))
#define vse64_v_u64m4_m(op2, op1, op0, op3) \
__builtin_rvv_vse64_v_u64m4_m((vuint64m4_t)(op0), (uint64_t *)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vse64_v_u64m8(op1, op0, op2) \
__builtin_rvv_vse64_v_u64m8((vuint64m8_t)(op0), (uint64_t *)(op1), (size_t)(op2))
#define vse64_v_u64m8_m(op2, op1, op0, op3) \
__builtin_rvv_vse64_v_u64m8_m((vuint64m8_t)(op0), (uint64_t *)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vluxei8_v_u8m1(op0, op1, op2) \
__builtin_rvv_vluxei8_v_u8m1((const uint8_t *)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vluxei8_v_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_u8m1_m((vuint8m1_t)(op0), (const uint8_t *)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei8_v_u8m2(op0, op1, op2) \
__builtin_rvv_vluxei8_v_u8m2((const uint8_t *)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vluxei8_v_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_u8m2_m((vuint8m2_t)(op0), (const uint8_t *)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vluxei8_v_u8m4(op0, op1, op2) \
__builtin_rvv_vluxei8_v_u8m4((const uint8_t *)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vluxei8_v_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_u8m4_m((vuint8m4_t)(op0), (const uint8_t *)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vluxei8_v_u8m8(op0, op1, op2) \
__builtin_rvv_vluxei8_v_u8m8((const uint8_t *)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vluxei8_v_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_u8m8_m((vuint8m8_t)(op0), (const uint8_t *)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vluxei8_v_u8mf2(op0, op1, op2) \
__builtin_rvv_vluxei8_v_u8mf2((const uint8_t *)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vluxei8_v_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_u8mf2_m((vuint8mf2_t)(op0), (const uint8_t *)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei8_v_u8mf4(op0, op1, op2) \
__builtin_rvv_vluxei8_v_u8mf4((const uint8_t *)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vluxei8_v_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_u8mf4_m((vuint8mf4_t)(op0), (const uint8_t *)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei8_v_u8mf8(op0, op1, op2) \
__builtin_rvv_vluxei8_v_u8mf8((const uint8_t *)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vluxei8_v_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_u8mf8_m((vuint8mf8_t)(op0), (const uint8_t *)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei16_v_i8m1(op0, op1, op2) \
__builtin_rvv_vluxei16_v_i8m1((const int8_t *)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vluxei16_v_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_i8m1_m((vint8m1_t)(op0), (const int8_t *)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei16_v_i8m2(op0, op1, op2) \
__builtin_rvv_vluxei16_v_i8m2((const int8_t *)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vluxei16_v_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_i8m2_m((vint8m2_t)(op0), (const int8_t *)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vluxei16_v_i8m4(op0, op1, op2) \
__builtin_rvv_vluxei16_v_i8m4((const int8_t *)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vluxei16_v_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_i8m4_m((vint8m4_t)(op0), (const int8_t *)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vluxei16_v_i8mf2(op0, op1, op2) \
__builtin_rvv_vluxei16_v_i8mf2((const int8_t *)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vluxei16_v_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_i8mf2_m((vint8mf2_t)(op0), (const int8_t *)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei16_v_i8mf4(op0, op1, op2) \
__builtin_rvv_vluxei16_v_i8mf4((const int8_t *)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vluxei16_v_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_i8mf4_m((vint8mf4_t)(op0), (const int8_t *)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei16_v_i8mf8(op0, op1, op2) \
__builtin_rvv_vluxei16_v_i8mf8((const int8_t *)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vluxei16_v_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_i8mf8_m((vint8mf8_t)(op0), (const int8_t *)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei16_v_u8m1(op0, op1, op2) \
__builtin_rvv_vluxei16_v_u8m1((const uint8_t *)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vluxei16_v_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_u8m1_m((vuint8m1_t)(op0), (const uint8_t *)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei16_v_u8m2(op0, op1, op2) \
__builtin_rvv_vluxei16_v_u8m2((const uint8_t *)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vluxei16_v_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_u8m2_m((vuint8m2_t)(op0), (const uint8_t *)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vluxei16_v_u8m4(op0, op1, op2) \
__builtin_rvv_vluxei16_v_u8m4((const uint8_t *)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vluxei16_v_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_u8m4_m((vuint8m4_t)(op0), (const uint8_t *)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vluxei16_v_u8mf2(op0, op1, op2) \
__builtin_rvv_vluxei16_v_u8mf2((const uint8_t *)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vluxei16_v_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_u8mf2_m((vuint8mf2_t)(op0), (const uint8_t *)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei16_v_u8mf4(op0, op1, op2) \
__builtin_rvv_vluxei16_v_u8mf4((const uint8_t *)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vluxei16_v_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_u8mf4_m((vuint8mf4_t)(op0), (const uint8_t *)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei16_v_u8mf8(op0, op1, op2) \
__builtin_rvv_vluxei16_v_u8mf8((const uint8_t *)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vluxei16_v_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_u8mf8_m((vuint8mf8_t)(op0), (const uint8_t *)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei32_v_i8m1(op0, op1, op2) \
__builtin_rvv_vluxei32_v_i8m1((const int8_t *)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vluxei32_v_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_i8m1_m((vint8m1_t)(op0), (const int8_t *)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei32_v_i8m2(op0, op1, op2) \
__builtin_rvv_vluxei32_v_i8m2((const int8_t *)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vluxei32_v_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_i8m2_m((vint8m2_t)(op0), (const int8_t *)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vluxei32_v_i8mf2(op0, op1, op2) \
__builtin_rvv_vluxei32_v_i8mf2((const int8_t *)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vluxei32_v_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_i8mf2_m((vint8mf2_t)(op0), (const int8_t *)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei32_v_i8mf4(op0, op1, op2) \
__builtin_rvv_vluxei32_v_i8mf4((const int8_t *)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vluxei32_v_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_i8mf4_m((vint8mf4_t)(op0), (const int8_t *)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei32_v_i8mf8(op0, op1, op2) \
__builtin_rvv_vluxei32_v_i8mf8((const int8_t *)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vluxei32_v_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_i8mf8_m((vint8mf8_t)(op0), (const int8_t *)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei32_v_u8m1(op0, op1, op2) \
__builtin_rvv_vluxei32_v_u8m1((const uint8_t *)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vluxei32_v_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_u8m1_m((vuint8m1_t)(op0), (const uint8_t *)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei32_v_u8m2(op0, op1, op2) \
__builtin_rvv_vluxei32_v_u8m2((const uint8_t *)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vluxei32_v_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_u8m2_m((vuint8m2_t)(op0), (const uint8_t *)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vluxei32_v_u8mf2(op0, op1, op2) \
__builtin_rvv_vluxei32_v_u8mf2((const uint8_t *)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vluxei32_v_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_u8mf2_m((vuint8mf2_t)(op0), (const uint8_t *)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei32_v_u8mf4(op0, op1, op2) \
__builtin_rvv_vluxei32_v_u8mf4((const uint8_t *)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vluxei32_v_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_u8mf4_m((vuint8mf4_t)(op0), (const uint8_t *)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei32_v_u8mf8(op0, op1, op2) \
__builtin_rvv_vluxei32_v_u8mf8((const uint8_t *)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vluxei32_v_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_u8mf8_m((vuint8mf8_t)(op0), (const uint8_t *)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei64_v_i8m1(op0, op1, op2) \
__builtin_rvv_vluxei64_v_i8m1((const int8_t *)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vluxei64_v_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_i8m1_m((vint8m1_t)(op0), (const int8_t *)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei64_v_i8mf2(op0, op1, op2) \
__builtin_rvv_vluxei64_v_i8mf2((const int8_t *)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vluxei64_v_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_i8mf2_m((vint8mf2_t)(op0), (const int8_t *)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei64_v_i8mf4(op0, op1, op2) \
__builtin_rvv_vluxei64_v_i8mf4((const int8_t *)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vluxei64_v_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_i8mf4_m((vint8mf4_t)(op0), (const int8_t *)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei64_v_i8mf8(op0, op1, op2) \
__builtin_rvv_vluxei64_v_i8mf8((const int8_t *)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vluxei64_v_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_i8mf8_m((vint8mf8_t)(op0), (const int8_t *)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei64_v_u8m1(op0, op1, op2) \
__builtin_rvv_vluxei64_v_u8m1((const uint8_t *)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vluxei64_v_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_u8m1_m((vuint8m1_t)(op0), (const uint8_t *)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei64_v_u8mf2(op0, op1, op2) \
__builtin_rvv_vluxei64_v_u8mf2((const uint8_t *)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vluxei64_v_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_u8mf2_m((vuint8mf2_t)(op0), (const uint8_t *)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei64_v_u8mf4(op0, op1, op2) \
__builtin_rvv_vluxei64_v_u8mf4((const uint8_t *)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vluxei64_v_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_u8mf4_m((vuint8mf4_t)(op0), (const uint8_t *)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei64_v_u8mf8(op0, op1, op2) \
__builtin_rvv_vluxei64_v_u8mf8((const uint8_t *)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vluxei64_v_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_u8mf8_m((vuint8mf8_t)(op0), (const uint8_t *)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei8_v_i16m1(op0, op1, op2) \
__builtin_rvv_vluxei8_v_i16m1((const int16_t *)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vluxei8_v_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_i16m1_m((vint16m1_t)(op0), (const int16_t *)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei8_v_i16m2(op0, op1, op2) \
__builtin_rvv_vluxei8_v_i16m2((const int16_t *)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vluxei8_v_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_i16m2_m((vint16m2_t)(op0), (const int16_t *)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei8_v_i16m4(op0, op1, op2) \
__builtin_rvv_vluxei8_v_i16m4((const int16_t *)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vluxei8_v_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_i16m4_m((vint16m4_t)(op0), (const int16_t *)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vluxei8_v_i16m8(op0, op1, op2) \
__builtin_rvv_vluxei8_v_i16m8((const int16_t *)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vluxei8_v_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_i16m8_m((vint16m8_t)(op0), (const int16_t *)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vluxei8_v_i16mf2(op0, op1, op2) \
__builtin_rvv_vluxei8_v_i16mf2((const int16_t *)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vluxei8_v_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_i16mf2_m((vint16mf2_t)(op0), (const int16_t *)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei8_v_i16mf4(op0, op1, op2) \
__builtin_rvv_vluxei8_v_i16mf4((const int16_t *)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vluxei8_v_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_i16mf4_m((vint16mf4_t)(op0), (const int16_t *)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei8_v_u16m1(op0, op1, op2) \
__builtin_rvv_vluxei8_v_u16m1((const uint16_t *)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vluxei8_v_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_u16m1_m((vuint16m1_t)(op0), (const uint16_t *)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei8_v_u16m2(op0, op1, op2) \
__builtin_rvv_vluxei8_v_u16m2((const uint16_t *)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vluxei8_v_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_u16m2_m((vuint16m2_t)(op0), (const uint16_t *)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei8_v_u16m4(op0, op1, op2) \
__builtin_rvv_vluxei8_v_u16m4((const uint16_t *)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vluxei8_v_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_u16m4_m((vuint16m4_t)(op0), (const uint16_t *)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vluxei8_v_u16m8(op0, op1, op2) \
__builtin_rvv_vluxei8_v_u16m8((const uint16_t *)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vluxei8_v_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_u16m8_m((vuint16m8_t)(op0), (const uint16_t *)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vluxei8_v_u16mf2(op0, op1, op2) \
__builtin_rvv_vluxei8_v_u16mf2((const uint16_t *)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vluxei8_v_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_u16mf2_m((vuint16mf2_t)(op0), (const uint16_t *)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei8_v_u16mf4(op0, op1, op2) \
__builtin_rvv_vluxei8_v_u16mf4((const uint16_t *)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vluxei8_v_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_u16mf4_m((vuint16mf4_t)(op0), (const uint16_t *)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei16_v_i16m1(op0, op1, op2) \
__builtin_rvv_vluxei16_v_i16m1((const int16_t *)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vluxei16_v_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_i16m1_m((vint16m1_t)(op0), (const int16_t *)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei16_v_i16m2(op0, op1, op2) \
__builtin_rvv_vluxei16_v_i16m2((const int16_t *)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vluxei16_v_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_i16m2_m((vint16m2_t)(op0), (const int16_t *)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei16_v_i16m4(op0, op1, op2) \
__builtin_rvv_vluxei16_v_i16m4((const int16_t *)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vluxei16_v_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_i16m4_m((vint16m4_t)(op0), (const int16_t *)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vluxei16_v_i16m8(op0, op1, op2) \
__builtin_rvv_vluxei16_v_i16m8((const int16_t *)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vluxei16_v_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_i16m8_m((vint16m8_t)(op0), (const int16_t *)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vluxei16_v_i16mf2(op0, op1, op2) \
__builtin_rvv_vluxei16_v_i16mf2((const int16_t *)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vluxei16_v_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_i16mf2_m((vint16mf2_t)(op0), (const int16_t *)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei16_v_i16mf4(op0, op1, op2) \
__builtin_rvv_vluxei16_v_i16mf4((const int16_t *)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vluxei16_v_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_i16mf4_m((vint16mf4_t)(op0), (const int16_t *)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei16_v_u16m1(op0, op1, op2) \
__builtin_rvv_vluxei16_v_u16m1((const uint16_t *)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vluxei16_v_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_u16m1_m((vuint16m1_t)(op0), (const uint16_t *)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei16_v_u16m2(op0, op1, op2) \
__builtin_rvv_vluxei16_v_u16m2((const uint16_t *)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vluxei16_v_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_u16m2_m((vuint16m2_t)(op0), (const uint16_t *)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei16_v_u16m4(op0, op1, op2) \
__builtin_rvv_vluxei16_v_u16m4((const uint16_t *)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vluxei16_v_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_u16m4_m((vuint16m4_t)(op0), (const uint16_t *)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vluxei16_v_u16m8(op0, op1, op2) \
__builtin_rvv_vluxei16_v_u16m8((const uint16_t *)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vluxei16_v_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_u16m8_m((vuint16m8_t)(op0), (const uint16_t *)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vluxei16_v_u16mf2(op0, op1, op2) \
__builtin_rvv_vluxei16_v_u16mf2((const uint16_t *)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vluxei16_v_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_u16mf2_m((vuint16mf2_t)(op0), (const uint16_t *)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei16_v_u16mf4(op0, op1, op2) \
__builtin_rvv_vluxei16_v_u16mf4((const uint16_t *)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vluxei16_v_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_u16mf4_m((vuint16mf4_t)(op0), (const uint16_t *)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei32_v_i16m1(op0, op1, op2) \
__builtin_rvv_vluxei32_v_i16m1((const int16_t *)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vluxei32_v_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_i16m1_m((vint16m1_t)(op0), (const int16_t *)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei32_v_i16m2(op0, op1, op2) \
__builtin_rvv_vluxei32_v_i16m2((const int16_t *)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vluxei32_v_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_i16m2_m((vint16m2_t)(op0), (const int16_t *)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei32_v_i16m4(op0, op1, op2) \
__builtin_rvv_vluxei32_v_i16m4((const int16_t *)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vluxei32_v_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_i16m4_m((vint16m4_t)(op0), (const int16_t *)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vluxei32_v_i16mf2(op0, op1, op2) \
__builtin_rvv_vluxei32_v_i16mf2((const int16_t *)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vluxei32_v_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_i16mf2_m((vint16mf2_t)(op0), (const int16_t *)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei32_v_i16mf4(op0, op1, op2) \
__builtin_rvv_vluxei32_v_i16mf4((const int16_t *)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vluxei32_v_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_i16mf4_m((vint16mf4_t)(op0), (const int16_t *)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei32_v_u16m1(op0, op1, op2) \
__builtin_rvv_vluxei32_v_u16m1((const uint16_t *)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vluxei32_v_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_u16m1_m((vuint16m1_t)(op0), (const uint16_t *)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei32_v_u16m2(op0, op1, op2) \
__builtin_rvv_vluxei32_v_u16m2((const uint16_t *)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vluxei32_v_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_u16m2_m((vuint16m2_t)(op0), (const uint16_t *)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei32_v_u16m4(op0, op1, op2) \
__builtin_rvv_vluxei32_v_u16m4((const uint16_t *)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vluxei32_v_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_u16m4_m((vuint16m4_t)(op0), (const uint16_t *)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vluxei32_v_u16mf2(op0, op1, op2) \
__builtin_rvv_vluxei32_v_u16mf2((const uint16_t *)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vluxei32_v_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_u16mf2_m((vuint16mf2_t)(op0), (const uint16_t *)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei32_v_u16mf4(op0, op1, op2) \
__builtin_rvv_vluxei32_v_u16mf4((const uint16_t *)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vluxei32_v_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_u16mf4_m((vuint16mf4_t)(op0), (const uint16_t *)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei64_v_i16m1(op0, op1, op2) \
__builtin_rvv_vluxei64_v_i16m1((const int16_t *)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vluxei64_v_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_i16m1_m((vint16m1_t)(op0), (const int16_t *)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei64_v_i16m2(op0, op1, op2) \
__builtin_rvv_vluxei64_v_i16m2((const int16_t *)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vluxei64_v_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_i16m2_m((vint16m2_t)(op0), (const int16_t *)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei64_v_i16mf2(op0, op1, op2) \
__builtin_rvv_vluxei64_v_i16mf2((const int16_t *)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vluxei64_v_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_i16mf2_m((vint16mf2_t)(op0), (const int16_t *)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei64_v_i16mf4(op0, op1, op2) \
__builtin_rvv_vluxei64_v_i16mf4((const int16_t *)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vluxei64_v_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_i16mf4_m((vint16mf4_t)(op0), (const int16_t *)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei64_v_u16m1(op0, op1, op2) \
__builtin_rvv_vluxei64_v_u16m1((const uint16_t *)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vluxei64_v_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_u16m1_m((vuint16m1_t)(op0), (const uint16_t *)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei64_v_u16m2(op0, op1, op2) \
__builtin_rvv_vluxei64_v_u16m2((const uint16_t *)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vluxei64_v_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_u16m2_m((vuint16m2_t)(op0), (const uint16_t *)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei64_v_u16mf2(op0, op1, op2) \
__builtin_rvv_vluxei64_v_u16mf2((const uint16_t *)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vluxei64_v_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_u16mf2_m((vuint16mf2_t)(op0), (const uint16_t *)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei64_v_u16mf4(op0, op1, op2) \
__builtin_rvv_vluxei64_v_u16mf4((const uint16_t *)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vluxei64_v_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_u16mf4_m((vuint16mf4_t)(op0), (const uint16_t *)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei8_v_i32m1(op0, op1, op2) \
__builtin_rvv_vluxei8_v_i32m1((const int32_t *)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vluxei8_v_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_i32m1_m((vint32m1_t)(op0), (const int32_t *)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei8_v_i32m2(op0, op1, op2) \
__builtin_rvv_vluxei8_v_i32m2((const int32_t *)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vluxei8_v_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_i32m2_m((vint32m2_t)(op0), (const int32_t *)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei8_v_i32m4(op0, op1, op2) \
__builtin_rvv_vluxei8_v_i32m4((const int32_t *)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vluxei8_v_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_i32m4_m((vint32m4_t)(op0), (const int32_t *)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei8_v_i32m8(op0, op1, op2) \
__builtin_rvv_vluxei8_v_i32m8((const int32_t *)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vluxei8_v_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_i32m8_m((vint32m8_t)(op0), (const int32_t *)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vluxei8_v_i32mf2(op0, op1, op2) \
__builtin_rvv_vluxei8_v_i32mf2((const int32_t *)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vluxei8_v_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_i32mf2_m((vint32mf2_t)(op0), (const int32_t *)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei8_v_u32m1(op0, op1, op2) \
__builtin_rvv_vluxei8_v_u32m1((const uint32_t *)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vluxei8_v_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_u32m1_m((vuint32m1_t)(op0), (const uint32_t *)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei8_v_u32m2(op0, op1, op2) \
__builtin_rvv_vluxei8_v_u32m2((const uint32_t *)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vluxei8_v_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_u32m2_m((vuint32m2_t)(op0), (const uint32_t *)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei8_v_u32m4(op0, op1, op2) \
__builtin_rvv_vluxei8_v_u32m4((const uint32_t *)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vluxei8_v_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_u32m4_m((vuint32m4_t)(op0), (const uint32_t *)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei8_v_u32m8(op0, op1, op2) \
__builtin_rvv_vluxei8_v_u32m8((const uint32_t *)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vluxei8_v_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_u32m8_m((vuint32m8_t)(op0), (const uint32_t *)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vluxei8_v_u32mf2(op0, op1, op2) \
__builtin_rvv_vluxei8_v_u32mf2((const uint32_t *)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vluxei8_v_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_u32mf2_m((vuint32mf2_t)(op0), (const uint32_t *)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei16_v_i32m1(op0, op1, op2) \
__builtin_rvv_vluxei16_v_i32m1((const int32_t *)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vluxei16_v_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_i32m1_m((vint32m1_t)(op0), (const int32_t *)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei16_v_i32m2(op0, op1, op2) \
__builtin_rvv_vluxei16_v_i32m2((const int32_t *)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vluxei16_v_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_i32m2_m((vint32m2_t)(op0), (const int32_t *)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei16_v_i32m4(op0, op1, op2) \
__builtin_rvv_vluxei16_v_i32m4((const int32_t *)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vluxei16_v_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_i32m4_m((vint32m4_t)(op0), (const int32_t *)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei16_v_i32m8(op0, op1, op2) \
__builtin_rvv_vluxei16_v_i32m8((const int32_t *)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vluxei16_v_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_i32m8_m((vint32m8_t)(op0), (const int32_t *)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vluxei16_v_i32mf2(op0, op1, op2) \
__builtin_rvv_vluxei16_v_i32mf2((const int32_t *)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vluxei16_v_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_i32mf2_m((vint32mf2_t)(op0), (const int32_t *)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei16_v_u32m1(op0, op1, op2) \
__builtin_rvv_vluxei16_v_u32m1((const uint32_t *)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vluxei16_v_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_u32m1_m((vuint32m1_t)(op0), (const uint32_t *)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei16_v_u32m2(op0, op1, op2) \
__builtin_rvv_vluxei16_v_u32m2((const uint32_t *)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vluxei16_v_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_u32m2_m((vuint32m2_t)(op0), (const uint32_t *)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei16_v_u32m4(op0, op1, op2) \
__builtin_rvv_vluxei16_v_u32m4((const uint32_t *)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vluxei16_v_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_u32m4_m((vuint32m4_t)(op0), (const uint32_t *)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei16_v_u32m8(op0, op1, op2) \
__builtin_rvv_vluxei16_v_u32m8((const uint32_t *)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vluxei16_v_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_u32m8_m((vuint32m8_t)(op0), (const uint32_t *)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vluxei16_v_u32mf2(op0, op1, op2) \
__builtin_rvv_vluxei16_v_u32mf2((const uint32_t *)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vluxei16_v_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_u32mf2_m((vuint32mf2_t)(op0), (const uint32_t *)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei32_v_i32m1(op0, op1, op2) \
__builtin_rvv_vluxei32_v_i32m1((const int32_t *)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vluxei32_v_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_i32m1_m((vint32m1_t)(op0), (const int32_t *)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei32_v_i32m2(op0, op1, op2) \
__builtin_rvv_vluxei32_v_i32m2((const int32_t *)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vluxei32_v_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_i32m2_m((vint32m2_t)(op0), (const int32_t *)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei32_v_i32m4(op0, op1, op2) \
__builtin_rvv_vluxei32_v_i32m4((const int32_t *)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vluxei32_v_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_i32m4_m((vint32m4_t)(op0), (const int32_t *)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei32_v_i32m8(op0, op1, op2) \
__builtin_rvv_vluxei32_v_i32m8((const int32_t *)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vluxei32_v_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_i32m8_m((vint32m8_t)(op0), (const int32_t *)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vluxei32_v_i32mf2(op0, op1, op2) \
__builtin_rvv_vluxei32_v_i32mf2((const int32_t *)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vluxei32_v_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_i32mf2_m((vint32mf2_t)(op0), (const int32_t *)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei32_v_u32m1(op0, op1, op2) \
__builtin_rvv_vluxei32_v_u32m1((const uint32_t *)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vluxei32_v_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_u32m1_m((vuint32m1_t)(op0), (const uint32_t *)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei32_v_u32m2(op0, op1, op2) \
__builtin_rvv_vluxei32_v_u32m2((const uint32_t *)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vluxei32_v_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_u32m2_m((vuint32m2_t)(op0), (const uint32_t *)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei32_v_u32m4(op0, op1, op2) \
__builtin_rvv_vluxei32_v_u32m4((const uint32_t *)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vluxei32_v_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_u32m4_m((vuint32m4_t)(op0), (const uint32_t *)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei32_v_u32m8(op0, op1, op2) \
__builtin_rvv_vluxei32_v_u32m8((const uint32_t *)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vluxei32_v_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_u32m8_m((vuint32m8_t)(op0), (const uint32_t *)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vluxei32_v_u32mf2(op0, op1, op2) \
__builtin_rvv_vluxei32_v_u32mf2((const uint32_t *)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vluxei32_v_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_u32mf2_m((vuint32mf2_t)(op0), (const uint32_t *)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei64_v_i32m1(op0, op1, op2) \
__builtin_rvv_vluxei64_v_i32m1((const int32_t *)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vluxei64_v_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_i32m1_m((vint32m1_t)(op0), (const int32_t *)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei64_v_i32m2(op0, op1, op2) \
__builtin_rvv_vluxei64_v_i32m2((const int32_t *)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vluxei64_v_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_i32m2_m((vint32m2_t)(op0), (const int32_t *)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei64_v_i32m4(op0, op1, op2) \
__builtin_rvv_vluxei64_v_i32m4((const int32_t *)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vluxei64_v_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_i32m4_m((vint32m4_t)(op0), (const int32_t *)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei64_v_i32mf2(op0, op1, op2) \
__builtin_rvv_vluxei64_v_i32mf2((const int32_t *)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vluxei64_v_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_i32mf2_m((vint32mf2_t)(op0), (const int32_t *)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei64_v_u32m1(op0, op1, op2) \
__builtin_rvv_vluxei64_v_u32m1((const uint32_t *)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vluxei64_v_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_u32m1_m((vuint32m1_t)(op0), (const uint32_t *)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei64_v_u32m2(op0, op1, op2) \
__builtin_rvv_vluxei64_v_u32m2((const uint32_t *)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vluxei64_v_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_u32m2_m((vuint32m2_t)(op0), (const uint32_t *)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei64_v_u32m4(op0, op1, op2) \
__builtin_rvv_vluxei64_v_u32m4((const uint32_t *)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vluxei64_v_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_u32m4_m((vuint32m4_t)(op0), (const uint32_t *)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei64_v_u32mf2(op0, op1, op2) \
__builtin_rvv_vluxei64_v_u32mf2((const uint32_t *)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vluxei64_v_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_u32mf2_m((vuint32mf2_t)(op0), (const uint32_t *)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei8_v_i64m1(op0, op1, op2) \
__builtin_rvv_vluxei8_v_i64m1((const int64_t *)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vluxei8_v_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_i64m1_m((vint64m1_t)(op0), (const int64_t *)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei8_v_i64m2(op0, op1, op2) \
__builtin_rvv_vluxei8_v_i64m2((const int64_t *)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vluxei8_v_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_i64m2_m((vint64m2_t)(op0), (const int64_t *)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei8_v_i64m4(op0, op1, op2) \
__builtin_rvv_vluxei8_v_i64m4((const int64_t *)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vluxei8_v_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_i64m4_m((vint64m4_t)(op0), (const int64_t *)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei8_v_i64m8(op0, op1, op2) \
__builtin_rvv_vluxei8_v_i64m8((const int64_t *)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vluxei8_v_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_i64m8_m((vint64m8_t)(op0), (const int64_t *)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei8_v_u64m1(op0, op1, op2) \
__builtin_rvv_vluxei8_v_u64m1((const uint64_t *)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vluxei8_v_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_u64m1_m((vuint64m1_t)(op0), (const uint64_t *)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei8_v_u64m2(op0, op1, op2) \
__builtin_rvv_vluxei8_v_u64m2((const uint64_t *)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vluxei8_v_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_u64m2_m((vuint64m2_t)(op0), (const uint64_t *)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei8_v_u64m4(op0, op1, op2) \
__builtin_rvv_vluxei8_v_u64m4((const uint64_t *)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vluxei8_v_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_u64m4_m((vuint64m4_t)(op0), (const uint64_t *)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei8_v_u64m8(op0, op1, op2) \
__builtin_rvv_vluxei8_v_u64m8((const uint64_t *)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vluxei8_v_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_u64m8_m((vuint64m8_t)(op0), (const uint64_t *)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei16_v_i64m1(op0, op1, op2) \
__builtin_rvv_vluxei16_v_i64m1((const int64_t *)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vluxei16_v_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_i64m1_m((vint64m1_t)(op0), (const int64_t *)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei16_v_i64m2(op0, op1, op2) \
__builtin_rvv_vluxei16_v_i64m2((const int64_t *)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vluxei16_v_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_i64m2_m((vint64m2_t)(op0), (const int64_t *)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei16_v_i64m4(op0, op1, op2) \
__builtin_rvv_vluxei16_v_i64m4((const int64_t *)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vluxei16_v_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_i64m4_m((vint64m4_t)(op0), (const int64_t *)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei16_v_i64m8(op0, op1, op2) \
__builtin_rvv_vluxei16_v_i64m8((const int64_t *)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vluxei16_v_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_i64m8_m((vint64m8_t)(op0), (const int64_t *)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei16_v_u64m1(op0, op1, op2) \
__builtin_rvv_vluxei16_v_u64m1((const uint64_t *)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vluxei16_v_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_u64m1_m((vuint64m1_t)(op0), (const uint64_t *)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei16_v_u64m2(op0, op1, op2) \
__builtin_rvv_vluxei16_v_u64m2((const uint64_t *)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vluxei16_v_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_u64m2_m((vuint64m2_t)(op0), (const uint64_t *)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei16_v_u64m4(op0, op1, op2) \
__builtin_rvv_vluxei16_v_u64m4((const uint64_t *)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vluxei16_v_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_u64m4_m((vuint64m4_t)(op0), (const uint64_t *)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei16_v_u64m8(op0, op1, op2) \
__builtin_rvv_vluxei16_v_u64m8((const uint64_t *)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vluxei16_v_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_u64m8_m((vuint64m8_t)(op0), (const uint64_t *)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei32_v_i64m1(op0, op1, op2) \
__builtin_rvv_vluxei32_v_i64m1((const int64_t *)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vluxei32_v_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_i64m1_m((vint64m1_t)(op0), (const int64_t *)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei32_v_i64m2(op0, op1, op2) \
__builtin_rvv_vluxei32_v_i64m2((const int64_t *)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vluxei32_v_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_i64m2_m((vint64m2_t)(op0), (const int64_t *)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei32_v_i64m4(op0, op1, op2) \
__builtin_rvv_vluxei32_v_i64m4((const int64_t *)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vluxei32_v_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_i64m4_m((vint64m4_t)(op0), (const int64_t *)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei32_v_i64m8(op0, op1, op2) \
__builtin_rvv_vluxei32_v_i64m8((const int64_t *)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vluxei32_v_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_i64m8_m((vint64m8_t)(op0), (const int64_t *)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei32_v_u64m1(op0, op1, op2) \
__builtin_rvv_vluxei32_v_u64m1((const uint64_t *)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vluxei32_v_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_u64m1_m((vuint64m1_t)(op0), (const uint64_t *)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei32_v_u64m2(op0, op1, op2) \
__builtin_rvv_vluxei32_v_u64m2((const uint64_t *)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vluxei32_v_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_u64m2_m((vuint64m2_t)(op0), (const uint64_t *)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei32_v_u64m4(op0, op1, op2) \
__builtin_rvv_vluxei32_v_u64m4((const uint64_t *)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vluxei32_v_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_u64m4_m((vuint64m4_t)(op0), (const uint64_t *)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei32_v_u64m8(op0, op1, op2) \
__builtin_rvv_vluxei32_v_u64m8((const uint64_t *)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vluxei32_v_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_u64m8_m((vuint64m8_t)(op0), (const uint64_t *)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei64_v_i64m1(op0, op1, op2) \
__builtin_rvv_vluxei64_v_i64m1((const int64_t *)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vluxei64_v_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_i64m1_m((vint64m1_t)(op0), (const int64_t *)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei64_v_i64m2(op0, op1, op2) \
__builtin_rvv_vluxei64_v_i64m2((const int64_t *)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vluxei64_v_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_i64m2_m((vint64m2_t)(op0), (const int64_t *)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei64_v_i64m4(op0, op1, op2) \
__builtin_rvv_vluxei64_v_i64m4((const int64_t *)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vluxei64_v_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_i64m4_m((vint64m4_t)(op0), (const int64_t *)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei64_v_i64m8(op0, op1, op2) \
__builtin_rvv_vluxei64_v_i64m8((const int64_t *)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vluxei64_v_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_i64m8_m((vint64m8_t)(op0), (const int64_t *)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei64_v_u64m1(op0, op1, op2) \
__builtin_rvv_vluxei64_v_u64m1((const uint64_t *)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vluxei64_v_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_u64m1_m((vuint64m1_t)(op0), (const uint64_t *)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei64_v_u64m2(op0, op1, op2) \
__builtin_rvv_vluxei64_v_u64m2((const uint64_t *)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vluxei64_v_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_u64m2_m((vuint64m2_t)(op0), (const uint64_t *)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei64_v_u64m4(op0, op1, op2) \
__builtin_rvv_vluxei64_v_u64m4((const uint64_t *)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vluxei64_v_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_u64m4_m((vuint64m4_t)(op0), (const uint64_t *)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei64_v_u64m8(op0, op1, op2) \
__builtin_rvv_vluxei64_v_u64m8((const uint64_t *)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vluxei64_v_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_u64m8_m((vuint64m8_t)(op0), (const uint64_t *)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei8_v_i8m1(op0, op1, op2) \
__builtin_rvv_vloxei8_v_i8m1((const int8_t *)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vloxei8_v_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_i8m1_m((vint8m1_t)(op0), (const int8_t *)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei8_v_i8m2(op0, op1, op2) \
__builtin_rvv_vloxei8_v_i8m2((const int8_t *)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vloxei8_v_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_i8m2_m((vint8m2_t)(op0), (const int8_t *)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vloxei8_v_i8m4(op0, op1, op2) \
__builtin_rvv_vloxei8_v_i8m4((const int8_t *)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vloxei8_v_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_i8m4_m((vint8m4_t)(op0), (const int8_t *)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vloxei8_v_i8m8(op0, op1, op2) \
__builtin_rvv_vloxei8_v_i8m8((const int8_t *)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vloxei8_v_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_i8m8_m((vint8m8_t)(op0), (const int8_t *)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vloxei8_v_i8mf2(op0, op1, op2) \
__builtin_rvv_vloxei8_v_i8mf2((const int8_t *)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vloxei8_v_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_i8mf2_m((vint8mf2_t)(op0), (const int8_t *)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei8_v_i8mf4(op0, op1, op2) \
__builtin_rvv_vloxei8_v_i8mf4((const int8_t *)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vloxei8_v_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_i8mf4_m((vint8mf4_t)(op0), (const int8_t *)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei8_v_i8mf8(op0, op1, op2) \
__builtin_rvv_vloxei8_v_i8mf8((const int8_t *)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vloxei8_v_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_i8mf8_m((vint8mf8_t)(op0), (const int8_t *)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei8_v_u8m1(op0, op1, op2) \
__builtin_rvv_vloxei8_v_u8m1((const uint8_t *)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vloxei8_v_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_u8m1_m((vuint8m1_t)(op0), (const uint8_t *)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei8_v_u8m2(op0, op1, op2) \
__builtin_rvv_vloxei8_v_u8m2((const uint8_t *)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vloxei8_v_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_u8m2_m((vuint8m2_t)(op0), (const uint8_t *)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vloxei8_v_u8m4(op0, op1, op2) \
__builtin_rvv_vloxei8_v_u8m4((const uint8_t *)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vloxei8_v_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_u8m4_m((vuint8m4_t)(op0), (const uint8_t *)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vloxei8_v_u8m8(op0, op1, op2) \
__builtin_rvv_vloxei8_v_u8m8((const uint8_t *)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vloxei8_v_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_u8m8_m((vuint8m8_t)(op0), (const uint8_t *)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vloxei8_v_u8mf2(op0, op1, op2) \
__builtin_rvv_vloxei8_v_u8mf2((const uint8_t *)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vloxei8_v_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_u8mf2_m((vuint8mf2_t)(op0), (const uint8_t *)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei8_v_u8mf4(op0, op1, op2) \
__builtin_rvv_vloxei8_v_u8mf4((const uint8_t *)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vloxei8_v_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_u8mf4_m((vuint8mf4_t)(op0), (const uint8_t *)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei8_v_u8mf8(op0, op1, op2) \
__builtin_rvv_vloxei8_v_u8mf8((const uint8_t *)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vloxei8_v_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_u8mf8_m((vuint8mf8_t)(op0), (const uint8_t *)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei16_v_i8m1(op0, op1, op2) \
__builtin_rvv_vloxei16_v_i8m1((const int8_t *)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vloxei16_v_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_i8m1_m((vint8m1_t)(op0), (const int8_t *)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei16_v_i8m2(op0, op1, op2) \
__builtin_rvv_vloxei16_v_i8m2((const int8_t *)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vloxei16_v_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_i8m2_m((vint8m2_t)(op0), (const int8_t *)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vloxei16_v_i8m4(op0, op1, op2) \
__builtin_rvv_vloxei16_v_i8m4((const int8_t *)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vloxei16_v_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_i8m4_m((vint8m4_t)(op0), (const int8_t *)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vloxei16_v_i8mf2(op0, op1, op2) \
__builtin_rvv_vloxei16_v_i8mf2((const int8_t *)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vloxei16_v_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_i8mf2_m((vint8mf2_t)(op0), (const int8_t *)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei16_v_i8mf4(op0, op1, op2) \
__builtin_rvv_vloxei16_v_i8mf4((const int8_t *)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vloxei16_v_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_i8mf4_m((vint8mf4_t)(op0), (const int8_t *)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei16_v_i8mf8(op0, op1, op2) \
__builtin_rvv_vloxei16_v_i8mf8((const int8_t *)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vloxei16_v_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_i8mf8_m((vint8mf8_t)(op0), (const int8_t *)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei16_v_u8m1(op0, op1, op2) \
__builtin_rvv_vloxei16_v_u8m1((const uint8_t *)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vloxei16_v_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_u8m1_m((vuint8m1_t)(op0), (const uint8_t *)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei16_v_u8m2(op0, op1, op2) \
__builtin_rvv_vloxei16_v_u8m2((const uint8_t *)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vloxei16_v_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_u8m2_m((vuint8m2_t)(op0), (const uint8_t *)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vloxei16_v_u8m4(op0, op1, op2) \
__builtin_rvv_vloxei16_v_u8m4((const uint8_t *)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vloxei16_v_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_u8m4_m((vuint8m4_t)(op0), (const uint8_t *)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vloxei16_v_u8mf2(op0, op1, op2) \
__builtin_rvv_vloxei16_v_u8mf2((const uint8_t *)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vloxei16_v_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_u8mf2_m((vuint8mf2_t)(op0), (const uint8_t *)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei16_v_u8mf4(op0, op1, op2) \
__builtin_rvv_vloxei16_v_u8mf4((const uint8_t *)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vloxei16_v_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_u8mf4_m((vuint8mf4_t)(op0), (const uint8_t *)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei16_v_u8mf8(op0, op1, op2) \
__builtin_rvv_vloxei16_v_u8mf8((const uint8_t *)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vloxei16_v_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_u8mf8_m((vuint8mf8_t)(op0), (const uint8_t *)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei32_v_i8m1(op0, op1, op2) \
__builtin_rvv_vloxei32_v_i8m1((const int8_t *)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vloxei32_v_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_i8m1_m((vint8m1_t)(op0), (const int8_t *)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei32_v_i8m2(op0, op1, op2) \
__builtin_rvv_vloxei32_v_i8m2((const int8_t *)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vloxei32_v_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_i8m2_m((vint8m2_t)(op0), (const int8_t *)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vloxei32_v_i8mf2(op0, op1, op2) \
__builtin_rvv_vloxei32_v_i8mf2((const int8_t *)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vloxei32_v_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_i8mf2_m((vint8mf2_t)(op0), (const int8_t *)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei32_v_i8mf4(op0, op1, op2) \
__builtin_rvv_vloxei32_v_i8mf4((const int8_t *)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vloxei32_v_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_i8mf4_m((vint8mf4_t)(op0), (const int8_t *)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei32_v_i8mf8(op0, op1, op2) \
__builtin_rvv_vloxei32_v_i8mf8((const int8_t *)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vloxei32_v_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_i8mf8_m((vint8mf8_t)(op0), (const int8_t *)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei32_v_u8m1(op0, op1, op2) \
__builtin_rvv_vloxei32_v_u8m1((const uint8_t *)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vloxei32_v_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_u8m1_m((vuint8m1_t)(op0), (const uint8_t *)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei32_v_u8m2(op0, op1, op2) \
__builtin_rvv_vloxei32_v_u8m2((const uint8_t *)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vloxei32_v_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_u8m2_m((vuint8m2_t)(op0), (const uint8_t *)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vloxei32_v_u8mf2(op0, op1, op2) \
__builtin_rvv_vloxei32_v_u8mf2((const uint8_t *)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vloxei32_v_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_u8mf2_m((vuint8mf2_t)(op0), (const uint8_t *)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei32_v_u8mf4(op0, op1, op2) \
__builtin_rvv_vloxei32_v_u8mf4((const uint8_t *)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vloxei32_v_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_u8mf4_m((vuint8mf4_t)(op0), (const uint8_t *)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei32_v_u8mf8(op0, op1, op2) \
__builtin_rvv_vloxei32_v_u8mf8((const uint8_t *)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vloxei32_v_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_u8mf8_m((vuint8mf8_t)(op0), (const uint8_t *)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei64_v_i8m1(op0, op1, op2) \
__builtin_rvv_vloxei64_v_i8m1((const int8_t *)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vloxei64_v_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_i8m1_m((vint8m1_t)(op0), (const int8_t *)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei64_v_i8mf2(op0, op1, op2) \
__builtin_rvv_vloxei64_v_i8mf2((const int8_t *)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vloxei64_v_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_i8mf2_m((vint8mf2_t)(op0), (const int8_t *)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei64_v_i8mf4(op0, op1, op2) \
__builtin_rvv_vloxei64_v_i8mf4((const int8_t *)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vloxei64_v_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_i8mf4_m((vint8mf4_t)(op0), (const int8_t *)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei64_v_i8mf8(op0, op1, op2) \
__builtin_rvv_vloxei64_v_i8mf8((const int8_t *)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vloxei64_v_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_i8mf8_m((vint8mf8_t)(op0), (const int8_t *)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei64_v_u8m1(op0, op1, op2) \
__builtin_rvv_vloxei64_v_u8m1((const uint8_t *)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vloxei64_v_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_u8m1_m((vuint8m1_t)(op0), (const uint8_t *)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei64_v_u8mf2(op0, op1, op2) \
__builtin_rvv_vloxei64_v_u8mf2((const uint8_t *)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vloxei64_v_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_u8mf2_m((vuint8mf2_t)(op0), (const uint8_t *)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei64_v_u8mf4(op0, op1, op2) \
__builtin_rvv_vloxei64_v_u8mf4((const uint8_t *)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vloxei64_v_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_u8mf4_m((vuint8mf4_t)(op0), (const uint8_t *)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei64_v_u8mf8(op0, op1, op2) \
__builtin_rvv_vloxei64_v_u8mf8((const uint8_t *)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vloxei64_v_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_u8mf8_m((vuint8mf8_t)(op0), (const uint8_t *)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei8_v_i16m1(op0, op1, op2) \
__builtin_rvv_vloxei8_v_i16m1((const int16_t *)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vloxei8_v_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_i16m1_m((vint16m1_t)(op0), (const int16_t *)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei8_v_i16m2(op0, op1, op2) \
__builtin_rvv_vloxei8_v_i16m2((const int16_t *)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vloxei8_v_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_i16m2_m((vint16m2_t)(op0), (const int16_t *)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei8_v_i16m4(op0, op1, op2) \
__builtin_rvv_vloxei8_v_i16m4((const int16_t *)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vloxei8_v_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_i16m4_m((vint16m4_t)(op0), (const int16_t *)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vloxei8_v_i16m8(op0, op1, op2) \
__builtin_rvv_vloxei8_v_i16m8((const int16_t *)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vloxei8_v_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_i16m8_m((vint16m8_t)(op0), (const int16_t *)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vloxei8_v_i16mf2(op0, op1, op2) \
__builtin_rvv_vloxei8_v_i16mf2((const int16_t *)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vloxei8_v_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_i16mf2_m((vint16mf2_t)(op0), (const int16_t *)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei8_v_i16mf4(op0, op1, op2) \
__builtin_rvv_vloxei8_v_i16mf4((const int16_t *)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vloxei8_v_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_i16mf4_m((vint16mf4_t)(op0), (const int16_t *)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei8_v_u16m1(op0, op1, op2) \
__builtin_rvv_vloxei8_v_u16m1((const uint16_t *)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vloxei8_v_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_u16m1_m((vuint16m1_t)(op0), (const uint16_t *)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei8_v_u16m2(op0, op1, op2) \
__builtin_rvv_vloxei8_v_u16m2((const uint16_t *)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vloxei8_v_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_u16m2_m((vuint16m2_t)(op0), (const uint16_t *)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei8_v_u16m4(op0, op1, op2) \
__builtin_rvv_vloxei8_v_u16m4((const uint16_t *)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vloxei8_v_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_u16m4_m((vuint16m4_t)(op0), (const uint16_t *)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vloxei8_v_u16m8(op0, op1, op2) \
__builtin_rvv_vloxei8_v_u16m8((const uint16_t *)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vloxei8_v_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_u16m8_m((vuint16m8_t)(op0), (const uint16_t *)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vloxei8_v_u16mf2(op0, op1, op2) \
__builtin_rvv_vloxei8_v_u16mf2((const uint16_t *)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vloxei8_v_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_u16mf2_m((vuint16mf2_t)(op0), (const uint16_t *)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei8_v_u16mf4(op0, op1, op2) \
__builtin_rvv_vloxei8_v_u16mf4((const uint16_t *)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vloxei8_v_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_u16mf4_m((vuint16mf4_t)(op0), (const uint16_t *)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei16_v_i16m1(op0, op1, op2) \
__builtin_rvv_vloxei16_v_i16m1((const int16_t *)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vloxei16_v_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_i16m1_m((vint16m1_t)(op0), (const int16_t *)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei16_v_i16m2(op0, op1, op2) \
__builtin_rvv_vloxei16_v_i16m2((const int16_t *)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vloxei16_v_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_i16m2_m((vint16m2_t)(op0), (const int16_t *)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei16_v_i16m4(op0, op1, op2) \
__builtin_rvv_vloxei16_v_i16m4((const int16_t *)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vloxei16_v_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_i16m4_m((vint16m4_t)(op0), (const int16_t *)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vloxei16_v_i16m8(op0, op1, op2) \
__builtin_rvv_vloxei16_v_i16m8((const int16_t *)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vloxei16_v_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_i16m8_m((vint16m8_t)(op0), (const int16_t *)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vloxei16_v_i16mf2(op0, op1, op2) \
__builtin_rvv_vloxei16_v_i16mf2((const int16_t *)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vloxei16_v_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_i16mf2_m((vint16mf2_t)(op0), (const int16_t *)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei16_v_i16mf4(op0, op1, op2) \
__builtin_rvv_vloxei16_v_i16mf4((const int16_t *)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vloxei16_v_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_i16mf4_m((vint16mf4_t)(op0), (const int16_t *)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei16_v_u16m1(op0, op1, op2) \
__builtin_rvv_vloxei16_v_u16m1((const uint16_t *)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vloxei16_v_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_u16m1_m((vuint16m1_t)(op0), (const uint16_t *)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei16_v_u16m2(op0, op1, op2) \
__builtin_rvv_vloxei16_v_u16m2((const uint16_t *)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vloxei16_v_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_u16m2_m((vuint16m2_t)(op0), (const uint16_t *)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei16_v_u16m4(op0, op1, op2) \
__builtin_rvv_vloxei16_v_u16m4((const uint16_t *)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vloxei16_v_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_u16m4_m((vuint16m4_t)(op0), (const uint16_t *)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vloxei16_v_u16m8(op0, op1, op2) \
__builtin_rvv_vloxei16_v_u16m8((const uint16_t *)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vloxei16_v_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_u16m8_m((vuint16m8_t)(op0), (const uint16_t *)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vloxei16_v_u16mf2(op0, op1, op2) \
__builtin_rvv_vloxei16_v_u16mf2((const uint16_t *)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vloxei16_v_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_u16mf2_m((vuint16mf2_t)(op0), (const uint16_t *)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei16_v_u16mf4(op0, op1, op2) \
__builtin_rvv_vloxei16_v_u16mf4((const uint16_t *)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vloxei16_v_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_u16mf4_m((vuint16mf4_t)(op0), (const uint16_t *)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei32_v_i16m1(op0, op1, op2) \
__builtin_rvv_vloxei32_v_i16m1((const int16_t *)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vloxei32_v_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_i16m1_m((vint16m1_t)(op0), (const int16_t *)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei32_v_i16m2(op0, op1, op2) \
__builtin_rvv_vloxei32_v_i16m2((const int16_t *)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vloxei32_v_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_i16m2_m((vint16m2_t)(op0), (const int16_t *)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei32_v_i16m4(op0, op1, op2) \
__builtin_rvv_vloxei32_v_i16m4((const int16_t *)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vloxei32_v_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_i16m4_m((vint16m4_t)(op0), (const int16_t *)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vloxei32_v_i16mf2(op0, op1, op2) \
__builtin_rvv_vloxei32_v_i16mf2((const int16_t *)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vloxei32_v_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_i16mf2_m((vint16mf2_t)(op0), (const int16_t *)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei32_v_i16mf4(op0, op1, op2) \
__builtin_rvv_vloxei32_v_i16mf4((const int16_t *)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vloxei32_v_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_i16mf4_m((vint16mf4_t)(op0), (const int16_t *)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei32_v_u16m1(op0, op1, op2) \
__builtin_rvv_vloxei32_v_u16m1((const uint16_t *)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vloxei32_v_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_u16m1_m((vuint16m1_t)(op0), (const uint16_t *)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei32_v_u16m2(op0, op1, op2) \
__builtin_rvv_vloxei32_v_u16m2((const uint16_t *)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vloxei32_v_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_u16m2_m((vuint16m2_t)(op0), (const uint16_t *)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei32_v_u16m4(op0, op1, op2) \
__builtin_rvv_vloxei32_v_u16m4((const uint16_t *)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vloxei32_v_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_u16m4_m((vuint16m4_t)(op0), (const uint16_t *)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vloxei32_v_u16mf2(op0, op1, op2) \
__builtin_rvv_vloxei32_v_u16mf2((const uint16_t *)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vloxei32_v_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_u16mf2_m((vuint16mf2_t)(op0), (const uint16_t *)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei32_v_u16mf4(op0, op1, op2) \
__builtin_rvv_vloxei32_v_u16mf4((const uint16_t *)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vloxei32_v_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_u16mf4_m((vuint16mf4_t)(op0), (const uint16_t *)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei64_v_i16m1(op0, op1, op2) \
__builtin_rvv_vloxei64_v_i16m1((const int16_t *)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vloxei64_v_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_i16m1_m((vint16m1_t)(op0), (const int16_t *)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei64_v_i16m2(op0, op1, op2) \
__builtin_rvv_vloxei64_v_i16m2((const int16_t *)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vloxei64_v_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_i16m2_m((vint16m2_t)(op0), (const int16_t *)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei64_v_i16mf2(op0, op1, op2) \
__builtin_rvv_vloxei64_v_i16mf2((const int16_t *)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vloxei64_v_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_i16mf2_m((vint16mf2_t)(op0), (const int16_t *)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei64_v_i16mf4(op0, op1, op2) \
__builtin_rvv_vloxei64_v_i16mf4((const int16_t *)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vloxei64_v_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_i16mf4_m((vint16mf4_t)(op0), (const int16_t *)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei64_v_u16m1(op0, op1, op2) \
__builtin_rvv_vloxei64_v_u16m1((const uint16_t *)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vloxei64_v_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_u16m1_m((vuint16m1_t)(op0), (const uint16_t *)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei64_v_u16m2(op0, op1, op2) \
__builtin_rvv_vloxei64_v_u16m2((const uint16_t *)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vloxei64_v_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_u16m2_m((vuint16m2_t)(op0), (const uint16_t *)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei64_v_u16mf2(op0, op1, op2) \
__builtin_rvv_vloxei64_v_u16mf2((const uint16_t *)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vloxei64_v_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_u16mf2_m((vuint16mf2_t)(op0), (const uint16_t *)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei64_v_u16mf4(op0, op1, op2) \
__builtin_rvv_vloxei64_v_u16mf4((const uint16_t *)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vloxei64_v_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_u16mf4_m((vuint16mf4_t)(op0), (const uint16_t *)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei8_v_i32m1(op0, op1, op2) \
__builtin_rvv_vloxei8_v_i32m1((const int32_t *)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vloxei8_v_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_i32m1_m((vint32m1_t)(op0), (const int32_t *)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei8_v_i32m2(op0, op1, op2) \
__builtin_rvv_vloxei8_v_i32m2((const int32_t *)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vloxei8_v_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_i32m2_m((vint32m2_t)(op0), (const int32_t *)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei8_v_i32m4(op0, op1, op2) \
__builtin_rvv_vloxei8_v_i32m4((const int32_t *)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vloxei8_v_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_i32m4_m((vint32m4_t)(op0), (const int32_t *)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei8_v_i32m8(op0, op1, op2) \
__builtin_rvv_vloxei8_v_i32m8((const int32_t *)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vloxei8_v_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_i32m8_m((vint32m8_t)(op0), (const int32_t *)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vloxei8_v_i32mf2(op0, op1, op2) \
__builtin_rvv_vloxei8_v_i32mf2((const int32_t *)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vloxei8_v_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_i32mf2_m((vint32mf2_t)(op0), (const int32_t *)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei8_v_u32m1(op0, op1, op2) \
__builtin_rvv_vloxei8_v_u32m1((const uint32_t *)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vloxei8_v_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_u32m1_m((vuint32m1_t)(op0), (const uint32_t *)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei8_v_u32m2(op0, op1, op2) \
__builtin_rvv_vloxei8_v_u32m2((const uint32_t *)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vloxei8_v_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_u32m2_m((vuint32m2_t)(op0), (const uint32_t *)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei8_v_u32m4(op0, op1, op2) \
__builtin_rvv_vloxei8_v_u32m4((const uint32_t *)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vloxei8_v_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_u32m4_m((vuint32m4_t)(op0), (const uint32_t *)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei8_v_u32m8(op0, op1, op2) \
__builtin_rvv_vloxei8_v_u32m8((const uint32_t *)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vloxei8_v_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_u32m8_m((vuint32m8_t)(op0), (const uint32_t *)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vloxei8_v_u32mf2(op0, op1, op2) \
__builtin_rvv_vloxei8_v_u32mf2((const uint32_t *)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vloxei8_v_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_u32mf2_m((vuint32mf2_t)(op0), (const uint32_t *)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei16_v_i32m1(op0, op1, op2) \
__builtin_rvv_vloxei16_v_i32m1((const int32_t *)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vloxei16_v_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_i32m1_m((vint32m1_t)(op0), (const int32_t *)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei16_v_i32m2(op0, op1, op2) \
__builtin_rvv_vloxei16_v_i32m2((const int32_t *)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vloxei16_v_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_i32m2_m((vint32m2_t)(op0), (const int32_t *)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei16_v_i32m4(op0, op1, op2) \
__builtin_rvv_vloxei16_v_i32m4((const int32_t *)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vloxei16_v_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_i32m4_m((vint32m4_t)(op0), (const int32_t *)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei16_v_i32m8(op0, op1, op2) \
__builtin_rvv_vloxei16_v_i32m8((const int32_t *)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vloxei16_v_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_i32m8_m((vint32m8_t)(op0), (const int32_t *)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vloxei16_v_i32mf2(op0, op1, op2) \
__builtin_rvv_vloxei16_v_i32mf2((const int32_t *)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vloxei16_v_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_i32mf2_m((vint32mf2_t)(op0), (const int32_t *)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei16_v_u32m1(op0, op1, op2) \
__builtin_rvv_vloxei16_v_u32m1((const uint32_t *)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vloxei16_v_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_u32m1_m((vuint32m1_t)(op0), (const uint32_t *)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei16_v_u32m2(op0, op1, op2) \
__builtin_rvv_vloxei16_v_u32m2((const uint32_t *)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vloxei16_v_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_u32m2_m((vuint32m2_t)(op0), (const uint32_t *)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei16_v_u32m4(op0, op1, op2) \
__builtin_rvv_vloxei16_v_u32m4((const uint32_t *)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vloxei16_v_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_u32m4_m((vuint32m4_t)(op0), (const uint32_t *)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei16_v_u32m8(op0, op1, op2) \
__builtin_rvv_vloxei16_v_u32m8((const uint32_t *)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vloxei16_v_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_u32m8_m((vuint32m8_t)(op0), (const uint32_t *)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vloxei16_v_u32mf2(op0, op1, op2) \
__builtin_rvv_vloxei16_v_u32mf2((const uint32_t *)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vloxei16_v_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_u32mf2_m((vuint32mf2_t)(op0), (const uint32_t *)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei32_v_i32m1(op0, op1, op2) \
__builtin_rvv_vloxei32_v_i32m1((const int32_t *)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vloxei32_v_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_i32m1_m((vint32m1_t)(op0), (const int32_t *)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei32_v_i32m2(op0, op1, op2) \
__builtin_rvv_vloxei32_v_i32m2((const int32_t *)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vloxei32_v_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_i32m2_m((vint32m2_t)(op0), (const int32_t *)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei32_v_i32m4(op0, op1, op2) \
__builtin_rvv_vloxei32_v_i32m4((const int32_t *)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vloxei32_v_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_i32m4_m((vint32m4_t)(op0), (const int32_t *)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei32_v_i32m8(op0, op1, op2) \
__builtin_rvv_vloxei32_v_i32m8((const int32_t *)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vloxei32_v_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_i32m8_m((vint32m8_t)(op0), (const int32_t *)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vloxei32_v_i32mf2(op0, op1, op2) \
__builtin_rvv_vloxei32_v_i32mf2((const int32_t *)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vloxei32_v_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_i32mf2_m((vint32mf2_t)(op0), (const int32_t *)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsext_vf2_i16mf4(op0, op1) \
__builtin_rvv_vsext_vf2_i16mf4((vint8mf8_t)(op0), (size_t)(op1))
#define vsext_vf2_i16mf4_m(op2, op0, op1, op3) \
__builtin_rvv_vsext_vf2_i16mf4_m((vint16mf4_t)(op0), (vint8mf8_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vsext_vf2_i16mf2(op0, op1) \
__builtin_rvv_vsext_vf2_i16mf2((vint8mf4_t)(op0), (size_t)(op1))
#define vsext_vf2_i16mf2_m(op2, op0, op1, op3) \
__builtin_rvv_vsext_vf2_i16mf2_m((vint16mf2_t)(op0), (vint8mf4_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vsext_vf2_i16m1(op0, op1) \
__builtin_rvv_vsext_vf2_i16m1((vint8mf2_t)(op0), (size_t)(op1))
#define vsext_vf2_i16m1_m(op2, op0, op1, op3) \
__builtin_rvv_vsext_vf2_i16m1_m((vint16m1_t)(op0), (vint8mf2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vsext_vf2_i16m2(op0, op1) \
__builtin_rvv_vsext_vf2_i16m2((vint8m1_t)(op0), (size_t)(op1))
#define vsext_vf2_i16m2_m(op2, op0, op1, op3) \
__builtin_rvv_vsext_vf2_i16m2_m((vint16m2_t)(op0), (vint8m1_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vsext_vf2_i16m4(op0, op1) \
__builtin_rvv_vsext_vf2_i16m4((vint8m2_t)(op0), (size_t)(op1))
#define vsext_vf2_i16m4_m(op2, op0, op1, op3) \
__builtin_rvv_vsext_vf2_i16m4_m((vint16m4_t)(op0), (vint8m2_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vsext_vf2_i16m8(op0, op1) \
__builtin_rvv_vsext_vf2_i16m8((vint8m4_t)(op0), (size_t)(op1))
#define vsext_vf2_i16m8_m(op2, op0, op1, op3) \
__builtin_rvv_vsext_vf2_i16m8_m((vint16m8_t)(op0), (vint8m4_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vsext_vf2_i32mf2(op0, op1) \
__builtin_rvv_vsext_vf2_i32mf2((vint16mf4_t)(op0), (size_t)(op1))
#define vsext_vf2_i32mf2_m(op2, op0, op1, op3) \
__builtin_rvv_vsext_vf2_i32mf2_m((vint32mf2_t)(op0), (vint16mf4_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vsext_vf2_i32m1(op0, op1) \
__builtin_rvv_vsext_vf2_i32m1((vint16mf2_t)(op0), (size_t)(op1))
#define vsext_vf2_i32m1_m(op2, op0, op1, op3) \
__builtin_rvv_vsext_vf2_i32m1_m((vint32m1_t)(op0), (vint16mf2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vsext_vf2_i32m2(op0, op1) \
__builtin_rvv_vsext_vf2_i32m2((vint16m1_t)(op0), (size_t)(op1))
#define vsext_vf2_i32m2_m(op2, op0, op1, op3) \
__builtin_rvv_vsext_vf2_i32m2_m((vint32m2_t)(op0), (vint16m1_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vsext_vf2_i32m4(op0, op1) \
__builtin_rvv_vsext_vf2_i32m4((vint16m2_t)(op0), (size_t)(op1))
#define vsext_vf2_i32m4_m(op2, op0, op1, op3) \
__builtin_rvv_vsext_vf2_i32m4_m((vint32m4_t)(op0), (vint16m2_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vsext_vf2_i32m8(op0, op1) \
__builtin_rvv_vsext_vf2_i32m8((vint16m4_t)(op0), (size_t)(op1))
#define vsext_vf2_i32m8_m(op2, op0, op1, op3) \
__builtin_rvv_vsext_vf2_i32m8_m((vint32m8_t)(op0), (vint16m4_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vsext_vf2_i64m1(op0, op1) \
__builtin_rvv_vsext_vf2_i64m1((vint32mf2_t)(op0), (size_t)(op1))
#define vsext_vf2_i64m1_m(op2, op0, op1, op3) \
__builtin_rvv_vsext_vf2_i64m1_m((vint64m1_t)(op0), (vint32mf2_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vsext_vf2_i64m2(op0, op1) \
__builtin_rvv_vsext_vf2_i64m2((vint32m1_t)(op0), (size_t)(op1))
#define vsext_vf2_i64m2_m(op2, op0, op1, op3) \
__builtin_rvv_vsext_vf2_i64m2_m((vint64m2_t)(op0), (vint32m1_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vsext_vf2_i64m4(op0, op1) \
__builtin_rvv_vsext_vf2_i64m4((vint32m2_t)(op0), (size_t)(op1))
#define vsext_vf2_i64m4_m(op2, op0, op1, op3) \
__builtin_rvv_vsext_vf2_i64m4_m((vint64m4_t)(op0), (vint32m2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vsext_vf2_i64m8(op0, op1) \
__builtin_rvv_vsext_vf2_i64m8((vint32m4_t)(op0), (size_t)(op1))
#define vsext_vf2_i64m8_m(op2, op0, op1, op3) \
__builtin_rvv_vsext_vf2_i64m8_m((vint64m8_t)(op0), (vint32m4_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vsext_vf4_i32mf2(op0, op1) \
__builtin_rvv_vsext_vf4_i32mf2((vint8mf8_t)(op0), (size_t)(op1))
#define vsext_vf4_i32mf2_m(op2, op0, op1, op3) \
__builtin_rvv_vsext_vf4_i32mf2_m((vint32mf2_t)(op0), (vint8mf8_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vsext_vf4_i32m1(op0, op1) \
__builtin_rvv_vsext_vf4_i32m1((vint8mf4_t)(op0), (size_t)(op1))
#define vsext_vf4_i32m1_m(op2, op0, op1, op3) \
__builtin_rvv_vsext_vf4_i32m1_m((vint32m1_t)(op0), (vint8mf4_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vsext_vf4_i32m2(op0, op1) \
__builtin_rvv_vsext_vf4_i32m2((vint8mf2_t)(op0), (size_t)(op1))
#define vsext_vf4_i32m2_m(op2, op0, op1, op3) \
__builtin_rvv_vsext_vf4_i32m2_m((vint32m2_t)(op0), (vint8mf2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vsext_vf4_i32m4(op0, op1) \
__builtin_rvv_vsext_vf4_i32m4((vint8m1_t)(op0), (size_t)(op1))
#define vsext_vf4_i32m4_m(op2, op0, op1, op3) \
__builtin_rvv_vsext_vf4_i32m4_m((vint32m4_t)(op0), (vint8m1_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vsext_vf4_i32m8(op0, op1) \
__builtin_rvv_vsext_vf4_i32m8((vint8m2_t)(op0), (size_t)(op1))
#define vsext_vf4_i32m8_m(op2, op0, op1, op3) \
__builtin_rvv_vsext_vf4_i32m8_m((vint32m8_t)(op0), (vint8m2_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vsext_vf4_i64m1(op0, op1) \
__builtin_rvv_vsext_vf4_i64m1((vint16mf4_t)(op0), (size_t)(op1))
#define vsext_vf4_i64m1_m(op2, op0, op1, op3) \
__builtin_rvv_vsext_vf4_i64m1_m((vint64m1_t)(op0), (vint16mf4_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vsext_vf4_i64m2(op0, op1) \
__builtin_rvv_vsext_vf4_i64m2((vint16mf2_t)(op0), (size_t)(op1))
#define vsext_vf4_i64m2_m(op2, op0, op1, op3) \
__builtin_rvv_vsext_vf4_i64m2_m((vint64m2_t)(op0), (vint16mf2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vsext_vf4_i64m4(op0, op1) \
__builtin_rvv_vsext_vf4_i64m4((vint16m1_t)(op0), (size_t)(op1))
#define vsext_vf4_i64m4_m(op2, op0, op1, op3) \
__builtin_rvv_vsext_vf4_i64m4_m((vint64m4_t)(op0), (vint16m1_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vsext_vf4_i64m8(op0, op1) \
__builtin_rvv_vsext_vf4_i64m8((vint16m2_t)(op0), (size_t)(op1))
#define vsext_vf4_i64m8_m(op2, op0, op1, op3) \
__builtin_rvv_vsext_vf4_i64m8_m((vint64m8_t)(op0), (vint16m2_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vsext_vf8_i64m1(op0, op1) \
__builtin_rvv_vsext_vf8_i64m1((vint8mf8_t)(op0), (size_t)(op1))
#define vsext_vf8_i64m1_m(op2, op0, op1, op3) \
__builtin_rvv_vsext_vf8_i64m1_m((vint64m1_t)(op0), (vint8mf8_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vsext_vf8_i64m2(op0, op1) \
__builtin_rvv_vsext_vf8_i64m2((vint8mf4_t)(op0), (size_t)(op1))
#define vsext_vf8_i64m2_m(op2, op0, op1, op3) \
__builtin_rvv_vsext_vf8_i64m2_m((vint64m2_t)(op0), (vint8mf4_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vsext_vf8_i64m4(op0, op1) \
__builtin_rvv_vsext_vf8_i64m4((vint8mf2_t)(op0), (size_t)(op1))
#define vsext_vf8_i64m4_m(op2, op0, op1, op3) \
__builtin_rvv_vsext_vf8_i64m4_m((vint64m4_t)(op0), (vint8mf2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vsext_vf8_i64m8(op0, op1) \
__builtin_rvv_vsext_vf8_i64m8((vint8m1_t)(op0), (size_t)(op1))
#define vsext_vf8_i64m8_m(op2, op0, op1, op3) \
__builtin_rvv_vsext_vf8_i64m8_m((vint64m8_t)(op0), (vint8m1_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vzext_vf2_u16mf4(op0, op1) \
__builtin_rvv_vzext_vf2_u16mf4((vuint8mf8_t)(op0), (size_t)(op1))
#define vzext_vf2_u16mf4_m(op2, op0, op1, op3) \
__builtin_rvv_vzext_vf2_u16mf4_m((vuint16mf4_t)(op0), (vuint8mf8_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vzext_vf2_u16mf2(op0, op1) \
__builtin_rvv_vzext_vf2_u16mf2((vuint8mf4_t)(op0), (size_t)(op1))
#define vzext_vf2_u16mf2_m(op2, op0, op1, op3) \
__builtin_rvv_vzext_vf2_u16mf2_m((vuint16mf2_t)(op0), (vuint8mf4_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vzext_vf2_u16m1(op0, op1) \
__builtin_rvv_vzext_vf2_u16m1((vuint8mf2_t)(op0), (size_t)(op1))
#define vzext_vf2_u16m1_m(op2, op0, op1, op3) \
__builtin_rvv_vzext_vf2_u16m1_m((vuint16m1_t)(op0), (vuint8mf2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vzext_vf2_u16m2(op0, op1) \
__builtin_rvv_vzext_vf2_u16m2((vuint8m1_t)(op0), (size_t)(op1))
#define vzext_vf2_u16m2_m(op2, op0, op1, op3) \
__builtin_rvv_vzext_vf2_u16m2_m((vuint16m2_t)(op0), (vuint8m1_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vzext_vf2_u16m4(op0, op1) \
__builtin_rvv_vzext_vf2_u16m4((vuint8m2_t)(op0), (size_t)(op1))
#define vzext_vf2_u16m4_m(op2, op0, op1, op3) \
__builtin_rvv_vzext_vf2_u16m4_m((vuint16m4_t)(op0), (vuint8m2_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vzext_vf2_u16m8(op0, op1) \
__builtin_rvv_vzext_vf2_u16m8((vuint8m4_t)(op0), (size_t)(op1))
#define vzext_vf2_u16m8_m(op2, op0, op1, op3) \
__builtin_rvv_vzext_vf2_u16m8_m((vuint16m8_t)(op0), (vuint8m4_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vzext_vf2_u32mf2(op0, op1) \
__builtin_rvv_vzext_vf2_u32mf2((vuint16mf4_t)(op0), (size_t)(op1))
#define vzext_vf2_u32mf2_m(op2, op0, op1, op3) \
__builtin_rvv_vzext_vf2_u32mf2_m((vuint32mf2_t)(op0), (vuint16mf4_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vzext_vf2_u32m1(op0, op1) \
__builtin_rvv_vzext_vf2_u32m1((vuint16mf2_t)(op0), (size_t)(op1))
#define vzext_vf2_u32m1_m(op2, op0, op1, op3) \
__builtin_rvv_vzext_vf2_u32m1_m((vuint32m1_t)(op0), (vuint16mf2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vzext_vf2_u32m2(op0, op1) \
__builtin_rvv_vzext_vf2_u32m2((vuint16m1_t)(op0), (size_t)(op1))
#define vzext_vf2_u32m2_m(op2, op0, op1, op3) \
__builtin_rvv_vzext_vf2_u32m2_m((vuint32m2_t)(op0), (vuint16m1_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vzext_vf2_u32m4(op0, op1) \
__builtin_rvv_vzext_vf2_u32m4((vuint16m2_t)(op0), (size_t)(op1))
#define vzext_vf2_u32m4_m(op2, op0, op1, op3) \
__builtin_rvv_vzext_vf2_u32m4_m((vuint32m4_t)(op0), (vuint16m2_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vzext_vf2_u32m8(op0, op1) \
__builtin_rvv_vzext_vf2_u32m8((vuint16m4_t)(op0), (size_t)(op1))
#define vzext_vf2_u32m8_m(op2, op0, op1, op3) \
__builtin_rvv_vzext_vf2_u32m8_m((vuint32m8_t)(op0), (vuint16m4_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vzext_vf2_u64m1(op0, op1) \
__builtin_rvv_vzext_vf2_u64m1((vuint32mf2_t)(op0), (size_t)(op1))
#define vzext_vf2_u64m1_m(op2, op0, op1, op3) \
__builtin_rvv_vzext_vf2_u64m1_m((vuint64m1_t)(op0), (vuint32mf2_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vzext_vf2_u64m2(op0, op1) \
__builtin_rvv_vzext_vf2_u64m2((vuint32m1_t)(op0), (size_t)(op1))
#define vzext_vf2_u64m2_m(op2, op0, op1, op3) \
__builtin_rvv_vzext_vf2_u64m2_m((vuint64m2_t)(op0), (vuint32m1_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vzext_vf2_u64m4(op0, op1) \
__builtin_rvv_vzext_vf2_u64m4((vuint32m2_t)(op0), (size_t)(op1))
#define vzext_vf2_u64m4_m(op2, op0, op1, op3) \
__builtin_rvv_vzext_vf2_u64m4_m((vuint64m4_t)(op0), (vuint32m2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vzext_vf2_u64m8(op0, op1) \
__builtin_rvv_vzext_vf2_u64m8((vuint32m4_t)(op0), (size_t)(op1))
#define vzext_vf2_u64m8_m(op2, op0, op1, op3) \
__builtin_rvv_vzext_vf2_u64m8_m((vuint64m8_t)(op0), (vuint32m4_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vzext_vf4_u32mf2(op0, op1) \
__builtin_rvv_vzext_vf4_u32mf2((vuint8mf8_t)(op0), (size_t)(op1))
#define vzext_vf4_u32mf2_m(op2, op0, op1, op3) \
__builtin_rvv_vzext_vf4_u32mf2_m((vuint32mf2_t)(op0), (vuint8mf8_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vzext_vf4_u32m1(op0, op1) \
__builtin_rvv_vzext_vf4_u32m1((vuint8mf4_t)(op0), (size_t)(op1))
#define vzext_vf4_u32m1_m(op2, op0, op1, op3) \
__builtin_rvv_vzext_vf4_u32m1_m((vuint32m1_t)(op0), (vuint8mf4_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vzext_vf4_u32m2(op0, op1) \
__builtin_rvv_vzext_vf4_u32m2((vuint8mf2_t)(op0), (size_t)(op1))
#define vzext_vf4_u32m2_m(op2, op0, op1, op3) \
__builtin_rvv_vzext_vf4_u32m2_m((vuint32m2_t)(op0), (vuint8mf2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vzext_vf4_u32m4(op0, op1) \
__builtin_rvv_vzext_vf4_u32m4((vuint8m1_t)(op0), (size_t)(op1))
#define vzext_vf4_u32m4_m(op2, op0, op1, op3) \
__builtin_rvv_vzext_vf4_u32m4_m((vuint32m4_t)(op0), (vuint8m1_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vzext_vf4_u32m8(op0, op1) \
__builtin_rvv_vzext_vf4_u32m8((vuint8m2_t)(op0), (size_t)(op1))
#define vzext_vf4_u32m8_m(op2, op0, op1, op3) \
__builtin_rvv_vzext_vf4_u32m8_m((vuint32m8_t)(op0), (vuint8m2_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vzext_vf4_u64m1(op0, op1) \
__builtin_rvv_vzext_vf4_u64m1((vuint16mf4_t)(op0), (size_t)(op1))
#define vzext_vf4_u64m1_m(op2, op0, op1, op3) \
__builtin_rvv_vzext_vf4_u64m1_m((vuint64m1_t)(op0), (vuint16mf4_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vzext_vf4_u64m2(op0, op1) \
__builtin_rvv_vzext_vf4_u64m2((vuint16mf2_t)(op0), (size_t)(op1))
#define vzext_vf4_u64m2_m(op2, op0, op1, op3) \
__builtin_rvv_vzext_vf4_u64m2_m((vuint64m2_t)(op0), (vuint16mf2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vzext_vf4_u64m4(op0, op1) \
__builtin_rvv_vzext_vf4_u64m4((vuint16m1_t)(op0), (size_t)(op1))
#define vzext_vf4_u64m4_m(op2, op0, op1, op3) \
__builtin_rvv_vzext_vf4_u64m4_m((vuint64m4_t)(op0), (vuint16m1_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vzext_vf4_u64m8(op0, op1) \
__builtin_rvv_vzext_vf4_u64m8((vuint16m2_t)(op0), (size_t)(op1))
#define vzext_vf4_u64m8_m(op2, op0, op1, op3) \
__builtin_rvv_vzext_vf4_u64m8_m((vuint64m8_t)(op0), (vuint16m2_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vzext_vf8_u64m1(op0, op1) \
__builtin_rvv_vzext_vf8_u64m1((vuint8mf8_t)(op0), (size_t)(op1))
#define vzext_vf8_u64m1_m(op2, op0, op1, op3) \
__builtin_rvv_vzext_vf8_u64m1_m((vuint64m1_t)(op0), (vuint8mf8_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vzext_vf8_u64m2(op0, op1) \
__builtin_rvv_vzext_vf8_u64m2((vuint8mf4_t)(op0), (size_t)(op1))
#define vzext_vf8_u64m2_m(op2, op0, op1, op3) \
__builtin_rvv_vzext_vf8_u64m2_m((vuint64m2_t)(op0), (vuint8mf4_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vzext_vf8_u64m4(op0, op1) \
__builtin_rvv_vzext_vf8_u64m4((vuint8mf2_t)(op0), (size_t)(op1))
#define vzext_vf8_u64m4_m(op2, op0, op1, op3) \
__builtin_rvv_vzext_vf8_u64m4_m((vuint64m4_t)(op0), (vuint8mf2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vzext_vf8_u64m8(op0, op1) \
__builtin_rvv_vzext_vf8_u64m8((vuint8m1_t)(op0), (size_t)(op1))
#define vzext_vf8_u64m8_m(op2, op0, op1, op3) \
__builtin_rvv_vzext_vf8_u64m8_m((vuint64m8_t)(op0), (vuint8m1_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#if defined(__riscv_f)
#define vloxei8_v_f32m1(op0, op1, op2) \
__builtin_rvv_vloxei8_v_f32m1((const float *)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vloxei8_v_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_f32m1_m((vfloat32m1_t)(op0), (const float *)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei8_v_f32m2(op0, op1, op2) \
__builtin_rvv_vloxei8_v_f32m2((const float *)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vloxei8_v_f32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_f32m2_m((vfloat32m2_t)(op0), (const float *)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei8_v_f32m4(op0, op1, op2) \
__builtin_rvv_vloxei8_v_f32m4((const float *)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vloxei8_v_f32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_f32m4_m((vfloat32m4_t)(op0), (const float *)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei8_v_f32m8(op0, op1, op2) \
__builtin_rvv_vloxei8_v_f32m8((const float *)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vloxei8_v_f32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_f32m8_m((vfloat32m8_t)(op0), (const float *)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vloxei8_v_f32mf2(op0, op1, op2) \
__builtin_rvv_vloxei8_v_f32mf2((const float *)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vloxei8_v_f32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_f32mf2_m((vfloat32mf2_t)(op0), (const float *)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei16_v_f32m1(op0, op1, op2) \
__builtin_rvv_vloxei16_v_f32m1((const float *)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vloxei16_v_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_f32m1_m((vfloat32m1_t)(op0), (const float *)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei16_v_f32m2(op0, op1, op2) \
__builtin_rvv_vloxei16_v_f32m2((const float *)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vloxei16_v_f32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_f32m2_m((vfloat32m2_t)(op0), (const float *)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei16_v_f32m4(op0, op1, op2) \
__builtin_rvv_vloxei16_v_f32m4((const float *)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vloxei16_v_f32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_f32m4_m((vfloat32m4_t)(op0), (const float *)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei16_v_f32m8(op0, op1, op2) \
__builtin_rvv_vloxei16_v_f32m8((const float *)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vloxei16_v_f32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_f32m8_m((vfloat32m8_t)(op0), (const float *)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vloxei16_v_f32mf2(op0, op1, op2) \
__builtin_rvv_vloxei16_v_f32mf2((const float *)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vloxei16_v_f32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_f32mf2_m((vfloat32mf2_t)(op0), (const float *)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei32_v_f32m1(op0, op1, op2) \
__builtin_rvv_vloxei32_v_f32m1((const float *)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vloxei32_v_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_f32m1_m((vfloat32m1_t)(op0), (const float *)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei32_v_f32m2(op0, op1, op2) \
__builtin_rvv_vloxei32_v_f32m2((const float *)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vloxei32_v_f32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_f32m2_m((vfloat32m2_t)(op0), (const float *)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei32_v_f32m4(op0, op1, op2) \
__builtin_rvv_vloxei32_v_f32m4((const float *)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vloxei32_v_f32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_f32m4_m((vfloat32m4_t)(op0), (const float *)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei32_v_f32m8(op0, op1, op2) \
__builtin_rvv_vloxei32_v_f32m8((const float *)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vloxei32_v_f32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_f32m8_m((vfloat32m8_t)(op0), (const float *)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vloxei32_v_f32mf2(op0, op1, op2) \
__builtin_rvv_vloxei32_v_f32mf2((const float *)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vloxei32_v_f32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_f32mf2_m((vfloat32mf2_t)(op0), (const float *)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei64_v_f32m1(op0, op1, op2) \
__builtin_rvv_vloxei64_v_f32m1((const float *)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vloxei64_v_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_f32m1_m((vfloat32m1_t)(op0), (const float *)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei64_v_f32m2(op0, op1, op2) \
__builtin_rvv_vloxei64_v_f32m2((const float *)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vloxei64_v_f32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_f32m2_m((vfloat32m2_t)(op0), (const float *)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei64_v_f32m4(op0, op1, op2) \
__builtin_rvv_vloxei64_v_f32m4((const float *)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vloxei64_v_f32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_f32m4_m((vfloat32m4_t)(op0), (const float *)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei64_v_f32mf2(op0, op1, op2) \
__builtin_rvv_vloxei64_v_f32mf2((const float *)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vloxei64_v_f32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_f32mf2_m((vfloat32mf2_t)(op0), (const float *)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vle32_v_f32m1(op0, op1) \
__builtin_rvv_vle32_v_f32m1((const float *)(op0), (size_t)(op1))
#define vle32_v_f32m1_m(op2, op0, op1, op3) \
__builtin_rvv_vle32_v_f32m1_m((vfloat32m1_t)(op0), (const float *)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vle32_v_f32m2(op0, op1) \
__builtin_rvv_vle32_v_f32m2((const float *)(op0), (size_t)(op1))
#define vle32_v_f32m2_m(op2, op0, op1, op3) \
__builtin_rvv_vle32_v_f32m2_m((vfloat32m2_t)(op0), (const float *)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vle32_v_f32m4(op0, op1) \
__builtin_rvv_vle32_v_f32m4((const float *)(op0), (size_t)(op1))
#define vle32_v_f32m4_m(op2, op0, op1, op3) \
__builtin_rvv_vle32_v_f32m4_m((vfloat32m4_t)(op0), (const float *)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vle32_v_f32m8(op0, op1) \
__builtin_rvv_vle32_v_f32m8((const float *)(op0), (size_t)(op1))
#define vle32_v_f32m8_m(op2, op0, op1, op3) \
__builtin_rvv_vle32_v_f32m8_m((vfloat32m8_t)(op0), (const float *)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vle32_v_f32mf2(op0, op1) \
__builtin_rvv_vle32_v_f32mf2((const float *)(op0), (size_t)(op1))
#define vle32_v_f32mf2_m(op2, op0, op1, op3) \
__builtin_rvv_vle32_v_f32mf2_m((vfloat32mf2_t)(op0), (const float *)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vle32ff_v_f32m1(op0, op1, op2) \
__builtin_rvv_vle32ff_v_f32m1((const float *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle32ff_v_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle32ff_v_f32m1_m((vfloat32m1_t)(op0), (const float *)(op1), (size_t *)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vle32ff_v_f32m2(op0, op1, op2) \
__builtin_rvv_vle32ff_v_f32m2((const float *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle32ff_v_f32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle32ff_v_f32m2_m((vfloat32m2_t)(op0), (const float *)(op1), (size_t *)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vle32ff_v_f32m4(op0, op1, op2) \
__builtin_rvv_vle32ff_v_f32m4((const float *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle32ff_v_f32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle32ff_v_f32m4_m((vfloat32m4_t)(op0), (const float *)(op1), (size_t *)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vle32ff_v_f32m8(op0, op1, op2) \
__builtin_rvv_vle32ff_v_f32m8((const float *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle32ff_v_f32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle32ff_v_f32m8_m((vfloat32m8_t)(op0), (const float *)(op1), (size_t *)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vle32ff_v_f32mf2(op0, op1, op2) \
__builtin_rvv_vle32ff_v_f32mf2((const float *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle32ff_v_f32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle32ff_v_f32mf2_m((vfloat32mf2_t)(op0), (const float *)(op1), (size_t *)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfadd_vv_f32m1(op0, op1, op2) \
__builtin_rvv_vfadd_vv_f32m1((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (size_t)(op2))
#define vfadd_vv_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfadd_vv_f32m1_m((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (vfloat32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfadd_vv_f32m2(op0, op1, op2) \
__builtin_rvv_vfadd_vv_f32m2((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (size_t)(op2))
#define vfadd_vv_f32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfadd_vv_f32m2_m((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (vfloat32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfadd_vv_f32m4(op0, op1, op2) \
__builtin_rvv_vfadd_vv_f32m4((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (size_t)(op2))
#define vfadd_vv_f32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfadd_vv_f32m4_m((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (vfloat32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfadd_vv_f32m8(op0, op1, op2) \
__builtin_rvv_vfadd_vv_f32m8((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (size_t)(op2))
#define vfadd_vv_f32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfadd_vv_f32m8_m((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (vfloat32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vfadd_vv_f32mf2(op0, op1, op2) \
__builtin_rvv_vfadd_vv_f32mf2((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (size_t)(op2))
#define vfadd_vv_f32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfadd_vv_f32mf2_m((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (vfloat32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfadd_vf_f32m1(op0, op1, op2) \
__builtin_rvv_vfadd_vf_f32m1((vfloat32m1_t)(op0), (float)(op1), (size_t)(op2))
#define vfadd_vf_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfadd_vf_f32m1_m((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (float)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfadd_vf_f32m2(op0, op1, op2) \
__builtin_rvv_vfadd_vf_f32m2((vfloat32m2_t)(op0), (float)(op1), (size_t)(op2))
#define vfadd_vf_f32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfadd_vf_f32m2_m((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (float)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfadd_vf_f32m4(op0, op1, op2) \
__builtin_rvv_vfadd_vf_f32m4((vfloat32m4_t)(op0), (float)(op1), (size_t)(op2))
#define vfadd_vf_f32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfadd_vf_f32m4_m((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (float)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfadd_vf_f32m8(op0, op1, op2) \
__builtin_rvv_vfadd_vf_f32m8((vfloat32m8_t)(op0), (float)(op1), (size_t)(op2))
#define vfadd_vf_f32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfadd_vf_f32m8_m((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (float)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vfadd_vf_f32mf2(op0, op1, op2) \
__builtin_rvv_vfadd_vf_f32mf2((vfloat32mf2_t)(op0), (float)(op1), (size_t)(op2))
#define vfadd_vf_f32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfadd_vf_f32mf2_m((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (float)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vse32_v_f32m1(op1, op0, op2) \
__builtin_rvv_vse32_v_f32m1((vfloat32m1_t)(op0), (float *)(op1), (size_t)(op2))
#define vse32_v_f32m1_m(op2, op1, op0, op3) \
__builtin_rvv_vse32_v_f32m1_m((vfloat32m1_t)(op0), (float *)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vse32_v_f32m2(op1, op0, op2) \
__builtin_rvv_vse32_v_f32m2((vfloat32m2_t)(op0), (float *)(op1), (size_t)(op2))
#define vse32_v_f32m2_m(op2, op1, op0, op3) \
__builtin_rvv_vse32_v_f32m2_m((vfloat32m2_t)(op0), (float *)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vse32_v_f32m4(op1, op0, op2) \
__builtin_rvv_vse32_v_f32m4((vfloat32m4_t)(op0), (float *)(op1), (size_t)(op2))
#define vse32_v_f32m4_m(op2, op1, op0, op3) \
__builtin_rvv_vse32_v_f32m4_m((vfloat32m4_t)(op0), (float *)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vse32_v_f32m8(op1, op0, op2) \
__builtin_rvv_vse32_v_f32m8((vfloat32m8_t)(op0), (float *)(op1), (size_t)(op2))
#define vse32_v_f32m8_m(op2, op1, op0, op3) \
__builtin_rvv_vse32_v_f32m8_m((vfloat32m8_t)(op0), (float *)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vse32_v_f32mf2(op1, op0, op2) \
__builtin_rvv_vse32_v_f32mf2((vfloat32mf2_t)(op0), (float *)(op1), (size_t)(op2))
#define vse32_v_f32mf2_m(op2, op1, op0, op3) \
__builtin_rvv_vse32_v_f32mf2_m((vfloat32mf2_t)(op0), (float *)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vluxei8_v_f32m1(op0, op1, op2) \
__builtin_rvv_vluxei8_v_f32m1((const float *)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vluxei8_v_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_f32m1_m((vfloat32m1_t)(op0), (const float *)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei8_v_f32m2(op0, op1, op2) \
__builtin_rvv_vluxei8_v_f32m2((const float *)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vluxei8_v_f32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_f32m2_m((vfloat32m2_t)(op0), (const float *)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei8_v_f32m4(op0, op1, op2) \
__builtin_rvv_vluxei8_v_f32m4((const float *)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vluxei8_v_f32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_f32m4_m((vfloat32m4_t)(op0), (const float *)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei8_v_f32m8(op0, op1, op2) \
__builtin_rvv_vluxei8_v_f32m8((const float *)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vluxei8_v_f32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_f32m8_m((vfloat32m8_t)(op0), (const float *)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vluxei8_v_f32mf2(op0, op1, op2) \
__builtin_rvv_vluxei8_v_f32mf2((const float *)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vluxei8_v_f32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_f32mf2_m((vfloat32mf2_t)(op0), (const float *)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei16_v_f32m1(op0, op1, op2) \
__builtin_rvv_vluxei16_v_f32m1((const float *)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vluxei16_v_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_f32m1_m((vfloat32m1_t)(op0), (const float *)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei16_v_f32m2(op0, op1, op2) \
__builtin_rvv_vluxei16_v_f32m2((const float *)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vluxei16_v_f32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_f32m2_m((vfloat32m2_t)(op0), (const float *)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei16_v_f32m4(op0, op1, op2) \
__builtin_rvv_vluxei16_v_f32m4((const float *)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vluxei16_v_f32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_f32m4_m((vfloat32m4_t)(op0), (const float *)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei16_v_f32m8(op0, op1, op2) \
__builtin_rvv_vluxei16_v_f32m8((const float *)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vluxei16_v_f32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_f32m8_m((vfloat32m8_t)(op0), (const float *)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vluxei16_v_f32mf2(op0, op1, op2) \
__builtin_rvv_vluxei16_v_f32mf2((const float *)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vluxei16_v_f32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_f32mf2_m((vfloat32mf2_t)(op0), (const float *)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei32_v_f32m1(op0, op1, op2) \
__builtin_rvv_vluxei32_v_f32m1((const float *)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vluxei32_v_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_f32m1_m((vfloat32m1_t)(op0), (const float *)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei32_v_f32m2(op0, op1, op2) \
__builtin_rvv_vluxei32_v_f32m2((const float *)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vluxei32_v_f32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_f32m2_m((vfloat32m2_t)(op0), (const float *)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei32_v_f32m4(op0, op1, op2) \
__builtin_rvv_vluxei32_v_f32m4((const float *)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vluxei32_v_f32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_f32m4_m((vfloat32m4_t)(op0), (const float *)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei32_v_f32m8(op0, op1, op2) \
__builtin_rvv_vluxei32_v_f32m8((const float *)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vluxei32_v_f32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_f32m8_m((vfloat32m8_t)(op0), (const float *)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vluxei32_v_f32mf2(op0, op1, op2) \
__builtin_rvv_vluxei32_v_f32mf2((const float *)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vluxei32_v_f32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_f32mf2_m((vfloat32mf2_t)(op0), (const float *)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei64_v_f32m1(op0, op1, op2) \
__builtin_rvv_vluxei64_v_f32m1((const float *)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vluxei64_v_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_f32m1_m((vfloat32m1_t)(op0), (const float *)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei64_v_f32m2(op0, op1, op2) \
__builtin_rvv_vluxei64_v_f32m2((const float *)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vluxei64_v_f32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_f32m2_m((vfloat32m2_t)(op0), (const float *)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei64_v_f32m4(op0, op1, op2) \
__builtin_rvv_vluxei64_v_f32m4((const float *)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vluxei64_v_f32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_f32m4_m((vfloat32m4_t)(op0), (const float *)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei64_v_f32mf2(op0, op1, op2) \
__builtin_rvv_vluxei64_v_f32mf2((const float *)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vluxei64_v_f32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_f32mf2_m((vfloat32mf2_t)(op0), (const float *)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#endif

#if defined(__riscv_d)
#define vloxei8_v_f64m1(op0, op1, op2) \
__builtin_rvv_vloxei8_v_f64m1((const double *)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vloxei8_v_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_f64m1_m((vfloat64m1_t)(op0), (const double *)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei8_v_f64m2(op0, op1, op2) \
__builtin_rvv_vloxei8_v_f64m2((const double *)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vloxei8_v_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_f64m2_m((vfloat64m2_t)(op0), (const double *)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei8_v_f64m4(op0, op1, op2) \
__builtin_rvv_vloxei8_v_f64m4((const double *)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vloxei8_v_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_f64m4_m((vfloat64m4_t)(op0), (const double *)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei8_v_f64m8(op0, op1, op2) \
__builtin_rvv_vloxei8_v_f64m8((const double *)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vloxei8_v_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_f64m8_m((vfloat64m8_t)(op0), (const double *)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei16_v_f64m1(op0, op1, op2) \
__builtin_rvv_vloxei16_v_f64m1((const double *)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vloxei16_v_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_f64m1_m((vfloat64m1_t)(op0), (const double *)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei16_v_f64m2(op0, op1, op2) \
__builtin_rvv_vloxei16_v_f64m2((const double *)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vloxei16_v_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_f64m2_m((vfloat64m2_t)(op0), (const double *)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei16_v_f64m4(op0, op1, op2) \
__builtin_rvv_vloxei16_v_f64m4((const double *)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vloxei16_v_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_f64m4_m((vfloat64m4_t)(op0), (const double *)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei16_v_f64m8(op0, op1, op2) \
__builtin_rvv_vloxei16_v_f64m8((const double *)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vloxei16_v_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_f64m8_m((vfloat64m8_t)(op0), (const double *)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei32_v_f64m1(op0, op1, op2) \
__builtin_rvv_vloxei32_v_f64m1((const double *)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vloxei32_v_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_f64m1_m((vfloat64m1_t)(op0), (const double *)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei32_v_f64m2(op0, op1, op2) \
__builtin_rvv_vloxei32_v_f64m2((const double *)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vloxei32_v_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_f64m2_m((vfloat64m2_t)(op0), (const double *)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei32_v_f64m4(op0, op1, op2) \
__builtin_rvv_vloxei32_v_f64m4((const double *)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vloxei32_v_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_f64m4_m((vfloat64m4_t)(op0), (const double *)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei32_v_f64m8(op0, op1, op2) \
__builtin_rvv_vloxei32_v_f64m8((const double *)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vloxei32_v_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_f64m8_m((vfloat64m8_t)(op0), (const double *)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei64_v_f64m1(op0, op1, op2) \
__builtin_rvv_vloxei64_v_f64m1((const double *)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vloxei64_v_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_f64m1_m((vfloat64m1_t)(op0), (const double *)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei64_v_f64m2(op0, op1, op2) \
__builtin_rvv_vloxei64_v_f64m2((const double *)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vloxei64_v_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_f64m2_m((vfloat64m2_t)(op0), (const double *)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei64_v_f64m4(op0, op1, op2) \
__builtin_rvv_vloxei64_v_f64m4((const double *)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vloxei64_v_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_f64m4_m((vfloat64m4_t)(op0), (const double *)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei64_v_f64m8(op0, op1, op2) \
__builtin_rvv_vloxei64_v_f64m8((const double *)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vloxei64_v_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_f64m8_m((vfloat64m8_t)(op0), (const double *)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vle64_v_f64m1(op0, op1) \
__builtin_rvv_vle64_v_f64m1((const double *)(op0), (size_t)(op1))
#define vle64_v_f64m1_m(op2, op0, op1, op3) \
__builtin_rvv_vle64_v_f64m1_m((vfloat64m1_t)(op0), (const double *)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vle64_v_f64m2(op0, op1) \
__builtin_rvv_vle64_v_f64m2((const double *)(op0), (size_t)(op1))
#define vle64_v_f64m2_m(op2, op0, op1, op3) \
__builtin_rvv_vle64_v_f64m2_m((vfloat64m2_t)(op0), (const double *)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vle64_v_f64m4(op0, op1) \
__builtin_rvv_vle64_v_f64m4((const double *)(op0), (size_t)(op1))
#define vle64_v_f64m4_m(op2, op0, op1, op3) \
__builtin_rvv_vle64_v_f64m4_m((vfloat64m4_t)(op0), (const double *)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vle64_v_f64m8(op0, op1) \
__builtin_rvv_vle64_v_f64m8((const double *)(op0), (size_t)(op1))
#define vle64_v_f64m8_m(op2, op0, op1, op3) \
__builtin_rvv_vle64_v_f64m8_m((vfloat64m8_t)(op0), (const double *)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vfadd_vv_f64m1(op0, op1, op2) \
__builtin_rvv_vfadd_vv_f64m1((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (size_t)(op2))
#define vfadd_vv_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfadd_vv_f64m1_m((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (vfloat64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfadd_vv_f64m2(op0, op1, op2) \
__builtin_rvv_vfadd_vv_f64m2((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (size_t)(op2))
#define vfadd_vv_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfadd_vv_f64m2_m((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (vfloat64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfadd_vv_f64m4(op0, op1, op2) \
__builtin_rvv_vfadd_vv_f64m4((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (size_t)(op2))
#define vfadd_vv_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfadd_vv_f64m4_m((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (vfloat64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfadd_vv_f64m8(op0, op1, op2) \
__builtin_rvv_vfadd_vv_f64m8((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (size_t)(op2))
#define vfadd_vv_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfadd_vv_f64m8_m((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (vfloat64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfadd_vf_f64m1(op0, op1, op2) \
__builtin_rvv_vfadd_vf_f64m1((vfloat64m1_t)(op0), (double)(op1), (size_t)(op2))
#define vfadd_vf_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfadd_vf_f64m1_m((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (double)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfadd_vf_f64m2(op0, op1, op2) \
__builtin_rvv_vfadd_vf_f64m2((vfloat64m2_t)(op0), (double)(op1), (size_t)(op2))
#define vfadd_vf_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfadd_vf_f64m2_m((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (double)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfadd_vf_f64m4(op0, op1, op2) \
__builtin_rvv_vfadd_vf_f64m4((vfloat64m4_t)(op0), (double)(op1), (size_t)(op2))
#define vfadd_vf_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfadd_vf_f64m4_m((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (double)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfadd_vf_f64m8(op0, op1, op2) \
__builtin_rvv_vfadd_vf_f64m8((vfloat64m8_t)(op0), (double)(op1), (size_t)(op2))
#define vfadd_vf_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfadd_vf_f64m8_m((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (double)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vle64ff_v_f64m1(op0, op1, op2) \
__builtin_rvv_vle64ff_v_f64m1((const double *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle64ff_v_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle64ff_v_f64m1_m((vfloat64m1_t)(op0), (const double *)(op1), (size_t *)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vle64ff_v_f64m2(op0, op1, op2) \
__builtin_rvv_vle64ff_v_f64m2((const double *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle64ff_v_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle64ff_v_f64m2_m((vfloat64m2_t)(op0), (const double *)(op1), (size_t *)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vle64ff_v_f64m4(op0, op1, op2) \
__builtin_rvv_vle64ff_v_f64m4((const double *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle64ff_v_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle64ff_v_f64m4_m((vfloat64m4_t)(op0), (const double *)(op1), (size_t *)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vle64ff_v_f64m8(op0, op1, op2) \
__builtin_rvv_vle64ff_v_f64m8((const double *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle64ff_v_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle64ff_v_f64m8_m((vfloat64m8_t)(op0), (const double *)(op1), (size_t *)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vse64_v_f64m1(op1, op0, op2) \
__builtin_rvv_vse64_v_f64m1((vfloat64m1_t)(op0), (double *)(op1), (size_t)(op2))
#define vse64_v_f64m1_m(op2, op1, op0, op3) \
__builtin_rvv_vse64_v_f64m1_m((vfloat64m1_t)(op0), (double *)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vse64_v_f64m2(op1, op0, op2) \
__builtin_rvv_vse64_v_f64m2((vfloat64m2_t)(op0), (double *)(op1), (size_t)(op2))
#define vse64_v_f64m2_m(op2, op1, op0, op3) \
__builtin_rvv_vse64_v_f64m2_m((vfloat64m2_t)(op0), (double *)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vse64_v_f64m4(op1, op0, op2) \
__builtin_rvv_vse64_v_f64m4((vfloat64m4_t)(op0), (double *)(op1), (size_t)(op2))
#define vse64_v_f64m4_m(op2, op1, op0, op3) \
__builtin_rvv_vse64_v_f64m4_m((vfloat64m4_t)(op0), (double *)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vse64_v_f64m8(op1, op0, op2) \
__builtin_rvv_vse64_v_f64m8((vfloat64m8_t)(op0), (double *)(op1), (size_t)(op2))
#define vse64_v_f64m8_m(op2, op1, op0, op3) \
__builtin_rvv_vse64_v_f64m8_m((vfloat64m8_t)(op0), (double *)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vluxei8_v_f64m1(op0, op1, op2) \
__builtin_rvv_vluxei8_v_f64m1((const double *)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vluxei8_v_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_f64m1_m((vfloat64m1_t)(op0), (const double *)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei8_v_f64m2(op0, op1, op2) \
__builtin_rvv_vluxei8_v_f64m2((const double *)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vluxei8_v_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_f64m2_m((vfloat64m2_t)(op0), (const double *)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei8_v_f64m4(op0, op1, op2) \
__builtin_rvv_vluxei8_v_f64m4((const double *)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vluxei8_v_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_f64m4_m((vfloat64m4_t)(op0), (const double *)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei8_v_f64m8(op0, op1, op2) \
__builtin_rvv_vluxei8_v_f64m8((const double *)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vluxei8_v_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_f64m8_m((vfloat64m8_t)(op0), (const double *)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei16_v_f64m1(op0, op1, op2) \
__builtin_rvv_vluxei16_v_f64m1((const double *)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vluxei16_v_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_f64m1_m((vfloat64m1_t)(op0), (const double *)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei16_v_f64m2(op0, op1, op2) \
__builtin_rvv_vluxei16_v_f64m2((const double *)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vluxei16_v_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_f64m2_m((vfloat64m2_t)(op0), (const double *)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei16_v_f64m4(op0, op1, op2) \
__builtin_rvv_vluxei16_v_f64m4((const double *)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vluxei16_v_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_f64m4_m((vfloat64m4_t)(op0), (const double *)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei16_v_f64m8(op0, op1, op2) \
__builtin_rvv_vluxei16_v_f64m8((const double *)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vluxei16_v_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_f64m8_m((vfloat64m8_t)(op0), (const double *)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei32_v_f64m1(op0, op1, op2) \
__builtin_rvv_vluxei32_v_f64m1((const double *)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vluxei32_v_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_f64m1_m((vfloat64m1_t)(op0), (const double *)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei32_v_f64m2(op0, op1, op2) \
__builtin_rvv_vluxei32_v_f64m2((const double *)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vluxei32_v_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_f64m2_m((vfloat64m2_t)(op0), (const double *)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei32_v_f64m4(op0, op1, op2) \
__builtin_rvv_vluxei32_v_f64m4((const double *)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vluxei32_v_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_f64m4_m((vfloat64m4_t)(op0), (const double *)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei32_v_f64m8(op0, op1, op2) \
__builtin_rvv_vluxei32_v_f64m8((const double *)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vluxei32_v_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_f64m8_m((vfloat64m8_t)(op0), (const double *)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei64_v_f64m1(op0, op1, op2) \
__builtin_rvv_vluxei64_v_f64m1((const double *)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vluxei64_v_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_f64m1_m((vfloat64m1_t)(op0), (const double *)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei64_v_f64m2(op0, op1, op2) \
__builtin_rvv_vluxei64_v_f64m2((const double *)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vluxei64_v_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_f64m2_m((vfloat64m2_t)(op0), (const double *)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei64_v_f64m4(op0, op1, op2) \
__builtin_rvv_vluxei64_v_f64m4((const double *)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vluxei64_v_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_f64m4_m((vfloat64m4_t)(op0), (const double *)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei64_v_f64m8(op0, op1, op2) \
__builtin_rvv_vluxei64_v_f64m8((const double *)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vluxei64_v_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_f64m8_m((vfloat64m8_t)(op0), (const double *)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#endif

#define __riscv_v_intrinsic_overloading 1
#define __rvv_overloaded static inline __attribute__((__always_inline__, __nodebug__, __overloadable__))
__rvv_overloaded vint8m1_t vadd(vint8m1_t op0, vint8m1_t op1, size_t op2){
  return vadd_vv_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vadd(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, vint8m1_t op3, size_t op4){
  return vadd_vv_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vadd(vint8m2_t op0, vint8m2_t op1, size_t op2){
  return vadd_vv_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vadd(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, vint8m2_t op3, size_t op4){
  return vadd_vv_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vadd(vint8m4_t op0, vint8m4_t op1, size_t op2){
  return vadd_vv_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vadd(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, vint8m4_t op3, size_t op4){
  return vadd_vv_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vadd(vint8m8_t op0, vint8m8_t op1, size_t op2){
  return vadd_vv_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vadd(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, vint8m8_t op3, size_t op4){
  return vadd_vv_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vadd(vint8mf2_t op0, vint8mf2_t op1, size_t op2){
  return vadd_vv_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vadd(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, vint8mf2_t op3, size_t op4){
  return vadd_vv_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vadd(vint8mf4_t op0, vint8mf4_t op1, size_t op2){
  return vadd_vv_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vadd(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, vint8mf4_t op3, size_t op4){
  return vadd_vv_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vadd(vint8mf8_t op0, vint8mf8_t op1, size_t op2){
  return vadd_vv_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vadd(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, vint8mf8_t op3, size_t op4){
  return vadd_vv_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vadd(vint16m1_t op0, vint16m1_t op1, size_t op2){
  return vadd_vv_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vadd(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, vint16m1_t op3, size_t op4){
  return vadd_vv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vadd(vint16m2_t op0, vint16m2_t op1, size_t op2){
  return vadd_vv_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vadd(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, vint16m2_t op3, size_t op4){
  return vadd_vv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vadd(vint16m4_t op0, vint16m4_t op1, size_t op2){
  return vadd_vv_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vadd(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, vint16m4_t op3, size_t op4){
  return vadd_vv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vadd(vint16m8_t op0, vint16m8_t op1, size_t op2){
  return vadd_vv_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vadd(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, vint16m8_t op3, size_t op4){
  return vadd_vv_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vadd(vint16mf2_t op0, vint16mf2_t op1, size_t op2){
  return vadd_vv_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vadd(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, vint16mf2_t op3, size_t op4){
  return vadd_vv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vadd(vint16mf4_t op0, vint16mf4_t op1, size_t op2){
  return vadd_vv_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vadd(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, vint16mf4_t op3, size_t op4){
  return vadd_vv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vadd(vint32m1_t op0, vint32m1_t op1, size_t op2){
  return vadd_vv_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vadd(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, vint32m1_t op3, size_t op4){
  return vadd_vv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vadd(vint32m2_t op0, vint32m2_t op1, size_t op2){
  return vadd_vv_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vadd(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, vint32m2_t op3, size_t op4){
  return vadd_vv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vadd(vint32m4_t op0, vint32m4_t op1, size_t op2){
  return vadd_vv_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vadd(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, vint32m4_t op3, size_t op4){
  return vadd_vv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vadd(vint32m8_t op0, vint32m8_t op1, size_t op2){
  return vadd_vv_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vadd(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, vint32m8_t op3, size_t op4){
  return vadd_vv_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vadd(vint32mf2_t op0, vint32mf2_t op1, size_t op2){
  return vadd_vv_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vadd(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, vint32mf2_t op3, size_t op4){
  return vadd_vv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vadd(vint64m1_t op0, vint64m1_t op1, size_t op2){
  return vadd_vv_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vadd(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, vint64m1_t op3, size_t op4){
  return vadd_vv_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vadd(vint64m2_t op0, vint64m2_t op1, size_t op2){
  return vadd_vv_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vadd(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, vint64m2_t op3, size_t op4){
  return vadd_vv_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vadd(vint64m4_t op0, vint64m4_t op1, size_t op2){
  return vadd_vv_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vadd(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, vint64m4_t op3, size_t op4){
  return vadd_vv_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vadd(vint64m8_t op0, vint64m8_t op1, size_t op2){
  return vadd_vv_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vadd(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, vint64m8_t op3, size_t op4){
  return vadd_vv_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vle8(vbool8_t op0, vint8m1_t op1, const int8_t * op2, size_t op3){
  return vle8_v_i8m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vint8m2_t vle8(vbool4_t op0, vint8m2_t op1, const int8_t * op2, size_t op3){
  return vle8_v_i8m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vint8m4_t vle8(vbool2_t op0, vint8m4_t op1, const int8_t * op2, size_t op3){
  return vle8_v_i8m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vint8m8_t vle8(vbool1_t op0, vint8m8_t op1, const int8_t * op2, size_t op3){
  return vle8_v_i8m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf2_t vle8(vbool16_t op0, vint8mf2_t op1, const int8_t * op2, size_t op3){
  return vle8_v_i8mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf4_t vle8(vbool32_t op0, vint8mf4_t op1, const int8_t * op2, size_t op3){
  return vle8_v_i8mf4_m(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf8_t vle8(vbool64_t op0, vint8mf8_t op1, const int8_t * op2, size_t op3){
  return vle8_v_i8mf8_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vloxei32(const uint32_t * op0, vuint32m1_t op1, size_t op2){
  return vloxei32_v_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vloxei32(vbool32_t op0, vuint32m1_t op1, const uint32_t * op2, vuint32m1_t op3, size_t op4){
  return vloxei32_v_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vloxei32(const uint32_t * op0, vuint32m2_t op1, size_t op2){
  return vloxei32_v_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vloxei32(vbool16_t op0, vuint32m2_t op1, const uint32_t * op2, vuint32m2_t op3, size_t op4){
  return vloxei32_v_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vloxei32(const uint32_t * op0, vuint32m4_t op1, size_t op2){
  return vloxei32_v_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vloxei32(vbool8_t op0, vuint32m4_t op1, const uint32_t * op2, vuint32m4_t op3, size_t op4){
  return vloxei32_v_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vloxei32(const uint32_t * op0, vuint32m8_t op1, size_t op2){
  return vloxei32_v_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vloxei32(vbool4_t op0, vuint32m8_t op1, const uint32_t * op2, vuint32m8_t op3, size_t op4){
  return vloxei32_v_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vloxei32(const uint32_t * op0, vuint32mf2_t op1, size_t op2){
  return vloxei32_v_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vloxei32(vbool64_t op0, vuint32mf2_t op1, const uint32_t * op2, vuint32mf2_t op3, size_t op4){
  return vloxei32_v_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vloxei64(const int32_t * op0, vuint64m2_t op1, size_t op2){
  return vloxei64_v_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vloxei64(vbool32_t op0, vint32m1_t op1, const int32_t * op2, vuint64m2_t op3, size_t op4){
  return vloxei64_v_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vloxei64(const int32_t * op0, vuint64m4_t op1, size_t op2){
  return vloxei64_v_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vloxei64(vbool16_t op0, vint32m2_t op1, const int32_t * op2, vuint64m4_t op3, size_t op4){
  return vloxei64_v_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vloxei64(const int32_t * op0, vuint64m8_t op1, size_t op2){
  return vloxei64_v_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vloxei64(vbool8_t op0, vint32m4_t op1, const int32_t * op2, vuint64m8_t op3, size_t op4){
  return vloxei64_v_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vloxei64(const int32_t * op0, vuint64m1_t op1, size_t op2){
  return vloxei64_v_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vloxei64(vbool64_t op0, vint32mf2_t op1, const int32_t * op2, vuint64m1_t op3, size_t op4){
  return vloxei64_v_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vloxei64(const uint32_t * op0, vuint64m2_t op1, size_t op2){
  return vloxei64_v_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vloxei64(vbool32_t op0, vuint32m1_t op1, const uint32_t * op2, vuint64m2_t op3, size_t op4){
  return vloxei64_v_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vloxei64(const uint32_t * op0, vuint64m4_t op1, size_t op2){
  return vloxei64_v_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vloxei64(vbool16_t op0, vuint32m2_t op1, const uint32_t * op2, vuint64m4_t op3, size_t op4){
  return vloxei64_v_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vloxei64(const uint32_t * op0, vuint64m8_t op1, size_t op2){
  return vloxei64_v_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vloxei64(vbool8_t op0, vuint32m4_t op1, const uint32_t * op2, vuint64m8_t op3, size_t op4){
  return vloxei64_v_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vloxei64(const uint32_t * op0, vuint64m1_t op1, size_t op2){
  return vloxei64_v_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vloxei64(vbool64_t op0, vuint32mf2_t op1, const uint32_t * op2, vuint64m1_t op3, size_t op4){
  return vloxei64_v_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vloxei8(const int64_t * op0, vuint8mf8_t op1, size_t op2){
  return vloxei8_v_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vloxei8(vbool64_t op0, vint64m1_t op1, const int64_t * op2, vuint8mf8_t op3, size_t op4){
  return vloxei8_v_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vloxei8(const int64_t * op0, vuint8mf4_t op1, size_t op2){
  return vloxei8_v_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vloxei8(vbool32_t op0, vint64m2_t op1, const int64_t * op2, vuint8mf4_t op3, size_t op4){
  return vloxei8_v_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vloxei8(const int64_t * op0, vuint8mf2_t op1, size_t op2){
  return vloxei8_v_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vloxei8(vbool16_t op0, vint64m4_t op1, const int64_t * op2, vuint8mf2_t op3, size_t op4){
  return vloxei8_v_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vloxei8(const int64_t * op0, vuint8m1_t op1, size_t op2){
  return vloxei8_v_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vloxei8(vbool8_t op0, vint64m8_t op1, const int64_t * op2, vuint8m1_t op3, size_t op4){
  return vloxei8_v_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vloxei8(const uint64_t * op0, vuint8mf8_t op1, size_t op2){
  return vloxei8_v_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vloxei8(vbool64_t op0, vuint64m1_t op1, const uint64_t * op2, vuint8mf8_t op3, size_t op4){
  return vloxei8_v_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vloxei8(const uint64_t * op0, vuint8mf4_t op1, size_t op2){
  return vloxei8_v_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vloxei8(vbool32_t op0, vuint64m2_t op1, const uint64_t * op2, vuint8mf4_t op3, size_t op4){
  return vloxei8_v_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vloxei8(const uint64_t * op0, vuint8mf2_t op1, size_t op2){
  return vloxei8_v_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vloxei8(vbool16_t op0, vuint64m4_t op1, const uint64_t * op2, vuint8mf2_t op3, size_t op4){
  return vloxei8_v_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vloxei8(const uint64_t * op0, vuint8m1_t op1, size_t op2){
  return vloxei8_v_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vloxei8(vbool8_t op0, vuint64m8_t op1, const uint64_t * op2, vuint8m1_t op3, size_t op4){
  return vloxei8_v_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vloxei16(const int64_t * op0, vuint16mf4_t op1, size_t op2){
  return vloxei16_v_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vloxei16(vbool64_t op0, vint64m1_t op1, const int64_t * op2, vuint16mf4_t op3, size_t op4){
  return vloxei16_v_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vloxei16(const int64_t * op0, vuint16mf2_t op1, size_t op2){
  return vloxei16_v_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vloxei16(vbool32_t op0, vint64m2_t op1, const int64_t * op2, vuint16mf2_t op3, size_t op4){
  return vloxei16_v_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vloxei16(const int64_t * op0, vuint16m1_t op1, size_t op2){
  return vloxei16_v_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vloxei16(vbool16_t op0, vint64m4_t op1, const int64_t * op2, vuint16m1_t op3, size_t op4){
  return vloxei16_v_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vloxei16(const int64_t * op0, vuint16m2_t op1, size_t op2){
  return vloxei16_v_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vloxei16(vbool8_t op0, vint64m8_t op1, const int64_t * op2, vuint16m2_t op3, size_t op4){
  return vloxei16_v_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vloxei16(const uint64_t * op0, vuint16mf4_t op1, size_t op2){
  return vloxei16_v_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vloxei16(vbool64_t op0, vuint64m1_t op1, const uint64_t * op2, vuint16mf4_t op3, size_t op4){
  return vloxei16_v_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vloxei16(const uint64_t * op0, vuint16mf2_t op1, size_t op2){
  return vloxei16_v_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vloxei16(vbool32_t op0, vuint64m2_t op1, const uint64_t * op2, vuint16mf2_t op3, size_t op4){
  return vloxei16_v_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vloxei16(const uint64_t * op0, vuint16m1_t op1, size_t op2){
  return vloxei16_v_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vloxei16(vbool16_t op0, vuint64m4_t op1, const uint64_t * op2, vuint16m1_t op3, size_t op4){
  return vloxei16_v_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vloxei16(const uint64_t * op0, vuint16m2_t op1, size_t op2){
  return vloxei16_v_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vloxei16(vbool8_t op0, vuint64m8_t op1, const uint64_t * op2, vuint16m2_t op3, size_t op4){
  return vloxei16_v_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vloxei32(const int64_t * op0, vuint32mf2_t op1, size_t op2){
  return vloxei32_v_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vloxei32(vbool64_t op0, vint64m1_t op1, const int64_t * op2, vuint32mf2_t op3, size_t op4){
  return vloxei32_v_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vloxei32(const int64_t * op0, vuint32m1_t op1, size_t op2){
  return vloxei32_v_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vloxei32(vbool32_t op0, vint64m2_t op1, const int64_t * op2, vuint32m1_t op3, size_t op4){
  return vloxei32_v_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vloxei32(const int64_t * op0, vuint32m2_t op1, size_t op2){
  return vloxei32_v_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vloxei32(vbool16_t op0, vint64m4_t op1, const int64_t * op2, vuint32m2_t op3, size_t op4){
  return vloxei32_v_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vloxei32(const int64_t * op0, vuint32m4_t op1, size_t op2){
  return vloxei32_v_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vloxei32(vbool8_t op0, vint64m8_t op1, const int64_t * op2, vuint32m4_t op3, size_t op4){
  return vloxei32_v_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vloxei32(const uint64_t * op0, vuint32mf2_t op1, size_t op2){
  return vloxei32_v_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vloxei32(vbool64_t op0, vuint64m1_t op1, const uint64_t * op2, vuint32mf2_t op3, size_t op4){
  return vloxei32_v_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vloxei32(const uint64_t * op0, vuint32m1_t op1, size_t op2){
  return vloxei32_v_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vloxei32(vbool32_t op0, vuint64m2_t op1, const uint64_t * op2, vuint32m1_t op3, size_t op4){
  return vloxei32_v_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vloxei32(const uint64_t * op0, vuint32m2_t op1, size_t op2){
  return vloxei32_v_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vloxei32(vbool16_t op0, vuint64m4_t op1, const uint64_t * op2, vuint32m2_t op3, size_t op4){
  return vloxei32_v_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vloxei32(const uint64_t * op0, vuint32m4_t op1, size_t op2){
  return vloxei32_v_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vloxei32(vbool8_t op0, vuint64m8_t op1, const uint64_t * op2, vuint32m4_t op3, size_t op4){
  return vloxei32_v_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vloxei64(const int64_t * op0, vuint64m1_t op1, size_t op2){
  return vloxei64_v_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vloxei64(vbool64_t op0, vint64m1_t op1, const int64_t * op2, vuint64m1_t op3, size_t op4){
  return vloxei64_v_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vloxei64(const int64_t * op0, vuint64m2_t op1, size_t op2){
  return vloxei64_v_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vloxei64(vbool32_t op0, vint64m2_t op1, const int64_t * op2, vuint64m2_t op3, size_t op4){
  return vloxei64_v_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vloxei64(const int64_t * op0, vuint64m4_t op1, size_t op2){
  return vloxei64_v_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vloxei64(vbool16_t op0, vint64m4_t op1, const int64_t * op2, vuint64m4_t op3, size_t op4){
  return vloxei64_v_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vloxei64(const int64_t * op0, vuint64m8_t op1, size_t op2){
  return vloxei64_v_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vloxei64(vbool8_t op0, vint64m8_t op1, const int64_t * op2, vuint64m8_t op3, size_t op4){
  return vloxei64_v_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vle8ff(vbool8_t op0, vint8m1_t op1, const int8_t * op2, size_t * op3, size_t op4){
  return vle8ff_v_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vle8ff(vbool4_t op0, vint8m2_t op1, const int8_t * op2, size_t * op3, size_t op4){
  return vle8ff_v_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vle8ff(vbool2_t op0, vint8m4_t op1, const int8_t * op2, size_t * op3, size_t op4){
  return vle8ff_v_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vle8ff(vbool1_t op0, vint8m8_t op1, const int8_t * op2, size_t * op3, size_t op4){
  return vle8ff_v_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vle8ff(vbool16_t op0, vint8mf2_t op1, const int8_t * op2, size_t * op3, size_t op4){
  return vle8ff_v_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vle8ff(vbool32_t op0, vint8mf4_t op1, const int8_t * op2, size_t * op3, size_t op4){
  return vle8ff_v_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vle8ff(vbool64_t op0, vint8mf8_t op1, const int8_t * op2, size_t * op3, size_t op4){
  return vle8ff_v_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vloxei64(const uint64_t * op0, vuint64m1_t op1, size_t op2){
  return vloxei64_v_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vloxei64(vbool64_t op0, vuint64m1_t op1, const uint64_t * op2, vuint64m1_t op3, size_t op4){
  return vloxei64_v_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vloxei64(const uint64_t * op0, vuint64m2_t op1, size_t op2){
  return vloxei64_v_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vloxei64(vbool32_t op0, vuint64m2_t op1, const uint64_t * op2, vuint64m2_t op3, size_t op4){
  return vloxei64_v_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vloxei64(const uint64_t * op0, vuint64m4_t op1, size_t op2){
  return vloxei64_v_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vloxei64(vbool16_t op0, vuint64m4_t op1, const uint64_t * op2, vuint64m4_t op3, size_t op4){
  return vloxei64_v_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vloxei64(const uint64_t * op0, vuint64m8_t op1, size_t op2){
  return vloxei64_v_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vloxei64(vbool8_t op0, vuint64m8_t op1, const uint64_t * op2, vuint64m8_t op3, size_t op4){
  return vloxei64_v_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vadd(vint8m1_t op0, int8_t op1, size_t op2){
  return vadd_vx_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vadd(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, int8_t op3, size_t op4){
  return vadd_vx_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vadd(vint8m2_t op0, int8_t op1, size_t op2){
  return vadd_vx_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vadd(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, int8_t op3, size_t op4){
  return vadd_vx_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vadd(vint8m4_t op0, int8_t op1, size_t op2){
  return vadd_vx_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vadd(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, int8_t op3, size_t op4){
  return vadd_vx_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vadd(vint8m8_t op0, int8_t op1, size_t op2){
  return vadd_vx_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vadd(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, int8_t op3, size_t op4){
  return vadd_vx_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vadd(vint8mf2_t op0, int8_t op1, size_t op2){
  return vadd_vx_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vadd(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, int8_t op3, size_t op4){
  return vadd_vx_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vadd(vint8mf4_t op0, int8_t op1, size_t op2){
  return vadd_vx_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vadd(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, int8_t op3, size_t op4){
  return vadd_vx_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vadd(vint8mf8_t op0, int8_t op1, size_t op2){
  return vadd_vx_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vadd(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, int8_t op3, size_t op4){
  return vadd_vx_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vadd(vint16m1_t op0, int16_t op1, size_t op2){
  return vadd_vx_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vadd(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, int16_t op3, size_t op4){
  return vadd_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vadd(vint16m2_t op0, int16_t op1, size_t op2){
  return vadd_vx_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vadd(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, int16_t op3, size_t op4){
  return vadd_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vadd(vint16m4_t op0, int16_t op1, size_t op2){
  return vadd_vx_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vadd(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, int16_t op3, size_t op4){
  return vadd_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vadd(vint16m8_t op0, int16_t op1, size_t op2){
  return vadd_vx_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vadd(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, int16_t op3, size_t op4){
  return vadd_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vadd(vint16mf2_t op0, int16_t op1, size_t op2){
  return vadd_vx_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vadd(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, int16_t op3, size_t op4){
  return vadd_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vadd(vint16mf4_t op0, int16_t op1, size_t op2){
  return vadd_vx_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vadd(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, int16_t op3, size_t op4){
  return vadd_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vadd(vint32m1_t op0, int32_t op1, size_t op2){
  return vadd_vx_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vadd(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, int32_t op3, size_t op4){
  return vadd_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vadd(vint32m2_t op0, int32_t op1, size_t op2){
  return vadd_vx_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vadd(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, int32_t op3, size_t op4){
  return vadd_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vadd(vint32m4_t op0, int32_t op1, size_t op2){
  return vadd_vx_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vadd(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, int32_t op3, size_t op4){
  return vadd_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vadd(vint32m8_t op0, int32_t op1, size_t op2){
  return vadd_vx_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vadd(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, int32_t op3, size_t op4){
  return vadd_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vadd(vint32mf2_t op0, int32_t op1, size_t op2){
  return vadd_vx_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vadd(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, int32_t op3, size_t op4){
  return vadd_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vadd(vint64m1_t op0, int64_t op1, size_t op2){
  return vadd_vx_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vadd(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, int64_t op3, size_t op4){
  return vadd_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vadd(vint64m2_t op0, int64_t op1, size_t op2){
  return vadd_vx_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vadd(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, int64_t op3, size_t op4){
  return vadd_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vadd(vint64m4_t op0, int64_t op1, size_t op2){
  return vadd_vx_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vadd(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, int64_t op3, size_t op4){
  return vadd_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vadd(vint64m8_t op0, int64_t op1, size_t op2){
  return vadd_vx_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vadd(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, int64_t op3, size_t op4){
  return vadd_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vle8ff(vbool8_t op0, vuint8m1_t op1, const uint8_t * op2, size_t * op3, size_t op4){
  return vle8ff_v_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vle8ff(vbool4_t op0, vuint8m2_t op1, const uint8_t * op2, size_t * op3, size_t op4){
  return vle8ff_v_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vle8ff(vbool2_t op0, vuint8m4_t op1, const uint8_t * op2, size_t * op3, size_t op4){
  return vle8ff_v_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vle8ff(vbool1_t op0, vuint8m8_t op1, const uint8_t * op2, size_t * op3, size_t op4){
  return vle8ff_v_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vle8ff(vbool16_t op0, vuint8mf2_t op1, const uint8_t * op2, size_t * op3, size_t op4){
  return vle8ff_v_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vle8ff(vbool32_t op0, vuint8mf4_t op1, const uint8_t * op2, size_t * op3, size_t op4){
  return vle8ff_v_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vle8ff(vbool64_t op0, vuint8mf8_t op1, const uint8_t * op2, size_t * op3, size_t op4){
  return vle8ff_v_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vadd(vuint8m1_t op0, vuint8m1_t op1, size_t op2){
  return vadd_vv_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vadd(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vadd_vv_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vadd(vuint8m2_t op0, vuint8m2_t op1, size_t op2){
  return vadd_vv_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vadd(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vadd_vv_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vadd(vuint8m4_t op0, vuint8m4_t op1, size_t op2){
  return vadd_vv_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vadd(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vadd_vv_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vadd(vuint8m8_t op0, vuint8m8_t op1, size_t op2){
  return vadd_vv_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vadd(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, vuint8m8_t op3, size_t op4){
  return vadd_vv_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vadd(vuint8mf2_t op0, vuint8mf2_t op1, size_t op2){
  return vadd_vv_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vadd(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vadd_vv_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vadd(vuint8mf4_t op0, vuint8mf4_t op1, size_t op2){
  return vadd_vv_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vadd(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vadd_vv_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vadd(vuint8mf8_t op0, vuint8mf8_t op1, size_t op2){
  return vadd_vv_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vadd(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vadd_vv_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vadd(vuint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vadd_vv_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vadd(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vadd_vv_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vadd(vuint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vadd_vv_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vadd(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vadd_vv_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vadd(vuint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vadd_vv_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vadd(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vadd_vv_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vadd(vuint16m8_t op0, vuint16m8_t op1, size_t op2){
  return vadd_vv_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vadd(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vadd_vv_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vadd(vuint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vadd_vv_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vadd(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vadd_vv_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vadd(vuint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vadd_vv_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vadd(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vadd_vv_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vadd(vuint32m1_t op0, vuint32m1_t op1, size_t op2){
  return vadd_vv_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vadd(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vadd_vv_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vadd(vuint32m2_t op0, vuint32m2_t op1, size_t op2){
  return vadd_vv_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vadd(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vadd_vv_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vadd(vuint32m4_t op0, vuint32m4_t op1, size_t op2){
  return vadd_vv_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vadd(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vadd_vv_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vadd(vuint32m8_t op0, vuint32m8_t op1, size_t op2){
  return vadd_vv_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vadd(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, vuint32m8_t op3, size_t op4){
  return vadd_vv_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vadd(vuint32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vadd_vv_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vadd(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vadd_vv_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vadd(vuint64m1_t op0, vuint64m1_t op1, size_t op2){
  return vadd_vv_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vadd(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vadd_vv_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vadd(vuint64m2_t op0, vuint64m2_t op1, size_t op2){
  return vadd_vv_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vadd(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, vuint64m2_t op3, size_t op4){
  return vadd_vv_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vadd(vuint64m4_t op0, vuint64m4_t op1, size_t op2){
  return vadd_vv_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vadd(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, vuint64m4_t op3, size_t op4){
  return vadd_vv_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vadd(vuint64m8_t op0, vuint64m8_t op1, size_t op2){
  return vadd_vv_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vadd(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, vuint64m8_t op3, size_t op4){
  return vadd_vv_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vadd(vuint8m1_t op0, uint8_t op1, size_t op2){
  return vadd_vx_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vadd(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, uint8_t op3, size_t op4){
  return vadd_vx_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vadd(vuint8m2_t op0, uint8_t op1, size_t op2){
  return vadd_vx_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vadd(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, uint8_t op3, size_t op4){
  return vadd_vx_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vadd(vuint8m4_t op0, uint8_t op1, size_t op2){
  return vadd_vx_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vadd(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, uint8_t op3, size_t op4){
  return vadd_vx_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vadd(vuint8m8_t op0, uint8_t op1, size_t op2){
  return vadd_vx_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vadd(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, uint8_t op3, size_t op4){
  return vadd_vx_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vadd(vuint8mf2_t op0, uint8_t op1, size_t op2){
  return vadd_vx_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vadd(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, uint8_t op3, size_t op4){
  return vadd_vx_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vadd(vuint8mf4_t op0, uint8_t op1, size_t op2){
  return vadd_vx_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vadd(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, uint8_t op3, size_t op4){
  return vadd_vx_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vadd(vuint8mf8_t op0, uint8_t op1, size_t op2){
  return vadd_vx_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vadd(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, uint8_t op3, size_t op4){
  return vadd_vx_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vadd(vuint16m1_t op0, uint16_t op1, size_t op2){
  return vadd_vx_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vadd(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, uint16_t op3, size_t op4){
  return vadd_vx_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vadd(vuint16m2_t op0, uint16_t op1, size_t op2){
  return vadd_vx_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vadd(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, uint16_t op3, size_t op4){
  return vadd_vx_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vadd(vuint16m4_t op0, uint16_t op1, size_t op2){
  return vadd_vx_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vadd(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, uint16_t op3, size_t op4){
  return vadd_vx_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vadd(vuint16m8_t op0, uint16_t op1, size_t op2){
  return vadd_vx_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vadd(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, uint16_t op3, size_t op4){
  return vadd_vx_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vadd(vuint16mf2_t op0, uint16_t op1, size_t op2){
  return vadd_vx_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vadd(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, uint16_t op3, size_t op4){
  return vadd_vx_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vadd(vuint16mf4_t op0, uint16_t op1, size_t op2){
  return vadd_vx_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vadd(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, uint16_t op3, size_t op4){
  return vadd_vx_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vadd(vuint32m1_t op0, uint32_t op1, size_t op2){
  return vadd_vx_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vadd(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, uint32_t op3, size_t op4){
  return vadd_vx_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vadd(vuint32m2_t op0, uint32_t op1, size_t op2){
  return vadd_vx_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vadd(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, uint32_t op3, size_t op4){
  return vadd_vx_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vadd(vuint32m4_t op0, uint32_t op1, size_t op2){
  return vadd_vx_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vadd(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, uint32_t op3, size_t op4){
  return vadd_vx_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vadd(vuint32m8_t op0, uint32_t op1, size_t op2){
  return vadd_vx_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vadd(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, uint32_t op3, size_t op4){
  return vadd_vx_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vadd(vuint32mf2_t op0, uint32_t op1, size_t op2){
  return vadd_vx_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vadd(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, uint32_t op3, size_t op4){
  return vadd_vx_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vadd(vuint64m1_t op0, uint64_t op1, size_t op2){
  return vadd_vx_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vadd(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, uint64_t op3, size_t op4){
  return vadd_vx_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vadd(vuint64m2_t op0, uint64_t op1, size_t op2){
  return vadd_vx_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vadd(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, uint64_t op3, size_t op4){
  return vadd_vx_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vadd(vuint64m4_t op0, uint64_t op1, size_t op2){
  return vadd_vx_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vadd(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, uint64_t op3, size_t op4){
  return vadd_vx_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vadd(vuint64m8_t op0, uint64_t op1, size_t op2){
  return vadd_vx_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vadd(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, uint64_t op3, size_t op4){
  return vadd_vx_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vsub(vint8m1_t op0, vint8m1_t op1, size_t op2){
  return vsub_vv_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vsub(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, vint8m1_t op3, size_t op4){
  return vsub_vv_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vsub(vint8m2_t op0, vint8m2_t op1, size_t op2){
  return vsub_vv_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vsub(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, vint8m2_t op3, size_t op4){
  return vsub_vv_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vsub(vint8m4_t op0, vint8m4_t op1, size_t op2){
  return vsub_vv_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vsub(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, vint8m4_t op3, size_t op4){
  return vsub_vv_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vsub(vint8m8_t op0, vint8m8_t op1, size_t op2){
  return vsub_vv_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vsub(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, vint8m8_t op3, size_t op4){
  return vsub_vv_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vsub(vint8mf2_t op0, vint8mf2_t op1, size_t op2){
  return vsub_vv_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vsub(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, vint8mf2_t op3, size_t op4){
  return vsub_vv_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vsub(vint8mf4_t op0, vint8mf4_t op1, size_t op2){
  return vsub_vv_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vsub(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, vint8mf4_t op3, size_t op4){
  return vsub_vv_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vsub(vint8mf8_t op0, vint8mf8_t op1, size_t op2){
  return vsub_vv_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vsub(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, vint8mf8_t op3, size_t op4){
  return vsub_vv_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vsub(vint16m1_t op0, vint16m1_t op1, size_t op2){
  return vsub_vv_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vsub(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, vint16m1_t op3, size_t op4){
  return vsub_vv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vsub(vint16m2_t op0, vint16m2_t op1, size_t op2){
  return vsub_vv_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vsub(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, vint16m2_t op3, size_t op4){
  return vsub_vv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vsub(vint16m4_t op0, vint16m4_t op1, size_t op2){
  return vsub_vv_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vsub(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, vint16m4_t op3, size_t op4){
  return vsub_vv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vsub(vint16m8_t op0, vint16m8_t op1, size_t op2){
  return vsub_vv_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vsub(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, vint16m8_t op3, size_t op4){
  return vsub_vv_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vsub(vint16mf2_t op0, vint16mf2_t op1, size_t op2){
  return vsub_vv_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vsub(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, vint16mf2_t op3, size_t op4){
  return vsub_vv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vsub(vint16mf4_t op0, vint16mf4_t op1, size_t op2){
  return vsub_vv_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vsub(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, vint16mf4_t op3, size_t op4){
  return vsub_vv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vsub(vint32m1_t op0, vint32m1_t op1, size_t op2){
  return vsub_vv_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vsub(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, vint32m1_t op3, size_t op4){
  return vsub_vv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vsub(vint32m2_t op0, vint32m2_t op1, size_t op2){
  return vsub_vv_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vsub(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, vint32m2_t op3, size_t op4){
  return vsub_vv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vsub(vint32m4_t op0, vint32m4_t op1, size_t op2){
  return vsub_vv_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vsub(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, vint32m4_t op3, size_t op4){
  return vsub_vv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vsub(vint32m8_t op0, vint32m8_t op1, size_t op2){
  return vsub_vv_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vsub(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, vint32m8_t op3, size_t op4){
  return vsub_vv_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vsub(vint32mf2_t op0, vint32mf2_t op1, size_t op2){
  return vsub_vv_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vsub(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, vint32mf2_t op3, size_t op4){
  return vsub_vv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vsub(vint64m1_t op0, vint64m1_t op1, size_t op2){
  return vsub_vv_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vsub(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, vint64m1_t op3, size_t op4){
  return vsub_vv_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vsub(vint64m2_t op0, vint64m2_t op1, size_t op2){
  return vsub_vv_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vsub(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, vint64m2_t op3, size_t op4){
  return vsub_vv_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vsub(vint64m4_t op0, vint64m4_t op1, size_t op2){
  return vsub_vv_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vsub(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, vint64m4_t op3, size_t op4){
  return vsub_vv_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vsub(vint64m8_t op0, vint64m8_t op1, size_t op2){
  return vsub_vv_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vsub(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, vint64m8_t op3, size_t op4){
  return vsub_vv_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vsub(vint8m1_t op0, int8_t op1, size_t op2){
  return vsub_vx_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vsub(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, int8_t op3, size_t op4){
  return vsub_vx_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vsub(vint8m2_t op0, int8_t op1, size_t op2){
  return vsub_vx_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vsub(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, int8_t op3, size_t op4){
  return vsub_vx_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vsub(vint8m4_t op0, int8_t op1, size_t op2){
  return vsub_vx_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vsub(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, int8_t op3, size_t op4){
  return vsub_vx_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vsub(vint8m8_t op0, int8_t op1, size_t op2){
  return vsub_vx_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vsub(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, int8_t op3, size_t op4){
  return vsub_vx_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vsub(vint8mf2_t op0, int8_t op1, size_t op2){
  return vsub_vx_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vsub(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, int8_t op3, size_t op4){
  return vsub_vx_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vsub(vint8mf4_t op0, int8_t op1, size_t op2){
  return vsub_vx_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vsub(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, int8_t op3, size_t op4){
  return vsub_vx_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vsub(vint8mf8_t op0, int8_t op1, size_t op2){
  return vsub_vx_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vsub(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, int8_t op3, size_t op4){
  return vsub_vx_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vsub(vint16m1_t op0, int16_t op1, size_t op2){
  return vsub_vx_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vsub(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, int16_t op3, size_t op4){
  return vsub_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vsub(vint16m2_t op0, int16_t op1, size_t op2){
  return vsub_vx_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vsub(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, int16_t op3, size_t op4){
  return vsub_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vsub(vint16m4_t op0, int16_t op1, size_t op2){
  return vsub_vx_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vsub(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, int16_t op3, size_t op4){
  return vsub_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vsub(vint16m8_t op0, int16_t op1, size_t op2){
  return vsub_vx_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vsub(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, int16_t op3, size_t op4){
  return vsub_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vsub(vint16mf2_t op0, int16_t op1, size_t op2){
  return vsub_vx_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vsub(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, int16_t op3, size_t op4){
  return vsub_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vsub(vint16mf4_t op0, int16_t op1, size_t op2){
  return vsub_vx_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vsub(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, int16_t op3, size_t op4){
  return vsub_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vsub(vint32m1_t op0, int32_t op1, size_t op2){
  return vsub_vx_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vsub(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, int32_t op3, size_t op4){
  return vsub_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vsub(vint32m2_t op0, int32_t op1, size_t op2){
  return vsub_vx_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vsub(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, int32_t op3, size_t op4){
  return vsub_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vsub(vint32m4_t op0, int32_t op1, size_t op2){
  return vsub_vx_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vsub(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, int32_t op3, size_t op4){
  return vsub_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vsub(vint32m8_t op0, int32_t op1, size_t op2){
  return vsub_vx_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vsub(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, int32_t op3, size_t op4){
  return vsub_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vsub(vint32mf2_t op0, int32_t op1, size_t op2){
  return vsub_vx_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vsub(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, int32_t op3, size_t op4){
  return vsub_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vsub(vint64m1_t op0, int64_t op1, size_t op2){
  return vsub_vx_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vsub(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, int64_t op3, size_t op4){
  return vsub_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vsub(vint64m2_t op0, int64_t op1, size_t op2){
  return vsub_vx_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vsub(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, int64_t op3, size_t op4){
  return vsub_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vsub(vint64m4_t op0, int64_t op1, size_t op2){
  return vsub_vx_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vsub(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, int64_t op3, size_t op4){
  return vsub_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vsub(vint64m8_t op0, int64_t op1, size_t op2){
  return vsub_vx_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vsub(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, int64_t op3, size_t op4){
  return vsub_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vsub(vuint8m1_t op0, vuint8m1_t op1, size_t op2){
  return vsub_vv_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vsub(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vsub_vv_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vsub(vuint8m2_t op0, vuint8m2_t op1, size_t op2){
  return vsub_vv_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vsub(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vsub_vv_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vsub(vuint8m4_t op0, vuint8m4_t op1, size_t op2){
  return vsub_vv_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vsub(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vsub_vv_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vsub(vuint8m8_t op0, vuint8m8_t op1, size_t op2){
  return vsub_vv_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vsub(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, vuint8m8_t op3, size_t op4){
  return vsub_vv_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vsub(vuint8mf2_t op0, vuint8mf2_t op1, size_t op2){
  return vsub_vv_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vsub(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vsub_vv_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vsub(vuint8mf4_t op0, vuint8mf4_t op1, size_t op2){
  return vsub_vv_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vsub(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vsub_vv_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vsub(vuint8mf8_t op0, vuint8mf8_t op1, size_t op2){
  return vsub_vv_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vsub(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vsub_vv_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vsub(vuint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vsub_vv_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vsub(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vsub_vv_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vsub(vuint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vsub_vv_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vsub(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vsub_vv_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vsub(vuint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vsub_vv_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vsub(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vsub_vv_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vsub(vuint16m8_t op0, vuint16m8_t op1, size_t op2){
  return vsub_vv_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vsub(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vsub_vv_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vsub(vuint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vsub_vv_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vsub(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vsub_vv_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vsub(vuint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vsub_vv_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vsub(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vsub_vv_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vsub(vuint32m1_t op0, vuint32m1_t op1, size_t op2){
  return vsub_vv_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vsub(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vsub_vv_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vsub(vuint32m2_t op0, vuint32m2_t op1, size_t op2){
  return vsub_vv_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vsub(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vsub_vv_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vsub(vuint32m4_t op0, vuint32m4_t op1, size_t op2){
  return vsub_vv_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vsub(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vsub_vv_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vsub(vuint32m8_t op0, vuint32m8_t op1, size_t op2){
  return vsub_vv_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vsub(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, vuint32m8_t op3, size_t op4){
  return vsub_vv_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vsub(vuint32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vsub_vv_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vsub(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vsub_vv_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vsub(vuint64m1_t op0, vuint64m1_t op1, size_t op2){
  return vsub_vv_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vsub(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vsub_vv_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vsub(vuint64m2_t op0, vuint64m2_t op1, size_t op2){
  return vsub_vv_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vsub(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, vuint64m2_t op3, size_t op4){
  return vsub_vv_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vsub(vuint64m4_t op0, vuint64m4_t op1, size_t op2){
  return vsub_vv_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vsub(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, vuint64m4_t op3, size_t op4){
  return vsub_vv_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vsub(vuint64m8_t op0, vuint64m8_t op1, size_t op2){
  return vsub_vv_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vsub(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, vuint64m8_t op3, size_t op4){
  return vsub_vv_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vsub(vuint8m1_t op0, uint8_t op1, size_t op2){
  return vsub_vx_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vsub(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, uint8_t op3, size_t op4){
  return vsub_vx_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vsub(vuint8m2_t op0, uint8_t op1, size_t op2){
  return vsub_vx_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vsub(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, uint8_t op3, size_t op4){
  return vsub_vx_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vsub(vuint8m4_t op0, uint8_t op1, size_t op2){
  return vsub_vx_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vsub(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, uint8_t op3, size_t op4){
  return vsub_vx_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vsub(vuint8m8_t op0, uint8_t op1, size_t op2){
  return vsub_vx_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vsub(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, uint8_t op3, size_t op4){
  return vsub_vx_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vsub(vuint8mf2_t op0, uint8_t op1, size_t op2){
  return vsub_vx_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vsub(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, uint8_t op3, size_t op4){
  return vsub_vx_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vsub(vuint8mf4_t op0, uint8_t op1, size_t op2){
  return vsub_vx_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vsub(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, uint8_t op3, size_t op4){
  return vsub_vx_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vsub(vuint8mf8_t op0, uint8_t op1, size_t op2){
  return vsub_vx_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vsub(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, uint8_t op3, size_t op4){
  return vsub_vx_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vsub(vuint16m1_t op0, uint16_t op1, size_t op2){
  return vsub_vx_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vsub(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, uint16_t op3, size_t op4){
  return vsub_vx_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vsub(vuint16m2_t op0, uint16_t op1, size_t op2){
  return vsub_vx_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vsub(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, uint16_t op3, size_t op4){
  return vsub_vx_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vsub(vuint16m4_t op0, uint16_t op1, size_t op2){
  return vsub_vx_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vsub(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, uint16_t op3, size_t op4){
  return vsub_vx_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vsub(vuint16m8_t op0, uint16_t op1, size_t op2){
  return vsub_vx_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vsub(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, uint16_t op3, size_t op4){
  return vsub_vx_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vsub(vuint16mf2_t op0, uint16_t op1, size_t op2){
  return vsub_vx_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vsub(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, uint16_t op3, size_t op4){
  return vsub_vx_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vsub(vuint16mf4_t op0, uint16_t op1, size_t op2){
  return vsub_vx_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vsub(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, uint16_t op3, size_t op4){
  return vsub_vx_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vsub(vuint32m1_t op0, uint32_t op1, size_t op2){
  return vsub_vx_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vsub(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, uint32_t op3, size_t op4){
  return vsub_vx_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vsub(vuint32m2_t op0, uint32_t op1, size_t op2){
  return vsub_vx_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vsub(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, uint32_t op3, size_t op4){
  return vsub_vx_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vsub(vuint32m4_t op0, uint32_t op1, size_t op2){
  return vsub_vx_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vsub(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, uint32_t op3, size_t op4){
  return vsub_vx_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vsub(vuint32m8_t op0, uint32_t op1, size_t op2){
  return vsub_vx_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vsub(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, uint32_t op3, size_t op4){
  return vsub_vx_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vsub(vuint32mf2_t op0, uint32_t op1, size_t op2){
  return vsub_vx_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vsub(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, uint32_t op3, size_t op4){
  return vsub_vx_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vsub(vuint64m1_t op0, uint64_t op1, size_t op2){
  return vsub_vx_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vsub(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, uint64_t op3, size_t op4){
  return vsub_vx_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vsub(vuint64m2_t op0, uint64_t op1, size_t op2){
  return vsub_vx_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vsub(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, uint64_t op3, size_t op4){
  return vsub_vx_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vsub(vuint64m4_t op0, uint64_t op1, size_t op2){
  return vsub_vx_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vsub(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, uint64_t op3, size_t op4){
  return vsub_vx_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vsub(vuint64m8_t op0, uint64_t op1, size_t op2){
  return vsub_vx_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vsub(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, uint64_t op3, size_t op4){
  return vsub_vx_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vrsub(vint8m1_t op0, int8_t op1, size_t op2){
  return vrsub_vx_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vrsub(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, int8_t op3, size_t op4){
  return vrsub_vx_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vrsub(vint8m2_t op0, int8_t op1, size_t op2){
  return vrsub_vx_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vrsub(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, int8_t op3, size_t op4){
  return vrsub_vx_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vrsub(vint8m4_t op0, int8_t op1, size_t op2){
  return vrsub_vx_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vrsub(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, int8_t op3, size_t op4){
  return vrsub_vx_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vrsub(vint8m8_t op0, int8_t op1, size_t op2){
  return vrsub_vx_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vrsub(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, int8_t op3, size_t op4){
  return vrsub_vx_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vrsub(vint8mf2_t op0, int8_t op1, size_t op2){
  return vrsub_vx_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vrsub(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, int8_t op3, size_t op4){
  return vrsub_vx_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vrsub(vint8mf4_t op0, int8_t op1, size_t op2){
  return vrsub_vx_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vrsub(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, int8_t op3, size_t op4){
  return vrsub_vx_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vrsub(vint8mf8_t op0, int8_t op1, size_t op2){
  return vrsub_vx_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vrsub(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, int8_t op3, size_t op4){
  return vrsub_vx_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vrsub(vint16m1_t op0, int16_t op1, size_t op2){
  return vrsub_vx_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vrsub(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, int16_t op3, size_t op4){
  return vrsub_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vrsub(vint16m2_t op0, int16_t op1, size_t op2){
  return vrsub_vx_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vrsub(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, int16_t op3, size_t op4){
  return vrsub_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vrsub(vint16m4_t op0, int16_t op1, size_t op2){
  return vrsub_vx_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vrsub(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, int16_t op3, size_t op4){
  return vrsub_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vrsub(vint16m8_t op0, int16_t op1, size_t op2){
  return vrsub_vx_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vrsub(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, int16_t op3, size_t op4){
  return vrsub_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vrsub(vint16mf2_t op0, int16_t op1, size_t op2){
  return vrsub_vx_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vrsub(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, int16_t op3, size_t op4){
  return vrsub_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vrsub(vint16mf4_t op0, int16_t op1, size_t op2){
  return vrsub_vx_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vrsub(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, int16_t op3, size_t op4){
  return vrsub_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vrsub(vint32m1_t op0, int32_t op1, size_t op2){
  return vrsub_vx_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vrsub(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, int32_t op3, size_t op4){
  return vrsub_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vrsub(vint32m2_t op0, int32_t op1, size_t op2){
  return vrsub_vx_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vrsub(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, int32_t op3, size_t op4){
  return vrsub_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vrsub(vint32m4_t op0, int32_t op1, size_t op2){
  return vrsub_vx_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vrsub(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, int32_t op3, size_t op4){
  return vrsub_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vrsub(vint32m8_t op0, int32_t op1, size_t op2){
  return vrsub_vx_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vrsub(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, int32_t op3, size_t op4){
  return vrsub_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vrsub(vint32mf2_t op0, int32_t op1, size_t op2){
  return vrsub_vx_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vrsub(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, int32_t op3, size_t op4){
  return vrsub_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vrsub(vint64m1_t op0, int64_t op1, size_t op2){
  return vrsub_vx_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vrsub(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, int64_t op3, size_t op4){
  return vrsub_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vrsub(vint64m2_t op0, int64_t op1, size_t op2){
  return vrsub_vx_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vrsub(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, int64_t op3, size_t op4){
  return vrsub_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vrsub(vint64m4_t op0, int64_t op1, size_t op2){
  return vrsub_vx_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vrsub(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, int64_t op3, size_t op4){
  return vrsub_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vrsub(vint64m8_t op0, int64_t op1, size_t op2){
  return vrsub_vx_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vrsub(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, int64_t op3, size_t op4){
  return vrsub_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vrsub(vuint8m1_t op0, uint8_t op1, size_t op2){
  return vrsub_vx_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vrsub(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, uint8_t op3, size_t op4){
  return vrsub_vx_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vrsub(vuint8m2_t op0, uint8_t op1, size_t op2){
  return vrsub_vx_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vrsub(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, uint8_t op3, size_t op4){
  return vrsub_vx_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vrsub(vuint8m4_t op0, uint8_t op1, size_t op2){
  return vrsub_vx_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vrsub(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, uint8_t op3, size_t op4){
  return vrsub_vx_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vrsub(vuint8m8_t op0, uint8_t op1, size_t op2){
  return vrsub_vx_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vrsub(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, uint8_t op3, size_t op4){
  return vrsub_vx_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vrsub(vuint8mf2_t op0, uint8_t op1, size_t op2){
  return vrsub_vx_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vrsub(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, uint8_t op3, size_t op4){
  return vrsub_vx_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vrsub(vuint8mf4_t op0, uint8_t op1, size_t op2){
  return vrsub_vx_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vrsub(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, uint8_t op3, size_t op4){
  return vrsub_vx_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vrsub(vuint8mf8_t op0, uint8_t op1, size_t op2){
  return vrsub_vx_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vrsub(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, uint8_t op3, size_t op4){
  return vrsub_vx_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vrsub(vuint16m1_t op0, uint16_t op1, size_t op2){
  return vrsub_vx_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vrsub(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, uint16_t op3, size_t op4){
  return vrsub_vx_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vrsub(vuint16m2_t op0, uint16_t op1, size_t op2){
  return vrsub_vx_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vrsub(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, uint16_t op3, size_t op4){
  return vrsub_vx_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vrsub(vuint16m4_t op0, uint16_t op1, size_t op2){
  return vrsub_vx_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vrsub(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, uint16_t op3, size_t op4){
  return vrsub_vx_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vrsub(vuint16m8_t op0, uint16_t op1, size_t op2){
  return vrsub_vx_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vrsub(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, uint16_t op3, size_t op4){
  return vrsub_vx_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vrsub(vuint16mf2_t op0, uint16_t op1, size_t op2){
  return vrsub_vx_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vrsub(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, uint16_t op3, size_t op4){
  return vrsub_vx_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vrsub(vuint16mf4_t op0, uint16_t op1, size_t op2){
  return vrsub_vx_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vrsub(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, uint16_t op3, size_t op4){
  return vrsub_vx_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vrsub(vuint32m1_t op0, uint32_t op1, size_t op2){
  return vrsub_vx_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vrsub(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, uint32_t op3, size_t op4){
  return vrsub_vx_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vrsub(vuint32m2_t op0, uint32_t op1, size_t op2){
  return vrsub_vx_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vrsub(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, uint32_t op3, size_t op4){
  return vrsub_vx_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vrsub(vuint32m4_t op0, uint32_t op1, size_t op2){
  return vrsub_vx_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vrsub(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, uint32_t op3, size_t op4){
  return vrsub_vx_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vrsub(vuint32m8_t op0, uint32_t op1, size_t op2){
  return vrsub_vx_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vrsub(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, uint32_t op3, size_t op4){
  return vrsub_vx_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vrsub(vuint32mf2_t op0, uint32_t op1, size_t op2){
  return vrsub_vx_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vrsub(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, uint32_t op3, size_t op4){
  return vrsub_vx_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vrsub(vuint64m1_t op0, uint64_t op1, size_t op2){
  return vrsub_vx_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vrsub(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, uint64_t op3, size_t op4){
  return vrsub_vx_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vrsub(vuint64m2_t op0, uint64_t op1, size_t op2){
  return vrsub_vx_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vrsub(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, uint64_t op3, size_t op4){
  return vrsub_vx_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vrsub(vuint64m4_t op0, uint64_t op1, size_t op2){
  return vrsub_vx_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vrsub(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, uint64_t op3, size_t op4){
  return vrsub_vx_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vrsub(vuint64m8_t op0, uint64_t op1, size_t op2){
  return vrsub_vx_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vrsub(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, uint64_t op3, size_t op4){
  return vrsub_vx_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vadc(vint8m1_t op0, vint8m1_t op1, vbool8_t op2, size_t op3){
  return vadc_vvm_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m2_t vadc(vint8m2_t op0, vint8m2_t op1, vbool4_t op2, size_t op3){
  return vadc_vvm_i8m2(op0, op1, op2, op3);
}

__rvv_overloaded vint8m4_t vadc(vint8m4_t op0, vint8m4_t op1, vbool2_t op2, size_t op3){
  return vadc_vvm_i8m4(op0, op1, op2, op3);
}

__rvv_overloaded vint8m8_t vadc(vint8m8_t op0, vint8m8_t op1, vbool1_t op2, size_t op3){
  return vadc_vvm_i8m8(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf2_t vadc(vint8mf2_t op0, vint8mf2_t op1, vbool16_t op2, size_t op3){
  return vadc_vvm_i8mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf4_t vadc(vint8mf4_t op0, vint8mf4_t op1, vbool32_t op2, size_t op3){
  return vadc_vvm_i8mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf8_t vadc(vint8mf8_t op0, vint8mf8_t op1, vbool64_t op2, size_t op3){
  return vadc_vvm_i8mf8(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vadc(vint16m1_t op0, vint16m1_t op1, vbool16_t op2, size_t op3){
  return vadc_vvm_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m2_t vadc(vint16m2_t op0, vint16m2_t op1, vbool8_t op2, size_t op3){
  return vadc_vvm_i16m2(op0, op1, op2, op3);
}

__rvv_overloaded vint16m4_t vadc(vint16m4_t op0, vint16m4_t op1, vbool4_t op2, size_t op3){
  return vadc_vvm_i16m4(op0, op1, op2, op3);
}

__rvv_overloaded vint16m8_t vadc(vint16m8_t op0, vint16m8_t op1, vbool2_t op2, size_t op3){
  return vadc_vvm_i16m8(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf2_t vadc(vint16mf2_t op0, vint16mf2_t op1, vbool32_t op2, size_t op3){
  return vadc_vvm_i16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf4_t vadc(vint16mf4_t op0, vint16mf4_t op1, vbool64_t op2, size_t op3){
  return vadc_vvm_i16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vadc(vint32m1_t op0, vint32m1_t op1, vbool32_t op2, size_t op3){
  return vadc_vvm_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m2_t vadc(vint32m2_t op0, vint32m2_t op1, vbool16_t op2, size_t op3){
  return vadc_vvm_i32m2(op0, op1, op2, op3);
}

__rvv_overloaded vint32m4_t vadc(vint32m4_t op0, vint32m4_t op1, vbool8_t op2, size_t op3){
  return vadc_vvm_i32m4(op0, op1, op2, op3);
}

__rvv_overloaded vint32m8_t vadc(vint32m8_t op0, vint32m8_t op1, vbool4_t op2, size_t op3){
  return vadc_vvm_i32m8(op0, op1, op2, op3);
}

__rvv_overloaded vint32mf2_t vadc(vint32mf2_t op0, vint32mf2_t op1, vbool64_t op2, size_t op3){
  return vadc_vvm_i32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vadc(vint64m1_t op0, vint64m1_t op1, vbool64_t op2, size_t op3){
  return vadc_vvm_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m2_t vadc(vint64m2_t op0, vint64m2_t op1, vbool32_t op2, size_t op3){
  return vadc_vvm_i64m2(op0, op1, op2, op3);
}

__rvv_overloaded vint64m4_t vadc(vint64m4_t op0, vint64m4_t op1, vbool16_t op2, size_t op3){
  return vadc_vvm_i64m4(op0, op1, op2, op3);
}

__rvv_overloaded vint64m8_t vadc(vint64m8_t op0, vint64m8_t op1, vbool8_t op2, size_t op3){
  return vadc_vvm_i64m8(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vadc(vint8m1_t op0, int8_t op1, vbool8_t op2, size_t op3){
  return vadc_vxm_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m2_t vadc(vint8m2_t op0, int8_t op1, vbool4_t op2, size_t op3){
  return vadc_vxm_i8m2(op0, op1, op2, op3);
}

__rvv_overloaded vint8m4_t vadc(vint8m4_t op0, int8_t op1, vbool2_t op2, size_t op3){
  return vadc_vxm_i8m4(op0, op1, op2, op3);
}

__rvv_overloaded vint8m8_t vadc(vint8m8_t op0, int8_t op1, vbool1_t op2, size_t op3){
  return vadc_vxm_i8m8(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf2_t vadc(vint8mf2_t op0, int8_t op1, vbool16_t op2, size_t op3){
  return vadc_vxm_i8mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf4_t vadc(vint8mf4_t op0, int8_t op1, vbool32_t op2, size_t op3){
  return vadc_vxm_i8mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf8_t vadc(vint8mf8_t op0, int8_t op1, vbool64_t op2, size_t op3){
  return vadc_vxm_i8mf8(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vadc(vint16m1_t op0, int16_t op1, vbool16_t op2, size_t op3){
  return vadc_vxm_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m2_t vadc(vint16m2_t op0, int16_t op1, vbool8_t op2, size_t op3){
  return vadc_vxm_i16m2(op0, op1, op2, op3);
}

__rvv_overloaded vint16m4_t vadc(vint16m4_t op0, int16_t op1, vbool4_t op2, size_t op3){
  return vadc_vxm_i16m4(op0, op1, op2, op3);
}

__rvv_overloaded vint16m8_t vadc(vint16m8_t op0, int16_t op1, vbool2_t op2, size_t op3){
  return vadc_vxm_i16m8(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf2_t vadc(vint16mf2_t op0, int16_t op1, vbool32_t op2, size_t op3){
  return vadc_vxm_i16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf4_t vadc(vint16mf4_t op0, int16_t op1, vbool64_t op2, size_t op3){
  return vadc_vxm_i16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vadc(vint32m1_t op0, int32_t op1, vbool32_t op2, size_t op3){
  return vadc_vxm_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m2_t vadc(vint32m2_t op0, int32_t op1, vbool16_t op2, size_t op3){
  return vadc_vxm_i32m2(op0, op1, op2, op3);
}

__rvv_overloaded vint32m4_t vadc(vint32m4_t op0, int32_t op1, vbool8_t op2, size_t op3){
  return vadc_vxm_i32m4(op0, op1, op2, op3);
}

__rvv_overloaded vint32m8_t vadc(vint32m8_t op0, int32_t op1, vbool4_t op2, size_t op3){
  return vadc_vxm_i32m8(op0, op1, op2, op3);
}

__rvv_overloaded vint32mf2_t vadc(vint32mf2_t op0, int32_t op1, vbool64_t op2, size_t op3){
  return vadc_vxm_i32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vadc(vint64m1_t op0, int64_t op1, vbool64_t op2, size_t op3){
  return vadc_vxm_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m2_t vadc(vint64m2_t op0, int64_t op1, vbool32_t op2, size_t op3){
  return vadc_vxm_i64m2(op0, op1, op2, op3);
}

__rvv_overloaded vint64m4_t vadc(vint64m4_t op0, int64_t op1, vbool16_t op2, size_t op3){
  return vadc_vxm_i64m4(op0, op1, op2, op3);
}

__rvv_overloaded vint64m8_t vadc(vint64m8_t op0, int64_t op1, vbool8_t op2, size_t op3){
  return vadc_vxm_i64m8(op0, op1, op2, op3);
}

__rvv_overloaded void vse8(int8_t * op0, vint8m1_t op1, size_t op2){
  return vse8_v_i8m1(op0, op1, op2);
}

__rvv_overloaded void vse8(vbool8_t op0, int8_t * op1, vint8m1_t op2, size_t op3){
  return vse8_v_i8m1_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse8(int8_t * op0, vint8m2_t op1, size_t op2){
  return vse8_v_i8m2(op0, op1, op2);
}

__rvv_overloaded void vse8(vbool4_t op0, int8_t * op1, vint8m2_t op2, size_t op3){
  return vse8_v_i8m2_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse8(int8_t * op0, vint8m4_t op1, size_t op2){
  return vse8_v_i8m4(op0, op1, op2);
}

__rvv_overloaded void vse8(vbool2_t op0, int8_t * op1, vint8m4_t op2, size_t op3){
  return vse8_v_i8m4_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse8(int8_t * op0, vint8m8_t op1, size_t op2){
  return vse8_v_i8m8(op0, op1, op2);
}

__rvv_overloaded void vse8(vbool1_t op0, int8_t * op1, vint8m8_t op2, size_t op3){
  return vse8_v_i8m8_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse8(int8_t * op0, vint8mf2_t op1, size_t op2){
  return vse8_v_i8mf2(op0, op1, op2);
}

__rvv_overloaded void vse8(vbool16_t op0, int8_t * op1, vint8mf2_t op2, size_t op3){
  return vse8_v_i8mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse8(int8_t * op0, vint8mf4_t op1, size_t op2){
  return vse8_v_i8mf4(op0, op1, op2);
}

__rvv_overloaded void vse8(vbool32_t op0, int8_t * op1, vint8mf4_t op2, size_t op3){
  return vse8_v_i8mf4_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse8(int8_t * op0, vint8mf8_t op1, size_t op2){
  return vse8_v_i8mf8(op0, op1, op2);
}

__rvv_overloaded void vse8(vbool64_t op0, int8_t * op1, vint8mf8_t op2, size_t op3){
  return vse8_v_i8mf8_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vadc(vuint8m1_t op0, vuint8m1_t op1, vbool8_t op2, size_t op3){
  return vadc_vvm_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m2_t vadc(vuint8m2_t op0, vuint8m2_t op1, vbool4_t op2, size_t op3){
  return vadc_vvm_u8m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m4_t vadc(vuint8m4_t op0, vuint8m4_t op1, vbool2_t op2, size_t op3){
  return vadc_vvm_u8m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m8_t vadc(vuint8m8_t op0, vuint8m8_t op1, vbool1_t op2, size_t op3){
  return vadc_vvm_u8m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf2_t vadc(vuint8mf2_t op0, vuint8mf2_t op1, vbool16_t op2, size_t op3){
  return vadc_vvm_u8mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf4_t vadc(vuint8mf4_t op0, vuint8mf4_t op1, vbool32_t op2, size_t op3){
  return vadc_vvm_u8mf4(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf8_t vadc(vuint8mf8_t op0, vuint8mf8_t op1, vbool64_t op2, size_t op3){
  return vadc_vvm_u8mf8(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vadc(vuint16m1_t op0, vuint16m1_t op1, vbool16_t op2, size_t op3){
  return vadc_vvm_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m2_t vadc(vuint16m2_t op0, vuint16m2_t op1, vbool8_t op2, size_t op3){
  return vadc_vvm_u16m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m4_t vadc(vuint16m4_t op0, vuint16m4_t op1, vbool4_t op2, size_t op3){
  return vadc_vvm_u16m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m8_t vadc(vuint16m8_t op0, vuint16m8_t op1, vbool2_t op2, size_t op3){
  return vadc_vvm_u16m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf2_t vadc(vuint16mf2_t op0, vuint16mf2_t op1, vbool32_t op2, size_t op3){
  return vadc_vvm_u16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf4_t vadc(vuint16mf4_t op0, vuint16mf4_t op1, vbool64_t op2, size_t op3){
  return vadc_vvm_u16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vadc(vuint32m1_t op0, vuint32m1_t op1, vbool32_t op2, size_t op3){
  return vadc_vvm_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m2_t vadc(vuint32m2_t op0, vuint32m2_t op1, vbool16_t op2, size_t op3){
  return vadc_vvm_u32m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m4_t vadc(vuint32m4_t op0, vuint32m4_t op1, vbool8_t op2, size_t op3){
  return vadc_vvm_u32m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m8_t vadc(vuint32m8_t op0, vuint32m8_t op1, vbool4_t op2, size_t op3){
  return vadc_vvm_u32m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint32mf2_t vadc(vuint32mf2_t op0, vuint32mf2_t op1, vbool64_t op2, size_t op3){
  return vadc_vvm_u32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vadc(vuint64m1_t op0, vuint64m1_t op1, vbool64_t op2, size_t op3){
  return vadc_vvm_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m2_t vadc(vuint64m2_t op0, vuint64m2_t op1, vbool32_t op2, size_t op3){
  return vadc_vvm_u64m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m4_t vadc(vuint64m4_t op0, vuint64m4_t op1, vbool16_t op2, size_t op3){
  return vadc_vvm_u64m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m8_t vadc(vuint64m8_t op0, vuint64m8_t op1, vbool8_t op2, size_t op3){
  return vadc_vvm_u64m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vadc(vuint8m1_t op0, uint8_t op1, vbool8_t op2, size_t op3){
  return vadc_vxm_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m2_t vadc(vuint8m2_t op0, uint8_t op1, vbool4_t op2, size_t op3){
  return vadc_vxm_u8m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m4_t vadc(vuint8m4_t op0, uint8_t op1, vbool2_t op2, size_t op3){
  return vadc_vxm_u8m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m8_t vadc(vuint8m8_t op0, uint8_t op1, vbool1_t op2, size_t op3){
  return vadc_vxm_u8m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf2_t vadc(vuint8mf2_t op0, uint8_t op1, vbool16_t op2, size_t op3){
  return vadc_vxm_u8mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf4_t vadc(vuint8mf4_t op0, uint8_t op1, vbool32_t op2, size_t op3){
  return vadc_vxm_u8mf4(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf8_t vadc(vuint8mf8_t op0, uint8_t op1, vbool64_t op2, size_t op3){
  return vadc_vxm_u8mf8(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vadc(vuint16m1_t op0, uint16_t op1, vbool16_t op2, size_t op3){
  return vadc_vxm_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m2_t vadc(vuint16m2_t op0, uint16_t op1, vbool8_t op2, size_t op3){
  return vadc_vxm_u16m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m4_t vadc(vuint16m4_t op0, uint16_t op1, vbool4_t op2, size_t op3){
  return vadc_vxm_u16m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m8_t vadc(vuint16m8_t op0, uint16_t op1, vbool2_t op2, size_t op3){
  return vadc_vxm_u16m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf2_t vadc(vuint16mf2_t op0, uint16_t op1, vbool32_t op2, size_t op3){
  return vadc_vxm_u16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf4_t vadc(vuint16mf4_t op0, uint16_t op1, vbool64_t op2, size_t op3){
  return vadc_vxm_u16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vadc(vuint32m1_t op0, uint32_t op1, vbool32_t op2, size_t op3){
  return vadc_vxm_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m2_t vadc(vuint32m2_t op0, uint32_t op1, vbool16_t op2, size_t op3){
  return vadc_vxm_u32m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m4_t vadc(vuint32m4_t op0, uint32_t op1, vbool8_t op2, size_t op3){
  return vadc_vxm_u32m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m8_t vadc(vuint32m8_t op0, uint32_t op1, vbool4_t op2, size_t op3){
  return vadc_vxm_u32m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint32mf2_t vadc(vuint32mf2_t op0, uint32_t op1, vbool64_t op2, size_t op3){
  return vadc_vxm_u32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vadc(vuint64m1_t op0, uint64_t op1, vbool64_t op2, size_t op3){
  return vadc_vxm_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m2_t vadc(vuint64m2_t op0, uint64_t op1, vbool32_t op2, size_t op3){
  return vadc_vxm_u64m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m4_t vadc(vuint64m4_t op0, uint64_t op1, vbool16_t op2, size_t op3){
  return vadc_vxm_u64m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m8_t vadc(vuint64m8_t op0, uint64_t op1, vbool8_t op2, size_t op3){
  return vadc_vxm_u64m8(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmadc(vint8m1_t op0, vint8m1_t op1, vbool8_t op2, size_t op3){
  return vmadc_vvm_i8m1_b8(op0, op1, op2, op3);
}

__rvv_overloaded vbool4_t vmadc(vint8m2_t op0, vint8m2_t op1, vbool4_t op2, size_t op3){
  return vmadc_vvm_i8m2_b4(op0, op1, op2, op3);
}

__rvv_overloaded vbool2_t vmadc(vint8m4_t op0, vint8m4_t op1, vbool2_t op2, size_t op3){
  return vmadc_vvm_i8m4_b2(op0, op1, op2, op3);
}

__rvv_overloaded vbool1_t vmadc(vint8m8_t op0, vint8m8_t op1, vbool1_t op2, size_t op3){
  return vmadc_vvm_i8m8_b1(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmadc(vint8mf2_t op0, vint8mf2_t op1, vbool16_t op2, size_t op3){
  return vmadc_vvm_i8mf2_b16(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmadc(vint8mf4_t op0, vint8mf4_t op1, vbool32_t op2, size_t op3){
  return vmadc_vvm_i8mf4_b32(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmadc(vint8mf8_t op0, vint8mf8_t op1, vbool64_t op2, size_t op3){
  return vmadc_vvm_i8mf8_b64(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmadc(vint16m1_t op0, vint16m1_t op1, vbool16_t op2, size_t op3){
  return vmadc_vvm_i16m1_b16(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmadc(vint16m2_t op0, vint16m2_t op1, vbool8_t op2, size_t op3){
  return vmadc_vvm_i16m2_b8(op0, op1, op2, op3);
}

__rvv_overloaded vbool4_t vmadc(vint16m4_t op0, vint16m4_t op1, vbool4_t op2, size_t op3){
  return vmadc_vvm_i16m4_b4(op0, op1, op2, op3);
}

__rvv_overloaded vbool2_t vmadc(vint16m8_t op0, vint16m8_t op1, vbool2_t op2, size_t op3){
  return vmadc_vvm_i16m8_b2(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmadc(vint16mf2_t op0, vint16mf2_t op1, vbool32_t op2, size_t op3){
  return vmadc_vvm_i16mf2_b32(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmadc(vint16mf4_t op0, vint16mf4_t op1, vbool64_t op2, size_t op3){
  return vmadc_vvm_i16mf4_b64(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmadc(vint32m1_t op0, vint32m1_t op1, vbool32_t op2, size_t op3){
  return vmadc_vvm_i32m1_b32(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmadc(vint32m2_t op0, vint32m2_t op1, vbool16_t op2, size_t op3){
  return vmadc_vvm_i32m2_b16(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmadc(vint32m4_t op0, vint32m4_t op1, vbool8_t op2, size_t op3){
  return vmadc_vvm_i32m4_b8(op0, op1, op2, op3);
}

__rvv_overloaded vbool4_t vmadc(vint32m8_t op0, vint32m8_t op1, vbool4_t op2, size_t op3){
  return vmadc_vvm_i32m8_b4(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmadc(vint32mf2_t op0, vint32mf2_t op1, vbool64_t op2, size_t op3){
  return vmadc_vvm_i32mf2_b64(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmadc(vint64m1_t op0, vint64m1_t op1, vbool64_t op2, size_t op3){
  return vmadc_vvm_i64m1_b64(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmadc(vint64m2_t op0, vint64m2_t op1, vbool32_t op2, size_t op3){
  return vmadc_vvm_i64m2_b32(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmadc(vint64m4_t op0, vint64m4_t op1, vbool16_t op2, size_t op3){
  return vmadc_vvm_i64m4_b16(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmadc(vint64m8_t op0, vint64m8_t op1, vbool8_t op2, size_t op3){
  return vmadc_vvm_i64m8_b8(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmadc(vint8m1_t op0, int8_t op1, vbool8_t op2, size_t op3){
  return vmadc_vxm_i8m1_b8(op0, op1, op2, op3);
}

__rvv_overloaded vbool4_t vmadc(vint8m2_t op0, int8_t op1, vbool4_t op2, size_t op3){
  return vmadc_vxm_i8m2_b4(op0, op1, op2, op3);
}

__rvv_overloaded vbool2_t vmadc(vint8m4_t op0, int8_t op1, vbool2_t op2, size_t op3){
  return vmadc_vxm_i8m4_b2(op0, op1, op2, op3);
}

__rvv_overloaded vbool1_t vmadc(vint8m8_t op0, int8_t op1, vbool1_t op2, size_t op3){
  return vmadc_vxm_i8m8_b1(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmadc(vint8mf2_t op0, int8_t op1, vbool16_t op2, size_t op3){
  return vmadc_vxm_i8mf2_b16(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmadc(vint8mf4_t op0, int8_t op1, vbool32_t op2, size_t op3){
  return vmadc_vxm_i8mf4_b32(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmadc(vint8mf8_t op0, int8_t op1, vbool64_t op2, size_t op3){
  return vmadc_vxm_i8mf8_b64(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmadc(vint16m1_t op0, int16_t op1, vbool16_t op2, size_t op3){
  return vmadc_vxm_i16m1_b16(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmadc(vint16m2_t op0, int16_t op1, vbool8_t op2, size_t op3){
  return vmadc_vxm_i16m2_b8(op0, op1, op2, op3);
}

__rvv_overloaded vbool4_t vmadc(vint16m4_t op0, int16_t op1, vbool4_t op2, size_t op3){
  return vmadc_vxm_i16m4_b4(op0, op1, op2, op3);
}

__rvv_overloaded vbool2_t vmadc(vint16m8_t op0, int16_t op1, vbool2_t op2, size_t op3){
  return vmadc_vxm_i16m8_b2(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmadc(vint16mf2_t op0, int16_t op1, vbool32_t op2, size_t op3){
  return vmadc_vxm_i16mf2_b32(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmadc(vint16mf4_t op0, int16_t op1, vbool64_t op2, size_t op3){
  return vmadc_vxm_i16mf4_b64(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmadc(vint32m1_t op0, int32_t op1, vbool32_t op2, size_t op3){
  return vmadc_vxm_i32m1_b32(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmadc(vint32m2_t op0, int32_t op1, vbool16_t op2, size_t op3){
  return vmadc_vxm_i32m2_b16(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmadc(vint32m4_t op0, int32_t op1, vbool8_t op2, size_t op3){
  return vmadc_vxm_i32m4_b8(op0, op1, op2, op3);
}

__rvv_overloaded vbool4_t vmadc(vint32m8_t op0, int32_t op1, vbool4_t op2, size_t op3){
  return vmadc_vxm_i32m8_b4(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmadc(vint32mf2_t op0, int32_t op1, vbool64_t op2, size_t op3){
  return vmadc_vxm_i32mf2_b64(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmadc(vint64m1_t op0, int64_t op1, vbool64_t op2, size_t op3){
  return vmadc_vxm_i64m1_b64(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmadc(vint64m2_t op0, int64_t op1, vbool32_t op2, size_t op3){
  return vmadc_vxm_i64m2_b32(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmadc(vint64m4_t op0, int64_t op1, vbool16_t op2, size_t op3){
  return vmadc_vxm_i64m4_b16(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmadc(vint64m8_t op0, int64_t op1, vbool8_t op2, size_t op3){
  return vmadc_vxm_i64m8_b8(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmadc(vuint8m1_t op0, vuint8m1_t op1, vbool8_t op2, size_t op3){
  return vmadc_vvm_u8m1_b8(op0, op1, op2, op3);
}

__rvv_overloaded vbool4_t vmadc(vuint8m2_t op0, vuint8m2_t op1, vbool4_t op2, size_t op3){
  return vmadc_vvm_u8m2_b4(op0, op1, op2, op3);
}

__rvv_overloaded vbool2_t vmadc(vuint8m4_t op0, vuint8m4_t op1, vbool2_t op2, size_t op3){
  return vmadc_vvm_u8m4_b2(op0, op1, op2, op3);
}

__rvv_overloaded vbool1_t vmadc(vuint8m8_t op0, vuint8m8_t op1, vbool1_t op2, size_t op3){
  return vmadc_vvm_u8m8_b1(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmadc(vuint8mf2_t op0, vuint8mf2_t op1, vbool16_t op2, size_t op3){
  return vmadc_vvm_u8mf2_b16(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmadc(vuint8mf4_t op0, vuint8mf4_t op1, vbool32_t op2, size_t op3){
  return vmadc_vvm_u8mf4_b32(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmadc(vuint8mf8_t op0, vuint8mf8_t op1, vbool64_t op2, size_t op3){
  return vmadc_vvm_u8mf8_b64(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmadc(vuint16m1_t op0, vuint16m1_t op1, vbool16_t op2, size_t op3){
  return vmadc_vvm_u16m1_b16(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmadc(vuint16m2_t op0, vuint16m2_t op1, vbool8_t op2, size_t op3){
  return vmadc_vvm_u16m2_b8(op0, op1, op2, op3);
}

__rvv_overloaded vbool4_t vmadc(vuint16m4_t op0, vuint16m4_t op1, vbool4_t op2, size_t op3){
  return vmadc_vvm_u16m4_b4(op0, op1, op2, op3);
}

__rvv_overloaded vbool2_t vmadc(vuint16m8_t op0, vuint16m8_t op1, vbool2_t op2, size_t op3){
  return vmadc_vvm_u16m8_b2(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmadc(vuint16mf2_t op0, vuint16mf2_t op1, vbool32_t op2, size_t op3){
  return vmadc_vvm_u16mf2_b32(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmadc(vuint16mf4_t op0, vuint16mf4_t op1, vbool64_t op2, size_t op3){
  return vmadc_vvm_u16mf4_b64(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmadc(vuint32m1_t op0, vuint32m1_t op1, vbool32_t op2, size_t op3){
  return vmadc_vvm_u32m1_b32(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmadc(vuint32m2_t op0, vuint32m2_t op1, vbool16_t op2, size_t op3){
  return vmadc_vvm_u32m2_b16(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmadc(vuint32m4_t op0, vuint32m4_t op1, vbool8_t op2, size_t op3){
  return vmadc_vvm_u32m4_b8(op0, op1, op2, op3);
}

__rvv_overloaded vbool4_t vmadc(vuint32m8_t op0, vuint32m8_t op1, vbool4_t op2, size_t op3){
  return vmadc_vvm_u32m8_b4(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmadc(vuint32mf2_t op0, vuint32mf2_t op1, vbool64_t op2, size_t op3){
  return vmadc_vvm_u32mf2_b64(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmadc(vuint64m1_t op0, vuint64m1_t op1, vbool64_t op2, size_t op3){
  return vmadc_vvm_u64m1_b64(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmadc(vuint64m2_t op0, vuint64m2_t op1, vbool32_t op2, size_t op3){
  return vmadc_vvm_u64m2_b32(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmadc(vuint64m4_t op0, vuint64m4_t op1, vbool16_t op2, size_t op3){
  return vmadc_vvm_u64m4_b16(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmadc(vuint64m8_t op0, vuint64m8_t op1, vbool8_t op2, size_t op3){
  return vmadc_vvm_u64m8_b8(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmadc(vuint8m1_t op0, uint8_t op1, vbool8_t op2, size_t op3){
  return vmadc_vxm_u8m1_b8(op0, op1, op2, op3);
}

__rvv_overloaded vbool4_t vmadc(vuint8m2_t op0, uint8_t op1, vbool4_t op2, size_t op3){
  return vmadc_vxm_u8m2_b4(op0, op1, op2, op3);
}

__rvv_overloaded vbool2_t vmadc(vuint8m4_t op0, uint8_t op1, vbool2_t op2, size_t op3){
  return vmadc_vxm_u8m4_b2(op0, op1, op2, op3);
}

__rvv_overloaded vbool1_t vmadc(vuint8m8_t op0, uint8_t op1, vbool1_t op2, size_t op3){
  return vmadc_vxm_u8m8_b1(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmadc(vuint8mf2_t op0, uint8_t op1, vbool16_t op2, size_t op3){
  return vmadc_vxm_u8mf2_b16(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmadc(vuint8mf4_t op0, uint8_t op1, vbool32_t op2, size_t op3){
  return vmadc_vxm_u8mf4_b32(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmadc(vuint8mf8_t op0, uint8_t op1, vbool64_t op2, size_t op3){
  return vmadc_vxm_u8mf8_b64(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmadc(vuint16m1_t op0, uint16_t op1, vbool16_t op2, size_t op3){
  return vmadc_vxm_u16m1_b16(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmadc(vuint16m2_t op0, uint16_t op1, vbool8_t op2, size_t op3){
  return vmadc_vxm_u16m2_b8(op0, op1, op2, op3);
}

__rvv_overloaded vbool4_t vmadc(vuint16m4_t op0, uint16_t op1, vbool4_t op2, size_t op3){
  return vmadc_vxm_u16m4_b4(op0, op1, op2, op3);
}

__rvv_overloaded vbool2_t vmadc(vuint16m8_t op0, uint16_t op1, vbool2_t op2, size_t op3){
  return vmadc_vxm_u16m8_b2(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmadc(vuint16mf2_t op0, uint16_t op1, vbool32_t op2, size_t op3){
  return vmadc_vxm_u16mf2_b32(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmadc(vuint16mf4_t op0, uint16_t op1, vbool64_t op2, size_t op3){
  return vmadc_vxm_u16mf4_b64(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmadc(vuint32m1_t op0, uint32_t op1, vbool32_t op2, size_t op3){
  return vmadc_vxm_u32m1_b32(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmadc(vuint32m2_t op0, uint32_t op1, vbool16_t op2, size_t op3){
  return vmadc_vxm_u32m2_b16(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmadc(vuint32m4_t op0, uint32_t op1, vbool8_t op2, size_t op3){
  return vmadc_vxm_u32m4_b8(op0, op1, op2, op3);
}

__rvv_overloaded vbool4_t vmadc(vuint32m8_t op0, uint32_t op1, vbool4_t op2, size_t op3){
  return vmadc_vxm_u32m8_b4(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmadc(vuint32mf2_t op0, uint32_t op1, vbool64_t op2, size_t op3){
  return vmadc_vxm_u32mf2_b64(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmadc(vuint64m1_t op0, uint64_t op1, vbool64_t op2, size_t op3){
  return vmadc_vxm_u64m1_b64(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmadc(vuint64m2_t op0, uint64_t op1, vbool32_t op2, size_t op3){
  return vmadc_vxm_u64m2_b32(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmadc(vuint64m4_t op0, uint64_t op1, vbool16_t op2, size_t op3){
  return vmadc_vxm_u64m4_b16(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmadc(vuint64m8_t op0, uint64_t op1, vbool8_t op2, size_t op3){
  return vmadc_vxm_u64m8_b8(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmadc(vint8m1_t op0, vint8m1_t op1, size_t op2){
  return vmadc_vv_i8m1_b8(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmadc(vint8m2_t op0, vint8m2_t op1, size_t op2){
  return vmadc_vv_i8m2_b4(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmadc(vint8m4_t op0, vint8m4_t op1, size_t op2){
  return vmadc_vv_i8m4_b2(op0, op1, op2);
}

__rvv_overloaded vbool1_t vmadc(vint8m8_t op0, vint8m8_t op1, size_t op2){
  return vmadc_vv_i8m8_b1(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmadc(vint8mf2_t op0, vint8mf2_t op1, size_t op2){
  return vmadc_vv_i8mf2_b16(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmadc(vint8mf4_t op0, vint8mf4_t op1, size_t op2){
  return vmadc_vv_i8mf4_b32(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmadc(vint8mf8_t op0, vint8mf8_t op1, size_t op2){
  return vmadc_vv_i8mf8_b64(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmadc(vint16m1_t op0, vint16m1_t op1, size_t op2){
  return vmadc_vv_i16m1_b16(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmadc(vint16m2_t op0, vint16m2_t op1, size_t op2){
  return vmadc_vv_i16m2_b8(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmadc(vint16m4_t op0, vint16m4_t op1, size_t op2){
  return vmadc_vv_i16m4_b4(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmadc(vint16m8_t op0, vint16m8_t op1, size_t op2){
  return vmadc_vv_i16m8_b2(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmadc(vint16mf2_t op0, vint16mf2_t op1, size_t op2){
  return vmadc_vv_i16mf2_b32(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmadc(vint16mf4_t op0, vint16mf4_t op1, size_t op2){
  return vmadc_vv_i16mf4_b64(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmadc(vint32m1_t op0, vint32m1_t op1, size_t op2){
  return vmadc_vv_i32m1_b32(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmadc(vint32m2_t op0, vint32m2_t op1, size_t op2){
  return vmadc_vv_i32m2_b16(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmadc(vint32m4_t op0, vint32m4_t op1, size_t op2){
  return vmadc_vv_i32m4_b8(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmadc(vint32m8_t op0, vint32m8_t op1, size_t op2){
  return vmadc_vv_i32m8_b4(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmadc(vint32mf2_t op0, vint32mf2_t op1, size_t op2){
  return vmadc_vv_i32mf2_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmadc(vint64m1_t op0, vint64m1_t op1, size_t op2){
  return vmadc_vv_i64m1_b64(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmadc(vint64m2_t op0, vint64m2_t op1, size_t op2){
  return vmadc_vv_i64m2_b32(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmadc(vint64m4_t op0, vint64m4_t op1, size_t op2){
  return vmadc_vv_i64m4_b16(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmadc(vint64m8_t op0, vint64m8_t op1, size_t op2){
  return vmadc_vv_i64m8_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmadc(vint8m1_t op0, int8_t op1, size_t op2){
  return vmadc_vx_i8m1_b8(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmadc(vint8m2_t op0, int8_t op1, size_t op2){
  return vmadc_vx_i8m2_b4(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmadc(vint8m4_t op0, int8_t op1, size_t op2){
  return vmadc_vx_i8m4_b2(op0, op1, op2);
}

__rvv_overloaded vbool1_t vmadc(vint8m8_t op0, int8_t op1, size_t op2){
  return vmadc_vx_i8m8_b1(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmadc(vint8mf2_t op0, int8_t op1, size_t op2){
  return vmadc_vx_i8mf2_b16(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmadc(vint8mf4_t op0, int8_t op1, size_t op2){
  return vmadc_vx_i8mf4_b32(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmadc(vint8mf8_t op0, int8_t op1, size_t op2){
  return vmadc_vx_i8mf8_b64(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmadc(vint16m1_t op0, int16_t op1, size_t op2){
  return vmadc_vx_i16m1_b16(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmadc(vint16m2_t op0, int16_t op1, size_t op2){
  return vmadc_vx_i16m2_b8(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmadc(vint16m4_t op0, int16_t op1, size_t op2){
  return vmadc_vx_i16m4_b4(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmadc(vint16m8_t op0, int16_t op1, size_t op2){
  return vmadc_vx_i16m8_b2(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmadc(vint16mf2_t op0, int16_t op1, size_t op2){
  return vmadc_vx_i16mf2_b32(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmadc(vint16mf4_t op0, int16_t op1, size_t op2){
  return vmadc_vx_i16mf4_b64(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmadc(vint32m1_t op0, int32_t op1, size_t op2){
  return vmadc_vx_i32m1_b32(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmadc(vint32m2_t op0, int32_t op1, size_t op2){
  return vmadc_vx_i32m2_b16(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmadc(vint32m4_t op0, int32_t op1, size_t op2){
  return vmadc_vx_i32m4_b8(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmadc(vint32m8_t op0, int32_t op1, size_t op2){
  return vmadc_vx_i32m8_b4(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmadc(vint32mf2_t op0, int32_t op1, size_t op2){
  return vmadc_vx_i32mf2_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmadc(vint64m1_t op0, int64_t op1, size_t op2){
  return vmadc_vx_i64m1_b64(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmadc(vint64m2_t op0, int64_t op1, size_t op2){
  return vmadc_vx_i64m2_b32(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmadc(vint64m4_t op0, int64_t op1, size_t op2){
  return vmadc_vx_i64m4_b16(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmadc(vint64m8_t op0, int64_t op1, size_t op2){
  return vmadc_vx_i64m8_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmadc(vuint8m1_t op0, vuint8m1_t op1, size_t op2){
  return vmadc_vv_u8m1_b8(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmadc(vuint8m2_t op0, vuint8m2_t op1, size_t op2){
  return vmadc_vv_u8m2_b4(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmadc(vuint8m4_t op0, vuint8m4_t op1, size_t op2){
  return vmadc_vv_u8m4_b2(op0, op1, op2);
}

__rvv_overloaded vbool1_t vmadc(vuint8m8_t op0, vuint8m8_t op1, size_t op2){
  return vmadc_vv_u8m8_b1(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmadc(vuint8mf2_t op0, vuint8mf2_t op1, size_t op2){
  return vmadc_vv_u8mf2_b16(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmadc(vuint8mf4_t op0, vuint8mf4_t op1, size_t op2){
  return vmadc_vv_u8mf4_b32(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmadc(vuint8mf8_t op0, vuint8mf8_t op1, size_t op2){
  return vmadc_vv_u8mf8_b64(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmadc(vuint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vmadc_vv_u16m1_b16(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmadc(vuint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vmadc_vv_u16m2_b8(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmadc(vuint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vmadc_vv_u16m4_b4(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmadc(vuint16m8_t op0, vuint16m8_t op1, size_t op2){
  return vmadc_vv_u16m8_b2(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmadc(vuint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vmadc_vv_u16mf2_b32(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmadc(vuint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vmadc_vv_u16mf4_b64(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmadc(vuint32m1_t op0, vuint32m1_t op1, size_t op2){
  return vmadc_vv_u32m1_b32(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmadc(vuint32m2_t op0, vuint32m2_t op1, size_t op2){
  return vmadc_vv_u32m2_b16(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmadc(vuint32m4_t op0, vuint32m4_t op1, size_t op2){
  return vmadc_vv_u32m4_b8(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmadc(vuint32m8_t op0, vuint32m8_t op1, size_t op2){
  return vmadc_vv_u32m8_b4(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmadc(vuint32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vmadc_vv_u32mf2_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmadc(vuint64m1_t op0, vuint64m1_t op1, size_t op2){
  return vmadc_vv_u64m1_b64(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmadc(vuint64m2_t op0, vuint64m2_t op1, size_t op2){
  return vmadc_vv_u64m2_b32(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmadc(vuint64m4_t op0, vuint64m4_t op1, size_t op2){
  return vmadc_vv_u64m4_b16(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmadc(vuint64m8_t op0, vuint64m8_t op1, size_t op2){
  return vmadc_vv_u64m8_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmadc(vuint8m1_t op0, uint8_t op1, size_t op2){
  return vmadc_vx_u8m1_b8(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmadc(vuint8m2_t op0, uint8_t op1, size_t op2){
  return vmadc_vx_u8m2_b4(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmadc(vuint8m4_t op0, uint8_t op1, size_t op2){
  return vmadc_vx_u8m4_b2(op0, op1, op2);
}

__rvv_overloaded vbool1_t vmadc(vuint8m8_t op0, uint8_t op1, size_t op2){
  return vmadc_vx_u8m8_b1(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmadc(vuint8mf2_t op0, uint8_t op1, size_t op2){
  return vmadc_vx_u8mf2_b16(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmadc(vuint8mf4_t op0, uint8_t op1, size_t op2){
  return vmadc_vx_u8mf4_b32(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmadc(vuint8mf8_t op0, uint8_t op1, size_t op2){
  return vmadc_vx_u8mf8_b64(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmadc(vuint16m1_t op0, uint16_t op1, size_t op2){
  return vmadc_vx_u16m1_b16(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmadc(vuint16m2_t op0, uint16_t op1, size_t op2){
  return vmadc_vx_u16m2_b8(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmadc(vuint16m4_t op0, uint16_t op1, size_t op2){
  return vmadc_vx_u16m4_b4(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmadc(vuint16m8_t op0, uint16_t op1, size_t op2){
  return vmadc_vx_u16m8_b2(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmadc(vuint16mf2_t op0, uint16_t op1, size_t op2){
  return vmadc_vx_u16mf2_b32(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmadc(vuint16mf4_t op0, uint16_t op1, size_t op2){
  return vmadc_vx_u16mf4_b64(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmadc(vuint32m1_t op0, uint32_t op1, size_t op2){
  return vmadc_vx_u32m1_b32(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmadc(vuint32m2_t op0, uint32_t op1, size_t op2){
  return vmadc_vx_u32m2_b16(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmadc(vuint32m4_t op0, uint32_t op1, size_t op2){
  return vmadc_vx_u32m4_b8(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmadc(vuint32m8_t op0, uint32_t op1, size_t op2){
  return vmadc_vx_u32m8_b4(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmadc(vuint32mf2_t op0, uint32_t op1, size_t op2){
  return vmadc_vx_u32mf2_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmadc(vuint64m1_t op0, uint64_t op1, size_t op2){
  return vmadc_vx_u64m1_b64(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmadc(vuint64m2_t op0, uint64_t op1, size_t op2){
  return vmadc_vx_u64m2_b32(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmadc(vuint64m4_t op0, uint64_t op1, size_t op2){
  return vmadc_vx_u64m4_b16(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmadc(vuint64m8_t op0, uint64_t op1, size_t op2){
  return vmadc_vx_u64m8_b8(op0, op1, op2);
}

__rvv_overloaded void vse8(uint8_t * op0, vuint8m1_t op1, size_t op2){
  return vse8_v_u8m1(op0, op1, op2);
}

__rvv_overloaded void vse8(vbool8_t op0, uint8_t * op1, vuint8m1_t op2, size_t op3){
  return vse8_v_u8m1_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse8(uint8_t * op0, vuint8m2_t op1, size_t op2){
  return vse8_v_u8m2(op0, op1, op2);
}

__rvv_overloaded void vse8(vbool4_t op0, uint8_t * op1, vuint8m2_t op2, size_t op3){
  return vse8_v_u8m2_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse8(uint8_t * op0, vuint8m4_t op1, size_t op2){
  return vse8_v_u8m4(op0, op1, op2);
}

__rvv_overloaded void vse8(vbool2_t op0, uint8_t * op1, vuint8m4_t op2, size_t op3){
  return vse8_v_u8m4_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse8(uint8_t * op0, vuint8m8_t op1, size_t op2){
  return vse8_v_u8m8(op0, op1, op2);
}

__rvv_overloaded void vse8(vbool1_t op0, uint8_t * op1, vuint8m8_t op2, size_t op3){
  return vse8_v_u8m8_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse8(uint8_t * op0, vuint8mf2_t op1, size_t op2){
  return vse8_v_u8mf2(op0, op1, op2);
}

__rvv_overloaded void vse8(vbool16_t op0, uint8_t * op1, vuint8mf2_t op2, size_t op3){
  return vse8_v_u8mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse8(uint8_t * op0, vuint8mf4_t op1, size_t op2){
  return vse8_v_u8mf4(op0, op1, op2);
}

__rvv_overloaded void vse8(vbool32_t op0, uint8_t * op1, vuint8mf4_t op2, size_t op3){
  return vse8_v_u8mf4_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse8(uint8_t * op0, vuint8mf8_t op1, size_t op2){
  return vse8_v_u8mf8(op0, op1, op2);
}

__rvv_overloaded void vse8(vbool64_t op0, uint8_t * op1, vuint8mf8_t op2, size_t op3){
  return vse8_v_u8mf8_m(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vsbc(vint8m1_t op0, vint8m1_t op1, vbool8_t op2, size_t op3){
  return vsbc_vvm_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m2_t vsbc(vint8m2_t op0, vint8m2_t op1, vbool4_t op2, size_t op3){
  return vsbc_vvm_i8m2(op0, op1, op2, op3);
}

__rvv_overloaded vint8m4_t vsbc(vint8m4_t op0, vint8m4_t op1, vbool2_t op2, size_t op3){
  return vsbc_vvm_i8m4(op0, op1, op2, op3);
}

__rvv_overloaded vint8m8_t vsbc(vint8m8_t op0, vint8m8_t op1, vbool1_t op2, size_t op3){
  return vsbc_vvm_i8m8(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf2_t vsbc(vint8mf2_t op0, vint8mf2_t op1, vbool16_t op2, size_t op3){
  return vsbc_vvm_i8mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf4_t vsbc(vint8mf4_t op0, vint8mf4_t op1, vbool32_t op2, size_t op3){
  return vsbc_vvm_i8mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf8_t vsbc(vint8mf8_t op0, vint8mf8_t op1, vbool64_t op2, size_t op3){
  return vsbc_vvm_i8mf8(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vsbc(vint16m1_t op0, vint16m1_t op1, vbool16_t op2, size_t op3){
  return vsbc_vvm_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m2_t vsbc(vint16m2_t op0, vint16m2_t op1, vbool8_t op2, size_t op3){
  return vsbc_vvm_i16m2(op0, op1, op2, op3);
}

__rvv_overloaded vint16m4_t vsbc(vint16m4_t op0, vint16m4_t op1, vbool4_t op2, size_t op3){
  return vsbc_vvm_i16m4(op0, op1, op2, op3);
}

__rvv_overloaded vint16m8_t vsbc(vint16m8_t op0, vint16m8_t op1, vbool2_t op2, size_t op3){
  return vsbc_vvm_i16m8(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf2_t vsbc(vint16mf2_t op0, vint16mf2_t op1, vbool32_t op2, size_t op3){
  return vsbc_vvm_i16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf4_t vsbc(vint16mf4_t op0, vint16mf4_t op1, vbool64_t op2, size_t op3){
  return vsbc_vvm_i16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vsbc(vint32m1_t op0, vint32m1_t op1, vbool32_t op2, size_t op3){
  return vsbc_vvm_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m2_t vsbc(vint32m2_t op0, vint32m2_t op1, vbool16_t op2, size_t op3){
  return vsbc_vvm_i32m2(op0, op1, op2, op3);
}

__rvv_overloaded vint32m4_t vsbc(vint32m4_t op0, vint32m4_t op1, vbool8_t op2, size_t op3){
  return vsbc_vvm_i32m4(op0, op1, op2, op3);
}

__rvv_overloaded vint32m8_t vsbc(vint32m8_t op0, vint32m8_t op1, vbool4_t op2, size_t op3){
  return vsbc_vvm_i32m8(op0, op1, op2, op3);
}

__rvv_overloaded vint32mf2_t vsbc(vint32mf2_t op0, vint32mf2_t op1, vbool64_t op2, size_t op3){
  return vsbc_vvm_i32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vsbc(vint64m1_t op0, vint64m1_t op1, vbool64_t op2, size_t op3){
  return vsbc_vvm_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m2_t vsbc(vint64m2_t op0, vint64m2_t op1, vbool32_t op2, size_t op3){
  return vsbc_vvm_i64m2(op0, op1, op2, op3);
}

__rvv_overloaded vint64m4_t vsbc(vint64m4_t op0, vint64m4_t op1, vbool16_t op2, size_t op3){
  return vsbc_vvm_i64m4(op0, op1, op2, op3);
}

__rvv_overloaded vint64m8_t vsbc(vint64m8_t op0, vint64m8_t op1, vbool8_t op2, size_t op3){
  return vsbc_vvm_i64m8(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vsbc(vint8m1_t op0, int8_t op1, vbool8_t op2, size_t op3){
  return vsbc_vxm_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m2_t vsbc(vint8m2_t op0, int8_t op1, vbool4_t op2, size_t op3){
  return vsbc_vxm_i8m2(op0, op1, op2, op3);
}

__rvv_overloaded vint8m4_t vsbc(vint8m4_t op0, int8_t op1, vbool2_t op2, size_t op3){
  return vsbc_vxm_i8m4(op0, op1, op2, op3);
}

__rvv_overloaded vint8m8_t vsbc(vint8m8_t op0, int8_t op1, vbool1_t op2, size_t op3){
  return vsbc_vxm_i8m8(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf2_t vsbc(vint8mf2_t op0, int8_t op1, vbool16_t op2, size_t op3){
  return vsbc_vxm_i8mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf4_t vsbc(vint8mf4_t op0, int8_t op1, vbool32_t op2, size_t op3){
  return vsbc_vxm_i8mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf8_t vsbc(vint8mf8_t op0, int8_t op1, vbool64_t op2, size_t op3){
  return vsbc_vxm_i8mf8(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vsbc(vint16m1_t op0, int16_t op1, vbool16_t op2, size_t op3){
  return vsbc_vxm_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m2_t vsbc(vint16m2_t op0, int16_t op1, vbool8_t op2, size_t op3){
  return vsbc_vxm_i16m2(op0, op1, op2, op3);
}

__rvv_overloaded vint16m4_t vsbc(vint16m4_t op0, int16_t op1, vbool4_t op2, size_t op3){
  return vsbc_vxm_i16m4(op0, op1, op2, op3);
}

__rvv_overloaded vint16m8_t vsbc(vint16m8_t op0, int16_t op1, vbool2_t op2, size_t op3){
  return vsbc_vxm_i16m8(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf2_t vsbc(vint16mf2_t op0, int16_t op1, vbool32_t op2, size_t op3){
  return vsbc_vxm_i16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf4_t vsbc(vint16mf4_t op0, int16_t op1, vbool64_t op2, size_t op3){
  return vsbc_vxm_i16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vsbc(vint32m1_t op0, int32_t op1, vbool32_t op2, size_t op3){
  return vsbc_vxm_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m2_t vsbc(vint32m2_t op0, int32_t op1, vbool16_t op2, size_t op3){
  return vsbc_vxm_i32m2(op0, op1, op2, op3);
}

__rvv_overloaded vint32m4_t vsbc(vint32m4_t op0, int32_t op1, vbool8_t op2, size_t op3){
  return vsbc_vxm_i32m4(op0, op1, op2, op3);
}

__rvv_overloaded vint32m8_t vsbc(vint32m8_t op0, int32_t op1, vbool4_t op2, size_t op3){
  return vsbc_vxm_i32m8(op0, op1, op2, op3);
}

__rvv_overloaded vint32mf2_t vsbc(vint32mf2_t op0, int32_t op1, vbool64_t op2, size_t op3){
  return vsbc_vxm_i32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vsbc(vint64m1_t op0, int64_t op1, vbool64_t op2, size_t op3){
  return vsbc_vxm_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m2_t vsbc(vint64m2_t op0, int64_t op1, vbool32_t op2, size_t op3){
  return vsbc_vxm_i64m2(op0, op1, op2, op3);
}

__rvv_overloaded vint64m4_t vsbc(vint64m4_t op0, int64_t op1, vbool16_t op2, size_t op3){
  return vsbc_vxm_i64m4(op0, op1, op2, op3);
}

__rvv_overloaded vint64m8_t vsbc(vint64m8_t op0, int64_t op1, vbool8_t op2, size_t op3){
  return vsbc_vxm_i64m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vsbc(vuint8m1_t op0, vuint8m1_t op1, vbool8_t op2, size_t op3){
  return vsbc_vvm_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m2_t vsbc(vuint8m2_t op0, vuint8m2_t op1, vbool4_t op2, size_t op3){
  return vsbc_vvm_u8m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m4_t vsbc(vuint8m4_t op0, vuint8m4_t op1, vbool2_t op2, size_t op3){
  return vsbc_vvm_u8m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m8_t vsbc(vuint8m8_t op0, vuint8m8_t op1, vbool1_t op2, size_t op3){
  return vsbc_vvm_u8m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf2_t vsbc(vuint8mf2_t op0, vuint8mf2_t op1, vbool16_t op2, size_t op3){
  return vsbc_vvm_u8mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf4_t vsbc(vuint8mf4_t op0, vuint8mf4_t op1, vbool32_t op2, size_t op3){
  return vsbc_vvm_u8mf4(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf8_t vsbc(vuint8mf8_t op0, vuint8mf8_t op1, vbool64_t op2, size_t op3){
  return vsbc_vvm_u8mf8(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vsbc(vuint16m1_t op0, vuint16m1_t op1, vbool16_t op2, size_t op3){
  return vsbc_vvm_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m2_t vsbc(vuint16m2_t op0, vuint16m2_t op1, vbool8_t op2, size_t op3){
  return vsbc_vvm_u16m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m4_t vsbc(vuint16m4_t op0, vuint16m4_t op1, vbool4_t op2, size_t op3){
  return vsbc_vvm_u16m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m8_t vsbc(vuint16m8_t op0, vuint16m8_t op1, vbool2_t op2, size_t op3){
  return vsbc_vvm_u16m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf2_t vsbc(vuint16mf2_t op0, vuint16mf2_t op1, vbool32_t op2, size_t op3){
  return vsbc_vvm_u16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf4_t vsbc(vuint16mf4_t op0, vuint16mf4_t op1, vbool64_t op2, size_t op3){
  return vsbc_vvm_u16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vsbc(vuint32m1_t op0, vuint32m1_t op1, vbool32_t op2, size_t op3){
  return vsbc_vvm_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m2_t vsbc(vuint32m2_t op0, vuint32m2_t op1, vbool16_t op2, size_t op3){
  return vsbc_vvm_u32m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m4_t vsbc(vuint32m4_t op0, vuint32m4_t op1, vbool8_t op2, size_t op3){
  return vsbc_vvm_u32m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m8_t vsbc(vuint32m8_t op0, vuint32m8_t op1, vbool4_t op2, size_t op3){
  return vsbc_vvm_u32m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint32mf2_t vsbc(vuint32mf2_t op0, vuint32mf2_t op1, vbool64_t op2, size_t op3){
  return vsbc_vvm_u32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vsbc(vuint64m1_t op0, vuint64m1_t op1, vbool64_t op2, size_t op3){
  return vsbc_vvm_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m2_t vsbc(vuint64m2_t op0, vuint64m2_t op1, vbool32_t op2, size_t op3){
  return vsbc_vvm_u64m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m4_t vsbc(vuint64m4_t op0, vuint64m4_t op1, vbool16_t op2, size_t op3){
  return vsbc_vvm_u64m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m8_t vsbc(vuint64m8_t op0, vuint64m8_t op1, vbool8_t op2, size_t op3){
  return vsbc_vvm_u64m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vsbc(vuint8m1_t op0, uint8_t op1, vbool8_t op2, size_t op3){
  return vsbc_vxm_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m2_t vsbc(vuint8m2_t op0, uint8_t op1, vbool4_t op2, size_t op3){
  return vsbc_vxm_u8m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m4_t vsbc(vuint8m4_t op0, uint8_t op1, vbool2_t op2, size_t op3){
  return vsbc_vxm_u8m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m8_t vsbc(vuint8m8_t op0, uint8_t op1, vbool1_t op2, size_t op3){
  return vsbc_vxm_u8m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf2_t vsbc(vuint8mf2_t op0, uint8_t op1, vbool16_t op2, size_t op3){
  return vsbc_vxm_u8mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf4_t vsbc(vuint8mf4_t op0, uint8_t op1, vbool32_t op2, size_t op3){
  return vsbc_vxm_u8mf4(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf8_t vsbc(vuint8mf8_t op0, uint8_t op1, vbool64_t op2, size_t op3){
  return vsbc_vxm_u8mf8(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vsbc(vuint16m1_t op0, uint16_t op1, vbool16_t op2, size_t op3){
  return vsbc_vxm_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m2_t vsbc(vuint16m2_t op0, uint16_t op1, vbool8_t op2, size_t op3){
  return vsbc_vxm_u16m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m4_t vsbc(vuint16m4_t op0, uint16_t op1, vbool4_t op2, size_t op3){
  return vsbc_vxm_u16m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m8_t vsbc(vuint16m8_t op0, uint16_t op1, vbool2_t op2, size_t op3){
  return vsbc_vxm_u16m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf2_t vsbc(vuint16mf2_t op0, uint16_t op1, vbool32_t op2, size_t op3){
  return vsbc_vxm_u16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf4_t vsbc(vuint16mf4_t op0, uint16_t op1, vbool64_t op2, size_t op3){
  return vsbc_vxm_u16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vsbc(vuint32m1_t op0, uint32_t op1, vbool32_t op2, size_t op3){
  return vsbc_vxm_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m2_t vsbc(vuint32m2_t op0, uint32_t op1, vbool16_t op2, size_t op3){
  return vsbc_vxm_u32m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m4_t vsbc(vuint32m4_t op0, uint32_t op1, vbool8_t op2, size_t op3){
  return vsbc_vxm_u32m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m8_t vsbc(vuint32m8_t op0, uint32_t op1, vbool4_t op2, size_t op3){
  return vsbc_vxm_u32m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint32mf2_t vsbc(vuint32mf2_t op0, uint32_t op1, vbool64_t op2, size_t op3){
  return vsbc_vxm_u32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vsbc(vuint64m1_t op0, uint64_t op1, vbool64_t op2, size_t op3){
  return vsbc_vxm_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m2_t vsbc(vuint64m2_t op0, uint64_t op1, vbool32_t op2, size_t op3){
  return vsbc_vxm_u64m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m4_t vsbc(vuint64m4_t op0, uint64_t op1, vbool16_t op2, size_t op3){
  return vsbc_vxm_u64m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m8_t vsbc(vuint64m8_t op0, uint64_t op1, vbool8_t op2, size_t op3){
  return vsbc_vxm_u64m8(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmsbc(vint8m1_t op0, vint8m1_t op1, vbool8_t op2, size_t op3){
  return vmsbc_vvm_i8m1_b8(op0, op1, op2, op3);
}

__rvv_overloaded vbool4_t vmsbc(vint8m2_t op0, vint8m2_t op1, vbool4_t op2, size_t op3){
  return vmsbc_vvm_i8m2_b4(op0, op1, op2, op3);
}

__rvv_overloaded vbool2_t vmsbc(vint8m4_t op0, vint8m4_t op1, vbool2_t op2, size_t op3){
  return vmsbc_vvm_i8m4_b2(op0, op1, op2, op3);
}

__rvv_overloaded vbool1_t vmsbc(vint8m8_t op0, vint8m8_t op1, vbool1_t op2, size_t op3){
  return vmsbc_vvm_i8m8_b1(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmsbc(vint8mf2_t op0, vint8mf2_t op1, vbool16_t op2, size_t op3){
  return vmsbc_vvm_i8mf2_b16(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmsbc(vint8mf4_t op0, vint8mf4_t op1, vbool32_t op2, size_t op3){
  return vmsbc_vvm_i8mf4_b32(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmsbc(vint8mf8_t op0, vint8mf8_t op1, vbool64_t op2, size_t op3){
  return vmsbc_vvm_i8mf8_b64(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmsbc(vint16m1_t op0, vint16m1_t op1, vbool16_t op2, size_t op3){
  return vmsbc_vvm_i16m1_b16(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmsbc(vint16m2_t op0, vint16m2_t op1, vbool8_t op2, size_t op3){
  return vmsbc_vvm_i16m2_b8(op0, op1, op2, op3);
}

__rvv_overloaded vbool4_t vmsbc(vint16m4_t op0, vint16m4_t op1, vbool4_t op2, size_t op3){
  return vmsbc_vvm_i16m4_b4(op0, op1, op2, op3);
}

__rvv_overloaded vbool2_t vmsbc(vint16m8_t op0, vint16m8_t op1, vbool2_t op2, size_t op3){
  return vmsbc_vvm_i16m8_b2(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmsbc(vint16mf2_t op0, vint16mf2_t op1, vbool32_t op2, size_t op3){
  return vmsbc_vvm_i16mf2_b32(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmsbc(vint16mf4_t op0, vint16mf4_t op1, vbool64_t op2, size_t op3){
  return vmsbc_vvm_i16mf4_b64(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmsbc(vint32m1_t op0, vint32m1_t op1, vbool32_t op2, size_t op3){
  return vmsbc_vvm_i32m1_b32(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmsbc(vint32m2_t op0, vint32m2_t op1, vbool16_t op2, size_t op3){
  return vmsbc_vvm_i32m2_b16(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmsbc(vint32m4_t op0, vint32m4_t op1, vbool8_t op2, size_t op3){
  return vmsbc_vvm_i32m4_b8(op0, op1, op2, op3);
}

__rvv_overloaded vbool4_t vmsbc(vint32m8_t op0, vint32m8_t op1, vbool4_t op2, size_t op3){
  return vmsbc_vvm_i32m8_b4(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmsbc(vint32mf2_t op0, vint32mf2_t op1, vbool64_t op2, size_t op3){
  return vmsbc_vvm_i32mf2_b64(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmsbc(vint64m1_t op0, vint64m1_t op1, vbool64_t op2, size_t op3){
  return vmsbc_vvm_i64m1_b64(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmsbc(vint64m2_t op0, vint64m2_t op1, vbool32_t op2, size_t op3){
  return vmsbc_vvm_i64m2_b32(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmsbc(vint64m4_t op0, vint64m4_t op1, vbool16_t op2, size_t op3){
  return vmsbc_vvm_i64m4_b16(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmsbc(vint64m8_t op0, vint64m8_t op1, vbool8_t op2, size_t op3){
  return vmsbc_vvm_i64m8_b8(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmsbc(vint8m1_t op0, int8_t op1, vbool8_t op2, size_t op3){
  return vmsbc_vxm_i8m1_b8(op0, op1, op2, op3);
}

__rvv_overloaded vbool4_t vmsbc(vint8m2_t op0, int8_t op1, vbool4_t op2, size_t op3){
  return vmsbc_vxm_i8m2_b4(op0, op1, op2, op3);
}

__rvv_overloaded vbool2_t vmsbc(vint8m4_t op0, int8_t op1, vbool2_t op2, size_t op3){
  return vmsbc_vxm_i8m4_b2(op0, op1, op2, op3);
}

__rvv_overloaded vbool1_t vmsbc(vint8m8_t op0, int8_t op1, vbool1_t op2, size_t op3){
  return vmsbc_vxm_i8m8_b1(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmsbc(vint8mf2_t op0, int8_t op1, vbool16_t op2, size_t op3){
  return vmsbc_vxm_i8mf2_b16(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmsbc(vint8mf4_t op0, int8_t op1, vbool32_t op2, size_t op3){
  return vmsbc_vxm_i8mf4_b32(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmsbc(vint8mf8_t op0, int8_t op1, vbool64_t op2, size_t op3){
  return vmsbc_vxm_i8mf8_b64(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmsbc(vint16m1_t op0, int16_t op1, vbool16_t op2, size_t op3){
  return vmsbc_vxm_i16m1_b16(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmsbc(vint16m2_t op0, int16_t op1, vbool8_t op2, size_t op3){
  return vmsbc_vxm_i16m2_b8(op0, op1, op2, op3);
}

__rvv_overloaded vbool4_t vmsbc(vint16m4_t op0, int16_t op1, vbool4_t op2, size_t op3){
  return vmsbc_vxm_i16m4_b4(op0, op1, op2, op3);
}

__rvv_overloaded vbool2_t vmsbc(vint16m8_t op0, int16_t op1, vbool2_t op2, size_t op3){
  return vmsbc_vxm_i16m8_b2(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmsbc(vint16mf2_t op0, int16_t op1, vbool32_t op2, size_t op3){
  return vmsbc_vxm_i16mf2_b32(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmsbc(vint16mf4_t op0, int16_t op1, vbool64_t op2, size_t op3){
  return vmsbc_vxm_i16mf4_b64(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmsbc(vint32m1_t op0, int32_t op1, vbool32_t op2, size_t op3){
  return vmsbc_vxm_i32m1_b32(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmsbc(vint32m2_t op0, int32_t op1, vbool16_t op2, size_t op3){
  return vmsbc_vxm_i32m2_b16(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmsbc(vint32m4_t op0, int32_t op1, vbool8_t op2, size_t op3){
  return vmsbc_vxm_i32m4_b8(op0, op1, op2, op3);
}

__rvv_overloaded vbool4_t vmsbc(vint32m8_t op0, int32_t op1, vbool4_t op2, size_t op3){
  return vmsbc_vxm_i32m8_b4(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmsbc(vint32mf2_t op0, int32_t op1, vbool64_t op2, size_t op3){
  return vmsbc_vxm_i32mf2_b64(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmsbc(vint64m1_t op0, int64_t op1, vbool64_t op2, size_t op3){
  return vmsbc_vxm_i64m1_b64(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmsbc(vint64m2_t op0, int64_t op1, vbool32_t op2, size_t op3){
  return vmsbc_vxm_i64m2_b32(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmsbc(vint64m4_t op0, int64_t op1, vbool16_t op2, size_t op3){
  return vmsbc_vxm_i64m4_b16(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmsbc(vint64m8_t op0, int64_t op1, vbool8_t op2, size_t op3){
  return vmsbc_vxm_i64m8_b8(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmsbc(vuint8m1_t op0, vuint8m1_t op1, vbool8_t op2, size_t op3){
  return vmsbc_vvm_u8m1_b8(op0, op1, op2, op3);
}

__rvv_overloaded vbool4_t vmsbc(vuint8m2_t op0, vuint8m2_t op1, vbool4_t op2, size_t op3){
  return vmsbc_vvm_u8m2_b4(op0, op1, op2, op3);
}

__rvv_overloaded vbool2_t vmsbc(vuint8m4_t op0, vuint8m4_t op1, vbool2_t op2, size_t op3){
  return vmsbc_vvm_u8m4_b2(op0, op1, op2, op3);
}

__rvv_overloaded vbool1_t vmsbc(vuint8m8_t op0, vuint8m8_t op1, vbool1_t op2, size_t op3){
  return vmsbc_vvm_u8m8_b1(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmsbc(vuint8mf2_t op0, vuint8mf2_t op1, vbool16_t op2, size_t op3){
  return vmsbc_vvm_u8mf2_b16(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmsbc(vuint8mf4_t op0, vuint8mf4_t op1, vbool32_t op2, size_t op3){
  return vmsbc_vvm_u8mf4_b32(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmsbc(vuint8mf8_t op0, vuint8mf8_t op1, vbool64_t op2, size_t op3){
  return vmsbc_vvm_u8mf8_b64(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmsbc(vuint16m1_t op0, vuint16m1_t op1, vbool16_t op2, size_t op3){
  return vmsbc_vvm_u16m1_b16(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmsbc(vuint16m2_t op0, vuint16m2_t op1, vbool8_t op2, size_t op3){
  return vmsbc_vvm_u16m2_b8(op0, op1, op2, op3);
}

__rvv_overloaded vbool4_t vmsbc(vuint16m4_t op0, vuint16m4_t op1, vbool4_t op2, size_t op3){
  return vmsbc_vvm_u16m4_b4(op0, op1, op2, op3);
}

__rvv_overloaded vbool2_t vmsbc(vuint16m8_t op0, vuint16m8_t op1, vbool2_t op2, size_t op3){
  return vmsbc_vvm_u16m8_b2(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmsbc(vuint16mf2_t op0, vuint16mf2_t op1, vbool32_t op2, size_t op3){
  return vmsbc_vvm_u16mf2_b32(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmsbc(vuint16mf4_t op0, vuint16mf4_t op1, vbool64_t op2, size_t op3){
  return vmsbc_vvm_u16mf4_b64(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmsbc(vuint32m1_t op0, vuint32m1_t op1, vbool32_t op2, size_t op3){
  return vmsbc_vvm_u32m1_b32(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmsbc(vuint32m2_t op0, vuint32m2_t op1, vbool16_t op2, size_t op3){
  return vmsbc_vvm_u32m2_b16(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmsbc(vuint32m4_t op0, vuint32m4_t op1, vbool8_t op2, size_t op3){
  return vmsbc_vvm_u32m4_b8(op0, op1, op2, op3);
}

__rvv_overloaded vbool4_t vmsbc(vuint32m8_t op0, vuint32m8_t op1, vbool4_t op2, size_t op3){
  return vmsbc_vvm_u32m8_b4(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmsbc(vuint32mf2_t op0, vuint32mf2_t op1, vbool64_t op2, size_t op3){
  return vmsbc_vvm_u32mf2_b64(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmsbc(vuint64m1_t op0, vuint64m1_t op1, vbool64_t op2, size_t op3){
  return vmsbc_vvm_u64m1_b64(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmsbc(vuint64m2_t op0, vuint64m2_t op1, vbool32_t op2, size_t op3){
  return vmsbc_vvm_u64m2_b32(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmsbc(vuint64m4_t op0, vuint64m4_t op1, vbool16_t op2, size_t op3){
  return vmsbc_vvm_u64m4_b16(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmsbc(vuint64m8_t op0, vuint64m8_t op1, vbool8_t op2, size_t op3){
  return vmsbc_vvm_u64m8_b8(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmsbc(vuint8m1_t op0, uint8_t op1, vbool8_t op2, size_t op3){
  return vmsbc_vxm_u8m1_b8(op0, op1, op2, op3);
}

__rvv_overloaded vbool4_t vmsbc(vuint8m2_t op0, uint8_t op1, vbool4_t op2, size_t op3){
  return vmsbc_vxm_u8m2_b4(op0, op1, op2, op3);
}

__rvv_overloaded vbool2_t vmsbc(vuint8m4_t op0, uint8_t op1, vbool2_t op2, size_t op3){
  return vmsbc_vxm_u8m4_b2(op0, op1, op2, op3);
}

__rvv_overloaded vbool1_t vmsbc(vuint8m8_t op0, uint8_t op1, vbool1_t op2, size_t op3){
  return vmsbc_vxm_u8m8_b1(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmsbc(vuint8mf2_t op0, uint8_t op1, vbool16_t op2, size_t op3){
  return vmsbc_vxm_u8mf2_b16(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmsbc(vuint8mf4_t op0, uint8_t op1, vbool32_t op2, size_t op3){
  return vmsbc_vxm_u8mf4_b32(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmsbc(vuint8mf8_t op0, uint8_t op1, vbool64_t op2, size_t op3){
  return vmsbc_vxm_u8mf8_b64(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmsbc(vuint16m1_t op0, uint16_t op1, vbool16_t op2, size_t op3){
  return vmsbc_vxm_u16m1_b16(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmsbc(vuint16m2_t op0, uint16_t op1, vbool8_t op2, size_t op3){
  return vmsbc_vxm_u16m2_b8(op0, op1, op2, op3);
}

__rvv_overloaded vbool4_t vmsbc(vuint16m4_t op0, uint16_t op1, vbool4_t op2, size_t op3){
  return vmsbc_vxm_u16m4_b4(op0, op1, op2, op3);
}

__rvv_overloaded vbool2_t vmsbc(vuint16m8_t op0, uint16_t op1, vbool2_t op2, size_t op3){
  return vmsbc_vxm_u16m8_b2(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmsbc(vuint16mf2_t op0, uint16_t op1, vbool32_t op2, size_t op3){
  return vmsbc_vxm_u16mf2_b32(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmsbc(vuint16mf4_t op0, uint16_t op1, vbool64_t op2, size_t op3){
  return vmsbc_vxm_u16mf4_b64(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmsbc(vuint32m1_t op0, uint32_t op1, vbool32_t op2, size_t op3){
  return vmsbc_vxm_u32m1_b32(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmsbc(vuint32m2_t op0, uint32_t op1, vbool16_t op2, size_t op3){
  return vmsbc_vxm_u32m2_b16(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmsbc(vuint32m4_t op0, uint32_t op1, vbool8_t op2, size_t op3){
  return vmsbc_vxm_u32m4_b8(op0, op1, op2, op3);
}

__rvv_overloaded vbool4_t vmsbc(vuint32m8_t op0, uint32_t op1, vbool4_t op2, size_t op3){
  return vmsbc_vxm_u32m8_b4(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmsbc(vuint32mf2_t op0, uint32_t op1, vbool64_t op2, size_t op3){
  return vmsbc_vxm_u32mf2_b64(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmsbc(vuint64m1_t op0, uint64_t op1, vbool64_t op2, size_t op3){
  return vmsbc_vxm_u64m1_b64(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmsbc(vuint64m2_t op0, uint64_t op1, vbool32_t op2, size_t op3){
  return vmsbc_vxm_u64m2_b32(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmsbc(vuint64m4_t op0, uint64_t op1, vbool16_t op2, size_t op3){
  return vmsbc_vxm_u64m4_b16(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmsbc(vuint64m8_t op0, uint64_t op1, vbool8_t op2, size_t op3){
  return vmsbc_vxm_u64m8_b8(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmsbc(vint8m1_t op0, vint8m1_t op1, size_t op2){
  return vmsbc_vv_i8m1_b8(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsbc(vint8m2_t op0, vint8m2_t op1, size_t op2){
  return vmsbc_vv_i8m2_b4(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmsbc(vint8m4_t op0, vint8m4_t op1, size_t op2){
  return vmsbc_vv_i8m4_b2(op0, op1, op2);
}

__rvv_overloaded vbool1_t vmsbc(vint8m8_t op0, vint8m8_t op1, size_t op2){
  return vmsbc_vv_i8m8_b1(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsbc(vint8mf2_t op0, vint8mf2_t op1, size_t op2){
  return vmsbc_vv_i8mf2_b16(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsbc(vint8mf4_t op0, vint8mf4_t op1, size_t op2){
  return vmsbc_vv_i8mf4_b32(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsbc(vint8mf8_t op0, vint8mf8_t op1, size_t op2){
  return vmsbc_vv_i8mf8_b64(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsbc(vint16m1_t op0, vint16m1_t op1, size_t op2){
  return vmsbc_vv_i16m1_b16(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsbc(vint16m2_t op0, vint16m2_t op1, size_t op2){
  return vmsbc_vv_i16m2_b8(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsbc(vint16m4_t op0, vint16m4_t op1, size_t op2){
  return vmsbc_vv_i16m4_b4(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmsbc(vint16m8_t op0, vint16m8_t op1, size_t op2){
  return vmsbc_vv_i16m8_b2(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsbc(vint16mf2_t op0, vint16mf2_t op1, size_t op2){
  return vmsbc_vv_i16mf2_b32(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsbc(vint16mf4_t op0, vint16mf4_t op1, size_t op2){
  return vmsbc_vv_i16mf4_b64(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsbc(vint32m1_t op0, vint32m1_t op1, size_t op2){
  return vmsbc_vv_i32m1_b32(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsbc(vint32m2_t op0, vint32m2_t op1, size_t op2){
  return vmsbc_vv_i32m2_b16(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsbc(vint32m4_t op0, vint32m4_t op1, size_t op2){
  return vmsbc_vv_i32m4_b8(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsbc(vint32m8_t op0, vint32m8_t op1, size_t op2){
  return vmsbc_vv_i32m8_b4(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsbc(vint32mf2_t op0, vint32mf2_t op1, size_t op2){
  return vmsbc_vv_i32mf2_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsbc(vint64m1_t op0, vint64m1_t op1, size_t op2){
  return vmsbc_vv_i64m1_b64(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsbc(vint64m2_t op0, vint64m2_t op1, size_t op2){
  return vmsbc_vv_i64m2_b32(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsbc(vint64m4_t op0, vint64m4_t op1, size_t op2){
  return vmsbc_vv_i64m4_b16(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsbc(vint64m8_t op0, vint64m8_t op1, size_t op2){
  return vmsbc_vv_i64m8_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsbc(vint8m1_t op0, int8_t op1, size_t op2){
  return vmsbc_vx_i8m1_b8(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsbc(vint8m2_t op0, int8_t op1, size_t op2){
  return vmsbc_vx_i8m2_b4(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmsbc(vint8m4_t op0, int8_t op1, size_t op2){
  return vmsbc_vx_i8m4_b2(op0, op1, op2);
}

__rvv_overloaded vbool1_t vmsbc(vint8m8_t op0, int8_t op1, size_t op2){
  return vmsbc_vx_i8m8_b1(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsbc(vint8mf2_t op0, int8_t op1, size_t op2){
  return vmsbc_vx_i8mf2_b16(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsbc(vint8mf4_t op0, int8_t op1, size_t op2){
  return vmsbc_vx_i8mf4_b32(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsbc(vint8mf8_t op0, int8_t op1, size_t op2){
  return vmsbc_vx_i8mf8_b64(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsbc(vint16m1_t op0, int16_t op1, size_t op2){
  return vmsbc_vx_i16m1_b16(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsbc(vint16m2_t op0, int16_t op1, size_t op2){
  return vmsbc_vx_i16m2_b8(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsbc(vint16m4_t op0, int16_t op1, size_t op2){
  return vmsbc_vx_i16m4_b4(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmsbc(vint16m8_t op0, int16_t op1, size_t op2){
  return vmsbc_vx_i16m8_b2(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsbc(vint16mf2_t op0, int16_t op1, size_t op2){
  return vmsbc_vx_i16mf2_b32(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsbc(vint16mf4_t op0, int16_t op1, size_t op2){
  return vmsbc_vx_i16mf4_b64(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsbc(vint32m1_t op0, int32_t op1, size_t op2){
  return vmsbc_vx_i32m1_b32(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsbc(vint32m2_t op0, int32_t op1, size_t op2){
  return vmsbc_vx_i32m2_b16(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsbc(vint32m4_t op0, int32_t op1, size_t op2){
  return vmsbc_vx_i32m4_b8(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsbc(vint32m8_t op0, int32_t op1, size_t op2){
  return vmsbc_vx_i32m8_b4(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsbc(vint32mf2_t op0, int32_t op1, size_t op2){
  return vmsbc_vx_i32mf2_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsbc(vint64m1_t op0, int64_t op1, size_t op2){
  return vmsbc_vx_i64m1_b64(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsbc(vint64m2_t op0, int64_t op1, size_t op2){
  return vmsbc_vx_i64m2_b32(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsbc(vint64m4_t op0, int64_t op1, size_t op2){
  return vmsbc_vx_i64m4_b16(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsbc(vint64m8_t op0, int64_t op1, size_t op2){
  return vmsbc_vx_i64m8_b8(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vle16(vbool16_t op0, vint16m1_t op1, const int16_t * op2, size_t op3){
  return vle16_v_i16m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vint16m2_t vle16(vbool8_t op0, vint16m2_t op1, const int16_t * op2, size_t op3){
  return vle16_v_i16m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vint16m4_t vle16(vbool4_t op0, vint16m4_t op1, const int16_t * op2, size_t op3){
  return vle16_v_i16m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vint16m8_t vle16(vbool2_t op0, vint16m8_t op1, const int16_t * op2, size_t op3){
  return vle16_v_i16m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf2_t vle16(vbool32_t op0, vint16mf2_t op1, const int16_t * op2, size_t op3){
  return vle16_v_i16mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf4_t vle16(vbool64_t op0, vint16mf4_t op1, const int16_t * op2, size_t op3){
  return vle16_v_i16mf4_m(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmsbc(vuint8m1_t op0, vuint8m1_t op1, size_t op2){
  return vmsbc_vv_u8m1_b8(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsbc(vuint8m2_t op0, vuint8m2_t op1, size_t op2){
  return vmsbc_vv_u8m2_b4(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmsbc(vuint8m4_t op0, vuint8m4_t op1, size_t op2){
  return vmsbc_vv_u8m4_b2(op0, op1, op2);
}

__rvv_overloaded vbool1_t vmsbc(vuint8m8_t op0, vuint8m8_t op1, size_t op2){
  return vmsbc_vv_u8m8_b1(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsbc(vuint8mf2_t op0, vuint8mf2_t op1, size_t op2){
  return vmsbc_vv_u8mf2_b16(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsbc(vuint8mf4_t op0, vuint8mf4_t op1, size_t op2){
  return vmsbc_vv_u8mf4_b32(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsbc(vuint8mf8_t op0, vuint8mf8_t op1, size_t op2){
  return vmsbc_vv_u8mf8_b64(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsbc(vuint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vmsbc_vv_u16m1_b16(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsbc(vuint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vmsbc_vv_u16m2_b8(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsbc(vuint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vmsbc_vv_u16m4_b4(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmsbc(vuint16m8_t op0, vuint16m8_t op1, size_t op2){
  return vmsbc_vv_u16m8_b2(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsbc(vuint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vmsbc_vv_u16mf2_b32(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsbc(vuint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vmsbc_vv_u16mf4_b64(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsbc(vuint32m1_t op0, vuint32m1_t op1, size_t op2){
  return vmsbc_vv_u32m1_b32(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsbc(vuint32m2_t op0, vuint32m2_t op1, size_t op2){
  return vmsbc_vv_u32m2_b16(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsbc(vuint32m4_t op0, vuint32m4_t op1, size_t op2){
  return vmsbc_vv_u32m4_b8(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsbc(vuint32m8_t op0, vuint32m8_t op1, size_t op2){
  return vmsbc_vv_u32m8_b4(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsbc(vuint32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vmsbc_vv_u32mf2_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsbc(vuint64m1_t op0, vuint64m1_t op1, size_t op2){
  return vmsbc_vv_u64m1_b64(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsbc(vuint64m2_t op0, vuint64m2_t op1, size_t op2){
  return vmsbc_vv_u64m2_b32(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsbc(vuint64m4_t op0, vuint64m4_t op1, size_t op2){
  return vmsbc_vv_u64m4_b16(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsbc(vuint64m8_t op0, vuint64m8_t op1, size_t op2){
  return vmsbc_vv_u64m8_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsbc(vuint8m1_t op0, uint8_t op1, size_t op2){
  return vmsbc_vx_u8m1_b8(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsbc(vuint8m2_t op0, uint8_t op1, size_t op2){
  return vmsbc_vx_u8m2_b4(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmsbc(vuint8m4_t op0, uint8_t op1, size_t op2){
  return vmsbc_vx_u8m4_b2(op0, op1, op2);
}

__rvv_overloaded vbool1_t vmsbc(vuint8m8_t op0, uint8_t op1, size_t op2){
  return vmsbc_vx_u8m8_b1(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsbc(vuint8mf2_t op0, uint8_t op1, size_t op2){
  return vmsbc_vx_u8mf2_b16(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsbc(vuint8mf4_t op0, uint8_t op1, size_t op2){
  return vmsbc_vx_u8mf4_b32(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsbc(vuint8mf8_t op0, uint8_t op1, size_t op2){
  return vmsbc_vx_u8mf8_b64(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsbc(vuint16m1_t op0, uint16_t op1, size_t op2){
  return vmsbc_vx_u16m1_b16(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsbc(vuint16m2_t op0, uint16_t op1, size_t op2){
  return vmsbc_vx_u16m2_b8(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsbc(vuint16m4_t op0, uint16_t op1, size_t op2){
  return vmsbc_vx_u16m4_b4(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmsbc(vuint16m8_t op0, uint16_t op1, size_t op2){
  return vmsbc_vx_u16m8_b2(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsbc(vuint16mf2_t op0, uint16_t op1, size_t op2){
  return vmsbc_vx_u16mf2_b32(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsbc(vuint16mf4_t op0, uint16_t op1, size_t op2){
  return vmsbc_vx_u16mf4_b64(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsbc(vuint32m1_t op0, uint32_t op1, size_t op2){
  return vmsbc_vx_u32m1_b32(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsbc(vuint32m2_t op0, uint32_t op1, size_t op2){
  return vmsbc_vx_u32m2_b16(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsbc(vuint32m4_t op0, uint32_t op1, size_t op2){
  return vmsbc_vx_u32m4_b8(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsbc(vuint32m8_t op0, uint32_t op1, size_t op2){
  return vmsbc_vx_u32m8_b4(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsbc(vuint32mf2_t op0, uint32_t op1, size_t op2){
  return vmsbc_vx_u32mf2_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsbc(vuint64m1_t op0, uint64_t op1, size_t op2){
  return vmsbc_vx_u64m1_b64(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsbc(vuint64m2_t op0, uint64_t op1, size_t op2){
  return vmsbc_vx_u64m2_b32(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsbc(vuint64m4_t op0, uint64_t op1, size_t op2){
  return vmsbc_vx_u64m4_b16(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsbc(vuint64m8_t op0, uint64_t op1, size_t op2){
  return vmsbc_vx_u64m8_b8(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vand(vint8m1_t op0, vint8m1_t op1, size_t op2){
  return vand_vv_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vand(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, vint8m1_t op3, size_t op4){
  return vand_vv_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vand(vint8m2_t op0, vint8m2_t op1, size_t op2){
  return vand_vv_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vand(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, vint8m2_t op3, size_t op4){
  return vand_vv_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vand(vint8m4_t op0, vint8m4_t op1, size_t op2){
  return vand_vv_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vand(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, vint8m4_t op3, size_t op4){
  return vand_vv_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vand(vint8m8_t op0, vint8m8_t op1, size_t op2){
  return vand_vv_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vand(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, vint8m8_t op3, size_t op4){
  return vand_vv_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vand(vint8mf2_t op0, vint8mf2_t op1, size_t op2){
  return vand_vv_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vand(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, vint8mf2_t op3, size_t op4){
  return vand_vv_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vand(vint8mf4_t op0, vint8mf4_t op1, size_t op2){
  return vand_vv_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vand(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, vint8mf4_t op3, size_t op4){
  return vand_vv_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vand(vint8mf8_t op0, vint8mf8_t op1, size_t op2){
  return vand_vv_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vand(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, vint8mf8_t op3, size_t op4){
  return vand_vv_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vand(vint16m1_t op0, vint16m1_t op1, size_t op2){
  return vand_vv_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vand(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, vint16m1_t op3, size_t op4){
  return vand_vv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vand(vint16m2_t op0, vint16m2_t op1, size_t op2){
  return vand_vv_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vand(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, vint16m2_t op3, size_t op4){
  return vand_vv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vand(vint16m4_t op0, vint16m4_t op1, size_t op2){
  return vand_vv_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vand(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, vint16m4_t op3, size_t op4){
  return vand_vv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vand(vint16m8_t op0, vint16m8_t op1, size_t op2){
  return vand_vv_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vand(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, vint16m8_t op3, size_t op4){
  return vand_vv_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vand(vint16mf2_t op0, vint16mf2_t op1, size_t op2){
  return vand_vv_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vand(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, vint16mf2_t op3, size_t op4){
  return vand_vv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vand(vint16mf4_t op0, vint16mf4_t op1, size_t op2){
  return vand_vv_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vand(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, vint16mf4_t op3, size_t op4){
  return vand_vv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vand(vint32m1_t op0, vint32m1_t op1, size_t op2){
  return vand_vv_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vand(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, vint32m1_t op3, size_t op4){
  return vand_vv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vand(vint32m2_t op0, vint32m2_t op1, size_t op2){
  return vand_vv_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vand(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, vint32m2_t op3, size_t op4){
  return vand_vv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vand(vint32m4_t op0, vint32m4_t op1, size_t op2){
  return vand_vv_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vand(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, vint32m4_t op3, size_t op4){
  return vand_vv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vand(vint32m8_t op0, vint32m8_t op1, size_t op2){
  return vand_vv_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vand(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, vint32m8_t op3, size_t op4){
  return vand_vv_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vand(vint32mf2_t op0, vint32mf2_t op1, size_t op2){
  return vand_vv_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vand(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, vint32mf2_t op3, size_t op4){
  return vand_vv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vand(vint64m1_t op0, vint64m1_t op1, size_t op2){
  return vand_vv_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vand(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, vint64m1_t op3, size_t op4){
  return vand_vv_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vand(vint64m2_t op0, vint64m2_t op1, size_t op2){
  return vand_vv_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vand(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, vint64m2_t op3, size_t op4){
  return vand_vv_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vand(vint64m4_t op0, vint64m4_t op1, size_t op2){
  return vand_vv_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vand(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, vint64m4_t op3, size_t op4){
  return vand_vv_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vand(vint64m8_t op0, vint64m8_t op1, size_t op2){
  return vand_vv_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vand(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, vint64m8_t op3, size_t op4){
  return vand_vv_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vand(vint8m1_t op0, int8_t op1, size_t op2){
  return vand_vx_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vand(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, int8_t op3, size_t op4){
  return vand_vx_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vand(vint8m2_t op0, int8_t op1, size_t op2){
  return vand_vx_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vand(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, int8_t op3, size_t op4){
  return vand_vx_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vand(vint8m4_t op0, int8_t op1, size_t op2){
  return vand_vx_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vand(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, int8_t op3, size_t op4){
  return vand_vx_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vand(vint8m8_t op0, int8_t op1, size_t op2){
  return vand_vx_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vand(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, int8_t op3, size_t op4){
  return vand_vx_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vand(vint8mf2_t op0, int8_t op1, size_t op2){
  return vand_vx_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vand(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, int8_t op3, size_t op4){
  return vand_vx_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vand(vint8mf4_t op0, int8_t op1, size_t op2){
  return vand_vx_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vand(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, int8_t op3, size_t op4){
  return vand_vx_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vand(vint8mf8_t op0, int8_t op1, size_t op2){
  return vand_vx_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vand(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, int8_t op3, size_t op4){
  return vand_vx_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vand(vint16m1_t op0, int16_t op1, size_t op2){
  return vand_vx_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vand(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, int16_t op3, size_t op4){
  return vand_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vand(vint16m2_t op0, int16_t op1, size_t op2){
  return vand_vx_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vand(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, int16_t op3, size_t op4){
  return vand_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vand(vint16m4_t op0, int16_t op1, size_t op2){
  return vand_vx_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vand(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, int16_t op3, size_t op4){
  return vand_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vand(vint16m8_t op0, int16_t op1, size_t op2){
  return vand_vx_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vand(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, int16_t op3, size_t op4){
  return vand_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vand(vint16mf2_t op0, int16_t op1, size_t op2){
  return vand_vx_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vand(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, int16_t op3, size_t op4){
  return vand_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vand(vint16mf4_t op0, int16_t op1, size_t op2){
  return vand_vx_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vand(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, int16_t op3, size_t op4){
  return vand_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vand(vint32m1_t op0, int32_t op1, size_t op2){
  return vand_vx_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vand(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, int32_t op3, size_t op4){
  return vand_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vand(vint32m2_t op0, int32_t op1, size_t op2){
  return vand_vx_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vand(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, int32_t op3, size_t op4){
  return vand_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vand(vint32m4_t op0, int32_t op1, size_t op2){
  return vand_vx_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vand(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, int32_t op3, size_t op4){
  return vand_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vand(vint32m8_t op0, int32_t op1, size_t op2){
  return vand_vx_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vand(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, int32_t op3, size_t op4){
  return vand_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vand(vint32mf2_t op0, int32_t op1, size_t op2){
  return vand_vx_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vand(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, int32_t op3, size_t op4){
  return vand_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vand(vint64m1_t op0, int64_t op1, size_t op2){
  return vand_vx_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vand(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, int64_t op3, size_t op4){
  return vand_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vand(vint64m2_t op0, int64_t op1, size_t op2){
  return vand_vx_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vand(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, int64_t op3, size_t op4){
  return vand_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vand(vint64m4_t op0, int64_t op1, size_t op2){
  return vand_vx_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vand(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, int64_t op3, size_t op4){
  return vand_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vand(vint64m8_t op0, int64_t op1, size_t op2){
  return vand_vx_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vand(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, int64_t op3, size_t op4){
  return vand_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vand(vuint8m1_t op0, vuint8m1_t op1, size_t op2){
  return vand_vv_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vand(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vand_vv_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vand(vuint8m2_t op0, vuint8m2_t op1, size_t op2){
  return vand_vv_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vand(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vand_vv_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vand(vuint8m4_t op0, vuint8m4_t op1, size_t op2){
  return vand_vv_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vand(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vand_vv_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vand(vuint8m8_t op0, vuint8m8_t op1, size_t op2){
  return vand_vv_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vand(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, vuint8m8_t op3, size_t op4){
  return vand_vv_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vand(vuint8mf2_t op0, vuint8mf2_t op1, size_t op2){
  return vand_vv_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vand(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vand_vv_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vand(vuint8mf4_t op0, vuint8mf4_t op1, size_t op2){
  return vand_vv_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vand(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vand_vv_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vand(vuint8mf8_t op0, vuint8mf8_t op1, size_t op2){
  return vand_vv_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vand(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vand_vv_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vand(vuint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vand_vv_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vand(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vand_vv_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vand(vuint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vand_vv_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vand(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vand_vv_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vand(vuint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vand_vv_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vand(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vand_vv_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vand(vuint16m8_t op0, vuint16m8_t op1, size_t op2){
  return vand_vv_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vand(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vand_vv_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vand(vuint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vand_vv_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vand(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vand_vv_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vand(vuint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vand_vv_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vand(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vand_vv_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vand(vuint32m1_t op0, vuint32m1_t op1, size_t op2){
  return vand_vv_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vand(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vand_vv_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vand(vuint32m2_t op0, vuint32m2_t op1, size_t op2){
  return vand_vv_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vand(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vand_vv_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vand(vuint32m4_t op0, vuint32m4_t op1, size_t op2){
  return vand_vv_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vand(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vand_vv_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vand(vuint32m8_t op0, vuint32m8_t op1, size_t op2){
  return vand_vv_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vand(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, vuint32m8_t op3, size_t op4){
  return vand_vv_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vand(vuint32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vand_vv_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vand(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vand_vv_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vand(vuint64m1_t op0, vuint64m1_t op1, size_t op2){
  return vand_vv_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vand(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vand_vv_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vand(vuint64m2_t op0, vuint64m2_t op1, size_t op2){
  return vand_vv_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vand(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, vuint64m2_t op3, size_t op4){
  return vand_vv_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vand(vuint64m4_t op0, vuint64m4_t op1, size_t op2){
  return vand_vv_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vand(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, vuint64m4_t op3, size_t op4){
  return vand_vv_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vand(vuint64m8_t op0, vuint64m8_t op1, size_t op2){
  return vand_vv_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vand(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, vuint64m8_t op3, size_t op4){
  return vand_vv_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vand(vuint8m1_t op0, uint8_t op1, size_t op2){
  return vand_vx_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vand(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, uint8_t op3, size_t op4){
  return vand_vx_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vand(vuint8m2_t op0, uint8_t op1, size_t op2){
  return vand_vx_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vand(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, uint8_t op3, size_t op4){
  return vand_vx_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vand(vuint8m4_t op0, uint8_t op1, size_t op2){
  return vand_vx_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vand(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, uint8_t op3, size_t op4){
  return vand_vx_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vand(vuint8m8_t op0, uint8_t op1, size_t op2){
  return vand_vx_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vand(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, uint8_t op3, size_t op4){
  return vand_vx_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vand(vuint8mf2_t op0, uint8_t op1, size_t op2){
  return vand_vx_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vand(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, uint8_t op3, size_t op4){
  return vand_vx_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vand(vuint8mf4_t op0, uint8_t op1, size_t op2){
  return vand_vx_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vand(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, uint8_t op3, size_t op4){
  return vand_vx_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vand(vuint8mf8_t op0, uint8_t op1, size_t op2){
  return vand_vx_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vand(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, uint8_t op3, size_t op4){
  return vand_vx_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vand(vuint16m1_t op0, uint16_t op1, size_t op2){
  return vand_vx_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vand(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, uint16_t op3, size_t op4){
  return vand_vx_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vand(vuint16m2_t op0, uint16_t op1, size_t op2){
  return vand_vx_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vand(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, uint16_t op3, size_t op4){
  return vand_vx_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vand(vuint16m4_t op0, uint16_t op1, size_t op2){
  return vand_vx_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vand(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, uint16_t op3, size_t op4){
  return vand_vx_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vand(vuint16m8_t op0, uint16_t op1, size_t op2){
  return vand_vx_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vand(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, uint16_t op3, size_t op4){
  return vand_vx_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vand(vuint16mf2_t op0, uint16_t op1, size_t op2){
  return vand_vx_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vand(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, uint16_t op3, size_t op4){
  return vand_vx_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vand(vuint16mf4_t op0, uint16_t op1, size_t op2){
  return vand_vx_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vand(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, uint16_t op3, size_t op4){
  return vand_vx_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vand(vuint32m1_t op0, uint32_t op1, size_t op2){
  return vand_vx_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vand(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, uint32_t op3, size_t op4){
  return vand_vx_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vand(vuint32m2_t op0, uint32_t op1, size_t op2){
  return vand_vx_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vand(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, uint32_t op3, size_t op4){
  return vand_vx_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vand(vuint32m4_t op0, uint32_t op1, size_t op2){
  return vand_vx_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vand(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, uint32_t op3, size_t op4){
  return vand_vx_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vand(vuint32m8_t op0, uint32_t op1, size_t op2){
  return vand_vx_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vand(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, uint32_t op3, size_t op4){
  return vand_vx_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vand(vuint32mf2_t op0, uint32_t op1, size_t op2){
  return vand_vx_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vand(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, uint32_t op3, size_t op4){
  return vand_vx_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vand(vuint64m1_t op0, uint64_t op1, size_t op2){
  return vand_vx_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vand(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, uint64_t op3, size_t op4){
  return vand_vx_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vand(vuint64m2_t op0, uint64_t op1, size_t op2){
  return vand_vx_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vand(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, uint64_t op3, size_t op4){
  return vand_vx_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vand(vuint64m4_t op0, uint64_t op1, size_t op2){
  return vand_vx_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vand(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, uint64_t op3, size_t op4){
  return vand_vx_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vand(vuint64m8_t op0, uint64_t op1, size_t op2){
  return vand_vx_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vand(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, uint64_t op3, size_t op4){
  return vand_vx_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vxor(vint8m1_t op0, vint8m1_t op1, size_t op2){
  return vxor_vv_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vxor(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, vint8m1_t op3, size_t op4){
  return vxor_vv_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vxor(vint8m2_t op0, vint8m2_t op1, size_t op2){
  return vxor_vv_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vxor(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, vint8m2_t op3, size_t op4){
  return vxor_vv_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vxor(vint8m4_t op0, vint8m4_t op1, size_t op2){
  return vxor_vv_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vxor(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, vint8m4_t op3, size_t op4){
  return vxor_vv_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vxor(vint8m8_t op0, vint8m8_t op1, size_t op2){
  return vxor_vv_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vxor(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, vint8m8_t op3, size_t op4){
  return vxor_vv_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vxor(vint8mf2_t op0, vint8mf2_t op1, size_t op2){
  return vxor_vv_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vxor(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, vint8mf2_t op3, size_t op4){
  return vxor_vv_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vxor(vint8mf4_t op0, vint8mf4_t op1, size_t op2){
  return vxor_vv_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vxor(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, vint8mf4_t op3, size_t op4){
  return vxor_vv_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vxor(vint8mf8_t op0, vint8mf8_t op1, size_t op2){
  return vxor_vv_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vxor(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, vint8mf8_t op3, size_t op4){
  return vxor_vv_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vxor(vint16m1_t op0, vint16m1_t op1, size_t op2){
  return vxor_vv_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vxor(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, vint16m1_t op3, size_t op4){
  return vxor_vv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vxor(vint16m2_t op0, vint16m2_t op1, size_t op2){
  return vxor_vv_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vxor(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, vint16m2_t op3, size_t op4){
  return vxor_vv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vxor(vint16m4_t op0, vint16m4_t op1, size_t op2){
  return vxor_vv_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vxor(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, vint16m4_t op3, size_t op4){
  return vxor_vv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vxor(vint16m8_t op0, vint16m8_t op1, size_t op2){
  return vxor_vv_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vxor(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, vint16m8_t op3, size_t op4){
  return vxor_vv_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vxor(vint16mf2_t op0, vint16mf2_t op1, size_t op2){
  return vxor_vv_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vxor(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, vint16mf2_t op3, size_t op4){
  return vxor_vv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vxor(vint16mf4_t op0, vint16mf4_t op1, size_t op2){
  return vxor_vv_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vxor(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, vint16mf4_t op3, size_t op4){
  return vxor_vv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vxor(vint32m1_t op0, vint32m1_t op1, size_t op2){
  return vxor_vv_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vxor(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, vint32m1_t op3, size_t op4){
  return vxor_vv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vxor(vint32m2_t op0, vint32m2_t op1, size_t op2){
  return vxor_vv_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vxor(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, vint32m2_t op3, size_t op4){
  return vxor_vv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vxor(vint32m4_t op0, vint32m4_t op1, size_t op2){
  return vxor_vv_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vxor(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, vint32m4_t op3, size_t op4){
  return vxor_vv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vxor(vint32m8_t op0, vint32m8_t op1, size_t op2){
  return vxor_vv_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vxor(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, vint32m8_t op3, size_t op4){
  return vxor_vv_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vxor(vint32mf2_t op0, vint32mf2_t op1, size_t op2){
  return vxor_vv_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vxor(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, vint32mf2_t op3, size_t op4){
  return vxor_vv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vxor(vint64m1_t op0, vint64m1_t op1, size_t op2){
  return vxor_vv_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vxor(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, vint64m1_t op3, size_t op4){
  return vxor_vv_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vxor(vint64m2_t op0, vint64m2_t op1, size_t op2){
  return vxor_vv_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vxor(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, vint64m2_t op3, size_t op4){
  return vxor_vv_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vxor(vint64m4_t op0, vint64m4_t op1, size_t op2){
  return vxor_vv_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vxor(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, vint64m4_t op3, size_t op4){
  return vxor_vv_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vxor(vint64m8_t op0, vint64m8_t op1, size_t op2){
  return vxor_vv_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vxor(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, vint64m8_t op3, size_t op4){
  return vxor_vv_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vxor(vint8m1_t op0, int8_t op1, size_t op2){
  return vxor_vx_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vxor(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, int8_t op3, size_t op4){
  return vxor_vx_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vxor(vint8m2_t op0, int8_t op1, size_t op2){
  return vxor_vx_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vxor(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, int8_t op3, size_t op4){
  return vxor_vx_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vxor(vint8m4_t op0, int8_t op1, size_t op2){
  return vxor_vx_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vxor(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, int8_t op3, size_t op4){
  return vxor_vx_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vxor(vint8m8_t op0, int8_t op1, size_t op2){
  return vxor_vx_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vxor(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, int8_t op3, size_t op4){
  return vxor_vx_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vxor(vint8mf2_t op0, int8_t op1, size_t op2){
  return vxor_vx_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vxor(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, int8_t op3, size_t op4){
  return vxor_vx_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vxor(vint8mf4_t op0, int8_t op1, size_t op2){
  return vxor_vx_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vxor(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, int8_t op3, size_t op4){
  return vxor_vx_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vxor(vint8mf8_t op0, int8_t op1, size_t op2){
  return vxor_vx_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vxor(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, int8_t op3, size_t op4){
  return vxor_vx_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vxor(vint16m1_t op0, int16_t op1, size_t op2){
  return vxor_vx_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vxor(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, int16_t op3, size_t op4){
  return vxor_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vxor(vint16m2_t op0, int16_t op1, size_t op2){
  return vxor_vx_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vxor(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, int16_t op3, size_t op4){
  return vxor_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vxor(vint16m4_t op0, int16_t op1, size_t op2){
  return vxor_vx_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vxor(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, int16_t op3, size_t op4){
  return vxor_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vxor(vint16m8_t op0, int16_t op1, size_t op2){
  return vxor_vx_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vxor(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, int16_t op3, size_t op4){
  return vxor_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vxor(vint16mf2_t op0, int16_t op1, size_t op2){
  return vxor_vx_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vxor(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, int16_t op3, size_t op4){
  return vxor_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vxor(vint16mf4_t op0, int16_t op1, size_t op2){
  return vxor_vx_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vxor(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, int16_t op3, size_t op4){
  return vxor_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vxor(vint32m1_t op0, int32_t op1, size_t op2){
  return vxor_vx_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vxor(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, int32_t op3, size_t op4){
  return vxor_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vxor(vint32m2_t op0, int32_t op1, size_t op2){
  return vxor_vx_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vxor(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, int32_t op3, size_t op4){
  return vxor_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vxor(vint32m4_t op0, int32_t op1, size_t op2){
  return vxor_vx_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vxor(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, int32_t op3, size_t op4){
  return vxor_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vxor(vint32m8_t op0, int32_t op1, size_t op2){
  return vxor_vx_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vxor(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, int32_t op3, size_t op4){
  return vxor_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vxor(vint32mf2_t op0, int32_t op1, size_t op2){
  return vxor_vx_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vxor(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, int32_t op3, size_t op4){
  return vxor_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vxor(vint64m1_t op0, int64_t op1, size_t op2){
  return vxor_vx_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vxor(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, int64_t op3, size_t op4){
  return vxor_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vxor(vint64m2_t op0, int64_t op1, size_t op2){
  return vxor_vx_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vxor(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, int64_t op3, size_t op4){
  return vxor_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vxor(vint64m4_t op0, int64_t op1, size_t op2){
  return vxor_vx_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vxor(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, int64_t op3, size_t op4){
  return vxor_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vxor(vint64m8_t op0, int64_t op1, size_t op2){
  return vxor_vx_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vxor(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, int64_t op3, size_t op4){
  return vxor_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vxor(vuint8m1_t op0, vuint8m1_t op1, size_t op2){
  return vxor_vv_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vxor(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vxor_vv_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vxor(vuint8m2_t op0, vuint8m2_t op1, size_t op2){
  return vxor_vv_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vxor(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vxor_vv_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vxor(vuint8m4_t op0, vuint8m4_t op1, size_t op2){
  return vxor_vv_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vxor(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vxor_vv_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vxor(vuint8m8_t op0, vuint8m8_t op1, size_t op2){
  return vxor_vv_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vxor(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, vuint8m8_t op3, size_t op4){
  return vxor_vv_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vxor(vuint8mf2_t op0, vuint8mf2_t op1, size_t op2){
  return vxor_vv_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vxor(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vxor_vv_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vxor(vuint8mf4_t op0, vuint8mf4_t op1, size_t op2){
  return vxor_vv_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vxor(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vxor_vv_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vxor(vuint8mf8_t op0, vuint8mf8_t op1, size_t op2){
  return vxor_vv_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vxor(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vxor_vv_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vxor(vuint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vxor_vv_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vxor(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vxor_vv_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vxor(vuint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vxor_vv_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vxor(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vxor_vv_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vxor(vuint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vxor_vv_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vxor(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vxor_vv_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vxor(vuint16m8_t op0, vuint16m8_t op1, size_t op2){
  return vxor_vv_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vxor(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vxor_vv_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vxor(vuint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vxor_vv_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vxor(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vxor_vv_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vxor(vuint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vxor_vv_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vxor(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vxor_vv_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vxor(vuint32m1_t op0, vuint32m1_t op1, size_t op2){
  return vxor_vv_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vxor(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vxor_vv_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vxor(vuint32m2_t op0, vuint32m2_t op1, size_t op2){
  return vxor_vv_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vxor(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vxor_vv_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vxor(vuint32m4_t op0, vuint32m4_t op1, size_t op2){
  return vxor_vv_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vxor(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vxor_vv_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vxor(vuint32m8_t op0, vuint32m8_t op1, size_t op2){
  return vxor_vv_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vxor(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, vuint32m8_t op3, size_t op4){
  return vxor_vv_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vxor(vuint32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vxor_vv_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vxor(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vxor_vv_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vxor(vuint64m1_t op0, vuint64m1_t op1, size_t op2){
  return vxor_vv_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vxor(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vxor_vv_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vxor(vuint64m2_t op0, vuint64m2_t op1, size_t op2){
  return vxor_vv_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vxor(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, vuint64m2_t op3, size_t op4){
  return vxor_vv_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vxor(vuint64m4_t op0, vuint64m4_t op1, size_t op2){
  return vxor_vv_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vxor(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, vuint64m4_t op3, size_t op4){
  return vxor_vv_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vxor(vuint64m8_t op0, vuint64m8_t op1, size_t op2){
  return vxor_vv_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vxor(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, vuint64m8_t op3, size_t op4){
  return vxor_vv_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vxor(vuint8m1_t op0, uint8_t op1, size_t op2){
  return vxor_vx_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vxor(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, uint8_t op3, size_t op4){
  return vxor_vx_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vxor(vuint8m2_t op0, uint8_t op1, size_t op2){
  return vxor_vx_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vxor(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, uint8_t op3, size_t op4){
  return vxor_vx_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vxor(vuint8m4_t op0, uint8_t op1, size_t op2){
  return vxor_vx_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vxor(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, uint8_t op3, size_t op4){
  return vxor_vx_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vxor(vuint8m8_t op0, uint8_t op1, size_t op2){
  return vxor_vx_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vxor(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, uint8_t op3, size_t op4){
  return vxor_vx_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vxor(vuint8mf2_t op0, uint8_t op1, size_t op2){
  return vxor_vx_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vxor(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, uint8_t op3, size_t op4){
  return vxor_vx_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vxor(vuint8mf4_t op0, uint8_t op1, size_t op2){
  return vxor_vx_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vxor(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, uint8_t op3, size_t op4){
  return vxor_vx_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vxor(vuint8mf8_t op0, uint8_t op1, size_t op2){
  return vxor_vx_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vxor(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, uint8_t op3, size_t op4){
  return vxor_vx_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vxor(vuint16m1_t op0, uint16_t op1, size_t op2){
  return vxor_vx_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vxor(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, uint16_t op3, size_t op4){
  return vxor_vx_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vxor(vuint16m2_t op0, uint16_t op1, size_t op2){
  return vxor_vx_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vxor(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, uint16_t op3, size_t op4){
  return vxor_vx_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vxor(vuint16m4_t op0, uint16_t op1, size_t op2){
  return vxor_vx_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vxor(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, uint16_t op3, size_t op4){
  return vxor_vx_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vxor(vuint16m8_t op0, uint16_t op1, size_t op2){
  return vxor_vx_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vxor(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, uint16_t op3, size_t op4){
  return vxor_vx_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vxor(vuint16mf2_t op0, uint16_t op1, size_t op2){
  return vxor_vx_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vxor(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, uint16_t op3, size_t op4){
  return vxor_vx_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vxor(vuint16mf4_t op0, uint16_t op1, size_t op2){
  return vxor_vx_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vxor(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, uint16_t op3, size_t op4){
  return vxor_vx_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vxor(vuint32m1_t op0, uint32_t op1, size_t op2){
  return vxor_vx_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vxor(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, uint32_t op3, size_t op4){
  return vxor_vx_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vxor(vuint32m2_t op0, uint32_t op1, size_t op2){
  return vxor_vx_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vxor(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, uint32_t op3, size_t op4){
  return vxor_vx_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vxor(vuint32m4_t op0, uint32_t op1, size_t op2){
  return vxor_vx_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vxor(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, uint32_t op3, size_t op4){
  return vxor_vx_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vxor(vuint32m8_t op0, uint32_t op1, size_t op2){
  return vxor_vx_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vxor(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, uint32_t op3, size_t op4){
  return vxor_vx_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vxor(vuint32mf2_t op0, uint32_t op1, size_t op2){
  return vxor_vx_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vxor(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, uint32_t op3, size_t op4){
  return vxor_vx_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vxor(vuint64m1_t op0, uint64_t op1, size_t op2){
  return vxor_vx_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vxor(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, uint64_t op3, size_t op4){
  return vxor_vx_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vxor(vuint64m2_t op0, uint64_t op1, size_t op2){
  return vxor_vx_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vxor(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, uint64_t op3, size_t op4){
  return vxor_vx_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vxor(vuint64m4_t op0, uint64_t op1, size_t op2){
  return vxor_vx_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vxor(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, uint64_t op3, size_t op4){
  return vxor_vx_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vxor(vuint64m8_t op0, uint64_t op1, size_t op2){
  return vxor_vx_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vxor(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, uint64_t op3, size_t op4){
  return vxor_vx_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vle16(vbool16_t op0, vuint16m1_t op1, const uint16_t * op2, size_t op3){
  return vle16_v_u16m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m2_t vle16(vbool8_t op0, vuint16m2_t op1, const uint16_t * op2, size_t op3){
  return vle16_v_u16m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m4_t vle16(vbool4_t op0, vuint16m4_t op1, const uint16_t * op2, size_t op3){
  return vle16_v_u16m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m8_t vle16(vbool2_t op0, vuint16m8_t op1, const uint16_t * op2, size_t op3){
  return vle16_v_u16m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf2_t vle16(vbool32_t op0, vuint16mf2_t op1, const uint16_t * op2, size_t op3){
  return vle16_v_u16mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf4_t vle16(vbool64_t op0, vuint16mf4_t op1, const uint16_t * op2, size_t op3){
  return vle16_v_u16mf4_m(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vor(vint8m1_t op0, vint8m1_t op1, size_t op2){
  return vor_vv_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vor(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, vint8m1_t op3, size_t op4){
  return vor_vv_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vor(vint8m2_t op0, vint8m2_t op1, size_t op2){
  return vor_vv_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vor(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, vint8m2_t op3, size_t op4){
  return vor_vv_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vor(vint8m4_t op0, vint8m4_t op1, size_t op2){
  return vor_vv_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vor(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, vint8m4_t op3, size_t op4){
  return vor_vv_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vor(vint8m8_t op0, vint8m8_t op1, size_t op2){
  return vor_vv_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vor(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, vint8m8_t op3, size_t op4){
  return vor_vv_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vor(vint8mf2_t op0, vint8mf2_t op1, size_t op2){
  return vor_vv_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vor(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, vint8mf2_t op3, size_t op4){
  return vor_vv_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vor(vint8mf4_t op0, vint8mf4_t op1, size_t op2){
  return vor_vv_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vor(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, vint8mf4_t op3, size_t op4){
  return vor_vv_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vor(vint8mf8_t op0, vint8mf8_t op1, size_t op2){
  return vor_vv_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vor(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, vint8mf8_t op3, size_t op4){
  return vor_vv_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vor(vint16m1_t op0, vint16m1_t op1, size_t op2){
  return vor_vv_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vor(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, vint16m1_t op3, size_t op4){
  return vor_vv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vor(vint16m2_t op0, vint16m2_t op1, size_t op2){
  return vor_vv_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vor(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, vint16m2_t op3, size_t op4){
  return vor_vv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vor(vint16m4_t op0, vint16m4_t op1, size_t op2){
  return vor_vv_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vor(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, vint16m4_t op3, size_t op4){
  return vor_vv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vor(vint16m8_t op0, vint16m8_t op1, size_t op2){
  return vor_vv_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vor(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, vint16m8_t op3, size_t op4){
  return vor_vv_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vor(vint16mf2_t op0, vint16mf2_t op1, size_t op2){
  return vor_vv_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vor(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, vint16mf2_t op3, size_t op4){
  return vor_vv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vor(vint16mf4_t op0, vint16mf4_t op1, size_t op2){
  return vor_vv_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vor(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, vint16mf4_t op3, size_t op4){
  return vor_vv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vor(vint32m1_t op0, vint32m1_t op1, size_t op2){
  return vor_vv_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vor(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, vint32m1_t op3, size_t op4){
  return vor_vv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vor(vint32m2_t op0, vint32m2_t op1, size_t op2){
  return vor_vv_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vor(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, vint32m2_t op3, size_t op4){
  return vor_vv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vor(vint32m4_t op0, vint32m4_t op1, size_t op2){
  return vor_vv_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vor(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, vint32m4_t op3, size_t op4){
  return vor_vv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vor(vint32m8_t op0, vint32m8_t op1, size_t op2){
  return vor_vv_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vor(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, vint32m8_t op3, size_t op4){
  return vor_vv_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vor(vint32mf2_t op0, vint32mf2_t op1, size_t op2){
  return vor_vv_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vor(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, vint32mf2_t op3, size_t op4){
  return vor_vv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vor(vint64m1_t op0, vint64m1_t op1, size_t op2){
  return vor_vv_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vor(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, vint64m1_t op3, size_t op4){
  return vor_vv_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vor(vint64m2_t op0, vint64m2_t op1, size_t op2){
  return vor_vv_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vor(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, vint64m2_t op3, size_t op4){
  return vor_vv_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vor(vint64m4_t op0, vint64m4_t op1, size_t op2){
  return vor_vv_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vor(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, vint64m4_t op3, size_t op4){
  return vor_vv_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vor(vint64m8_t op0, vint64m8_t op1, size_t op2){
  return vor_vv_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vor(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, vint64m8_t op3, size_t op4){
  return vor_vv_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vor(vint8m1_t op0, int8_t op1, size_t op2){
  return vor_vx_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vor(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, int8_t op3, size_t op4){
  return vor_vx_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vor(vint8m2_t op0, int8_t op1, size_t op2){
  return vor_vx_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vor(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, int8_t op3, size_t op4){
  return vor_vx_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vor(vint8m4_t op0, int8_t op1, size_t op2){
  return vor_vx_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vor(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, int8_t op3, size_t op4){
  return vor_vx_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vor(vint8m8_t op0, int8_t op1, size_t op2){
  return vor_vx_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vor(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, int8_t op3, size_t op4){
  return vor_vx_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vor(vint8mf2_t op0, int8_t op1, size_t op2){
  return vor_vx_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vor(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, int8_t op3, size_t op4){
  return vor_vx_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vor(vint8mf4_t op0, int8_t op1, size_t op2){
  return vor_vx_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vor(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, int8_t op3, size_t op4){
  return vor_vx_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vor(vint8mf8_t op0, int8_t op1, size_t op2){
  return vor_vx_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vor(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, int8_t op3, size_t op4){
  return vor_vx_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vor(vint16m1_t op0, int16_t op1, size_t op2){
  return vor_vx_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vor(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, int16_t op3, size_t op4){
  return vor_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vor(vint16m2_t op0, int16_t op1, size_t op2){
  return vor_vx_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vor(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, int16_t op3, size_t op4){
  return vor_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vor(vint16m4_t op0, int16_t op1, size_t op2){
  return vor_vx_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vor(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, int16_t op3, size_t op4){
  return vor_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vor(vint16m8_t op0, int16_t op1, size_t op2){
  return vor_vx_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vor(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, int16_t op3, size_t op4){
  return vor_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vor(vint16mf2_t op0, int16_t op1, size_t op2){
  return vor_vx_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vor(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, int16_t op3, size_t op4){
  return vor_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vor(vint16mf4_t op0, int16_t op1, size_t op2){
  return vor_vx_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vor(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, int16_t op3, size_t op4){
  return vor_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vor(vint32m1_t op0, int32_t op1, size_t op2){
  return vor_vx_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vor(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, int32_t op3, size_t op4){
  return vor_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vor(vint32m2_t op0, int32_t op1, size_t op2){
  return vor_vx_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vor(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, int32_t op3, size_t op4){
  return vor_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vor(vint32m4_t op0, int32_t op1, size_t op2){
  return vor_vx_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vor(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, int32_t op3, size_t op4){
  return vor_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vor(vint32m8_t op0, int32_t op1, size_t op2){
  return vor_vx_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vor(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, int32_t op3, size_t op4){
  return vor_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vor(vint32mf2_t op0, int32_t op1, size_t op2){
  return vor_vx_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vor(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, int32_t op3, size_t op4){
  return vor_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vor(vint64m1_t op0, int64_t op1, size_t op2){
  return vor_vx_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vor(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, int64_t op3, size_t op4){
  return vor_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vor(vint64m2_t op0, int64_t op1, size_t op2){
  return vor_vx_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vor(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, int64_t op3, size_t op4){
  return vor_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vor(vint64m4_t op0, int64_t op1, size_t op2){
  return vor_vx_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vor(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, int64_t op3, size_t op4){
  return vor_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vor(vint64m8_t op0, int64_t op1, size_t op2){
  return vor_vx_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vor(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, int64_t op3, size_t op4){
  return vor_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vor(vuint8m1_t op0, vuint8m1_t op1, size_t op2){
  return vor_vv_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vor(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vor_vv_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vor(vuint8m2_t op0, vuint8m2_t op1, size_t op2){
  return vor_vv_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vor(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vor_vv_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vor(vuint8m4_t op0, vuint8m4_t op1, size_t op2){
  return vor_vv_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vor(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vor_vv_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vor(vuint8m8_t op0, vuint8m8_t op1, size_t op2){
  return vor_vv_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vor(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, vuint8m8_t op3, size_t op4){
  return vor_vv_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vor(vuint8mf2_t op0, vuint8mf2_t op1, size_t op2){
  return vor_vv_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vor(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vor_vv_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vor(vuint8mf4_t op0, vuint8mf4_t op1, size_t op2){
  return vor_vv_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vor(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vor_vv_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vor(vuint8mf8_t op0, vuint8mf8_t op1, size_t op2){
  return vor_vv_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vor(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vor_vv_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vor(vuint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vor_vv_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vor(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vor_vv_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vor(vuint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vor_vv_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vor(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vor_vv_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vor(vuint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vor_vv_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vor(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vor_vv_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vor(vuint16m8_t op0, vuint16m8_t op1, size_t op2){
  return vor_vv_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vor(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vor_vv_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vor(vuint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vor_vv_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vor(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vor_vv_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vor(vuint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vor_vv_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vor(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vor_vv_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vor(vuint32m1_t op0, vuint32m1_t op1, size_t op2){
  return vor_vv_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vor(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vor_vv_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vor(vuint32m2_t op0, vuint32m2_t op1, size_t op2){
  return vor_vv_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vor(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vor_vv_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vor(vuint32m4_t op0, vuint32m4_t op1, size_t op2){
  return vor_vv_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vor(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vor_vv_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vor(vuint32m8_t op0, vuint32m8_t op1, size_t op2){
  return vor_vv_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vor(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, vuint32m8_t op3, size_t op4){
  return vor_vv_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vor(vuint32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vor_vv_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vor(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vor_vv_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vor(vuint64m1_t op0, vuint64m1_t op1, size_t op2){
  return vor_vv_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vor(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vor_vv_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vor(vuint64m2_t op0, vuint64m2_t op1, size_t op2){
  return vor_vv_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vor(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, vuint64m2_t op3, size_t op4){
  return vor_vv_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vor(vuint64m4_t op0, vuint64m4_t op1, size_t op2){
  return vor_vv_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vor(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, vuint64m4_t op3, size_t op4){
  return vor_vv_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vor(vuint64m8_t op0, vuint64m8_t op1, size_t op2){
  return vor_vv_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vor(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, vuint64m8_t op3, size_t op4){
  return vor_vv_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vor(vuint8m1_t op0, uint8_t op1, size_t op2){
  return vor_vx_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vor(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, uint8_t op3, size_t op4){
  return vor_vx_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vor(vuint8m2_t op0, uint8_t op1, size_t op2){
  return vor_vx_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vor(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, uint8_t op3, size_t op4){
  return vor_vx_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vor(vuint8m4_t op0, uint8_t op1, size_t op2){
  return vor_vx_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vor(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, uint8_t op3, size_t op4){
  return vor_vx_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vor(vuint8m8_t op0, uint8_t op1, size_t op2){
  return vor_vx_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vor(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, uint8_t op3, size_t op4){
  return vor_vx_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vor(vuint8mf2_t op0, uint8_t op1, size_t op2){
  return vor_vx_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vor(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, uint8_t op3, size_t op4){
  return vor_vx_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vor(vuint8mf4_t op0, uint8_t op1, size_t op2){
  return vor_vx_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vor(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, uint8_t op3, size_t op4){
  return vor_vx_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vor(vuint8mf8_t op0, uint8_t op1, size_t op2){
  return vor_vx_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vor(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, uint8_t op3, size_t op4){
  return vor_vx_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vor(vuint16m1_t op0, uint16_t op1, size_t op2){
  return vor_vx_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vor(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, uint16_t op3, size_t op4){
  return vor_vx_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vor(vuint16m2_t op0, uint16_t op1, size_t op2){
  return vor_vx_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vor(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, uint16_t op3, size_t op4){
  return vor_vx_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vor(vuint16m4_t op0, uint16_t op1, size_t op2){
  return vor_vx_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vor(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, uint16_t op3, size_t op4){
  return vor_vx_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vor(vuint16m8_t op0, uint16_t op1, size_t op2){
  return vor_vx_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vor(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, uint16_t op3, size_t op4){
  return vor_vx_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vor(vuint16mf2_t op0, uint16_t op1, size_t op2){
  return vor_vx_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vor(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, uint16_t op3, size_t op4){
  return vor_vx_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vor(vuint16mf4_t op0, uint16_t op1, size_t op2){
  return vor_vx_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vor(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, uint16_t op3, size_t op4){
  return vor_vx_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vor(vuint32m1_t op0, uint32_t op1, size_t op2){
  return vor_vx_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vor(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, uint32_t op3, size_t op4){
  return vor_vx_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vor(vuint32m2_t op0, uint32_t op1, size_t op2){
  return vor_vx_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vor(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, uint32_t op3, size_t op4){
  return vor_vx_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vor(vuint32m4_t op0, uint32_t op1, size_t op2){
  return vor_vx_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vor(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, uint32_t op3, size_t op4){
  return vor_vx_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vor(vuint32m8_t op0, uint32_t op1, size_t op2){
  return vor_vx_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vor(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, uint32_t op3, size_t op4){
  return vor_vx_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vor(vuint32mf2_t op0, uint32_t op1, size_t op2){
  return vor_vx_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vor(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, uint32_t op3, size_t op4){
  return vor_vx_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vor(vuint64m1_t op0, uint64_t op1, size_t op2){
  return vor_vx_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vor(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, uint64_t op3, size_t op4){
  return vor_vx_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vor(vuint64m2_t op0, uint64_t op1, size_t op2){
  return vor_vx_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vor(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, uint64_t op3, size_t op4){
  return vor_vx_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vor(vuint64m4_t op0, uint64_t op1, size_t op2){
  return vor_vx_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vor(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, uint64_t op3, size_t op4){
  return vor_vx_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vor(vuint64m8_t op0, uint64_t op1, size_t op2){
  return vor_vx_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vor(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, uint64_t op3, size_t op4){
  return vor_vx_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vsll(vint8m1_t op0, vuint8m1_t op1, size_t op2){
  return vsll_vv_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vsll(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vsll_vv_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vsll(vint8m2_t op0, vuint8m2_t op1, size_t op2){
  return vsll_vv_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vsll(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vsll_vv_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vsll(vint8m4_t op0, vuint8m4_t op1, size_t op2){
  return vsll_vv_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vsll(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vsll_vv_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vsll(vint8m8_t op0, vuint8m8_t op1, size_t op2){
  return vsll_vv_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vsll(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, vuint8m8_t op3, size_t op4){
  return vsll_vv_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vsll(vint8mf2_t op0, vuint8mf2_t op1, size_t op2){
  return vsll_vv_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vsll(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vsll_vv_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vsll(vint8mf4_t op0, vuint8mf4_t op1, size_t op2){
  return vsll_vv_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vsll(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vsll_vv_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vsll(vint8mf8_t op0, vuint8mf8_t op1, size_t op2){
  return vsll_vv_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vsll(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vsll_vv_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vsll(vint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vsll_vv_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vsll(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vsll_vv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vsll(vint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vsll_vv_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vsll(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vsll_vv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vsll(vint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vsll_vv_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vsll(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vsll_vv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vsll(vint16m8_t op0, vuint16m8_t op1, size_t op2){
  return vsll_vv_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vsll(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vsll_vv_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vsll(vint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vsll_vv_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vsll(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vsll_vv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vsll(vint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vsll_vv_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vsll(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vsll_vv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vsll(vint32m1_t op0, vuint32m1_t op1, size_t op2){
  return vsll_vv_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vsll(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vsll_vv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vsll(vint32m2_t op0, vuint32m2_t op1, size_t op2){
  return vsll_vv_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vsll(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vsll_vv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vsll(vint32m4_t op0, vuint32m4_t op1, size_t op2){
  return vsll_vv_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vsll(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vsll_vv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vsll(vint32m8_t op0, vuint32m8_t op1, size_t op2){
  return vsll_vv_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vsll(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, vuint32m8_t op3, size_t op4){
  return vsll_vv_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vsll(vint32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vsll_vv_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vsll(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vsll_vv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vsll(vint64m1_t op0, vuint64m1_t op1, size_t op2){
  return vsll_vv_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vsll(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vsll_vv_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vsll(vint64m2_t op0, vuint64m2_t op1, size_t op2){
  return vsll_vv_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vsll(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, vuint64m2_t op3, size_t op4){
  return vsll_vv_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vsll(vint64m4_t op0, vuint64m4_t op1, size_t op2){
  return vsll_vv_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vsll(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, vuint64m4_t op3, size_t op4){
  return vsll_vv_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vsll(vint64m8_t op0, vuint64m8_t op1, size_t op2){
  return vsll_vv_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vsll(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, vuint64m8_t op3, size_t op4){
  return vsll_vv_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vsll(vint8m1_t op0, size_t op1, size_t op2){
  return vsll_vx_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vsll(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, size_t op3, size_t op4){
  return vsll_vx_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vsll(vint8m2_t op0, size_t op1, size_t op2){
  return vsll_vx_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vsll(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, size_t op3, size_t op4){
  return vsll_vx_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vsll(vint8m4_t op0, size_t op1, size_t op2){
  return vsll_vx_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vsll(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, size_t op3, size_t op4){
  return vsll_vx_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vsll(vint8m8_t op0, size_t op1, size_t op2){
  return vsll_vx_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vsll(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, size_t op3, size_t op4){
  return vsll_vx_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vsll(vint8mf2_t op0, size_t op1, size_t op2){
  return vsll_vx_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vsll(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, size_t op3, size_t op4){
  return vsll_vx_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vsll(vint8mf4_t op0, size_t op1, size_t op2){
  return vsll_vx_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vsll(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, size_t op3, size_t op4){
  return vsll_vx_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vsll(vint8mf8_t op0, size_t op1, size_t op2){
  return vsll_vx_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vsll(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, size_t op3, size_t op4){
  return vsll_vx_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vsll(vint16m1_t op0, size_t op1, size_t op2){
  return vsll_vx_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vsll(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, size_t op3, size_t op4){
  return vsll_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vsll(vint16m2_t op0, size_t op1, size_t op2){
  return vsll_vx_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vsll(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, size_t op3, size_t op4){
  return vsll_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vsll(vint16m4_t op0, size_t op1, size_t op2){
  return vsll_vx_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vsll(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, size_t op3, size_t op4){
  return vsll_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vsll(vint16m8_t op0, size_t op1, size_t op2){
  return vsll_vx_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vsll(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, size_t op3, size_t op4){
  return vsll_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vsll(vint16mf2_t op0, size_t op1, size_t op2){
  return vsll_vx_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vsll(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, size_t op3, size_t op4){
  return vsll_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vsll(vint16mf4_t op0, size_t op1, size_t op2){
  return vsll_vx_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vsll(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, size_t op3, size_t op4){
  return vsll_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vsll(vint32m1_t op0, size_t op1, size_t op2){
  return vsll_vx_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vsll(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, size_t op3, size_t op4){
  return vsll_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vsll(vint32m2_t op0, size_t op1, size_t op2){
  return vsll_vx_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vsll(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, size_t op3, size_t op4){
  return vsll_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vsll(vint32m4_t op0, size_t op1, size_t op2){
  return vsll_vx_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vsll(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, size_t op3, size_t op4){
  return vsll_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vsll(vint32m8_t op0, size_t op1, size_t op2){
  return vsll_vx_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vsll(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, size_t op3, size_t op4){
  return vsll_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vsll(vint32mf2_t op0, size_t op1, size_t op2){
  return vsll_vx_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vsll(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, size_t op3, size_t op4){
  return vsll_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vsll(vint64m1_t op0, size_t op1, size_t op2){
  return vsll_vx_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vsll(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, size_t op3, size_t op4){
  return vsll_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vsll(vint64m2_t op0, size_t op1, size_t op2){
  return vsll_vx_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vsll(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, size_t op3, size_t op4){
  return vsll_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vsll(vint64m4_t op0, size_t op1, size_t op2){
  return vsll_vx_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vsll(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, size_t op3, size_t op4){
  return vsll_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vsll(vint64m8_t op0, size_t op1, size_t op2){
  return vsll_vx_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vsll(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, size_t op3, size_t op4){
  return vsll_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vsll(vuint8m1_t op0, vuint8m1_t op1, size_t op2){
  return vsll_vv_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vsll(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vsll_vv_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vsll(vuint8m2_t op0, vuint8m2_t op1, size_t op2){
  return vsll_vv_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vsll(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vsll_vv_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vsll(vuint8m4_t op0, vuint8m4_t op1, size_t op2){
  return vsll_vv_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vsll(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vsll_vv_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vsll(vuint8m8_t op0, vuint8m8_t op1, size_t op2){
  return vsll_vv_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vsll(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, vuint8m8_t op3, size_t op4){
  return vsll_vv_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vsll(vuint8mf2_t op0, vuint8mf2_t op1, size_t op2){
  return vsll_vv_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vsll(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vsll_vv_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vsll(vuint8mf4_t op0, vuint8mf4_t op1, size_t op2){
  return vsll_vv_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vsll(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vsll_vv_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vsll(vuint8mf8_t op0, vuint8mf8_t op1, size_t op2){
  return vsll_vv_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vsll(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vsll_vv_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vsll(vuint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vsll_vv_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vsll(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vsll_vv_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vsll(vuint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vsll_vv_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vsll(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vsll_vv_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vsll(vuint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vsll_vv_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vsll(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vsll_vv_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vsll(vuint16m8_t op0, vuint16m8_t op1, size_t op2){
  return vsll_vv_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vsll(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vsll_vv_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vsll(vuint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vsll_vv_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vsll(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vsll_vv_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vsll(vuint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vsll_vv_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vsll(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vsll_vv_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vsll(vuint32m1_t op0, vuint32m1_t op1, size_t op2){
  return vsll_vv_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vsll(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vsll_vv_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vsll(vuint32m2_t op0, vuint32m2_t op1, size_t op2){
  return vsll_vv_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vsll(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vsll_vv_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vsll(vuint32m4_t op0, vuint32m4_t op1, size_t op2){
  return vsll_vv_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vsll(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vsll_vv_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vsll(vuint32m8_t op0, vuint32m8_t op1, size_t op2){
  return vsll_vv_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vsll(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, vuint32m8_t op3, size_t op4){
  return vsll_vv_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vsll(vuint32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vsll_vv_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vsll(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vsll_vv_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vsll(vuint64m1_t op0, vuint64m1_t op1, size_t op2){
  return vsll_vv_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vsll(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vsll_vv_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vsll(vuint64m2_t op0, vuint64m2_t op1, size_t op2){
  return vsll_vv_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vsll(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, vuint64m2_t op3, size_t op4){
  return vsll_vv_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vsll(vuint64m4_t op0, vuint64m4_t op1, size_t op2){
  return vsll_vv_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vsll(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, vuint64m4_t op3, size_t op4){
  return vsll_vv_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vsll(vuint64m8_t op0, vuint64m8_t op1, size_t op2){
  return vsll_vv_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vsll(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, vuint64m8_t op3, size_t op4){
  return vsll_vv_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vsll(vuint8m1_t op0, size_t op1, size_t op2){
  return vsll_vx_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vsll(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, size_t op3, size_t op4){
  return vsll_vx_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vsll(vuint8m2_t op0, size_t op1, size_t op2){
  return vsll_vx_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vsll(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, size_t op3, size_t op4){
  return vsll_vx_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vsll(vuint8m4_t op0, size_t op1, size_t op2){
  return vsll_vx_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vsll(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, size_t op3, size_t op4){
  return vsll_vx_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vsll(vuint8m8_t op0, size_t op1, size_t op2){
  return vsll_vx_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vsll(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, size_t op3, size_t op4){
  return vsll_vx_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vsll(vuint8mf2_t op0, size_t op1, size_t op2){
  return vsll_vx_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vsll(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, size_t op3, size_t op4){
  return vsll_vx_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vsll(vuint8mf4_t op0, size_t op1, size_t op2){
  return vsll_vx_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vsll(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, size_t op3, size_t op4){
  return vsll_vx_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vsll(vuint8mf8_t op0, size_t op1, size_t op2){
  return vsll_vx_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vsll(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, size_t op3, size_t op4){
  return vsll_vx_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vsll(vuint16m1_t op0, size_t op1, size_t op2){
  return vsll_vx_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vsll(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, size_t op3, size_t op4){
  return vsll_vx_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vsll(vuint16m2_t op0, size_t op1, size_t op2){
  return vsll_vx_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vsll(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, size_t op3, size_t op4){
  return vsll_vx_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vsll(vuint16m4_t op0, size_t op1, size_t op2){
  return vsll_vx_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vsll(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, size_t op3, size_t op4){
  return vsll_vx_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vsll(vuint16m8_t op0, size_t op1, size_t op2){
  return vsll_vx_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vsll(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, size_t op3, size_t op4){
  return vsll_vx_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vsll(vuint16mf2_t op0, size_t op1, size_t op2){
  return vsll_vx_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vsll(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, size_t op3, size_t op4){
  return vsll_vx_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vsll(vuint16mf4_t op0, size_t op1, size_t op2){
  return vsll_vx_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vsll(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, size_t op3, size_t op4){
  return vsll_vx_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vsll(vuint32m1_t op0, size_t op1, size_t op2){
  return vsll_vx_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vsll(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, size_t op3, size_t op4){
  return vsll_vx_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vsll(vuint32m2_t op0, size_t op1, size_t op2){
  return vsll_vx_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vsll(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, size_t op3, size_t op4){
  return vsll_vx_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vsll(vuint32m4_t op0, size_t op1, size_t op2){
  return vsll_vx_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vsll(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, size_t op3, size_t op4){
  return vsll_vx_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vsll(vuint32m8_t op0, size_t op1, size_t op2){
  return vsll_vx_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vsll(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, size_t op3, size_t op4){
  return vsll_vx_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vsll(vuint32mf2_t op0, size_t op1, size_t op2){
  return vsll_vx_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vsll(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, size_t op3, size_t op4){
  return vsll_vx_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vsll(vuint64m1_t op0, size_t op1, size_t op2){
  return vsll_vx_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vsll(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, size_t op3, size_t op4){
  return vsll_vx_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vsll(vuint64m2_t op0, size_t op1, size_t op2){
  return vsll_vx_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vsll(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, size_t op3, size_t op4){
  return vsll_vx_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vsll(vuint64m4_t op0, size_t op1, size_t op2){
  return vsll_vx_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vsll(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, size_t op3, size_t op4){
  return vsll_vx_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vsll(vuint64m8_t op0, size_t op1, size_t op2){
  return vsll_vx_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vsll(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, size_t op3, size_t op4){
  return vsll_vx_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vsrl(vuint8m1_t op0, vuint8m1_t op1, size_t op2){
  return vsrl_vv_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vsrl(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vsrl_vv_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vsrl(vuint8m2_t op0, vuint8m2_t op1, size_t op2){
  return vsrl_vv_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vsrl(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vsrl_vv_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vsrl(vuint8m4_t op0, vuint8m4_t op1, size_t op2){
  return vsrl_vv_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vsrl(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vsrl_vv_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vsrl(vuint8m8_t op0, vuint8m8_t op1, size_t op2){
  return vsrl_vv_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vsrl(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, vuint8m8_t op3, size_t op4){
  return vsrl_vv_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vsrl(vuint8mf2_t op0, vuint8mf2_t op1, size_t op2){
  return vsrl_vv_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vsrl(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vsrl_vv_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vsrl(vuint8mf4_t op0, vuint8mf4_t op1, size_t op2){
  return vsrl_vv_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vsrl(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vsrl_vv_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vsrl(vuint8mf8_t op0, vuint8mf8_t op1, size_t op2){
  return vsrl_vv_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vsrl(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vsrl_vv_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vsrl(vuint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vsrl_vv_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vsrl(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vsrl_vv_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vsrl(vuint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vsrl_vv_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vsrl(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vsrl_vv_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vsrl(vuint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vsrl_vv_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vsrl(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vsrl_vv_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vsrl(vuint16m8_t op0, vuint16m8_t op1, size_t op2){
  return vsrl_vv_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vsrl(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vsrl_vv_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vsrl(vuint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vsrl_vv_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vsrl(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vsrl_vv_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vsrl(vuint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vsrl_vv_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vsrl(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vsrl_vv_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vsrl(vuint32m1_t op0, vuint32m1_t op1, size_t op2){
  return vsrl_vv_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vsrl(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vsrl_vv_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vsrl(vuint32m2_t op0, vuint32m2_t op1, size_t op2){
  return vsrl_vv_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vsrl(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vsrl_vv_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vsrl(vuint32m4_t op0, vuint32m4_t op1, size_t op2){
  return vsrl_vv_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vsrl(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vsrl_vv_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vsrl(vuint32m8_t op0, vuint32m8_t op1, size_t op2){
  return vsrl_vv_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vsrl(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, vuint32m8_t op3, size_t op4){
  return vsrl_vv_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vsrl(vuint32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vsrl_vv_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vsrl(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vsrl_vv_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vsrl(vuint64m1_t op0, vuint64m1_t op1, size_t op2){
  return vsrl_vv_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vsrl(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vsrl_vv_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vsrl(vuint64m2_t op0, vuint64m2_t op1, size_t op2){
  return vsrl_vv_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vsrl(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, vuint64m2_t op3, size_t op4){
  return vsrl_vv_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vsrl(vuint64m4_t op0, vuint64m4_t op1, size_t op2){
  return vsrl_vv_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vsrl(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, vuint64m4_t op3, size_t op4){
  return vsrl_vv_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vsrl(vuint64m8_t op0, vuint64m8_t op1, size_t op2){
  return vsrl_vv_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vsrl(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, vuint64m8_t op3, size_t op4){
  return vsrl_vv_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vsrl(vuint8m1_t op0, size_t op1, size_t op2){
  return vsrl_vx_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vsrl(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, size_t op3, size_t op4){
  return vsrl_vx_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vsrl(vuint8m2_t op0, size_t op1, size_t op2){
  return vsrl_vx_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vsrl(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, size_t op3, size_t op4){
  return vsrl_vx_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vsrl(vuint8m4_t op0, size_t op1, size_t op2){
  return vsrl_vx_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vsrl(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, size_t op3, size_t op4){
  return vsrl_vx_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vsrl(vuint8m8_t op0, size_t op1, size_t op2){
  return vsrl_vx_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vsrl(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, size_t op3, size_t op4){
  return vsrl_vx_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vsrl(vuint8mf2_t op0, size_t op1, size_t op2){
  return vsrl_vx_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vsrl(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, size_t op3, size_t op4){
  return vsrl_vx_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vsrl(vuint8mf4_t op0, size_t op1, size_t op2){
  return vsrl_vx_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vsrl(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, size_t op3, size_t op4){
  return vsrl_vx_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vsrl(vuint8mf8_t op0, size_t op1, size_t op2){
  return vsrl_vx_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vsrl(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, size_t op3, size_t op4){
  return vsrl_vx_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vsrl(vuint16m1_t op0, size_t op1, size_t op2){
  return vsrl_vx_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vsrl(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, size_t op3, size_t op4){
  return vsrl_vx_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vsrl(vuint16m2_t op0, size_t op1, size_t op2){
  return vsrl_vx_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vsrl(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, size_t op3, size_t op4){
  return vsrl_vx_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vsrl(vuint16m4_t op0, size_t op1, size_t op2){
  return vsrl_vx_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vsrl(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, size_t op3, size_t op4){
  return vsrl_vx_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vsrl(vuint16m8_t op0, size_t op1, size_t op2){
  return vsrl_vx_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vsrl(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, size_t op3, size_t op4){
  return vsrl_vx_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vsrl(vuint16mf2_t op0, size_t op1, size_t op2){
  return vsrl_vx_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vsrl(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, size_t op3, size_t op4){
  return vsrl_vx_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vsrl(vuint16mf4_t op0, size_t op1, size_t op2){
  return vsrl_vx_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vsrl(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, size_t op3, size_t op4){
  return vsrl_vx_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vsrl(vuint32m1_t op0, size_t op1, size_t op2){
  return vsrl_vx_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vsrl(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, size_t op3, size_t op4){
  return vsrl_vx_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vsrl(vuint32m2_t op0, size_t op1, size_t op2){
  return vsrl_vx_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vsrl(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, size_t op3, size_t op4){
  return vsrl_vx_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vsrl(vuint32m4_t op0, size_t op1, size_t op2){
  return vsrl_vx_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vsrl(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, size_t op3, size_t op4){
  return vsrl_vx_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vsrl(vuint32m8_t op0, size_t op1, size_t op2){
  return vsrl_vx_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vsrl(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, size_t op3, size_t op4){
  return vsrl_vx_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vsrl(vuint32mf2_t op0, size_t op1, size_t op2){
  return vsrl_vx_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vsrl(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, size_t op3, size_t op4){
  return vsrl_vx_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vsrl(vuint64m1_t op0, size_t op1, size_t op2){
  return vsrl_vx_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vsrl(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, size_t op3, size_t op4){
  return vsrl_vx_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vsrl(vuint64m2_t op0, size_t op1, size_t op2){
  return vsrl_vx_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vsrl(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, size_t op3, size_t op4){
  return vsrl_vx_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vsrl(vuint64m4_t op0, size_t op1, size_t op2){
  return vsrl_vx_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vsrl(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, size_t op3, size_t op4){
  return vsrl_vx_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vsrl(vuint64m8_t op0, size_t op1, size_t op2){
  return vsrl_vx_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vsrl(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, size_t op3, size_t op4){
  return vsrl_vx_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vle32(vbool32_t op0, vint32m1_t op1, const int32_t * op2, size_t op3){
  return vle32_v_i32m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vint32m2_t vle32(vbool16_t op0, vint32m2_t op1, const int32_t * op2, size_t op3){
  return vle32_v_i32m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vint32m4_t vle32(vbool8_t op0, vint32m4_t op1, const int32_t * op2, size_t op3){
  return vle32_v_i32m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vint32m8_t vle32(vbool4_t op0, vint32m8_t op1, const int32_t * op2, size_t op3){
  return vle32_v_i32m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vint32mf2_t vle32(vbool64_t op0, vint32mf2_t op1, const int32_t * op2, size_t op3){
  return vle32_v_i32mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vsra(vint8m1_t op0, vuint8m1_t op1, size_t op2){
  return vsra_vv_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vsra(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vsra_vv_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vsra(vint8m2_t op0, vuint8m2_t op1, size_t op2){
  return vsra_vv_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vsra(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vsra_vv_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vsra(vint8m4_t op0, vuint8m4_t op1, size_t op2){
  return vsra_vv_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vsra(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vsra_vv_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vsra(vint8m8_t op0, vuint8m8_t op1, size_t op2){
  return vsra_vv_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vsra(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, vuint8m8_t op3, size_t op4){
  return vsra_vv_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vsra(vint8mf2_t op0, vuint8mf2_t op1, size_t op2){
  return vsra_vv_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vsra(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vsra_vv_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vsra(vint8mf4_t op0, vuint8mf4_t op1, size_t op2){
  return vsra_vv_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vsra(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vsra_vv_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vsra(vint8mf8_t op0, vuint8mf8_t op1, size_t op2){
  return vsra_vv_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vsra(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vsra_vv_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vsra(vint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vsra_vv_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vsra(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vsra_vv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vsra(vint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vsra_vv_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vsra(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vsra_vv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vsra(vint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vsra_vv_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vsra(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vsra_vv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vsra(vint16m8_t op0, vuint16m8_t op1, size_t op2){
  return vsra_vv_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vsra(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vsra_vv_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vsra(vint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vsra_vv_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vsra(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vsra_vv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vsra(vint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vsra_vv_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vsra(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vsra_vv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vsra(vint32m1_t op0, vuint32m1_t op1, size_t op2){
  return vsra_vv_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vsra(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vsra_vv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vsra(vint32m2_t op0, vuint32m2_t op1, size_t op2){
  return vsra_vv_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vsra(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vsra_vv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vsra(vint32m4_t op0, vuint32m4_t op1, size_t op2){
  return vsra_vv_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vsra(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vsra_vv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vsra(vint32m8_t op0, vuint32m8_t op1, size_t op2){
  return vsra_vv_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vsra(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, vuint32m8_t op3, size_t op4){
  return vsra_vv_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vsra(vint32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vsra_vv_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vsra(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vsra_vv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vsra(vint64m1_t op0, vuint64m1_t op1, size_t op2){
  return vsra_vv_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vsra(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vsra_vv_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vsra(vint64m2_t op0, vuint64m2_t op1, size_t op2){
  return vsra_vv_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vsra(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, vuint64m2_t op3, size_t op4){
  return vsra_vv_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vsra(vint64m4_t op0, vuint64m4_t op1, size_t op2){
  return vsra_vv_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vsra(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, vuint64m4_t op3, size_t op4){
  return vsra_vv_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vsra(vint64m8_t op0, vuint64m8_t op1, size_t op2){
  return vsra_vv_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vsra(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, vuint64m8_t op3, size_t op4){
  return vsra_vv_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vsra(vint8m1_t op0, size_t op1, size_t op2){
  return vsra_vx_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vsra(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, size_t op3, size_t op4){
  return vsra_vx_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vsra(vint8m2_t op0, size_t op1, size_t op2){
  return vsra_vx_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vsra(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, size_t op3, size_t op4){
  return vsra_vx_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vsra(vint8m4_t op0, size_t op1, size_t op2){
  return vsra_vx_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vsra(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, size_t op3, size_t op4){
  return vsra_vx_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vsra(vint8m8_t op0, size_t op1, size_t op2){
  return vsra_vx_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vsra(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, size_t op3, size_t op4){
  return vsra_vx_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vsra(vint8mf2_t op0, size_t op1, size_t op2){
  return vsra_vx_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vsra(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, size_t op3, size_t op4){
  return vsra_vx_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vsra(vint8mf4_t op0, size_t op1, size_t op2){
  return vsra_vx_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vsra(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, size_t op3, size_t op4){
  return vsra_vx_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vsra(vint8mf8_t op0, size_t op1, size_t op2){
  return vsra_vx_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vsra(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, size_t op3, size_t op4){
  return vsra_vx_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vsra(vint16m1_t op0, size_t op1, size_t op2){
  return vsra_vx_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vsra(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, size_t op3, size_t op4){
  return vsra_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vsra(vint16m2_t op0, size_t op1, size_t op2){
  return vsra_vx_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vsra(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, size_t op3, size_t op4){
  return vsra_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vsra(vint16m4_t op0, size_t op1, size_t op2){
  return vsra_vx_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vsra(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, size_t op3, size_t op4){
  return vsra_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vsra(vint16m8_t op0, size_t op1, size_t op2){
  return vsra_vx_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vsra(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, size_t op3, size_t op4){
  return vsra_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vsra(vint16mf2_t op0, size_t op1, size_t op2){
  return vsra_vx_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vsra(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, size_t op3, size_t op4){
  return vsra_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vsra(vint16mf4_t op0, size_t op1, size_t op2){
  return vsra_vx_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vsra(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, size_t op3, size_t op4){
  return vsra_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vsra(vint32m1_t op0, size_t op1, size_t op2){
  return vsra_vx_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vsra(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, size_t op3, size_t op4){
  return vsra_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vsra(vint32m2_t op0, size_t op1, size_t op2){
  return vsra_vx_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vsra(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, size_t op3, size_t op4){
  return vsra_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vsra(vint32m4_t op0, size_t op1, size_t op2){
  return vsra_vx_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vsra(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, size_t op3, size_t op4){
  return vsra_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vsra(vint32m8_t op0, size_t op1, size_t op2){
  return vsra_vx_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vsra(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, size_t op3, size_t op4){
  return vsra_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vsra(vint32mf2_t op0, size_t op1, size_t op2){
  return vsra_vx_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vsra(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, size_t op3, size_t op4){
  return vsra_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vsra(vint64m1_t op0, size_t op1, size_t op2){
  return vsra_vx_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vsra(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, size_t op3, size_t op4){
  return vsra_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vsra(vint64m2_t op0, size_t op1, size_t op2){
  return vsra_vx_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vsra(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, size_t op3, size_t op4){
  return vsra_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vsra(vint64m4_t op0, size_t op1, size_t op2){
  return vsra_vx_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vsra(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, size_t op3, size_t op4){
  return vsra_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vsra(vint64m8_t op0, size_t op1, size_t op2){
  return vsra_vx_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vsra(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, size_t op3, size_t op4){
  return vsra_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vnsrl(vuint16m2_t op0, vuint8m1_t op1, size_t op2){
  return vnsrl_wv_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vnsrl(vbool8_t op0, vuint8m1_t op1, vuint16m2_t op2, vuint8m1_t op3, size_t op4){
  return vnsrl_wv_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vnsrl(vuint16m4_t op0, vuint8m2_t op1, size_t op2){
  return vnsrl_wv_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vnsrl(vbool4_t op0, vuint8m2_t op1, vuint16m4_t op2, vuint8m2_t op3, size_t op4){
  return vnsrl_wv_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vnsrl(vuint16m8_t op0, vuint8m4_t op1, size_t op2){
  return vnsrl_wv_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vnsrl(vbool2_t op0, vuint8m4_t op1, vuint16m8_t op2, vuint8m4_t op3, size_t op4){
  return vnsrl_wv_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vnsrl(vuint16m1_t op0, vuint8mf2_t op1, size_t op2){
  return vnsrl_wv_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vnsrl(vbool16_t op0, vuint8mf2_t op1, vuint16m1_t op2, vuint8mf2_t op3, size_t op4){
  return vnsrl_wv_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vnsrl(vuint16mf2_t op0, vuint8mf4_t op1, size_t op2){
  return vnsrl_wv_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vnsrl(vbool32_t op0, vuint8mf4_t op1, vuint16mf2_t op2, vuint8mf4_t op3, size_t op4){
  return vnsrl_wv_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vnsrl(vuint16mf4_t op0, vuint8mf8_t op1, size_t op2){
  return vnsrl_wv_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vnsrl(vbool64_t op0, vuint8mf8_t op1, vuint16mf4_t op2, vuint8mf8_t op3, size_t op4){
  return vnsrl_wv_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vnsrl(vuint32m2_t op0, vuint16m1_t op1, size_t op2){
  return vnsrl_wv_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vnsrl(vbool16_t op0, vuint16m1_t op1, vuint32m2_t op2, vuint16m1_t op3, size_t op4){
  return vnsrl_wv_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vnsrl(vuint32m4_t op0, vuint16m2_t op1, size_t op2){
  return vnsrl_wv_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vnsrl(vbool8_t op0, vuint16m2_t op1, vuint32m4_t op2, vuint16m2_t op3, size_t op4){
  return vnsrl_wv_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vnsrl(vuint32m8_t op0, vuint16m4_t op1, size_t op2){
  return vnsrl_wv_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vnsrl(vbool4_t op0, vuint16m4_t op1, vuint32m8_t op2, vuint16m4_t op3, size_t op4){
  return vnsrl_wv_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vnsrl(vuint32m1_t op0, vuint16mf2_t op1, size_t op2){
  return vnsrl_wv_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vnsrl(vbool32_t op0, vuint16mf2_t op1, vuint32m1_t op2, vuint16mf2_t op3, size_t op4){
  return vnsrl_wv_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vnsrl(vuint32mf2_t op0, vuint16mf4_t op1, size_t op2){
  return vnsrl_wv_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vnsrl(vbool64_t op0, vuint16mf4_t op1, vuint32mf2_t op2, vuint16mf4_t op3, size_t op4){
  return vnsrl_wv_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vnsrl(vuint64m2_t op0, vuint32m1_t op1, size_t op2){
  return vnsrl_wv_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vnsrl(vbool32_t op0, vuint32m1_t op1, vuint64m2_t op2, vuint32m1_t op3, size_t op4){
  return vnsrl_wv_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vnsrl(vuint64m4_t op0, vuint32m2_t op1, size_t op2){
  return vnsrl_wv_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vnsrl(vbool16_t op0, vuint32m2_t op1, vuint64m4_t op2, vuint32m2_t op3, size_t op4){
  return vnsrl_wv_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vnsrl(vuint64m8_t op0, vuint32m4_t op1, size_t op2){
  return vnsrl_wv_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vnsrl(vbool8_t op0, vuint32m4_t op1, vuint64m8_t op2, vuint32m4_t op3, size_t op4){
  return vnsrl_wv_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vnsrl(vuint64m1_t op0, vuint32mf2_t op1, size_t op2){
  return vnsrl_wv_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vnsrl(vbool64_t op0, vuint32mf2_t op1, vuint64m1_t op2, vuint32mf2_t op3, size_t op4){
  return vnsrl_wv_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vnsrl(vuint16m2_t op0, size_t op1, size_t op2){
  return vnsrl_wx_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vnsrl(vbool8_t op0, vuint8m1_t op1, vuint16m2_t op2, size_t op3, size_t op4){
  return vnsrl_wx_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vnsrl(vuint16m4_t op0, size_t op1, size_t op2){
  return vnsrl_wx_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vnsrl(vbool4_t op0, vuint8m2_t op1, vuint16m4_t op2, size_t op3, size_t op4){
  return vnsrl_wx_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vnsrl(vuint16m8_t op0, size_t op1, size_t op2){
  return vnsrl_wx_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vnsrl(vbool2_t op0, vuint8m4_t op1, vuint16m8_t op2, size_t op3, size_t op4){
  return vnsrl_wx_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vnsrl(vuint16m1_t op0, size_t op1, size_t op2){
  return vnsrl_wx_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vnsrl(vbool16_t op0, vuint8mf2_t op1, vuint16m1_t op2, size_t op3, size_t op4){
  return vnsrl_wx_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vnsrl(vuint16mf2_t op0, size_t op1, size_t op2){
  return vnsrl_wx_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vnsrl(vbool32_t op0, vuint8mf4_t op1, vuint16mf2_t op2, size_t op3, size_t op4){
  return vnsrl_wx_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vnsrl(vuint16mf4_t op0, size_t op1, size_t op2){
  return vnsrl_wx_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vnsrl(vbool64_t op0, vuint8mf8_t op1, vuint16mf4_t op2, size_t op3, size_t op4){
  return vnsrl_wx_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vnsrl(vuint32m2_t op0, size_t op1, size_t op2){
  return vnsrl_wx_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vnsrl(vbool16_t op0, vuint16m1_t op1, vuint32m2_t op2, size_t op3, size_t op4){
  return vnsrl_wx_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vnsrl(vuint32m4_t op0, size_t op1, size_t op2){
  return vnsrl_wx_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vnsrl(vbool8_t op0, vuint16m2_t op1, vuint32m4_t op2, size_t op3, size_t op4){
  return vnsrl_wx_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vnsrl(vuint32m8_t op0, size_t op1, size_t op2){
  return vnsrl_wx_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vnsrl(vbool4_t op0, vuint16m4_t op1, vuint32m8_t op2, size_t op3, size_t op4){
  return vnsrl_wx_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vnsrl(vuint32m1_t op0, size_t op1, size_t op2){
  return vnsrl_wx_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vnsrl(vbool32_t op0, vuint16mf2_t op1, vuint32m1_t op2, size_t op3, size_t op4){
  return vnsrl_wx_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vnsrl(vuint32mf2_t op0, size_t op1, size_t op2){
  return vnsrl_wx_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vnsrl(vbool64_t op0, vuint16mf4_t op1, vuint32mf2_t op2, size_t op3, size_t op4){
  return vnsrl_wx_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vnsrl(vuint64m2_t op0, size_t op1, size_t op2){
  return vnsrl_wx_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vnsrl(vbool32_t op0, vuint32m1_t op1, vuint64m2_t op2, size_t op3, size_t op4){
  return vnsrl_wx_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vnsrl(vuint64m4_t op0, size_t op1, size_t op2){
  return vnsrl_wx_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vnsrl(vbool16_t op0, vuint32m2_t op1, vuint64m4_t op2, size_t op3, size_t op4){
  return vnsrl_wx_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vnsrl(vuint64m8_t op0, size_t op1, size_t op2){
  return vnsrl_wx_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vnsrl(vbool8_t op0, vuint32m4_t op1, vuint64m8_t op2, size_t op3, size_t op4){
  return vnsrl_wx_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vnsrl(vuint64m1_t op0, size_t op1, size_t op2){
  return vnsrl_wx_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vnsrl(vbool64_t op0, vuint32mf2_t op1, vuint64m1_t op2, size_t op3, size_t op4){
  return vnsrl_wx_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vnsra(vint16m2_t op0, vuint8m1_t op1, size_t op2){
  return vnsra_wv_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vnsra(vbool8_t op0, vint8m1_t op1, vint16m2_t op2, vuint8m1_t op3, size_t op4){
  return vnsra_wv_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vnsra(vint16m4_t op0, vuint8m2_t op1, size_t op2){
  return vnsra_wv_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vnsra(vbool4_t op0, vint8m2_t op1, vint16m4_t op2, vuint8m2_t op3, size_t op4){
  return vnsra_wv_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vnsra(vint16m8_t op0, vuint8m4_t op1, size_t op2){
  return vnsra_wv_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vnsra(vbool2_t op0, vint8m4_t op1, vint16m8_t op2, vuint8m4_t op3, size_t op4){
  return vnsra_wv_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vnsra(vint16m1_t op0, vuint8mf2_t op1, size_t op2){
  return vnsra_wv_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vnsra(vbool16_t op0, vint8mf2_t op1, vint16m1_t op2, vuint8mf2_t op3, size_t op4){
  return vnsra_wv_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vnsra(vint16mf2_t op0, vuint8mf4_t op1, size_t op2){
  return vnsra_wv_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vnsra(vbool32_t op0, vint8mf4_t op1, vint16mf2_t op2, vuint8mf4_t op3, size_t op4){
  return vnsra_wv_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vnsra(vint16mf4_t op0, vuint8mf8_t op1, size_t op2){
  return vnsra_wv_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vnsra(vbool64_t op0, vint8mf8_t op1, vint16mf4_t op2, vuint8mf8_t op3, size_t op4){
  return vnsra_wv_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vnsra(vint32m2_t op0, vuint16m1_t op1, size_t op2){
  return vnsra_wv_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vnsra(vbool16_t op0, vint16m1_t op1, vint32m2_t op2, vuint16m1_t op3, size_t op4){
  return vnsra_wv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vnsra(vint32m4_t op0, vuint16m2_t op1, size_t op2){
  return vnsra_wv_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vnsra(vbool8_t op0, vint16m2_t op1, vint32m4_t op2, vuint16m2_t op3, size_t op4){
  return vnsra_wv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vnsra(vint32m8_t op0, vuint16m4_t op1, size_t op2){
  return vnsra_wv_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vnsra(vbool4_t op0, vint16m4_t op1, vint32m8_t op2, vuint16m4_t op3, size_t op4){
  return vnsra_wv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vnsra(vint32m1_t op0, vuint16mf2_t op1, size_t op2){
  return vnsra_wv_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vnsra(vbool32_t op0, vint16mf2_t op1, vint32m1_t op2, vuint16mf2_t op3, size_t op4){
  return vnsra_wv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vnsra(vint32mf2_t op0, vuint16mf4_t op1, size_t op2){
  return vnsra_wv_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vnsra(vbool64_t op0, vint16mf4_t op1, vint32mf2_t op2, vuint16mf4_t op3, size_t op4){
  return vnsra_wv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vnsra(vint64m2_t op0, vuint32m1_t op1, size_t op2){
  return vnsra_wv_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vnsra(vbool32_t op0, vint32m1_t op1, vint64m2_t op2, vuint32m1_t op3, size_t op4){
  return vnsra_wv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vnsra(vint64m4_t op0, vuint32m2_t op1, size_t op2){
  return vnsra_wv_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vnsra(vbool16_t op0, vint32m2_t op1, vint64m4_t op2, vuint32m2_t op3, size_t op4){
  return vnsra_wv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vnsra(vint64m8_t op0, vuint32m4_t op1, size_t op2){
  return vnsra_wv_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vnsra(vbool8_t op0, vint32m4_t op1, vint64m8_t op2, vuint32m4_t op3, size_t op4){
  return vnsra_wv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vnsra(vint64m1_t op0, vuint32mf2_t op1, size_t op2){
  return vnsra_wv_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vnsra(vbool64_t op0, vint32mf2_t op1, vint64m1_t op2, vuint32mf2_t op3, size_t op4){
  return vnsra_wv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vnsra(vint16m2_t op0, size_t op1, size_t op2){
  return vnsra_wx_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vnsra(vbool8_t op0, vint8m1_t op1, vint16m2_t op2, size_t op3, size_t op4){
  return vnsra_wx_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vnsra(vint16m4_t op0, size_t op1, size_t op2){
  return vnsra_wx_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vnsra(vbool4_t op0, vint8m2_t op1, vint16m4_t op2, size_t op3, size_t op4){
  return vnsra_wx_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vnsra(vint16m8_t op0, size_t op1, size_t op2){
  return vnsra_wx_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vnsra(vbool2_t op0, vint8m4_t op1, vint16m8_t op2, size_t op3, size_t op4){
  return vnsra_wx_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vnsra(vint16m1_t op0, size_t op1, size_t op2){
  return vnsra_wx_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vnsra(vbool16_t op0, vint8mf2_t op1, vint16m1_t op2, size_t op3, size_t op4){
  return vnsra_wx_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vnsra(vint16mf2_t op0, size_t op1, size_t op2){
  return vnsra_wx_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vnsra(vbool32_t op0, vint8mf4_t op1, vint16mf2_t op2, size_t op3, size_t op4){
  return vnsra_wx_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vnsra(vint16mf4_t op0, size_t op1, size_t op2){
  return vnsra_wx_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vnsra(vbool64_t op0, vint8mf8_t op1, vint16mf4_t op2, size_t op3, size_t op4){
  return vnsra_wx_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vnsra(vint32m2_t op0, size_t op1, size_t op2){
  return vnsra_wx_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vnsra(vbool16_t op0, vint16m1_t op1, vint32m2_t op2, size_t op3, size_t op4){
  return vnsra_wx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vnsra(vint32m4_t op0, size_t op1, size_t op2){
  return vnsra_wx_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vnsra(vbool8_t op0, vint16m2_t op1, vint32m4_t op2, size_t op3, size_t op4){
  return vnsra_wx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vnsra(vint32m8_t op0, size_t op1, size_t op2){
  return vnsra_wx_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vnsra(vbool4_t op0, vint16m4_t op1, vint32m8_t op2, size_t op3, size_t op4){
  return vnsra_wx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vnsra(vint32m1_t op0, size_t op1, size_t op2){
  return vnsra_wx_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vnsra(vbool32_t op0, vint16mf2_t op1, vint32m1_t op2, size_t op3, size_t op4){
  return vnsra_wx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vnsra(vint32mf2_t op0, size_t op1, size_t op2){
  return vnsra_wx_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vnsra(vbool64_t op0, vint16mf4_t op1, vint32mf2_t op2, size_t op3, size_t op4){
  return vnsra_wx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vnsra(vint64m2_t op0, size_t op1, size_t op2){
  return vnsra_wx_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vnsra(vbool32_t op0, vint32m1_t op1, vint64m2_t op2, size_t op3, size_t op4){
  return vnsra_wx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vnsra(vint64m4_t op0, size_t op1, size_t op2){
  return vnsra_wx_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vnsra(vbool16_t op0, vint32m2_t op1, vint64m4_t op2, size_t op3, size_t op4){
  return vnsra_wx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vnsra(vint64m8_t op0, size_t op1, size_t op2){
  return vnsra_wx_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vnsra(vbool8_t op0, vint32m4_t op1, vint64m8_t op2, size_t op3, size_t op4){
  return vnsra_wx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vnsra(vint64m1_t op0, size_t op1, size_t op2){
  return vnsra_wx_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vnsra(vbool64_t op0, vint32mf2_t op1, vint64m1_t op2, size_t op3, size_t op4){
  return vnsra_wx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmseq(vint8m1_t op0, vint8m1_t op1, size_t op2){
  return vmseq_vv_i8m1_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmseq(vbool8_t op0, vbool8_t op1, vint8m1_t op2, vint8m1_t op3, size_t op4){
  return vmseq_vv_i8m1_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmseq(vint8m2_t op0, vint8m2_t op1, size_t op2){
  return vmseq_vv_i8m2_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmseq(vbool4_t op0, vbool4_t op1, vint8m2_t op2, vint8m2_t op3, size_t op4){
  return vmseq_vv_i8m2_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmseq(vint8m4_t op0, vint8m4_t op1, size_t op2){
  return vmseq_vv_i8m4_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmseq(vbool2_t op0, vbool2_t op1, vint8m4_t op2, vint8m4_t op3, size_t op4){
  return vmseq_vv_i8m4_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool1_t vmseq(vint8m8_t op0, vint8m8_t op1, size_t op2){
  return vmseq_vv_i8m8_b1(op0, op1, op2);
}

__rvv_overloaded vbool1_t vmseq(vbool1_t op0, vbool1_t op1, vint8m8_t op2, vint8m8_t op3, size_t op4){
  return vmseq_vv_i8m8_b1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmseq(vint8mf2_t op0, vint8mf2_t op1, size_t op2){
  return vmseq_vv_i8mf2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmseq(vbool16_t op0, vbool16_t op1, vint8mf2_t op2, vint8mf2_t op3, size_t op4){
  return vmseq_vv_i8mf2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmseq(vint8mf4_t op0, vint8mf4_t op1, size_t op2){
  return vmseq_vv_i8mf4_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmseq(vbool32_t op0, vbool32_t op1, vint8mf4_t op2, vint8mf4_t op3, size_t op4){
  return vmseq_vv_i8mf4_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmseq(vint8mf8_t op0, vint8mf8_t op1, size_t op2){
  return vmseq_vv_i8mf8_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmseq(vbool64_t op0, vbool64_t op1, vint8mf8_t op2, vint8mf8_t op3, size_t op4){
  return vmseq_vv_i8mf8_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmseq(vint16m1_t op0, vint16m1_t op1, size_t op2){
  return vmseq_vv_i16m1_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmseq(vbool16_t op0, vbool16_t op1, vint16m1_t op2, vint16m1_t op3, size_t op4){
  return vmseq_vv_i16m1_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmseq(vint16m2_t op0, vint16m2_t op1, size_t op2){
  return vmseq_vv_i16m2_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmseq(vbool8_t op0, vbool8_t op1, vint16m2_t op2, vint16m2_t op3, size_t op4){
  return vmseq_vv_i16m2_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmseq(vint16m4_t op0, vint16m4_t op1, size_t op2){
  return vmseq_vv_i16m4_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmseq(vbool4_t op0, vbool4_t op1, vint16m4_t op2, vint16m4_t op3, size_t op4){
  return vmseq_vv_i16m4_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmseq(vint16m8_t op0, vint16m8_t op1, size_t op2){
  return vmseq_vv_i16m8_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmseq(vbool2_t op0, vbool2_t op1, vint16m8_t op2, vint16m8_t op3, size_t op4){
  return vmseq_vv_i16m8_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmseq(vint16mf2_t op0, vint16mf2_t op1, size_t op2){
  return vmseq_vv_i16mf2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmseq(vbool32_t op0, vbool32_t op1, vint16mf2_t op2, vint16mf2_t op3, size_t op4){
  return vmseq_vv_i16mf2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmseq(vint16mf4_t op0, vint16mf4_t op1, size_t op2){
  return vmseq_vv_i16mf4_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmseq(vbool64_t op0, vbool64_t op1, vint16mf4_t op2, vint16mf4_t op3, size_t op4){
  return vmseq_vv_i16mf4_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmseq(vint32m1_t op0, vint32m1_t op1, size_t op2){
  return vmseq_vv_i32m1_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmseq(vbool32_t op0, vbool32_t op1, vint32m1_t op2, vint32m1_t op3, size_t op4){
  return vmseq_vv_i32m1_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmseq(vint32m2_t op0, vint32m2_t op1, size_t op2){
  return vmseq_vv_i32m2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmseq(vbool16_t op0, vbool16_t op1, vint32m2_t op2, vint32m2_t op3, size_t op4){
  return vmseq_vv_i32m2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmseq(vint32m4_t op0, vint32m4_t op1, size_t op2){
  return vmseq_vv_i32m4_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmseq(vbool8_t op0, vbool8_t op1, vint32m4_t op2, vint32m4_t op3, size_t op4){
  return vmseq_vv_i32m4_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmseq(vint32m8_t op0, vint32m8_t op1, size_t op2){
  return vmseq_vv_i32m8_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmseq(vbool4_t op0, vbool4_t op1, vint32m8_t op2, vint32m8_t op3, size_t op4){
  return vmseq_vv_i32m8_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmseq(vint32mf2_t op0, vint32mf2_t op1, size_t op2){
  return vmseq_vv_i32mf2_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmseq(vbool64_t op0, vbool64_t op1, vint32mf2_t op2, vint32mf2_t op3, size_t op4){
  return vmseq_vv_i32mf2_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmseq(vint64m1_t op0, vint64m1_t op1, size_t op2){
  return vmseq_vv_i64m1_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmseq(vbool64_t op0, vbool64_t op1, vint64m1_t op2, vint64m1_t op3, size_t op4){
  return vmseq_vv_i64m1_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmseq(vint64m2_t op0, vint64m2_t op1, size_t op2){
  return vmseq_vv_i64m2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmseq(vbool32_t op0, vbool32_t op1, vint64m2_t op2, vint64m2_t op3, size_t op4){
  return vmseq_vv_i64m2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmseq(vint64m4_t op0, vint64m4_t op1, size_t op2){
  return vmseq_vv_i64m4_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmseq(vbool16_t op0, vbool16_t op1, vint64m4_t op2, vint64m4_t op3, size_t op4){
  return vmseq_vv_i64m4_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmseq(vint64m8_t op0, vint64m8_t op1, size_t op2){
  return vmseq_vv_i64m8_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmseq(vbool8_t op0, vbool8_t op1, vint64m8_t op2, vint64m8_t op3, size_t op4){
  return vmseq_vv_i64m8_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmseq(vint8m1_t op0, int8_t op1, size_t op2){
  return vmseq_vx_i8m1_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmseq(vbool8_t op0, vbool8_t op1, vint8m1_t op2, int8_t op3, size_t op4){
  return vmseq_vx_i8m1_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmseq(vint8m2_t op0, int8_t op1, size_t op2){
  return vmseq_vx_i8m2_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmseq(vbool4_t op0, vbool4_t op1, vint8m2_t op2, int8_t op3, size_t op4){
  return vmseq_vx_i8m2_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmseq(vint8m4_t op0, int8_t op1, size_t op2){
  return vmseq_vx_i8m4_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmseq(vbool2_t op0, vbool2_t op1, vint8m4_t op2, int8_t op3, size_t op4){
  return vmseq_vx_i8m4_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool1_t vmseq(vint8m8_t op0, int8_t op1, size_t op2){
  return vmseq_vx_i8m8_b1(op0, op1, op2);
}

__rvv_overloaded vbool1_t vmseq(vbool1_t op0, vbool1_t op1, vint8m8_t op2, int8_t op3, size_t op4){
  return vmseq_vx_i8m8_b1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmseq(vint8mf2_t op0, int8_t op1, size_t op2){
  return vmseq_vx_i8mf2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmseq(vbool16_t op0, vbool16_t op1, vint8mf2_t op2, int8_t op3, size_t op4){
  return vmseq_vx_i8mf2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmseq(vint8mf4_t op0, int8_t op1, size_t op2){
  return vmseq_vx_i8mf4_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmseq(vbool32_t op0, vbool32_t op1, vint8mf4_t op2, int8_t op3, size_t op4){
  return vmseq_vx_i8mf4_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmseq(vint8mf8_t op0, int8_t op1, size_t op2){
  return vmseq_vx_i8mf8_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmseq(vbool64_t op0, vbool64_t op1, vint8mf8_t op2, int8_t op3, size_t op4){
  return vmseq_vx_i8mf8_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmseq(vint16m1_t op0, int16_t op1, size_t op2){
  return vmseq_vx_i16m1_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmseq(vbool16_t op0, vbool16_t op1, vint16m1_t op2, int16_t op3, size_t op4){
  return vmseq_vx_i16m1_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmseq(vint16m2_t op0, int16_t op1, size_t op2){
  return vmseq_vx_i16m2_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmseq(vbool8_t op0, vbool8_t op1, vint16m2_t op2, int16_t op3, size_t op4){
  return vmseq_vx_i16m2_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmseq(vint16m4_t op0, int16_t op1, size_t op2){
  return vmseq_vx_i16m4_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmseq(vbool4_t op0, vbool4_t op1, vint16m4_t op2, int16_t op3, size_t op4){
  return vmseq_vx_i16m4_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmseq(vint16m8_t op0, int16_t op1, size_t op2){
  return vmseq_vx_i16m8_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmseq(vbool2_t op0, vbool2_t op1, vint16m8_t op2, int16_t op3, size_t op4){
  return vmseq_vx_i16m8_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmseq(vint16mf2_t op0, int16_t op1, size_t op2){
  return vmseq_vx_i16mf2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmseq(vbool32_t op0, vbool32_t op1, vint16mf2_t op2, int16_t op3, size_t op4){
  return vmseq_vx_i16mf2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmseq(vint16mf4_t op0, int16_t op1, size_t op2){
  return vmseq_vx_i16mf4_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmseq(vbool64_t op0, vbool64_t op1, vint16mf4_t op2, int16_t op3, size_t op4){
  return vmseq_vx_i16mf4_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmseq(vint32m1_t op0, int32_t op1, size_t op2){
  return vmseq_vx_i32m1_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmseq(vbool32_t op0, vbool32_t op1, vint32m1_t op2, int32_t op3, size_t op4){
  return vmseq_vx_i32m1_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmseq(vint32m2_t op0, int32_t op1, size_t op2){
  return vmseq_vx_i32m2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmseq(vbool16_t op0, vbool16_t op1, vint32m2_t op2, int32_t op3, size_t op4){
  return vmseq_vx_i32m2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmseq(vint32m4_t op0, int32_t op1, size_t op2){
  return vmseq_vx_i32m4_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmseq(vbool8_t op0, vbool8_t op1, vint32m4_t op2, int32_t op3, size_t op4){
  return vmseq_vx_i32m4_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmseq(vint32m8_t op0, int32_t op1, size_t op2){
  return vmseq_vx_i32m8_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmseq(vbool4_t op0, vbool4_t op1, vint32m8_t op2, int32_t op3, size_t op4){
  return vmseq_vx_i32m8_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmseq(vint32mf2_t op0, int32_t op1, size_t op2){
  return vmseq_vx_i32mf2_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmseq(vbool64_t op0, vbool64_t op1, vint32mf2_t op2, int32_t op3, size_t op4){
  return vmseq_vx_i32mf2_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmseq(vint64m1_t op0, int64_t op1, size_t op2){
  return vmseq_vx_i64m1_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmseq(vbool64_t op0, vbool64_t op1, vint64m1_t op2, int64_t op3, size_t op4){
  return vmseq_vx_i64m1_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmseq(vint64m2_t op0, int64_t op1, size_t op2){
  return vmseq_vx_i64m2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmseq(vbool32_t op0, vbool32_t op1, vint64m2_t op2, int64_t op3, size_t op4){
  return vmseq_vx_i64m2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmseq(vint64m4_t op0, int64_t op1, size_t op2){
  return vmseq_vx_i64m4_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmseq(vbool16_t op0, vbool16_t op1, vint64m4_t op2, int64_t op3, size_t op4){
  return vmseq_vx_i64m4_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmseq(vint64m8_t op0, int64_t op1, size_t op2){
  return vmseq_vx_i64m8_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmseq(vbool8_t op0, vbool8_t op1, vint64m8_t op2, int64_t op3, size_t op4){
  return vmseq_vx_i64m8_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmseq(vuint8m1_t op0, vuint8m1_t op1, size_t op2){
  return vmseq_vv_u8m1_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmseq(vbool8_t op0, vbool8_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vmseq_vv_u8m1_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmseq(vuint8m2_t op0, vuint8m2_t op1, size_t op2){
  return vmseq_vv_u8m2_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmseq(vbool4_t op0, vbool4_t op1, vuint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vmseq_vv_u8m2_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmseq(vuint8m4_t op0, vuint8m4_t op1, size_t op2){
  return vmseq_vv_u8m4_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmseq(vbool2_t op0, vbool2_t op1, vuint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vmseq_vv_u8m4_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool1_t vmseq(vuint8m8_t op0, vuint8m8_t op1, size_t op2){
  return vmseq_vv_u8m8_b1(op0, op1, op2);
}

__rvv_overloaded vbool1_t vmseq(vbool1_t op0, vbool1_t op1, vuint8m8_t op2, vuint8m8_t op3, size_t op4){
  return vmseq_vv_u8m8_b1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmseq(vuint8mf2_t op0, vuint8mf2_t op1, size_t op2){
  return vmseq_vv_u8mf2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmseq(vbool16_t op0, vbool16_t op1, vuint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vmseq_vv_u8mf2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmseq(vuint8mf4_t op0, vuint8mf4_t op1, size_t op2){
  return vmseq_vv_u8mf4_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmseq(vbool32_t op0, vbool32_t op1, vuint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vmseq_vv_u8mf4_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmseq(vuint8mf8_t op0, vuint8mf8_t op1, size_t op2){
  return vmseq_vv_u8mf8_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmseq(vbool64_t op0, vbool64_t op1, vuint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vmseq_vv_u8mf8_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmseq(vuint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vmseq_vv_u16m1_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmseq(vbool16_t op0, vbool16_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vmseq_vv_u16m1_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmseq(vuint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vmseq_vv_u16m2_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmseq(vbool8_t op0, vbool8_t op1, vuint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vmseq_vv_u16m2_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmseq(vuint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vmseq_vv_u16m4_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmseq(vbool4_t op0, vbool4_t op1, vuint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vmseq_vv_u16m4_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmseq(vuint16m8_t op0, vuint16m8_t op1, size_t op2){
  return vmseq_vv_u16m8_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmseq(vbool2_t op0, vbool2_t op1, vuint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vmseq_vv_u16m8_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmseq(vuint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vmseq_vv_u16mf2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmseq(vbool32_t op0, vbool32_t op1, vuint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vmseq_vv_u16mf2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmseq(vuint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vmseq_vv_u16mf4_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmseq(vbool64_t op0, vbool64_t op1, vuint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vmseq_vv_u16mf4_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmseq(vuint32m1_t op0, vuint32m1_t op1, size_t op2){
  return vmseq_vv_u32m1_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmseq(vbool32_t op0, vbool32_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vmseq_vv_u32m1_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmseq(vuint32m2_t op0, vuint32m2_t op1, size_t op2){
  return vmseq_vv_u32m2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmseq(vbool16_t op0, vbool16_t op1, vuint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vmseq_vv_u32m2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmseq(vuint32m4_t op0, vuint32m4_t op1, size_t op2){
  return vmseq_vv_u32m4_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmseq(vbool8_t op0, vbool8_t op1, vuint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vmseq_vv_u32m4_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmseq(vuint32m8_t op0, vuint32m8_t op1, size_t op2){
  return vmseq_vv_u32m8_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmseq(vbool4_t op0, vbool4_t op1, vuint32m8_t op2, vuint32m8_t op3, size_t op4){
  return vmseq_vv_u32m8_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmseq(vuint32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vmseq_vv_u32mf2_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmseq(vbool64_t op0, vbool64_t op1, vuint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vmseq_vv_u32mf2_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmseq(vuint64m1_t op0, vuint64m1_t op1, size_t op2){
  return vmseq_vv_u64m1_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmseq(vbool64_t op0, vbool64_t op1, vuint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vmseq_vv_u64m1_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmseq(vuint64m2_t op0, vuint64m2_t op1, size_t op2){
  return vmseq_vv_u64m2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmseq(vbool32_t op0, vbool32_t op1, vuint64m2_t op2, vuint64m2_t op3, size_t op4){
  return vmseq_vv_u64m2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmseq(vuint64m4_t op0, vuint64m4_t op1, size_t op2){
  return vmseq_vv_u64m4_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmseq(vbool16_t op0, vbool16_t op1, vuint64m4_t op2, vuint64m4_t op3, size_t op4){
  return vmseq_vv_u64m4_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmseq(vuint64m8_t op0, vuint64m8_t op1, size_t op2){
  return vmseq_vv_u64m8_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmseq(vbool8_t op0, vbool8_t op1, vuint64m8_t op2, vuint64m8_t op3, size_t op4){
  return vmseq_vv_u64m8_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmseq(vuint8m1_t op0, uint8_t op1, size_t op2){
  return vmseq_vx_u8m1_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmseq(vbool8_t op0, vbool8_t op1, vuint8m1_t op2, uint8_t op3, size_t op4){
  return vmseq_vx_u8m1_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmseq(vuint8m2_t op0, uint8_t op1, size_t op2){
  return vmseq_vx_u8m2_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmseq(vbool4_t op0, vbool4_t op1, vuint8m2_t op2, uint8_t op3, size_t op4){
  return vmseq_vx_u8m2_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmseq(vuint8m4_t op0, uint8_t op1, size_t op2){
  return vmseq_vx_u8m4_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmseq(vbool2_t op0, vbool2_t op1, vuint8m4_t op2, uint8_t op3, size_t op4){
  return vmseq_vx_u8m4_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool1_t vmseq(vuint8m8_t op0, uint8_t op1, size_t op2){
  return vmseq_vx_u8m8_b1(op0, op1, op2);
}

__rvv_overloaded vbool1_t vmseq(vbool1_t op0, vbool1_t op1, vuint8m8_t op2, uint8_t op3, size_t op4){
  return vmseq_vx_u8m8_b1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmseq(vuint8mf2_t op0, uint8_t op1, size_t op2){
  return vmseq_vx_u8mf2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmseq(vbool16_t op0, vbool16_t op1, vuint8mf2_t op2, uint8_t op3, size_t op4){
  return vmseq_vx_u8mf2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmseq(vuint8mf4_t op0, uint8_t op1, size_t op2){
  return vmseq_vx_u8mf4_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmseq(vbool32_t op0, vbool32_t op1, vuint8mf4_t op2, uint8_t op3, size_t op4){
  return vmseq_vx_u8mf4_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmseq(vuint8mf8_t op0, uint8_t op1, size_t op2){
  return vmseq_vx_u8mf8_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmseq(vbool64_t op0, vbool64_t op1, vuint8mf8_t op2, uint8_t op3, size_t op4){
  return vmseq_vx_u8mf8_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmseq(vuint16m1_t op0, uint16_t op1, size_t op2){
  return vmseq_vx_u16m1_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmseq(vbool16_t op0, vbool16_t op1, vuint16m1_t op2, uint16_t op3, size_t op4){
  return vmseq_vx_u16m1_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmseq(vuint16m2_t op0, uint16_t op1, size_t op2){
  return vmseq_vx_u16m2_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmseq(vbool8_t op0, vbool8_t op1, vuint16m2_t op2, uint16_t op3, size_t op4){
  return vmseq_vx_u16m2_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmseq(vuint16m4_t op0, uint16_t op1, size_t op2){
  return vmseq_vx_u16m4_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmseq(vbool4_t op0, vbool4_t op1, vuint16m4_t op2, uint16_t op3, size_t op4){
  return vmseq_vx_u16m4_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmseq(vuint16m8_t op0, uint16_t op1, size_t op2){
  return vmseq_vx_u16m8_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmseq(vbool2_t op0, vbool2_t op1, vuint16m8_t op2, uint16_t op3, size_t op4){
  return vmseq_vx_u16m8_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmseq(vuint16mf2_t op0, uint16_t op1, size_t op2){
  return vmseq_vx_u16mf2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmseq(vbool32_t op0, vbool32_t op1, vuint16mf2_t op2, uint16_t op3, size_t op4){
  return vmseq_vx_u16mf2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmseq(vuint16mf4_t op0, uint16_t op1, size_t op2){
  return vmseq_vx_u16mf4_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmseq(vbool64_t op0, vbool64_t op1, vuint16mf4_t op2, uint16_t op3, size_t op4){
  return vmseq_vx_u16mf4_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmseq(vuint32m1_t op0, uint32_t op1, size_t op2){
  return vmseq_vx_u32m1_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmseq(vbool32_t op0, vbool32_t op1, vuint32m1_t op2, uint32_t op3, size_t op4){
  return vmseq_vx_u32m1_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmseq(vuint32m2_t op0, uint32_t op1, size_t op2){
  return vmseq_vx_u32m2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmseq(vbool16_t op0, vbool16_t op1, vuint32m2_t op2, uint32_t op3, size_t op4){
  return vmseq_vx_u32m2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmseq(vuint32m4_t op0, uint32_t op1, size_t op2){
  return vmseq_vx_u32m4_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmseq(vbool8_t op0, vbool8_t op1, vuint32m4_t op2, uint32_t op3, size_t op4){
  return vmseq_vx_u32m4_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmseq(vuint32m8_t op0, uint32_t op1, size_t op2){
  return vmseq_vx_u32m8_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmseq(vbool4_t op0, vbool4_t op1, vuint32m8_t op2, uint32_t op3, size_t op4){
  return vmseq_vx_u32m8_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmseq(vuint32mf2_t op0, uint32_t op1, size_t op2){
  return vmseq_vx_u32mf2_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmseq(vbool64_t op0, vbool64_t op1, vuint32mf2_t op2, uint32_t op3, size_t op4){
  return vmseq_vx_u32mf2_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmseq(vuint64m1_t op0, uint64_t op1, size_t op2){
  return vmseq_vx_u64m1_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmseq(vbool64_t op0, vbool64_t op1, vuint64m1_t op2, uint64_t op3, size_t op4){
  return vmseq_vx_u64m1_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmseq(vuint64m2_t op0, uint64_t op1, size_t op2){
  return vmseq_vx_u64m2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmseq(vbool32_t op0, vbool32_t op1, vuint64m2_t op2, uint64_t op3, size_t op4){
  return vmseq_vx_u64m2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmseq(vuint64m4_t op0, uint64_t op1, size_t op2){
  return vmseq_vx_u64m4_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmseq(vbool16_t op0, vbool16_t op1, vuint64m4_t op2, uint64_t op3, size_t op4){
  return vmseq_vx_u64m4_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmseq(vuint64m8_t op0, uint64_t op1, size_t op2){
  return vmseq_vx_u64m8_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmseq(vbool8_t op0, vbool8_t op1, vuint64m8_t op2, uint64_t op3, size_t op4){
  return vmseq_vx_u64m8_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vle32(vbool32_t op0, vuint32m1_t op1, const uint32_t * op2, size_t op3){
  return vle32_v_u32m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m2_t vle32(vbool16_t op0, vuint32m2_t op1, const uint32_t * op2, size_t op3){
  return vle32_v_u32m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m4_t vle32(vbool8_t op0, vuint32m4_t op1, const uint32_t * op2, size_t op3){
  return vle32_v_u32m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m8_t vle32(vbool4_t op0, vuint32m8_t op1, const uint32_t * op2, size_t op3){
  return vle32_v_u32m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint32mf2_t vle32(vbool64_t op0, vuint32mf2_t op1, const uint32_t * op2, size_t op3){
  return vle32_v_u32mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmsne(vint8m1_t op0, vint8m1_t op1, size_t op2){
  return vmsne_vv_i8m1_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsne(vbool8_t op0, vbool8_t op1, vint8m1_t op2, vint8m1_t op3, size_t op4){
  return vmsne_vv_i8m1_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsne(vint8m2_t op0, vint8m2_t op1, size_t op2){
  return vmsne_vv_i8m2_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsne(vbool4_t op0, vbool4_t op1, vint8m2_t op2, vint8m2_t op3, size_t op4){
  return vmsne_vv_i8m2_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmsne(vint8m4_t op0, vint8m4_t op1, size_t op2){
  return vmsne_vv_i8m4_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmsne(vbool2_t op0, vbool2_t op1, vint8m4_t op2, vint8m4_t op3, size_t op4){
  return vmsne_vv_i8m4_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool1_t vmsne(vint8m8_t op0, vint8m8_t op1, size_t op2){
  return vmsne_vv_i8m8_b1(op0, op1, op2);
}

__rvv_overloaded vbool1_t vmsne(vbool1_t op0, vbool1_t op1, vint8m8_t op2, vint8m8_t op3, size_t op4){
  return vmsne_vv_i8m8_b1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsne(vint8mf2_t op0, vint8mf2_t op1, size_t op2){
  return vmsne_vv_i8mf2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsne(vbool16_t op0, vbool16_t op1, vint8mf2_t op2, vint8mf2_t op3, size_t op4){
  return vmsne_vv_i8mf2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsne(vint8mf4_t op0, vint8mf4_t op1, size_t op2){
  return vmsne_vv_i8mf4_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsne(vbool32_t op0, vbool32_t op1, vint8mf4_t op2, vint8mf4_t op3, size_t op4){
  return vmsne_vv_i8mf4_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsne(vint8mf8_t op0, vint8mf8_t op1, size_t op2){
  return vmsne_vv_i8mf8_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsne(vbool64_t op0, vbool64_t op1, vint8mf8_t op2, vint8mf8_t op3, size_t op4){
  return vmsne_vv_i8mf8_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsne(vint16m1_t op0, vint16m1_t op1, size_t op2){
  return vmsne_vv_i16m1_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsne(vbool16_t op0, vbool16_t op1, vint16m1_t op2, vint16m1_t op3, size_t op4){
  return vmsne_vv_i16m1_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsne(vint16m2_t op0, vint16m2_t op1, size_t op2){
  return vmsne_vv_i16m2_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsne(vbool8_t op0, vbool8_t op1, vint16m2_t op2, vint16m2_t op3, size_t op4){
  return vmsne_vv_i16m2_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsne(vint16m4_t op0, vint16m4_t op1, size_t op2){
  return vmsne_vv_i16m4_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsne(vbool4_t op0, vbool4_t op1, vint16m4_t op2, vint16m4_t op3, size_t op4){
  return vmsne_vv_i16m4_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmsne(vint16m8_t op0, vint16m8_t op1, size_t op2){
  return vmsne_vv_i16m8_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmsne(vbool2_t op0, vbool2_t op1, vint16m8_t op2, vint16m8_t op3, size_t op4){
  return vmsne_vv_i16m8_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsne(vint16mf2_t op0, vint16mf2_t op1, size_t op2){
  return vmsne_vv_i16mf2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsne(vbool32_t op0, vbool32_t op1, vint16mf2_t op2, vint16mf2_t op3, size_t op4){
  return vmsne_vv_i16mf2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsne(vint16mf4_t op0, vint16mf4_t op1, size_t op2){
  return vmsne_vv_i16mf4_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsne(vbool64_t op0, vbool64_t op1, vint16mf4_t op2, vint16mf4_t op3, size_t op4){
  return vmsne_vv_i16mf4_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsne(vint32m1_t op0, vint32m1_t op1, size_t op2){
  return vmsne_vv_i32m1_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsne(vbool32_t op0, vbool32_t op1, vint32m1_t op2, vint32m1_t op3, size_t op4){
  return vmsne_vv_i32m1_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsne(vint32m2_t op0, vint32m2_t op1, size_t op2){
  return vmsne_vv_i32m2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsne(vbool16_t op0, vbool16_t op1, vint32m2_t op2, vint32m2_t op3, size_t op4){
  return vmsne_vv_i32m2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsne(vint32m4_t op0, vint32m4_t op1, size_t op2){
  return vmsne_vv_i32m4_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsne(vbool8_t op0, vbool8_t op1, vint32m4_t op2, vint32m4_t op3, size_t op4){
  return vmsne_vv_i32m4_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsne(vint32m8_t op0, vint32m8_t op1, size_t op2){
  return vmsne_vv_i32m8_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsne(vbool4_t op0, vbool4_t op1, vint32m8_t op2, vint32m8_t op3, size_t op4){
  return vmsne_vv_i32m8_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsne(vint32mf2_t op0, vint32mf2_t op1, size_t op2){
  return vmsne_vv_i32mf2_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsne(vbool64_t op0, vbool64_t op1, vint32mf2_t op2, vint32mf2_t op3, size_t op4){
  return vmsne_vv_i32mf2_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsne(vint64m1_t op0, vint64m1_t op1, size_t op2){
  return vmsne_vv_i64m1_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsne(vbool64_t op0, vbool64_t op1, vint64m1_t op2, vint64m1_t op3, size_t op4){
  return vmsne_vv_i64m1_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsne(vint64m2_t op0, vint64m2_t op1, size_t op2){
  return vmsne_vv_i64m2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsne(vbool32_t op0, vbool32_t op1, vint64m2_t op2, vint64m2_t op3, size_t op4){
  return vmsne_vv_i64m2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsne(vint64m4_t op0, vint64m4_t op1, size_t op2){
  return vmsne_vv_i64m4_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsne(vbool16_t op0, vbool16_t op1, vint64m4_t op2, vint64m4_t op3, size_t op4){
  return vmsne_vv_i64m4_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsne(vint64m8_t op0, vint64m8_t op1, size_t op2){
  return vmsne_vv_i64m8_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsne(vbool8_t op0, vbool8_t op1, vint64m8_t op2, vint64m8_t op3, size_t op4){
  return vmsne_vv_i64m8_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsne(vint8m1_t op0, int8_t op1, size_t op2){
  return vmsne_vx_i8m1_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsne(vbool8_t op0, vbool8_t op1, vint8m1_t op2, int8_t op3, size_t op4){
  return vmsne_vx_i8m1_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsne(vint8m2_t op0, int8_t op1, size_t op2){
  return vmsne_vx_i8m2_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsne(vbool4_t op0, vbool4_t op1, vint8m2_t op2, int8_t op3, size_t op4){
  return vmsne_vx_i8m2_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmsne(vint8m4_t op0, int8_t op1, size_t op2){
  return vmsne_vx_i8m4_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmsne(vbool2_t op0, vbool2_t op1, vint8m4_t op2, int8_t op3, size_t op4){
  return vmsne_vx_i8m4_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool1_t vmsne(vint8m8_t op0, int8_t op1, size_t op2){
  return vmsne_vx_i8m8_b1(op0, op1, op2);
}

__rvv_overloaded vbool1_t vmsne(vbool1_t op0, vbool1_t op1, vint8m8_t op2, int8_t op3, size_t op4){
  return vmsne_vx_i8m8_b1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsne(vint8mf2_t op0, int8_t op1, size_t op2){
  return vmsne_vx_i8mf2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsne(vbool16_t op0, vbool16_t op1, vint8mf2_t op2, int8_t op3, size_t op4){
  return vmsne_vx_i8mf2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsne(vint8mf4_t op0, int8_t op1, size_t op2){
  return vmsne_vx_i8mf4_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsne(vbool32_t op0, vbool32_t op1, vint8mf4_t op2, int8_t op3, size_t op4){
  return vmsne_vx_i8mf4_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsne(vint8mf8_t op0, int8_t op1, size_t op2){
  return vmsne_vx_i8mf8_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsne(vbool64_t op0, vbool64_t op1, vint8mf8_t op2, int8_t op3, size_t op4){
  return vmsne_vx_i8mf8_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsne(vint16m1_t op0, int16_t op1, size_t op2){
  return vmsne_vx_i16m1_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsne(vbool16_t op0, vbool16_t op1, vint16m1_t op2, int16_t op3, size_t op4){
  return vmsne_vx_i16m1_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsne(vint16m2_t op0, int16_t op1, size_t op2){
  return vmsne_vx_i16m2_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsne(vbool8_t op0, vbool8_t op1, vint16m2_t op2, int16_t op3, size_t op4){
  return vmsne_vx_i16m2_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsne(vint16m4_t op0, int16_t op1, size_t op2){
  return vmsne_vx_i16m4_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsne(vbool4_t op0, vbool4_t op1, vint16m4_t op2, int16_t op3, size_t op4){
  return vmsne_vx_i16m4_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmsne(vint16m8_t op0, int16_t op1, size_t op2){
  return vmsne_vx_i16m8_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmsne(vbool2_t op0, vbool2_t op1, vint16m8_t op2, int16_t op3, size_t op4){
  return vmsne_vx_i16m8_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsne(vint16mf2_t op0, int16_t op1, size_t op2){
  return vmsne_vx_i16mf2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsne(vbool32_t op0, vbool32_t op1, vint16mf2_t op2, int16_t op3, size_t op4){
  return vmsne_vx_i16mf2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsne(vint16mf4_t op0, int16_t op1, size_t op2){
  return vmsne_vx_i16mf4_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsne(vbool64_t op0, vbool64_t op1, vint16mf4_t op2, int16_t op3, size_t op4){
  return vmsne_vx_i16mf4_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsne(vint32m1_t op0, int32_t op1, size_t op2){
  return vmsne_vx_i32m1_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsne(vbool32_t op0, vbool32_t op1, vint32m1_t op2, int32_t op3, size_t op4){
  return vmsne_vx_i32m1_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsne(vint32m2_t op0, int32_t op1, size_t op2){
  return vmsne_vx_i32m2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsne(vbool16_t op0, vbool16_t op1, vint32m2_t op2, int32_t op3, size_t op4){
  return vmsne_vx_i32m2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsne(vint32m4_t op0, int32_t op1, size_t op2){
  return vmsne_vx_i32m4_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsne(vbool8_t op0, vbool8_t op1, vint32m4_t op2, int32_t op3, size_t op4){
  return vmsne_vx_i32m4_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsne(vint32m8_t op0, int32_t op1, size_t op2){
  return vmsne_vx_i32m8_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsne(vbool4_t op0, vbool4_t op1, vint32m8_t op2, int32_t op3, size_t op4){
  return vmsne_vx_i32m8_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsne(vint32mf2_t op0, int32_t op1, size_t op2){
  return vmsne_vx_i32mf2_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsne(vbool64_t op0, vbool64_t op1, vint32mf2_t op2, int32_t op3, size_t op4){
  return vmsne_vx_i32mf2_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsne(vint64m1_t op0, int64_t op1, size_t op2){
  return vmsne_vx_i64m1_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsne(vbool64_t op0, vbool64_t op1, vint64m1_t op2, int64_t op3, size_t op4){
  return vmsne_vx_i64m1_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsne(vint64m2_t op0, int64_t op1, size_t op2){
  return vmsne_vx_i64m2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsne(vbool32_t op0, vbool32_t op1, vint64m2_t op2, int64_t op3, size_t op4){
  return vmsne_vx_i64m2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsne(vint64m4_t op0, int64_t op1, size_t op2){
  return vmsne_vx_i64m4_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsne(vbool16_t op0, vbool16_t op1, vint64m4_t op2, int64_t op3, size_t op4){
  return vmsne_vx_i64m4_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsne(vint64m8_t op0, int64_t op1, size_t op2){
  return vmsne_vx_i64m8_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsne(vbool8_t op0, vbool8_t op1, vint64m8_t op2, int64_t op3, size_t op4){
  return vmsne_vx_i64m8_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsne(vuint8m1_t op0, vuint8m1_t op1, size_t op2){
  return vmsne_vv_u8m1_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsne(vbool8_t op0, vbool8_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vmsne_vv_u8m1_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsne(vuint8m2_t op0, vuint8m2_t op1, size_t op2){
  return vmsne_vv_u8m2_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsne(vbool4_t op0, vbool4_t op1, vuint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vmsne_vv_u8m2_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmsne(vuint8m4_t op0, vuint8m4_t op1, size_t op2){
  return vmsne_vv_u8m4_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmsne(vbool2_t op0, vbool2_t op1, vuint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vmsne_vv_u8m4_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool1_t vmsne(vuint8m8_t op0, vuint8m8_t op1, size_t op2){
  return vmsne_vv_u8m8_b1(op0, op1, op2);
}

__rvv_overloaded vbool1_t vmsne(vbool1_t op0, vbool1_t op1, vuint8m8_t op2, vuint8m8_t op3, size_t op4){
  return vmsne_vv_u8m8_b1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsne(vuint8mf2_t op0, vuint8mf2_t op1, size_t op2){
  return vmsne_vv_u8mf2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsne(vbool16_t op0, vbool16_t op1, vuint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vmsne_vv_u8mf2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsne(vuint8mf4_t op0, vuint8mf4_t op1, size_t op2){
  return vmsne_vv_u8mf4_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsne(vbool32_t op0, vbool32_t op1, vuint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vmsne_vv_u8mf4_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsne(vuint8mf8_t op0, vuint8mf8_t op1, size_t op2){
  return vmsne_vv_u8mf8_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsne(vbool64_t op0, vbool64_t op1, vuint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vmsne_vv_u8mf8_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsne(vuint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vmsne_vv_u16m1_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsne(vbool16_t op0, vbool16_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vmsne_vv_u16m1_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsne(vuint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vmsne_vv_u16m2_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsne(vbool8_t op0, vbool8_t op1, vuint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vmsne_vv_u16m2_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsne(vuint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vmsne_vv_u16m4_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsne(vbool4_t op0, vbool4_t op1, vuint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vmsne_vv_u16m4_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmsne(vuint16m8_t op0, vuint16m8_t op1, size_t op2){
  return vmsne_vv_u16m8_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmsne(vbool2_t op0, vbool2_t op1, vuint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vmsne_vv_u16m8_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsne(vuint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vmsne_vv_u16mf2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsne(vbool32_t op0, vbool32_t op1, vuint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vmsne_vv_u16mf2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsne(vuint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vmsne_vv_u16mf4_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsne(vbool64_t op0, vbool64_t op1, vuint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vmsne_vv_u16mf4_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsne(vuint32m1_t op0, vuint32m1_t op1, size_t op2){
  return vmsne_vv_u32m1_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsne(vbool32_t op0, vbool32_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vmsne_vv_u32m1_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsne(vuint32m2_t op0, vuint32m2_t op1, size_t op2){
  return vmsne_vv_u32m2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsne(vbool16_t op0, vbool16_t op1, vuint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vmsne_vv_u32m2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsne(vuint32m4_t op0, vuint32m4_t op1, size_t op2){
  return vmsne_vv_u32m4_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsne(vbool8_t op0, vbool8_t op1, vuint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vmsne_vv_u32m4_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsne(vuint32m8_t op0, vuint32m8_t op1, size_t op2){
  return vmsne_vv_u32m8_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsne(vbool4_t op0, vbool4_t op1, vuint32m8_t op2, vuint32m8_t op3, size_t op4){
  return vmsne_vv_u32m8_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsne(vuint32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vmsne_vv_u32mf2_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsne(vbool64_t op0, vbool64_t op1, vuint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vmsne_vv_u32mf2_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsne(vuint64m1_t op0, vuint64m1_t op1, size_t op2){
  return vmsne_vv_u64m1_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsne(vbool64_t op0, vbool64_t op1, vuint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vmsne_vv_u64m1_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsne(vuint64m2_t op0, vuint64m2_t op1, size_t op2){
  return vmsne_vv_u64m2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsne(vbool32_t op0, vbool32_t op1, vuint64m2_t op2, vuint64m2_t op3, size_t op4){
  return vmsne_vv_u64m2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsne(vuint64m4_t op0, vuint64m4_t op1, size_t op2){
  return vmsne_vv_u64m4_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsne(vbool16_t op0, vbool16_t op1, vuint64m4_t op2, vuint64m4_t op3, size_t op4){
  return vmsne_vv_u64m4_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsne(vuint64m8_t op0, vuint64m8_t op1, size_t op2){
  return vmsne_vv_u64m8_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsne(vbool8_t op0, vbool8_t op1, vuint64m8_t op2, vuint64m8_t op3, size_t op4){
  return vmsne_vv_u64m8_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsne(vuint8m1_t op0, uint8_t op1, size_t op2){
  return vmsne_vx_u8m1_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsne(vbool8_t op0, vbool8_t op1, vuint8m1_t op2, uint8_t op3, size_t op4){
  return vmsne_vx_u8m1_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsne(vuint8m2_t op0, uint8_t op1, size_t op2){
  return vmsne_vx_u8m2_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsne(vbool4_t op0, vbool4_t op1, vuint8m2_t op2, uint8_t op3, size_t op4){
  return vmsne_vx_u8m2_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmsne(vuint8m4_t op0, uint8_t op1, size_t op2){
  return vmsne_vx_u8m4_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmsne(vbool2_t op0, vbool2_t op1, vuint8m4_t op2, uint8_t op3, size_t op4){
  return vmsne_vx_u8m4_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool1_t vmsne(vuint8m8_t op0, uint8_t op1, size_t op2){
  return vmsne_vx_u8m8_b1(op0, op1, op2);
}

__rvv_overloaded vbool1_t vmsne(vbool1_t op0, vbool1_t op1, vuint8m8_t op2, uint8_t op3, size_t op4){
  return vmsne_vx_u8m8_b1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsne(vuint8mf2_t op0, uint8_t op1, size_t op2){
  return vmsne_vx_u8mf2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsne(vbool16_t op0, vbool16_t op1, vuint8mf2_t op2, uint8_t op3, size_t op4){
  return vmsne_vx_u8mf2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsne(vuint8mf4_t op0, uint8_t op1, size_t op2){
  return vmsne_vx_u8mf4_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsne(vbool32_t op0, vbool32_t op1, vuint8mf4_t op2, uint8_t op3, size_t op4){
  return vmsne_vx_u8mf4_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsne(vuint8mf8_t op0, uint8_t op1, size_t op2){
  return vmsne_vx_u8mf8_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsne(vbool64_t op0, vbool64_t op1, vuint8mf8_t op2, uint8_t op3, size_t op4){
  return vmsne_vx_u8mf8_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsne(vuint16m1_t op0, uint16_t op1, size_t op2){
  return vmsne_vx_u16m1_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsne(vbool16_t op0, vbool16_t op1, vuint16m1_t op2, uint16_t op3, size_t op4){
  return vmsne_vx_u16m1_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsne(vuint16m2_t op0, uint16_t op1, size_t op2){
  return vmsne_vx_u16m2_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsne(vbool8_t op0, vbool8_t op1, vuint16m2_t op2, uint16_t op3, size_t op4){
  return vmsne_vx_u16m2_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsne(vuint16m4_t op0, uint16_t op1, size_t op2){
  return vmsne_vx_u16m4_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsne(vbool4_t op0, vbool4_t op1, vuint16m4_t op2, uint16_t op3, size_t op4){
  return vmsne_vx_u16m4_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmsne(vuint16m8_t op0, uint16_t op1, size_t op2){
  return vmsne_vx_u16m8_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmsne(vbool2_t op0, vbool2_t op1, vuint16m8_t op2, uint16_t op3, size_t op4){
  return vmsne_vx_u16m8_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsne(vuint16mf2_t op0, uint16_t op1, size_t op2){
  return vmsne_vx_u16mf2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsne(vbool32_t op0, vbool32_t op1, vuint16mf2_t op2, uint16_t op3, size_t op4){
  return vmsne_vx_u16mf2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsne(vuint16mf4_t op0, uint16_t op1, size_t op2){
  return vmsne_vx_u16mf4_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsne(vbool64_t op0, vbool64_t op1, vuint16mf4_t op2, uint16_t op3, size_t op4){
  return vmsne_vx_u16mf4_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsne(vuint32m1_t op0, uint32_t op1, size_t op2){
  return vmsne_vx_u32m1_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsne(vbool32_t op0, vbool32_t op1, vuint32m1_t op2, uint32_t op3, size_t op4){
  return vmsne_vx_u32m1_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsne(vuint32m2_t op0, uint32_t op1, size_t op2){
  return vmsne_vx_u32m2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsne(vbool16_t op0, vbool16_t op1, vuint32m2_t op2, uint32_t op3, size_t op4){
  return vmsne_vx_u32m2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsne(vuint32m4_t op0, uint32_t op1, size_t op2){
  return vmsne_vx_u32m4_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsne(vbool8_t op0, vbool8_t op1, vuint32m4_t op2, uint32_t op3, size_t op4){
  return vmsne_vx_u32m4_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsne(vuint32m8_t op0, uint32_t op1, size_t op2){
  return vmsne_vx_u32m8_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsne(vbool4_t op0, vbool4_t op1, vuint32m8_t op2, uint32_t op3, size_t op4){
  return vmsne_vx_u32m8_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsne(vuint32mf2_t op0, uint32_t op1, size_t op2){
  return vmsne_vx_u32mf2_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsne(vbool64_t op0, vbool64_t op1, vuint32mf2_t op2, uint32_t op3, size_t op4){
  return vmsne_vx_u32mf2_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsne(vuint64m1_t op0, uint64_t op1, size_t op2){
  return vmsne_vx_u64m1_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsne(vbool64_t op0, vbool64_t op1, vuint64m1_t op2, uint64_t op3, size_t op4){
  return vmsne_vx_u64m1_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsne(vuint64m2_t op0, uint64_t op1, size_t op2){
  return vmsne_vx_u64m2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsne(vbool32_t op0, vbool32_t op1, vuint64m2_t op2, uint64_t op3, size_t op4){
  return vmsne_vx_u64m2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsne(vuint64m4_t op0, uint64_t op1, size_t op2){
  return vmsne_vx_u64m4_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsne(vbool16_t op0, vbool16_t op1, vuint64m4_t op2, uint64_t op3, size_t op4){
  return vmsne_vx_u64m4_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsne(vuint64m8_t op0, uint64_t op1, size_t op2){
  return vmsne_vx_u64m8_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsne(vbool8_t op0, vbool8_t op1, vuint64m8_t op2, uint64_t op3, size_t op4){
  return vmsne_vx_u64m8_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsltu(vuint8m1_t op0, vuint8m1_t op1, size_t op2){
  return vmsltu_vv_u8m1_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsltu(vbool8_t op0, vbool8_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vmsltu_vv_u8m1_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsltu(vuint8m2_t op0, vuint8m2_t op1, size_t op2){
  return vmsltu_vv_u8m2_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsltu(vbool4_t op0, vbool4_t op1, vuint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vmsltu_vv_u8m2_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmsltu(vuint8m4_t op0, vuint8m4_t op1, size_t op2){
  return vmsltu_vv_u8m4_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmsltu(vbool2_t op0, vbool2_t op1, vuint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vmsltu_vv_u8m4_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool1_t vmsltu(vuint8m8_t op0, vuint8m8_t op1, size_t op2){
  return vmsltu_vv_u8m8_b1(op0, op1, op2);
}

__rvv_overloaded vbool1_t vmsltu(vbool1_t op0, vbool1_t op1, vuint8m8_t op2, vuint8m8_t op3, size_t op4){
  return vmsltu_vv_u8m8_b1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsltu(vuint8mf2_t op0, vuint8mf2_t op1, size_t op2){
  return vmsltu_vv_u8mf2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsltu(vbool16_t op0, vbool16_t op1, vuint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vmsltu_vv_u8mf2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsltu(vuint8mf4_t op0, vuint8mf4_t op1, size_t op2){
  return vmsltu_vv_u8mf4_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsltu(vbool32_t op0, vbool32_t op1, vuint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vmsltu_vv_u8mf4_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsltu(vuint8mf8_t op0, vuint8mf8_t op1, size_t op2){
  return vmsltu_vv_u8mf8_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsltu(vbool64_t op0, vbool64_t op1, vuint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vmsltu_vv_u8mf8_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsltu(vuint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vmsltu_vv_u16m1_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsltu(vbool16_t op0, vbool16_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vmsltu_vv_u16m1_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsltu(vuint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vmsltu_vv_u16m2_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsltu(vbool8_t op0, vbool8_t op1, vuint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vmsltu_vv_u16m2_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsltu(vuint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vmsltu_vv_u16m4_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsltu(vbool4_t op0, vbool4_t op1, vuint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vmsltu_vv_u16m4_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmsltu(vuint16m8_t op0, vuint16m8_t op1, size_t op2){
  return vmsltu_vv_u16m8_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmsltu(vbool2_t op0, vbool2_t op1, vuint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vmsltu_vv_u16m8_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsltu(vuint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vmsltu_vv_u16mf2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsltu(vbool32_t op0, vbool32_t op1, vuint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vmsltu_vv_u16mf2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsltu(vuint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vmsltu_vv_u16mf4_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsltu(vbool64_t op0, vbool64_t op1, vuint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vmsltu_vv_u16mf4_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsltu(vuint32m1_t op0, vuint32m1_t op1, size_t op2){
  return vmsltu_vv_u32m1_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsltu(vbool32_t op0, vbool32_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vmsltu_vv_u32m1_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsltu(vuint32m2_t op0, vuint32m2_t op1, size_t op2){
  return vmsltu_vv_u32m2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsltu(vbool16_t op0, vbool16_t op1, vuint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vmsltu_vv_u32m2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsltu(vuint32m4_t op0, vuint32m4_t op1, size_t op2){
  return vmsltu_vv_u32m4_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsltu(vbool8_t op0, vbool8_t op1, vuint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vmsltu_vv_u32m4_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsltu(vuint32m8_t op0, vuint32m8_t op1, size_t op2){
  return vmsltu_vv_u32m8_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsltu(vbool4_t op0, vbool4_t op1, vuint32m8_t op2, vuint32m8_t op3, size_t op4){
  return vmsltu_vv_u32m8_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsltu(vuint32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vmsltu_vv_u32mf2_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsltu(vbool64_t op0, vbool64_t op1, vuint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vmsltu_vv_u32mf2_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsltu(vuint64m1_t op0, vuint64m1_t op1, size_t op2){
  return vmsltu_vv_u64m1_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsltu(vbool64_t op0, vbool64_t op1, vuint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vmsltu_vv_u64m1_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsltu(vuint64m2_t op0, vuint64m2_t op1, size_t op2){
  return vmsltu_vv_u64m2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsltu(vbool32_t op0, vbool32_t op1, vuint64m2_t op2, vuint64m2_t op3, size_t op4){
  return vmsltu_vv_u64m2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsltu(vuint64m4_t op0, vuint64m4_t op1, size_t op2){
  return vmsltu_vv_u64m4_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsltu(vbool16_t op0, vbool16_t op1, vuint64m4_t op2, vuint64m4_t op3, size_t op4){
  return vmsltu_vv_u64m4_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsltu(vuint64m8_t op0, vuint64m8_t op1, size_t op2){
  return vmsltu_vv_u64m8_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsltu(vbool8_t op0, vbool8_t op1, vuint64m8_t op2, vuint64m8_t op3, size_t op4){
  return vmsltu_vv_u64m8_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsltu(vuint8m1_t op0, uint8_t op1, size_t op2){
  return vmsltu_vx_u8m1_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsltu(vbool8_t op0, vbool8_t op1, vuint8m1_t op2, uint8_t op3, size_t op4){
  return vmsltu_vx_u8m1_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsltu(vuint8m2_t op0, uint8_t op1, size_t op2){
  return vmsltu_vx_u8m2_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsltu(vbool4_t op0, vbool4_t op1, vuint8m2_t op2, uint8_t op3, size_t op4){
  return vmsltu_vx_u8m2_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmsltu(vuint8m4_t op0, uint8_t op1, size_t op2){
  return vmsltu_vx_u8m4_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmsltu(vbool2_t op0, vbool2_t op1, vuint8m4_t op2, uint8_t op3, size_t op4){
  return vmsltu_vx_u8m4_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool1_t vmsltu(vuint8m8_t op0, uint8_t op1, size_t op2){
  return vmsltu_vx_u8m8_b1(op0, op1, op2);
}

__rvv_overloaded vbool1_t vmsltu(vbool1_t op0, vbool1_t op1, vuint8m8_t op2, uint8_t op3, size_t op4){
  return vmsltu_vx_u8m8_b1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsltu(vuint8mf2_t op0, uint8_t op1, size_t op2){
  return vmsltu_vx_u8mf2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsltu(vbool16_t op0, vbool16_t op1, vuint8mf2_t op2, uint8_t op3, size_t op4){
  return vmsltu_vx_u8mf2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsltu(vuint8mf4_t op0, uint8_t op1, size_t op2){
  return vmsltu_vx_u8mf4_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsltu(vbool32_t op0, vbool32_t op1, vuint8mf4_t op2, uint8_t op3, size_t op4){
  return vmsltu_vx_u8mf4_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsltu(vuint8mf8_t op0, uint8_t op1, size_t op2){
  return vmsltu_vx_u8mf8_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsltu(vbool64_t op0, vbool64_t op1, vuint8mf8_t op2, uint8_t op3, size_t op4){
  return vmsltu_vx_u8mf8_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsltu(vuint16m1_t op0, uint16_t op1, size_t op2){
  return vmsltu_vx_u16m1_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsltu(vbool16_t op0, vbool16_t op1, vuint16m1_t op2, uint16_t op3, size_t op4){
  return vmsltu_vx_u16m1_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsltu(vuint16m2_t op0, uint16_t op1, size_t op2){
  return vmsltu_vx_u16m2_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsltu(vbool8_t op0, vbool8_t op1, vuint16m2_t op2, uint16_t op3, size_t op4){
  return vmsltu_vx_u16m2_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsltu(vuint16m4_t op0, uint16_t op1, size_t op2){
  return vmsltu_vx_u16m4_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsltu(vbool4_t op0, vbool4_t op1, vuint16m4_t op2, uint16_t op3, size_t op4){
  return vmsltu_vx_u16m4_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmsltu(vuint16m8_t op0, uint16_t op1, size_t op2){
  return vmsltu_vx_u16m8_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmsltu(vbool2_t op0, vbool2_t op1, vuint16m8_t op2, uint16_t op3, size_t op4){
  return vmsltu_vx_u16m8_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsltu(vuint16mf2_t op0, uint16_t op1, size_t op2){
  return vmsltu_vx_u16mf2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsltu(vbool32_t op0, vbool32_t op1, vuint16mf2_t op2, uint16_t op3, size_t op4){
  return vmsltu_vx_u16mf2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsltu(vuint16mf4_t op0, uint16_t op1, size_t op2){
  return vmsltu_vx_u16mf4_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsltu(vbool64_t op0, vbool64_t op1, vuint16mf4_t op2, uint16_t op3, size_t op4){
  return vmsltu_vx_u16mf4_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsltu(vuint32m1_t op0, uint32_t op1, size_t op2){
  return vmsltu_vx_u32m1_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsltu(vbool32_t op0, vbool32_t op1, vuint32m1_t op2, uint32_t op3, size_t op4){
  return vmsltu_vx_u32m1_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsltu(vuint32m2_t op0, uint32_t op1, size_t op2){
  return vmsltu_vx_u32m2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsltu(vbool16_t op0, vbool16_t op1, vuint32m2_t op2, uint32_t op3, size_t op4){
  return vmsltu_vx_u32m2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsltu(vuint32m4_t op0, uint32_t op1, size_t op2){
  return vmsltu_vx_u32m4_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsltu(vbool8_t op0, vbool8_t op1, vuint32m4_t op2, uint32_t op3, size_t op4){
  return vmsltu_vx_u32m4_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsltu(vuint32m8_t op0, uint32_t op1, size_t op2){
  return vmsltu_vx_u32m8_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsltu(vbool4_t op0, vbool4_t op1, vuint32m8_t op2, uint32_t op3, size_t op4){
  return vmsltu_vx_u32m8_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsltu(vuint32mf2_t op0, uint32_t op1, size_t op2){
  return vmsltu_vx_u32mf2_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsltu(vbool64_t op0, vbool64_t op1, vuint32mf2_t op2, uint32_t op3, size_t op4){
  return vmsltu_vx_u32mf2_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsltu(vuint64m1_t op0, uint64_t op1, size_t op2){
  return vmsltu_vx_u64m1_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsltu(vbool64_t op0, vbool64_t op1, vuint64m1_t op2, uint64_t op3, size_t op4){
  return vmsltu_vx_u64m1_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsltu(vuint64m2_t op0, uint64_t op1, size_t op2){
  return vmsltu_vx_u64m2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsltu(vbool32_t op0, vbool32_t op1, vuint64m2_t op2, uint64_t op3, size_t op4){
  return vmsltu_vx_u64m2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsltu(vuint64m4_t op0, uint64_t op1, size_t op2){
  return vmsltu_vx_u64m4_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsltu(vbool16_t op0, vbool16_t op1, vuint64m4_t op2, uint64_t op3, size_t op4){
  return vmsltu_vx_u64m4_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsltu(vuint64m8_t op0, uint64_t op1, size_t op2){
  return vmsltu_vx_u64m8_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsltu(vbool8_t op0, vbool8_t op1, vuint64m8_t op2, uint64_t op3, size_t op4){
  return vmsltu_vx_u64m8_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmslt(vint8m1_t op0, vint8m1_t op1, size_t op2){
  return vmslt_vv_i8m1_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmslt(vbool8_t op0, vbool8_t op1, vint8m1_t op2, vint8m1_t op3, size_t op4){
  return vmslt_vv_i8m1_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmslt(vint8m2_t op0, vint8m2_t op1, size_t op2){
  return vmslt_vv_i8m2_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmslt(vbool4_t op0, vbool4_t op1, vint8m2_t op2, vint8m2_t op3, size_t op4){
  return vmslt_vv_i8m2_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmslt(vint8m4_t op0, vint8m4_t op1, size_t op2){
  return vmslt_vv_i8m4_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmslt(vbool2_t op0, vbool2_t op1, vint8m4_t op2, vint8m4_t op3, size_t op4){
  return vmslt_vv_i8m4_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool1_t vmslt(vint8m8_t op0, vint8m8_t op1, size_t op2){
  return vmslt_vv_i8m8_b1(op0, op1, op2);
}

__rvv_overloaded vbool1_t vmslt(vbool1_t op0, vbool1_t op1, vint8m8_t op2, vint8m8_t op3, size_t op4){
  return vmslt_vv_i8m8_b1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmslt(vint8mf2_t op0, vint8mf2_t op1, size_t op2){
  return vmslt_vv_i8mf2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmslt(vbool16_t op0, vbool16_t op1, vint8mf2_t op2, vint8mf2_t op3, size_t op4){
  return vmslt_vv_i8mf2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmslt(vint8mf4_t op0, vint8mf4_t op1, size_t op2){
  return vmslt_vv_i8mf4_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmslt(vbool32_t op0, vbool32_t op1, vint8mf4_t op2, vint8mf4_t op3, size_t op4){
  return vmslt_vv_i8mf4_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmslt(vint8mf8_t op0, vint8mf8_t op1, size_t op2){
  return vmslt_vv_i8mf8_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmslt(vbool64_t op0, vbool64_t op1, vint8mf8_t op2, vint8mf8_t op3, size_t op4){
  return vmslt_vv_i8mf8_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmslt(vint16m1_t op0, vint16m1_t op1, size_t op2){
  return vmslt_vv_i16m1_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmslt(vbool16_t op0, vbool16_t op1, vint16m1_t op2, vint16m1_t op3, size_t op4){
  return vmslt_vv_i16m1_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmslt(vint16m2_t op0, vint16m2_t op1, size_t op2){
  return vmslt_vv_i16m2_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmslt(vbool8_t op0, vbool8_t op1, vint16m2_t op2, vint16m2_t op3, size_t op4){
  return vmslt_vv_i16m2_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmslt(vint16m4_t op0, vint16m4_t op1, size_t op2){
  return vmslt_vv_i16m4_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmslt(vbool4_t op0, vbool4_t op1, vint16m4_t op2, vint16m4_t op3, size_t op4){
  return vmslt_vv_i16m4_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmslt(vint16m8_t op0, vint16m8_t op1, size_t op2){
  return vmslt_vv_i16m8_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmslt(vbool2_t op0, vbool2_t op1, vint16m8_t op2, vint16m8_t op3, size_t op4){
  return vmslt_vv_i16m8_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmslt(vint16mf2_t op0, vint16mf2_t op1, size_t op2){
  return vmslt_vv_i16mf2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmslt(vbool32_t op0, vbool32_t op1, vint16mf2_t op2, vint16mf2_t op3, size_t op4){
  return vmslt_vv_i16mf2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmslt(vint16mf4_t op0, vint16mf4_t op1, size_t op2){
  return vmslt_vv_i16mf4_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmslt(vbool64_t op0, vbool64_t op1, vint16mf4_t op2, vint16mf4_t op3, size_t op4){
  return vmslt_vv_i16mf4_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmslt(vint32m1_t op0, vint32m1_t op1, size_t op2){
  return vmslt_vv_i32m1_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmslt(vbool32_t op0, vbool32_t op1, vint32m1_t op2, vint32m1_t op3, size_t op4){
  return vmslt_vv_i32m1_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmslt(vint32m2_t op0, vint32m2_t op1, size_t op2){
  return vmslt_vv_i32m2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmslt(vbool16_t op0, vbool16_t op1, vint32m2_t op2, vint32m2_t op3, size_t op4){
  return vmslt_vv_i32m2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmslt(vint32m4_t op0, vint32m4_t op1, size_t op2){
  return vmslt_vv_i32m4_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmslt(vbool8_t op0, vbool8_t op1, vint32m4_t op2, vint32m4_t op3, size_t op4){
  return vmslt_vv_i32m4_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmslt(vint32m8_t op0, vint32m8_t op1, size_t op2){
  return vmslt_vv_i32m8_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmslt(vbool4_t op0, vbool4_t op1, vint32m8_t op2, vint32m8_t op3, size_t op4){
  return vmslt_vv_i32m8_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmslt(vint32mf2_t op0, vint32mf2_t op1, size_t op2){
  return vmslt_vv_i32mf2_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmslt(vbool64_t op0, vbool64_t op1, vint32mf2_t op2, vint32mf2_t op3, size_t op4){
  return vmslt_vv_i32mf2_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmslt(vint64m1_t op0, vint64m1_t op1, size_t op2){
  return vmslt_vv_i64m1_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmslt(vbool64_t op0, vbool64_t op1, vint64m1_t op2, vint64m1_t op3, size_t op4){
  return vmslt_vv_i64m1_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmslt(vint64m2_t op0, vint64m2_t op1, size_t op2){
  return vmslt_vv_i64m2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmslt(vbool32_t op0, vbool32_t op1, vint64m2_t op2, vint64m2_t op3, size_t op4){
  return vmslt_vv_i64m2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmslt(vint64m4_t op0, vint64m4_t op1, size_t op2){
  return vmslt_vv_i64m4_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmslt(vbool16_t op0, vbool16_t op1, vint64m4_t op2, vint64m4_t op3, size_t op4){
  return vmslt_vv_i64m4_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmslt(vint64m8_t op0, vint64m8_t op1, size_t op2){
  return vmslt_vv_i64m8_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmslt(vbool8_t op0, vbool8_t op1, vint64m8_t op2, vint64m8_t op3, size_t op4){
  return vmslt_vv_i64m8_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmslt(vint8m1_t op0, int8_t op1, size_t op2){
  return vmslt_vx_i8m1_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmslt(vbool8_t op0, vbool8_t op1, vint8m1_t op2, int8_t op3, size_t op4){
  return vmslt_vx_i8m1_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmslt(vint8m2_t op0, int8_t op1, size_t op2){
  return vmslt_vx_i8m2_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmslt(vbool4_t op0, vbool4_t op1, vint8m2_t op2, int8_t op3, size_t op4){
  return vmslt_vx_i8m2_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmslt(vint8m4_t op0, int8_t op1, size_t op2){
  return vmslt_vx_i8m4_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmslt(vbool2_t op0, vbool2_t op1, vint8m4_t op2, int8_t op3, size_t op4){
  return vmslt_vx_i8m4_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool1_t vmslt(vint8m8_t op0, int8_t op1, size_t op2){
  return vmslt_vx_i8m8_b1(op0, op1, op2);
}

__rvv_overloaded vbool1_t vmslt(vbool1_t op0, vbool1_t op1, vint8m8_t op2, int8_t op3, size_t op4){
  return vmslt_vx_i8m8_b1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmslt(vint8mf2_t op0, int8_t op1, size_t op2){
  return vmslt_vx_i8mf2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmslt(vbool16_t op0, vbool16_t op1, vint8mf2_t op2, int8_t op3, size_t op4){
  return vmslt_vx_i8mf2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmslt(vint8mf4_t op0, int8_t op1, size_t op2){
  return vmslt_vx_i8mf4_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmslt(vbool32_t op0, vbool32_t op1, vint8mf4_t op2, int8_t op3, size_t op4){
  return vmslt_vx_i8mf4_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmslt(vint8mf8_t op0, int8_t op1, size_t op2){
  return vmslt_vx_i8mf8_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmslt(vbool64_t op0, vbool64_t op1, vint8mf8_t op2, int8_t op3, size_t op4){
  return vmslt_vx_i8mf8_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmslt(vint16m1_t op0, int16_t op1, size_t op2){
  return vmslt_vx_i16m1_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmslt(vbool16_t op0, vbool16_t op1, vint16m1_t op2, int16_t op3, size_t op4){
  return vmslt_vx_i16m1_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmslt(vint16m2_t op0, int16_t op1, size_t op2){
  return vmslt_vx_i16m2_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmslt(vbool8_t op0, vbool8_t op1, vint16m2_t op2, int16_t op3, size_t op4){
  return vmslt_vx_i16m2_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmslt(vint16m4_t op0, int16_t op1, size_t op2){
  return vmslt_vx_i16m4_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmslt(vbool4_t op0, vbool4_t op1, vint16m4_t op2, int16_t op3, size_t op4){
  return vmslt_vx_i16m4_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmslt(vint16m8_t op0, int16_t op1, size_t op2){
  return vmslt_vx_i16m8_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmslt(vbool2_t op0, vbool2_t op1, vint16m8_t op2, int16_t op3, size_t op4){
  return vmslt_vx_i16m8_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmslt(vint16mf2_t op0, int16_t op1, size_t op2){
  return vmslt_vx_i16mf2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmslt(vbool32_t op0, vbool32_t op1, vint16mf2_t op2, int16_t op3, size_t op4){
  return vmslt_vx_i16mf2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmslt(vint16mf4_t op0, int16_t op1, size_t op2){
  return vmslt_vx_i16mf4_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmslt(vbool64_t op0, vbool64_t op1, vint16mf4_t op2, int16_t op3, size_t op4){
  return vmslt_vx_i16mf4_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmslt(vint32m1_t op0, int32_t op1, size_t op2){
  return vmslt_vx_i32m1_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmslt(vbool32_t op0, vbool32_t op1, vint32m1_t op2, int32_t op3, size_t op4){
  return vmslt_vx_i32m1_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmslt(vint32m2_t op0, int32_t op1, size_t op2){
  return vmslt_vx_i32m2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmslt(vbool16_t op0, vbool16_t op1, vint32m2_t op2, int32_t op3, size_t op4){
  return vmslt_vx_i32m2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmslt(vint32m4_t op0, int32_t op1, size_t op2){
  return vmslt_vx_i32m4_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmslt(vbool8_t op0, vbool8_t op1, vint32m4_t op2, int32_t op3, size_t op4){
  return vmslt_vx_i32m4_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmslt(vint32m8_t op0, int32_t op1, size_t op2){
  return vmslt_vx_i32m8_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmslt(vbool4_t op0, vbool4_t op1, vint32m8_t op2, int32_t op3, size_t op4){
  return vmslt_vx_i32m8_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmslt(vint32mf2_t op0, int32_t op1, size_t op2){
  return vmslt_vx_i32mf2_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmslt(vbool64_t op0, vbool64_t op1, vint32mf2_t op2, int32_t op3, size_t op4){
  return vmslt_vx_i32mf2_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmslt(vint64m1_t op0, int64_t op1, size_t op2){
  return vmslt_vx_i64m1_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmslt(vbool64_t op0, vbool64_t op1, vint64m1_t op2, int64_t op3, size_t op4){
  return vmslt_vx_i64m1_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmslt(vint64m2_t op0, int64_t op1, size_t op2){
  return vmslt_vx_i64m2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmslt(vbool32_t op0, vbool32_t op1, vint64m2_t op2, int64_t op3, size_t op4){
  return vmslt_vx_i64m2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmslt(vint64m4_t op0, int64_t op1, size_t op2){
  return vmslt_vx_i64m4_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmslt(vbool16_t op0, vbool16_t op1, vint64m4_t op2, int64_t op3, size_t op4){
  return vmslt_vx_i64m4_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmslt(vint64m8_t op0, int64_t op1, size_t op2){
  return vmslt_vx_i64m8_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmslt(vbool8_t op0, vbool8_t op1, vint64m8_t op2, int64_t op3, size_t op4){
  return vmslt_vx_i64m8_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsleu(vuint8m1_t op0, vuint8m1_t op1, size_t op2){
  return vmsleu_vv_u8m1_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsleu(vbool8_t op0, vbool8_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vmsleu_vv_u8m1_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsleu(vuint8m2_t op0, vuint8m2_t op1, size_t op2){
  return vmsleu_vv_u8m2_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsleu(vbool4_t op0, vbool4_t op1, vuint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vmsleu_vv_u8m2_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmsleu(vuint8m4_t op0, vuint8m4_t op1, size_t op2){
  return vmsleu_vv_u8m4_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmsleu(vbool2_t op0, vbool2_t op1, vuint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vmsleu_vv_u8m4_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool1_t vmsleu(vuint8m8_t op0, vuint8m8_t op1, size_t op2){
  return vmsleu_vv_u8m8_b1(op0, op1, op2);
}

__rvv_overloaded vbool1_t vmsleu(vbool1_t op0, vbool1_t op1, vuint8m8_t op2, vuint8m8_t op3, size_t op4){
  return vmsleu_vv_u8m8_b1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsleu(vuint8mf2_t op0, vuint8mf2_t op1, size_t op2){
  return vmsleu_vv_u8mf2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsleu(vbool16_t op0, vbool16_t op1, vuint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vmsleu_vv_u8mf2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsleu(vuint8mf4_t op0, vuint8mf4_t op1, size_t op2){
  return vmsleu_vv_u8mf4_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsleu(vbool32_t op0, vbool32_t op1, vuint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vmsleu_vv_u8mf4_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsleu(vuint8mf8_t op0, vuint8mf8_t op1, size_t op2){
  return vmsleu_vv_u8mf8_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsleu(vbool64_t op0, vbool64_t op1, vuint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vmsleu_vv_u8mf8_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsleu(vuint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vmsleu_vv_u16m1_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsleu(vbool16_t op0, vbool16_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vmsleu_vv_u16m1_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsleu(vuint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vmsleu_vv_u16m2_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsleu(vbool8_t op0, vbool8_t op1, vuint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vmsleu_vv_u16m2_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsleu(vuint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vmsleu_vv_u16m4_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsleu(vbool4_t op0, vbool4_t op1, vuint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vmsleu_vv_u16m4_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmsleu(vuint16m8_t op0, vuint16m8_t op1, size_t op2){
  return vmsleu_vv_u16m8_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmsleu(vbool2_t op0, vbool2_t op1, vuint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vmsleu_vv_u16m8_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsleu(vuint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vmsleu_vv_u16mf2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsleu(vbool32_t op0, vbool32_t op1, vuint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vmsleu_vv_u16mf2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsleu(vuint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vmsleu_vv_u16mf4_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsleu(vbool64_t op0, vbool64_t op1, vuint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vmsleu_vv_u16mf4_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsleu(vuint32m1_t op0, vuint32m1_t op1, size_t op2){
  return vmsleu_vv_u32m1_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsleu(vbool32_t op0, vbool32_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vmsleu_vv_u32m1_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsleu(vuint32m2_t op0, vuint32m2_t op1, size_t op2){
  return vmsleu_vv_u32m2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsleu(vbool16_t op0, vbool16_t op1, vuint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vmsleu_vv_u32m2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsleu(vuint32m4_t op0, vuint32m4_t op1, size_t op2){
  return vmsleu_vv_u32m4_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsleu(vbool8_t op0, vbool8_t op1, vuint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vmsleu_vv_u32m4_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsleu(vuint32m8_t op0, vuint32m8_t op1, size_t op2){
  return vmsleu_vv_u32m8_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsleu(vbool4_t op0, vbool4_t op1, vuint32m8_t op2, vuint32m8_t op3, size_t op4){
  return vmsleu_vv_u32m8_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsleu(vuint32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vmsleu_vv_u32mf2_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsleu(vbool64_t op0, vbool64_t op1, vuint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vmsleu_vv_u32mf2_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsleu(vuint64m1_t op0, vuint64m1_t op1, size_t op2){
  return vmsleu_vv_u64m1_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsleu(vbool64_t op0, vbool64_t op1, vuint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vmsleu_vv_u64m1_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsleu(vuint64m2_t op0, vuint64m2_t op1, size_t op2){
  return vmsleu_vv_u64m2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsleu(vbool32_t op0, vbool32_t op1, vuint64m2_t op2, vuint64m2_t op3, size_t op4){
  return vmsleu_vv_u64m2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsleu(vuint64m4_t op0, vuint64m4_t op1, size_t op2){
  return vmsleu_vv_u64m4_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsleu(vbool16_t op0, vbool16_t op1, vuint64m4_t op2, vuint64m4_t op3, size_t op4){
  return vmsleu_vv_u64m4_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsleu(vuint64m8_t op0, vuint64m8_t op1, size_t op2){
  return vmsleu_vv_u64m8_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsleu(vbool8_t op0, vbool8_t op1, vuint64m8_t op2, vuint64m8_t op3, size_t op4){
  return vmsleu_vv_u64m8_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsleu(vuint8m1_t op0, uint8_t op1, size_t op2){
  return vmsleu_vx_u8m1_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsleu(vbool8_t op0, vbool8_t op1, vuint8m1_t op2, uint8_t op3, size_t op4){
  return vmsleu_vx_u8m1_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsleu(vuint8m2_t op0, uint8_t op1, size_t op2){
  return vmsleu_vx_u8m2_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsleu(vbool4_t op0, vbool4_t op1, vuint8m2_t op2, uint8_t op3, size_t op4){
  return vmsleu_vx_u8m2_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmsleu(vuint8m4_t op0, uint8_t op1, size_t op2){
  return vmsleu_vx_u8m4_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmsleu(vbool2_t op0, vbool2_t op1, vuint8m4_t op2, uint8_t op3, size_t op4){
  return vmsleu_vx_u8m4_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool1_t vmsleu(vuint8m8_t op0, uint8_t op1, size_t op2){
  return vmsleu_vx_u8m8_b1(op0, op1, op2);
}

__rvv_overloaded vbool1_t vmsleu(vbool1_t op0, vbool1_t op1, vuint8m8_t op2, uint8_t op3, size_t op4){
  return vmsleu_vx_u8m8_b1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsleu(vuint8mf2_t op0, uint8_t op1, size_t op2){
  return vmsleu_vx_u8mf2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsleu(vbool16_t op0, vbool16_t op1, vuint8mf2_t op2, uint8_t op3, size_t op4){
  return vmsleu_vx_u8mf2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsleu(vuint8mf4_t op0, uint8_t op1, size_t op2){
  return vmsleu_vx_u8mf4_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsleu(vbool32_t op0, vbool32_t op1, vuint8mf4_t op2, uint8_t op3, size_t op4){
  return vmsleu_vx_u8mf4_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsleu(vuint8mf8_t op0, uint8_t op1, size_t op2){
  return vmsleu_vx_u8mf8_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsleu(vbool64_t op0, vbool64_t op1, vuint8mf8_t op2, uint8_t op3, size_t op4){
  return vmsleu_vx_u8mf8_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsleu(vuint16m1_t op0, uint16_t op1, size_t op2){
  return vmsleu_vx_u16m1_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsleu(vbool16_t op0, vbool16_t op1, vuint16m1_t op2, uint16_t op3, size_t op4){
  return vmsleu_vx_u16m1_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsleu(vuint16m2_t op0, uint16_t op1, size_t op2){
  return vmsleu_vx_u16m2_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsleu(vbool8_t op0, vbool8_t op1, vuint16m2_t op2, uint16_t op3, size_t op4){
  return vmsleu_vx_u16m2_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsleu(vuint16m4_t op0, uint16_t op1, size_t op2){
  return vmsleu_vx_u16m4_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsleu(vbool4_t op0, vbool4_t op1, vuint16m4_t op2, uint16_t op3, size_t op4){
  return vmsleu_vx_u16m4_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmsleu(vuint16m8_t op0, uint16_t op1, size_t op2){
  return vmsleu_vx_u16m8_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmsleu(vbool2_t op0, vbool2_t op1, vuint16m8_t op2, uint16_t op3, size_t op4){
  return vmsleu_vx_u16m8_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsleu(vuint16mf2_t op0, uint16_t op1, size_t op2){
  return vmsleu_vx_u16mf2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsleu(vbool32_t op0, vbool32_t op1, vuint16mf2_t op2, uint16_t op3, size_t op4){
  return vmsleu_vx_u16mf2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsleu(vuint16mf4_t op0, uint16_t op1, size_t op2){
  return vmsleu_vx_u16mf4_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsleu(vbool64_t op0, vbool64_t op1, vuint16mf4_t op2, uint16_t op3, size_t op4){
  return vmsleu_vx_u16mf4_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsleu(vuint32m1_t op0, uint32_t op1, size_t op2){
  return vmsleu_vx_u32m1_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsleu(vbool32_t op0, vbool32_t op1, vuint32m1_t op2, uint32_t op3, size_t op4){
  return vmsleu_vx_u32m1_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsleu(vuint32m2_t op0, uint32_t op1, size_t op2){
  return vmsleu_vx_u32m2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsleu(vbool16_t op0, vbool16_t op1, vuint32m2_t op2, uint32_t op3, size_t op4){
  return vmsleu_vx_u32m2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsleu(vuint32m4_t op0, uint32_t op1, size_t op2){
  return vmsleu_vx_u32m4_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsleu(vbool8_t op0, vbool8_t op1, vuint32m4_t op2, uint32_t op3, size_t op4){
  return vmsleu_vx_u32m4_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsleu(vuint32m8_t op0, uint32_t op1, size_t op2){
  return vmsleu_vx_u32m8_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsleu(vbool4_t op0, vbool4_t op1, vuint32m8_t op2, uint32_t op3, size_t op4){
  return vmsleu_vx_u32m8_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsleu(vuint32mf2_t op0, uint32_t op1, size_t op2){
  return vmsleu_vx_u32mf2_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsleu(vbool64_t op0, vbool64_t op1, vuint32mf2_t op2, uint32_t op3, size_t op4){
  return vmsleu_vx_u32mf2_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsleu(vuint64m1_t op0, uint64_t op1, size_t op2){
  return vmsleu_vx_u64m1_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsleu(vbool64_t op0, vbool64_t op1, vuint64m1_t op2, uint64_t op3, size_t op4){
  return vmsleu_vx_u64m1_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsleu(vuint64m2_t op0, uint64_t op1, size_t op2){
  return vmsleu_vx_u64m2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsleu(vbool32_t op0, vbool32_t op1, vuint64m2_t op2, uint64_t op3, size_t op4){
  return vmsleu_vx_u64m2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsleu(vuint64m4_t op0, uint64_t op1, size_t op2){
  return vmsleu_vx_u64m4_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsleu(vbool16_t op0, vbool16_t op1, vuint64m4_t op2, uint64_t op3, size_t op4){
  return vmsleu_vx_u64m4_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsleu(vuint64m8_t op0, uint64_t op1, size_t op2){
  return vmsleu_vx_u64m8_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsleu(vbool8_t op0, vbool8_t op1, vuint64m8_t op2, uint64_t op3, size_t op4){
  return vmsleu_vx_u64m8_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsle(vint8m1_t op0, vint8m1_t op1, size_t op2){
  return vmsle_vv_i8m1_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsle(vbool8_t op0, vbool8_t op1, vint8m1_t op2, vint8m1_t op3, size_t op4){
  return vmsle_vv_i8m1_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsle(vint8m2_t op0, vint8m2_t op1, size_t op2){
  return vmsle_vv_i8m2_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsle(vbool4_t op0, vbool4_t op1, vint8m2_t op2, vint8m2_t op3, size_t op4){
  return vmsle_vv_i8m2_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmsle(vint8m4_t op0, vint8m4_t op1, size_t op2){
  return vmsle_vv_i8m4_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmsle(vbool2_t op0, vbool2_t op1, vint8m4_t op2, vint8m4_t op3, size_t op4){
  return vmsle_vv_i8m4_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool1_t vmsle(vint8m8_t op0, vint8m8_t op1, size_t op2){
  return vmsle_vv_i8m8_b1(op0, op1, op2);
}

__rvv_overloaded vbool1_t vmsle(vbool1_t op0, vbool1_t op1, vint8m8_t op2, vint8m8_t op3, size_t op4){
  return vmsle_vv_i8m8_b1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsle(vint8mf2_t op0, vint8mf2_t op1, size_t op2){
  return vmsle_vv_i8mf2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsle(vbool16_t op0, vbool16_t op1, vint8mf2_t op2, vint8mf2_t op3, size_t op4){
  return vmsle_vv_i8mf2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsle(vint8mf4_t op0, vint8mf4_t op1, size_t op2){
  return vmsle_vv_i8mf4_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsle(vbool32_t op0, vbool32_t op1, vint8mf4_t op2, vint8mf4_t op3, size_t op4){
  return vmsle_vv_i8mf4_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsle(vint8mf8_t op0, vint8mf8_t op1, size_t op2){
  return vmsle_vv_i8mf8_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsle(vbool64_t op0, vbool64_t op1, vint8mf8_t op2, vint8mf8_t op3, size_t op4){
  return vmsle_vv_i8mf8_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsle(vint16m1_t op0, vint16m1_t op1, size_t op2){
  return vmsle_vv_i16m1_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsle(vbool16_t op0, vbool16_t op1, vint16m1_t op2, vint16m1_t op3, size_t op4){
  return vmsle_vv_i16m1_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsle(vint16m2_t op0, vint16m2_t op1, size_t op2){
  return vmsle_vv_i16m2_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsle(vbool8_t op0, vbool8_t op1, vint16m2_t op2, vint16m2_t op3, size_t op4){
  return vmsle_vv_i16m2_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsle(vint16m4_t op0, vint16m4_t op1, size_t op2){
  return vmsle_vv_i16m4_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsle(vbool4_t op0, vbool4_t op1, vint16m4_t op2, vint16m4_t op3, size_t op4){
  return vmsle_vv_i16m4_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmsle(vint16m8_t op0, vint16m8_t op1, size_t op2){
  return vmsle_vv_i16m8_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmsle(vbool2_t op0, vbool2_t op1, vint16m8_t op2, vint16m8_t op3, size_t op4){
  return vmsle_vv_i16m8_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsle(vint16mf2_t op0, vint16mf2_t op1, size_t op2){
  return vmsle_vv_i16mf2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsle(vbool32_t op0, vbool32_t op1, vint16mf2_t op2, vint16mf2_t op3, size_t op4){
  return vmsle_vv_i16mf2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsle(vint16mf4_t op0, vint16mf4_t op1, size_t op2){
  return vmsle_vv_i16mf4_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsle(vbool64_t op0, vbool64_t op1, vint16mf4_t op2, vint16mf4_t op3, size_t op4){
  return vmsle_vv_i16mf4_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsle(vint32m1_t op0, vint32m1_t op1, size_t op2){
  return vmsle_vv_i32m1_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsle(vbool32_t op0, vbool32_t op1, vint32m1_t op2, vint32m1_t op3, size_t op4){
  return vmsle_vv_i32m1_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsle(vint32m2_t op0, vint32m2_t op1, size_t op2){
  return vmsle_vv_i32m2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsle(vbool16_t op0, vbool16_t op1, vint32m2_t op2, vint32m2_t op3, size_t op4){
  return vmsle_vv_i32m2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsle(vint32m4_t op0, vint32m4_t op1, size_t op2){
  return vmsle_vv_i32m4_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsle(vbool8_t op0, vbool8_t op1, vint32m4_t op2, vint32m4_t op3, size_t op4){
  return vmsle_vv_i32m4_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsle(vint32m8_t op0, vint32m8_t op1, size_t op2){
  return vmsle_vv_i32m8_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsle(vbool4_t op0, vbool4_t op1, vint32m8_t op2, vint32m8_t op3, size_t op4){
  return vmsle_vv_i32m8_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsle(vint32mf2_t op0, vint32mf2_t op1, size_t op2){
  return vmsle_vv_i32mf2_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsle(vbool64_t op0, vbool64_t op1, vint32mf2_t op2, vint32mf2_t op3, size_t op4){
  return vmsle_vv_i32mf2_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsle(vint64m1_t op0, vint64m1_t op1, size_t op2){
  return vmsle_vv_i64m1_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsle(vbool64_t op0, vbool64_t op1, vint64m1_t op2, vint64m1_t op3, size_t op4){
  return vmsle_vv_i64m1_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsle(vint64m2_t op0, vint64m2_t op1, size_t op2){
  return vmsle_vv_i64m2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsle(vbool32_t op0, vbool32_t op1, vint64m2_t op2, vint64m2_t op3, size_t op4){
  return vmsle_vv_i64m2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsle(vint64m4_t op0, vint64m4_t op1, size_t op2){
  return vmsle_vv_i64m4_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsle(vbool16_t op0, vbool16_t op1, vint64m4_t op2, vint64m4_t op3, size_t op4){
  return vmsle_vv_i64m4_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsle(vint64m8_t op0, vint64m8_t op1, size_t op2){
  return vmsle_vv_i64m8_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsle(vbool8_t op0, vbool8_t op1, vint64m8_t op2, vint64m8_t op3, size_t op4){
  return vmsle_vv_i64m8_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsle(vint8m1_t op0, int8_t op1, size_t op2){
  return vmsle_vx_i8m1_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsle(vbool8_t op0, vbool8_t op1, vint8m1_t op2, int8_t op3, size_t op4){
  return vmsle_vx_i8m1_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsle(vint8m2_t op0, int8_t op1, size_t op2){
  return vmsle_vx_i8m2_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsle(vbool4_t op0, vbool4_t op1, vint8m2_t op2, int8_t op3, size_t op4){
  return vmsle_vx_i8m2_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmsle(vint8m4_t op0, int8_t op1, size_t op2){
  return vmsle_vx_i8m4_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmsle(vbool2_t op0, vbool2_t op1, vint8m4_t op2, int8_t op3, size_t op4){
  return vmsle_vx_i8m4_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool1_t vmsle(vint8m8_t op0, int8_t op1, size_t op2){
  return vmsle_vx_i8m8_b1(op0, op1, op2);
}

__rvv_overloaded vbool1_t vmsle(vbool1_t op0, vbool1_t op1, vint8m8_t op2, int8_t op3, size_t op4){
  return vmsle_vx_i8m8_b1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsle(vint8mf2_t op0, int8_t op1, size_t op2){
  return vmsle_vx_i8mf2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsle(vbool16_t op0, vbool16_t op1, vint8mf2_t op2, int8_t op3, size_t op4){
  return vmsle_vx_i8mf2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsle(vint8mf4_t op0, int8_t op1, size_t op2){
  return vmsle_vx_i8mf4_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsle(vbool32_t op0, vbool32_t op1, vint8mf4_t op2, int8_t op3, size_t op4){
  return vmsle_vx_i8mf4_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsle(vint8mf8_t op0, int8_t op1, size_t op2){
  return vmsle_vx_i8mf8_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsle(vbool64_t op0, vbool64_t op1, vint8mf8_t op2, int8_t op3, size_t op4){
  return vmsle_vx_i8mf8_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsle(vint16m1_t op0, int16_t op1, size_t op2){
  return vmsle_vx_i16m1_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsle(vbool16_t op0, vbool16_t op1, vint16m1_t op2, int16_t op3, size_t op4){
  return vmsle_vx_i16m1_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsle(vint16m2_t op0, int16_t op1, size_t op2){
  return vmsle_vx_i16m2_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsle(vbool8_t op0, vbool8_t op1, vint16m2_t op2, int16_t op3, size_t op4){
  return vmsle_vx_i16m2_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsle(vint16m4_t op0, int16_t op1, size_t op2){
  return vmsle_vx_i16m4_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsle(vbool4_t op0, vbool4_t op1, vint16m4_t op2, int16_t op3, size_t op4){
  return vmsle_vx_i16m4_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmsle(vint16m8_t op0, int16_t op1, size_t op2){
  return vmsle_vx_i16m8_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmsle(vbool2_t op0, vbool2_t op1, vint16m8_t op2, int16_t op3, size_t op4){
  return vmsle_vx_i16m8_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsle(vint16mf2_t op0, int16_t op1, size_t op2){
  return vmsle_vx_i16mf2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsle(vbool32_t op0, vbool32_t op1, vint16mf2_t op2, int16_t op3, size_t op4){
  return vmsle_vx_i16mf2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsle(vint16mf4_t op0, int16_t op1, size_t op2){
  return vmsle_vx_i16mf4_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsle(vbool64_t op0, vbool64_t op1, vint16mf4_t op2, int16_t op3, size_t op4){
  return vmsle_vx_i16mf4_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsle(vint32m1_t op0, int32_t op1, size_t op2){
  return vmsle_vx_i32m1_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsle(vbool32_t op0, vbool32_t op1, vint32m1_t op2, int32_t op3, size_t op4){
  return vmsle_vx_i32m1_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsle(vint32m2_t op0, int32_t op1, size_t op2){
  return vmsle_vx_i32m2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsle(vbool16_t op0, vbool16_t op1, vint32m2_t op2, int32_t op3, size_t op4){
  return vmsle_vx_i32m2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsle(vint32m4_t op0, int32_t op1, size_t op2){
  return vmsle_vx_i32m4_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsle(vbool8_t op0, vbool8_t op1, vint32m4_t op2, int32_t op3, size_t op4){
  return vmsle_vx_i32m4_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsle(vint32m8_t op0, int32_t op1, size_t op2){
  return vmsle_vx_i32m8_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsle(vbool4_t op0, vbool4_t op1, vint32m8_t op2, int32_t op3, size_t op4){
  return vmsle_vx_i32m8_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsle(vint32mf2_t op0, int32_t op1, size_t op2){
  return vmsle_vx_i32mf2_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsle(vbool64_t op0, vbool64_t op1, vint32mf2_t op2, int32_t op3, size_t op4){
  return vmsle_vx_i32mf2_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsle(vint64m1_t op0, int64_t op1, size_t op2){
  return vmsle_vx_i64m1_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsle(vbool64_t op0, vbool64_t op1, vint64m1_t op2, int64_t op3, size_t op4){
  return vmsle_vx_i64m1_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsle(vint64m2_t op0, int64_t op1, size_t op2){
  return vmsle_vx_i64m2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsle(vbool32_t op0, vbool32_t op1, vint64m2_t op2, int64_t op3, size_t op4){
  return vmsle_vx_i64m2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsle(vint64m4_t op0, int64_t op1, size_t op2){
  return vmsle_vx_i64m4_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsle(vbool16_t op0, vbool16_t op1, vint64m4_t op2, int64_t op3, size_t op4){
  return vmsle_vx_i64m4_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsle(vint64m8_t op0, int64_t op1, size_t op2){
  return vmsle_vx_i64m8_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsle(vbool8_t op0, vbool8_t op1, vint64m8_t op2, int64_t op3, size_t op4){
  return vmsle_vx_i64m8_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsgtu(vuint8m1_t op0, uint8_t op1, size_t op2){
  return vmsgtu_vx_u8m1_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsgtu(vbool8_t op0, vbool8_t op1, vuint8m1_t op2, uint8_t op3, size_t op4){
  return vmsgtu_vx_u8m1_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsgtu(vuint8m2_t op0, uint8_t op1, size_t op2){
  return vmsgtu_vx_u8m2_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsgtu(vbool4_t op0, vbool4_t op1, vuint8m2_t op2, uint8_t op3, size_t op4){
  return vmsgtu_vx_u8m2_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmsgtu(vuint8m4_t op0, uint8_t op1, size_t op2){
  return vmsgtu_vx_u8m4_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmsgtu(vbool2_t op0, vbool2_t op1, vuint8m4_t op2, uint8_t op3, size_t op4){
  return vmsgtu_vx_u8m4_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool1_t vmsgtu(vuint8m8_t op0, uint8_t op1, size_t op2){
  return vmsgtu_vx_u8m8_b1(op0, op1, op2);
}

__rvv_overloaded vbool1_t vmsgtu(vbool1_t op0, vbool1_t op1, vuint8m8_t op2, uint8_t op3, size_t op4){
  return vmsgtu_vx_u8m8_b1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsgtu(vuint8mf2_t op0, uint8_t op1, size_t op2){
  return vmsgtu_vx_u8mf2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsgtu(vbool16_t op0, vbool16_t op1, vuint8mf2_t op2, uint8_t op3, size_t op4){
  return vmsgtu_vx_u8mf2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsgtu(vuint8mf4_t op0, uint8_t op1, size_t op2){
  return vmsgtu_vx_u8mf4_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsgtu(vbool32_t op0, vbool32_t op1, vuint8mf4_t op2, uint8_t op3, size_t op4){
  return vmsgtu_vx_u8mf4_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsgtu(vuint8mf8_t op0, uint8_t op1, size_t op2){
  return vmsgtu_vx_u8mf8_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsgtu(vbool64_t op0, vbool64_t op1, vuint8mf8_t op2, uint8_t op3, size_t op4){
  return vmsgtu_vx_u8mf8_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsgtu(vuint16m1_t op0, uint16_t op1, size_t op2){
  return vmsgtu_vx_u16m1_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsgtu(vbool16_t op0, vbool16_t op1, vuint16m1_t op2, uint16_t op3, size_t op4){
  return vmsgtu_vx_u16m1_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsgtu(vuint16m2_t op0, uint16_t op1, size_t op2){
  return vmsgtu_vx_u16m2_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsgtu(vbool8_t op0, vbool8_t op1, vuint16m2_t op2, uint16_t op3, size_t op4){
  return vmsgtu_vx_u16m2_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsgtu(vuint16m4_t op0, uint16_t op1, size_t op2){
  return vmsgtu_vx_u16m4_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsgtu(vbool4_t op0, vbool4_t op1, vuint16m4_t op2, uint16_t op3, size_t op4){
  return vmsgtu_vx_u16m4_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmsgtu(vuint16m8_t op0, uint16_t op1, size_t op2){
  return vmsgtu_vx_u16m8_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmsgtu(vbool2_t op0, vbool2_t op1, vuint16m8_t op2, uint16_t op3, size_t op4){
  return vmsgtu_vx_u16m8_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsgtu(vuint16mf2_t op0, uint16_t op1, size_t op2){
  return vmsgtu_vx_u16mf2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsgtu(vbool32_t op0, vbool32_t op1, vuint16mf2_t op2, uint16_t op3, size_t op4){
  return vmsgtu_vx_u16mf2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsgtu(vuint16mf4_t op0, uint16_t op1, size_t op2){
  return vmsgtu_vx_u16mf4_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsgtu(vbool64_t op0, vbool64_t op1, vuint16mf4_t op2, uint16_t op3, size_t op4){
  return vmsgtu_vx_u16mf4_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsgtu(vuint32m1_t op0, uint32_t op1, size_t op2){
  return vmsgtu_vx_u32m1_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsgtu(vbool32_t op0, vbool32_t op1, vuint32m1_t op2, uint32_t op3, size_t op4){
  return vmsgtu_vx_u32m1_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsgtu(vuint32m2_t op0, uint32_t op1, size_t op2){
  return vmsgtu_vx_u32m2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsgtu(vbool16_t op0, vbool16_t op1, vuint32m2_t op2, uint32_t op3, size_t op4){
  return vmsgtu_vx_u32m2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsgtu(vuint32m4_t op0, uint32_t op1, size_t op2){
  return vmsgtu_vx_u32m4_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsgtu(vbool8_t op0, vbool8_t op1, vuint32m4_t op2, uint32_t op3, size_t op4){
  return vmsgtu_vx_u32m4_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsgtu(vuint32m8_t op0, uint32_t op1, size_t op2){
  return vmsgtu_vx_u32m8_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsgtu(vbool4_t op0, vbool4_t op1, vuint32m8_t op2, uint32_t op3, size_t op4){
  return vmsgtu_vx_u32m8_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsgtu(vuint32mf2_t op0, uint32_t op1, size_t op2){
  return vmsgtu_vx_u32mf2_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsgtu(vbool64_t op0, vbool64_t op1, vuint32mf2_t op2, uint32_t op3, size_t op4){
  return vmsgtu_vx_u32mf2_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsgtu(vuint64m1_t op0, uint64_t op1, size_t op2){
  return vmsgtu_vx_u64m1_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsgtu(vbool64_t op0, vbool64_t op1, vuint64m1_t op2, uint64_t op3, size_t op4){
  return vmsgtu_vx_u64m1_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsgtu(vuint64m2_t op0, uint64_t op1, size_t op2){
  return vmsgtu_vx_u64m2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsgtu(vbool32_t op0, vbool32_t op1, vuint64m2_t op2, uint64_t op3, size_t op4){
  return vmsgtu_vx_u64m2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsgtu(vuint64m4_t op0, uint64_t op1, size_t op2){
  return vmsgtu_vx_u64m4_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsgtu(vbool16_t op0, vbool16_t op1, vuint64m4_t op2, uint64_t op3, size_t op4){
  return vmsgtu_vx_u64m4_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsgtu(vuint64m8_t op0, uint64_t op1, size_t op2){
  return vmsgtu_vx_u64m8_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsgtu(vbool8_t op0, vbool8_t op1, vuint64m8_t op2, uint64_t op3, size_t op4){
  return vmsgtu_vx_u64m8_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsgt(vint8m1_t op0, int8_t op1, size_t op2){
  return vmsgt_vx_i8m1_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsgt(vbool8_t op0, vbool8_t op1, vint8m1_t op2, int8_t op3, size_t op4){
  return vmsgt_vx_i8m1_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsgt(vint8m2_t op0, int8_t op1, size_t op2){
  return vmsgt_vx_i8m2_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsgt(vbool4_t op0, vbool4_t op1, vint8m2_t op2, int8_t op3, size_t op4){
  return vmsgt_vx_i8m2_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmsgt(vint8m4_t op0, int8_t op1, size_t op2){
  return vmsgt_vx_i8m4_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmsgt(vbool2_t op0, vbool2_t op1, vint8m4_t op2, int8_t op3, size_t op4){
  return vmsgt_vx_i8m4_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool1_t vmsgt(vint8m8_t op0, int8_t op1, size_t op2){
  return vmsgt_vx_i8m8_b1(op0, op1, op2);
}

__rvv_overloaded vbool1_t vmsgt(vbool1_t op0, vbool1_t op1, vint8m8_t op2, int8_t op3, size_t op4){
  return vmsgt_vx_i8m8_b1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsgt(vint8mf2_t op0, int8_t op1, size_t op2){
  return vmsgt_vx_i8mf2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsgt(vbool16_t op0, vbool16_t op1, vint8mf2_t op2, int8_t op3, size_t op4){
  return vmsgt_vx_i8mf2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsgt(vint8mf4_t op0, int8_t op1, size_t op2){
  return vmsgt_vx_i8mf4_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsgt(vbool32_t op0, vbool32_t op1, vint8mf4_t op2, int8_t op3, size_t op4){
  return vmsgt_vx_i8mf4_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsgt(vint8mf8_t op0, int8_t op1, size_t op2){
  return vmsgt_vx_i8mf8_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsgt(vbool64_t op0, vbool64_t op1, vint8mf8_t op2, int8_t op3, size_t op4){
  return vmsgt_vx_i8mf8_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsgt(vint16m1_t op0, int16_t op1, size_t op2){
  return vmsgt_vx_i16m1_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsgt(vbool16_t op0, vbool16_t op1, vint16m1_t op2, int16_t op3, size_t op4){
  return vmsgt_vx_i16m1_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsgt(vint16m2_t op0, int16_t op1, size_t op2){
  return vmsgt_vx_i16m2_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsgt(vbool8_t op0, vbool8_t op1, vint16m2_t op2, int16_t op3, size_t op4){
  return vmsgt_vx_i16m2_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsgt(vint16m4_t op0, int16_t op1, size_t op2){
  return vmsgt_vx_i16m4_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsgt(vbool4_t op0, vbool4_t op1, vint16m4_t op2, int16_t op3, size_t op4){
  return vmsgt_vx_i16m4_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmsgt(vint16m8_t op0, int16_t op1, size_t op2){
  return vmsgt_vx_i16m8_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmsgt(vbool2_t op0, vbool2_t op1, vint16m8_t op2, int16_t op3, size_t op4){
  return vmsgt_vx_i16m8_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsgt(vint16mf2_t op0, int16_t op1, size_t op2){
  return vmsgt_vx_i16mf2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsgt(vbool32_t op0, vbool32_t op1, vint16mf2_t op2, int16_t op3, size_t op4){
  return vmsgt_vx_i16mf2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsgt(vint16mf4_t op0, int16_t op1, size_t op2){
  return vmsgt_vx_i16mf4_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsgt(vbool64_t op0, vbool64_t op1, vint16mf4_t op2, int16_t op3, size_t op4){
  return vmsgt_vx_i16mf4_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsgt(vint32m1_t op0, int32_t op1, size_t op2){
  return vmsgt_vx_i32m1_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsgt(vbool32_t op0, vbool32_t op1, vint32m1_t op2, int32_t op3, size_t op4){
  return vmsgt_vx_i32m1_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsgt(vint32m2_t op0, int32_t op1, size_t op2){
  return vmsgt_vx_i32m2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsgt(vbool16_t op0, vbool16_t op1, vint32m2_t op2, int32_t op3, size_t op4){
  return vmsgt_vx_i32m2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsgt(vint32m4_t op0, int32_t op1, size_t op2){
  return vmsgt_vx_i32m4_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsgt(vbool8_t op0, vbool8_t op1, vint32m4_t op2, int32_t op3, size_t op4){
  return vmsgt_vx_i32m4_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsgt(vint32m8_t op0, int32_t op1, size_t op2){
  return vmsgt_vx_i32m8_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsgt(vbool4_t op0, vbool4_t op1, vint32m8_t op2, int32_t op3, size_t op4){
  return vmsgt_vx_i32m8_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsgt(vint32mf2_t op0, int32_t op1, size_t op2){
  return vmsgt_vx_i32mf2_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsgt(vbool64_t op0, vbool64_t op1, vint32mf2_t op2, int32_t op3, size_t op4){
  return vmsgt_vx_i32mf2_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsgt(vint64m1_t op0, int64_t op1, size_t op2){
  return vmsgt_vx_i64m1_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsgt(vbool64_t op0, vbool64_t op1, vint64m1_t op2, int64_t op3, size_t op4){
  return vmsgt_vx_i64m1_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsgt(vint64m2_t op0, int64_t op1, size_t op2){
  return vmsgt_vx_i64m2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsgt(vbool32_t op0, vbool32_t op1, vint64m2_t op2, int64_t op3, size_t op4){
  return vmsgt_vx_i64m2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsgt(vint64m4_t op0, int64_t op1, size_t op2){
  return vmsgt_vx_i64m4_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsgt(vbool16_t op0, vbool16_t op1, vint64m4_t op2, int64_t op3, size_t op4){
  return vmsgt_vx_i64m4_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsgt(vint64m8_t op0, int64_t op1, size_t op2){
  return vmsgt_vx_i64m8_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsgt(vbool8_t op0, vbool8_t op1, vint64m8_t op2, int64_t op3, size_t op4){
  return vmsgt_vx_i64m8_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vminu(vuint8m1_t op0, vuint8m1_t op1, size_t op2){
  return vminu_vv_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vminu(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vminu_vv_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vminu(vuint8m2_t op0, vuint8m2_t op1, size_t op2){
  return vminu_vv_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vminu(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vminu_vv_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vminu(vuint8m4_t op0, vuint8m4_t op1, size_t op2){
  return vminu_vv_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vminu(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vminu_vv_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vminu(vuint8m8_t op0, vuint8m8_t op1, size_t op2){
  return vminu_vv_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vminu(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, vuint8m8_t op3, size_t op4){
  return vminu_vv_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vminu(vuint8mf2_t op0, vuint8mf2_t op1, size_t op2){
  return vminu_vv_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vminu(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vminu_vv_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vminu(vuint8mf4_t op0, vuint8mf4_t op1, size_t op2){
  return vminu_vv_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vminu(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vminu_vv_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vminu(vuint8mf8_t op0, vuint8mf8_t op1, size_t op2){
  return vminu_vv_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vminu(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vminu_vv_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vminu(vuint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vminu_vv_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vminu(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vminu_vv_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vminu(vuint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vminu_vv_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vminu(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vminu_vv_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vminu(vuint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vminu_vv_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vminu(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vminu_vv_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vminu(vuint16m8_t op0, vuint16m8_t op1, size_t op2){
  return vminu_vv_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vminu(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vminu_vv_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vminu(vuint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vminu_vv_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vminu(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vminu_vv_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vminu(vuint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vminu_vv_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vminu(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vminu_vv_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vminu(vuint32m1_t op0, vuint32m1_t op1, size_t op2){
  return vminu_vv_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vminu(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vminu_vv_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vminu(vuint32m2_t op0, vuint32m2_t op1, size_t op2){
  return vminu_vv_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vminu(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vminu_vv_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vminu(vuint32m4_t op0, vuint32m4_t op1, size_t op2){
  return vminu_vv_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vminu(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vminu_vv_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vminu(vuint32m8_t op0, vuint32m8_t op1, size_t op2){
  return vminu_vv_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vminu(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, vuint32m8_t op3, size_t op4){
  return vminu_vv_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vminu(vuint32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vminu_vv_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vminu(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vminu_vv_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vminu(vuint64m1_t op0, vuint64m1_t op1, size_t op2){
  return vminu_vv_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vminu(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vminu_vv_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vminu(vuint64m2_t op0, vuint64m2_t op1, size_t op2){
  return vminu_vv_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vminu(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, vuint64m2_t op3, size_t op4){
  return vminu_vv_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vminu(vuint64m4_t op0, vuint64m4_t op1, size_t op2){
  return vminu_vv_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vminu(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, vuint64m4_t op3, size_t op4){
  return vminu_vv_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vminu(vuint64m8_t op0, vuint64m8_t op1, size_t op2){
  return vminu_vv_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vminu(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, vuint64m8_t op3, size_t op4){
  return vminu_vv_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vminu(vuint8m1_t op0, uint8_t op1, size_t op2){
  return vminu_vx_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vminu(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, uint8_t op3, size_t op4){
  return vminu_vx_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vminu(vuint8m2_t op0, uint8_t op1, size_t op2){
  return vminu_vx_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vminu(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, uint8_t op3, size_t op4){
  return vminu_vx_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vminu(vuint8m4_t op0, uint8_t op1, size_t op2){
  return vminu_vx_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vminu(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, uint8_t op3, size_t op4){
  return vminu_vx_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vminu(vuint8m8_t op0, uint8_t op1, size_t op2){
  return vminu_vx_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vminu(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, uint8_t op3, size_t op4){
  return vminu_vx_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vminu(vuint8mf2_t op0, uint8_t op1, size_t op2){
  return vminu_vx_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vminu(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, uint8_t op3, size_t op4){
  return vminu_vx_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vminu(vuint8mf4_t op0, uint8_t op1, size_t op2){
  return vminu_vx_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vminu(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, uint8_t op3, size_t op4){
  return vminu_vx_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vminu(vuint8mf8_t op0, uint8_t op1, size_t op2){
  return vminu_vx_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vminu(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, uint8_t op3, size_t op4){
  return vminu_vx_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vminu(vuint16m1_t op0, uint16_t op1, size_t op2){
  return vminu_vx_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vminu(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, uint16_t op3, size_t op4){
  return vminu_vx_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vminu(vuint16m2_t op0, uint16_t op1, size_t op2){
  return vminu_vx_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vminu(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, uint16_t op3, size_t op4){
  return vminu_vx_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vminu(vuint16m4_t op0, uint16_t op1, size_t op2){
  return vminu_vx_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vminu(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, uint16_t op3, size_t op4){
  return vminu_vx_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vminu(vuint16m8_t op0, uint16_t op1, size_t op2){
  return vminu_vx_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vminu(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, uint16_t op3, size_t op4){
  return vminu_vx_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vminu(vuint16mf2_t op0, uint16_t op1, size_t op2){
  return vminu_vx_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vminu(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, uint16_t op3, size_t op4){
  return vminu_vx_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vminu(vuint16mf4_t op0, uint16_t op1, size_t op2){
  return vminu_vx_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vminu(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, uint16_t op3, size_t op4){
  return vminu_vx_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vminu(vuint32m1_t op0, uint32_t op1, size_t op2){
  return vminu_vx_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vminu(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, uint32_t op3, size_t op4){
  return vminu_vx_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vminu(vuint32m2_t op0, uint32_t op1, size_t op2){
  return vminu_vx_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vminu(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, uint32_t op3, size_t op4){
  return vminu_vx_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vminu(vuint32m4_t op0, uint32_t op1, size_t op2){
  return vminu_vx_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vminu(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, uint32_t op3, size_t op4){
  return vminu_vx_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vminu(vuint32m8_t op0, uint32_t op1, size_t op2){
  return vminu_vx_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vminu(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, uint32_t op3, size_t op4){
  return vminu_vx_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vminu(vuint32mf2_t op0, uint32_t op1, size_t op2){
  return vminu_vx_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vminu(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, uint32_t op3, size_t op4){
  return vminu_vx_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vminu(vuint64m1_t op0, uint64_t op1, size_t op2){
  return vminu_vx_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vminu(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, uint64_t op3, size_t op4){
  return vminu_vx_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vminu(vuint64m2_t op0, uint64_t op1, size_t op2){
  return vminu_vx_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vminu(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, uint64_t op3, size_t op4){
  return vminu_vx_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vminu(vuint64m4_t op0, uint64_t op1, size_t op2){
  return vminu_vx_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vminu(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, uint64_t op3, size_t op4){
  return vminu_vx_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vminu(vuint64m8_t op0, uint64_t op1, size_t op2){
  return vminu_vx_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vminu(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, uint64_t op3, size_t op4){
  return vminu_vx_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vmin(vint8m1_t op0, vint8m1_t op1, size_t op2){
  return vmin_vv_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vmin(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, vint8m1_t op3, size_t op4){
  return vmin_vv_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vmin(vint8m2_t op0, vint8m2_t op1, size_t op2){
  return vmin_vv_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vmin(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, vint8m2_t op3, size_t op4){
  return vmin_vv_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vmin(vint8m4_t op0, vint8m4_t op1, size_t op2){
  return vmin_vv_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vmin(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, vint8m4_t op3, size_t op4){
  return vmin_vv_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vmin(vint8m8_t op0, vint8m8_t op1, size_t op2){
  return vmin_vv_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vmin(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, vint8m8_t op3, size_t op4){
  return vmin_vv_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vmin(vint8mf2_t op0, vint8mf2_t op1, size_t op2){
  return vmin_vv_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vmin(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, vint8mf2_t op3, size_t op4){
  return vmin_vv_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vmin(vint8mf4_t op0, vint8mf4_t op1, size_t op2){
  return vmin_vv_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vmin(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, vint8mf4_t op3, size_t op4){
  return vmin_vv_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vmin(vint8mf8_t op0, vint8mf8_t op1, size_t op2){
  return vmin_vv_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vmin(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, vint8mf8_t op3, size_t op4){
  return vmin_vv_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vmin(vint16m1_t op0, vint16m1_t op1, size_t op2){
  return vmin_vv_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vmin(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, vint16m1_t op3, size_t op4){
  return vmin_vv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vmin(vint16m2_t op0, vint16m2_t op1, size_t op2){
  return vmin_vv_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vmin(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, vint16m2_t op3, size_t op4){
  return vmin_vv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vmin(vint16m4_t op0, vint16m4_t op1, size_t op2){
  return vmin_vv_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vmin(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, vint16m4_t op3, size_t op4){
  return vmin_vv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vmin(vint16m8_t op0, vint16m8_t op1, size_t op2){
  return vmin_vv_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vmin(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, vint16m8_t op3, size_t op4){
  return vmin_vv_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vmin(vint16mf2_t op0, vint16mf2_t op1, size_t op2){
  return vmin_vv_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vmin(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, vint16mf2_t op3, size_t op4){
  return vmin_vv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vmin(vint16mf4_t op0, vint16mf4_t op1, size_t op2){
  return vmin_vv_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vmin(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, vint16mf4_t op3, size_t op4){
  return vmin_vv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vmin(vint32m1_t op0, vint32m1_t op1, size_t op2){
  return vmin_vv_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vmin(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, vint32m1_t op3, size_t op4){
  return vmin_vv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vmin(vint32m2_t op0, vint32m2_t op1, size_t op2){
  return vmin_vv_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vmin(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, vint32m2_t op3, size_t op4){
  return vmin_vv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vmin(vint32m4_t op0, vint32m4_t op1, size_t op2){
  return vmin_vv_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vmin(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, vint32m4_t op3, size_t op4){
  return vmin_vv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vmin(vint32m8_t op0, vint32m8_t op1, size_t op2){
  return vmin_vv_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vmin(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, vint32m8_t op3, size_t op4){
  return vmin_vv_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vmin(vint32mf2_t op0, vint32mf2_t op1, size_t op2){
  return vmin_vv_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vmin(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, vint32mf2_t op3, size_t op4){
  return vmin_vv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vmin(vint64m1_t op0, vint64m1_t op1, size_t op2){
  return vmin_vv_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vmin(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, vint64m1_t op3, size_t op4){
  return vmin_vv_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vmin(vint64m2_t op0, vint64m2_t op1, size_t op2){
  return vmin_vv_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vmin(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, vint64m2_t op3, size_t op4){
  return vmin_vv_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vmin(vint64m4_t op0, vint64m4_t op1, size_t op2){
  return vmin_vv_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vmin(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, vint64m4_t op3, size_t op4){
  return vmin_vv_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vmin(vint64m8_t op0, vint64m8_t op1, size_t op2){
  return vmin_vv_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vmin(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, vint64m8_t op3, size_t op4){
  return vmin_vv_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vmin(vint8m1_t op0, int8_t op1, size_t op2){
  return vmin_vx_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vmin(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, int8_t op3, size_t op4){
  return vmin_vx_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vmin(vint8m2_t op0, int8_t op1, size_t op2){
  return vmin_vx_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vmin(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, int8_t op3, size_t op4){
  return vmin_vx_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vmin(vint8m4_t op0, int8_t op1, size_t op2){
  return vmin_vx_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vmin(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, int8_t op3, size_t op4){
  return vmin_vx_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vmin(vint8m8_t op0, int8_t op1, size_t op2){
  return vmin_vx_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vmin(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, int8_t op3, size_t op4){
  return vmin_vx_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vmin(vint8mf2_t op0, int8_t op1, size_t op2){
  return vmin_vx_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vmin(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, int8_t op3, size_t op4){
  return vmin_vx_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vmin(vint8mf4_t op0, int8_t op1, size_t op2){
  return vmin_vx_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vmin(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, int8_t op3, size_t op4){
  return vmin_vx_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vmin(vint8mf8_t op0, int8_t op1, size_t op2){
  return vmin_vx_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vmin(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, int8_t op3, size_t op4){
  return vmin_vx_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vmin(vint16m1_t op0, int16_t op1, size_t op2){
  return vmin_vx_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vmin(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, int16_t op3, size_t op4){
  return vmin_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vmin(vint16m2_t op0, int16_t op1, size_t op2){
  return vmin_vx_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vmin(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, int16_t op3, size_t op4){
  return vmin_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vmin(vint16m4_t op0, int16_t op1, size_t op2){
  return vmin_vx_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vmin(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, int16_t op3, size_t op4){
  return vmin_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vmin(vint16m8_t op0, int16_t op1, size_t op2){
  return vmin_vx_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vmin(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, int16_t op3, size_t op4){
  return vmin_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vmin(vint16mf2_t op0, int16_t op1, size_t op2){
  return vmin_vx_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vmin(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, int16_t op3, size_t op4){
  return vmin_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vmin(vint16mf4_t op0, int16_t op1, size_t op2){
  return vmin_vx_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vmin(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, int16_t op3, size_t op4){
  return vmin_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vmin(vint32m1_t op0, int32_t op1, size_t op2){
  return vmin_vx_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vmin(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, int32_t op3, size_t op4){
  return vmin_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vmin(vint32m2_t op0, int32_t op1, size_t op2){
  return vmin_vx_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vmin(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, int32_t op3, size_t op4){
  return vmin_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vmin(vint32m4_t op0, int32_t op1, size_t op2){
  return vmin_vx_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vmin(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, int32_t op3, size_t op4){
  return vmin_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vmin(vint32m8_t op0, int32_t op1, size_t op2){
  return vmin_vx_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vmin(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, int32_t op3, size_t op4){
  return vmin_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vmin(vint32mf2_t op0, int32_t op1, size_t op2){
  return vmin_vx_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vmin(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, int32_t op3, size_t op4){
  return vmin_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vmin(vint64m1_t op0, int64_t op1, size_t op2){
  return vmin_vx_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vmin(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, int64_t op3, size_t op4){
  return vmin_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vmin(vint64m2_t op0, int64_t op1, size_t op2){
  return vmin_vx_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vmin(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, int64_t op3, size_t op4){
  return vmin_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vmin(vint64m4_t op0, int64_t op1, size_t op2){
  return vmin_vx_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vmin(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, int64_t op3, size_t op4){
  return vmin_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vmin(vint64m8_t op0, int64_t op1, size_t op2){
  return vmin_vx_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vmin(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, int64_t op3, size_t op4){
  return vmin_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vmaxu(vuint8m1_t op0, vuint8m1_t op1, size_t op2){
  return vmaxu_vv_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vmaxu(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vmaxu_vv_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vmaxu(vuint8m2_t op0, vuint8m2_t op1, size_t op2){
  return vmaxu_vv_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vmaxu(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vmaxu_vv_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vmaxu(vuint8m4_t op0, vuint8m4_t op1, size_t op2){
  return vmaxu_vv_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vmaxu(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vmaxu_vv_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vmaxu(vuint8m8_t op0, vuint8m8_t op1, size_t op2){
  return vmaxu_vv_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vmaxu(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, vuint8m8_t op3, size_t op4){
  return vmaxu_vv_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vmaxu(vuint8mf2_t op0, vuint8mf2_t op1, size_t op2){
  return vmaxu_vv_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vmaxu(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vmaxu_vv_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vmaxu(vuint8mf4_t op0, vuint8mf4_t op1, size_t op2){
  return vmaxu_vv_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vmaxu(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vmaxu_vv_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vmaxu(vuint8mf8_t op0, vuint8mf8_t op1, size_t op2){
  return vmaxu_vv_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vmaxu(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vmaxu_vv_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vmaxu(vuint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vmaxu_vv_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vmaxu(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vmaxu_vv_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vmaxu(vuint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vmaxu_vv_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vmaxu(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vmaxu_vv_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vmaxu(vuint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vmaxu_vv_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vmaxu(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vmaxu_vv_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vmaxu(vuint16m8_t op0, vuint16m8_t op1, size_t op2){
  return vmaxu_vv_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vmaxu(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vmaxu_vv_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vmaxu(vuint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vmaxu_vv_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vmaxu(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vmaxu_vv_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vmaxu(vuint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vmaxu_vv_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vmaxu(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vmaxu_vv_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vmaxu(vuint32m1_t op0, vuint32m1_t op1, size_t op2){
  return vmaxu_vv_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vmaxu(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vmaxu_vv_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vmaxu(vuint32m2_t op0, vuint32m2_t op1, size_t op2){
  return vmaxu_vv_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vmaxu(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vmaxu_vv_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vmaxu(vuint32m4_t op0, vuint32m4_t op1, size_t op2){
  return vmaxu_vv_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vmaxu(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vmaxu_vv_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vmaxu(vuint32m8_t op0, vuint32m8_t op1, size_t op2){
  return vmaxu_vv_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vmaxu(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, vuint32m8_t op3, size_t op4){
  return vmaxu_vv_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vmaxu(vuint32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vmaxu_vv_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vmaxu(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vmaxu_vv_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vmaxu(vuint64m1_t op0, vuint64m1_t op1, size_t op2){
  return vmaxu_vv_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vmaxu(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vmaxu_vv_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vmaxu(vuint64m2_t op0, vuint64m2_t op1, size_t op2){
  return vmaxu_vv_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vmaxu(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, vuint64m2_t op3, size_t op4){
  return vmaxu_vv_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vmaxu(vuint64m4_t op0, vuint64m4_t op1, size_t op2){
  return vmaxu_vv_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vmaxu(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, vuint64m4_t op3, size_t op4){
  return vmaxu_vv_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vmaxu(vuint64m8_t op0, vuint64m8_t op1, size_t op2){
  return vmaxu_vv_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vmaxu(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, vuint64m8_t op3, size_t op4){
  return vmaxu_vv_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vmaxu(vuint8m1_t op0, uint8_t op1, size_t op2){
  return vmaxu_vx_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vmaxu(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, uint8_t op3, size_t op4){
  return vmaxu_vx_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vmaxu(vuint8m2_t op0, uint8_t op1, size_t op2){
  return vmaxu_vx_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vmaxu(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, uint8_t op3, size_t op4){
  return vmaxu_vx_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vmaxu(vuint8m4_t op0, uint8_t op1, size_t op2){
  return vmaxu_vx_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vmaxu(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, uint8_t op3, size_t op4){
  return vmaxu_vx_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vmaxu(vuint8m8_t op0, uint8_t op1, size_t op2){
  return vmaxu_vx_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vmaxu(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, uint8_t op3, size_t op4){
  return vmaxu_vx_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vmaxu(vuint8mf2_t op0, uint8_t op1, size_t op2){
  return vmaxu_vx_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vmaxu(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, uint8_t op3, size_t op4){
  return vmaxu_vx_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vmaxu(vuint8mf4_t op0, uint8_t op1, size_t op2){
  return vmaxu_vx_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vmaxu(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, uint8_t op3, size_t op4){
  return vmaxu_vx_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vmaxu(vuint8mf8_t op0, uint8_t op1, size_t op2){
  return vmaxu_vx_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vmaxu(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, uint8_t op3, size_t op4){
  return vmaxu_vx_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vmaxu(vuint16m1_t op0, uint16_t op1, size_t op2){
  return vmaxu_vx_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vmaxu(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, uint16_t op3, size_t op4){
  return vmaxu_vx_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vmaxu(vuint16m2_t op0, uint16_t op1, size_t op2){
  return vmaxu_vx_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vmaxu(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, uint16_t op3, size_t op4){
  return vmaxu_vx_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vmaxu(vuint16m4_t op0, uint16_t op1, size_t op2){
  return vmaxu_vx_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vmaxu(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, uint16_t op3, size_t op4){
  return vmaxu_vx_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vmaxu(vuint16m8_t op0, uint16_t op1, size_t op2){
  return vmaxu_vx_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vmaxu(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, uint16_t op3, size_t op4){
  return vmaxu_vx_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vmaxu(vuint16mf2_t op0, uint16_t op1, size_t op2){
  return vmaxu_vx_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vmaxu(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, uint16_t op3, size_t op4){
  return vmaxu_vx_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vmaxu(vuint16mf4_t op0, uint16_t op1, size_t op2){
  return vmaxu_vx_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vmaxu(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, uint16_t op3, size_t op4){
  return vmaxu_vx_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vmaxu(vuint32m1_t op0, uint32_t op1, size_t op2){
  return vmaxu_vx_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vmaxu(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, uint32_t op3, size_t op4){
  return vmaxu_vx_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vmaxu(vuint32m2_t op0, uint32_t op1, size_t op2){
  return vmaxu_vx_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vmaxu(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, uint32_t op3, size_t op4){
  return vmaxu_vx_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vmaxu(vuint32m4_t op0, uint32_t op1, size_t op2){
  return vmaxu_vx_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vmaxu(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, uint32_t op3, size_t op4){
  return vmaxu_vx_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vmaxu(vuint32m8_t op0, uint32_t op1, size_t op2){
  return vmaxu_vx_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vmaxu(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, uint32_t op3, size_t op4){
  return vmaxu_vx_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vmaxu(vuint32mf2_t op0, uint32_t op1, size_t op2){
  return vmaxu_vx_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vmaxu(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, uint32_t op3, size_t op4){
  return vmaxu_vx_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vmaxu(vuint64m1_t op0, uint64_t op1, size_t op2){
  return vmaxu_vx_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vmaxu(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, uint64_t op3, size_t op4){
  return vmaxu_vx_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vmaxu(vuint64m2_t op0, uint64_t op1, size_t op2){
  return vmaxu_vx_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vmaxu(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, uint64_t op3, size_t op4){
  return vmaxu_vx_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vmaxu(vuint64m4_t op0, uint64_t op1, size_t op2){
  return vmaxu_vx_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vmaxu(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, uint64_t op3, size_t op4){
  return vmaxu_vx_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vmaxu(vuint64m8_t op0, uint64_t op1, size_t op2){
  return vmaxu_vx_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vmaxu(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, uint64_t op3, size_t op4){
  return vmaxu_vx_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vle8(vbool8_t op0, vuint8m1_t op1, const uint8_t * op2, size_t op3){
  return vle8_v_u8m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m2_t vle8(vbool4_t op0, vuint8m2_t op1, const uint8_t * op2, size_t op3){
  return vle8_v_u8m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m4_t vle8(vbool2_t op0, vuint8m4_t op1, const uint8_t * op2, size_t op3){
  return vle8_v_u8m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m8_t vle8(vbool1_t op0, vuint8m8_t op1, const uint8_t * op2, size_t op3){
  return vle8_v_u8m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf2_t vle8(vbool16_t op0, vuint8mf2_t op1, const uint8_t * op2, size_t op3){
  return vle8_v_u8mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf4_t vle8(vbool32_t op0, vuint8mf4_t op1, const uint8_t * op2, size_t op3){
  return vle8_v_u8mf4_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf8_t vle8(vbool64_t op0, vuint8mf8_t op1, const uint8_t * op2, size_t op3){
  return vle8_v_u8mf8_m(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vle64(vbool64_t op0, vint64m1_t op1, const int64_t * op2, size_t op3){
  return vle64_v_i64m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vint64m2_t vle64(vbool32_t op0, vint64m2_t op1, const int64_t * op2, size_t op3){
  return vle64_v_i64m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vint64m4_t vle64(vbool16_t op0, vint64m4_t op1, const int64_t * op2, size_t op3){
  return vle64_v_i64m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vint64m8_t vle64(vbool8_t op0, vint64m8_t op1, const int64_t * op2, size_t op3){
  return vle64_v_i64m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vmax(vint8m1_t op0, vint8m1_t op1, size_t op2){
  return vmax_vv_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vmax(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, vint8m1_t op3, size_t op4){
  return vmax_vv_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vmax(vint8m2_t op0, vint8m2_t op1, size_t op2){
  return vmax_vv_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vmax(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, vint8m2_t op3, size_t op4){
  return vmax_vv_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vmax(vint8m4_t op0, vint8m4_t op1, size_t op2){
  return vmax_vv_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vmax(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, vint8m4_t op3, size_t op4){
  return vmax_vv_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vmax(vint8m8_t op0, vint8m8_t op1, size_t op2){
  return vmax_vv_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vmax(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, vint8m8_t op3, size_t op4){
  return vmax_vv_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vmax(vint8mf2_t op0, vint8mf2_t op1, size_t op2){
  return vmax_vv_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vmax(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, vint8mf2_t op3, size_t op4){
  return vmax_vv_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vmax(vint8mf4_t op0, vint8mf4_t op1, size_t op2){
  return vmax_vv_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vmax(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, vint8mf4_t op3, size_t op4){
  return vmax_vv_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vmax(vint8mf8_t op0, vint8mf8_t op1, size_t op2){
  return vmax_vv_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vmax(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, vint8mf8_t op3, size_t op4){
  return vmax_vv_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vmax(vint16m1_t op0, vint16m1_t op1, size_t op2){
  return vmax_vv_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vmax(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, vint16m1_t op3, size_t op4){
  return vmax_vv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vmax(vint16m2_t op0, vint16m2_t op1, size_t op2){
  return vmax_vv_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vmax(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, vint16m2_t op3, size_t op4){
  return vmax_vv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vmax(vint16m4_t op0, vint16m4_t op1, size_t op2){
  return vmax_vv_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vmax(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, vint16m4_t op3, size_t op4){
  return vmax_vv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vmax(vint16m8_t op0, vint16m8_t op1, size_t op2){
  return vmax_vv_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vmax(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, vint16m8_t op3, size_t op4){
  return vmax_vv_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vmax(vint16mf2_t op0, vint16mf2_t op1, size_t op2){
  return vmax_vv_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vmax(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, vint16mf2_t op3, size_t op4){
  return vmax_vv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vmax(vint16mf4_t op0, vint16mf4_t op1, size_t op2){
  return vmax_vv_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vmax(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, vint16mf4_t op3, size_t op4){
  return vmax_vv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vmax(vint32m1_t op0, vint32m1_t op1, size_t op2){
  return vmax_vv_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vmax(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, vint32m1_t op3, size_t op4){
  return vmax_vv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vmax(vint32m2_t op0, vint32m2_t op1, size_t op2){
  return vmax_vv_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vmax(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, vint32m2_t op3, size_t op4){
  return vmax_vv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vmax(vint32m4_t op0, vint32m4_t op1, size_t op2){
  return vmax_vv_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vmax(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, vint32m4_t op3, size_t op4){
  return vmax_vv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vmax(vint32m8_t op0, vint32m8_t op1, size_t op2){
  return vmax_vv_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vmax(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, vint32m8_t op3, size_t op4){
  return vmax_vv_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vmax(vint32mf2_t op0, vint32mf2_t op1, size_t op2){
  return vmax_vv_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vmax(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, vint32mf2_t op3, size_t op4){
  return vmax_vv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vmax(vint64m1_t op0, vint64m1_t op1, size_t op2){
  return vmax_vv_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vmax(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, vint64m1_t op3, size_t op4){
  return vmax_vv_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vmax(vint64m2_t op0, vint64m2_t op1, size_t op2){
  return vmax_vv_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vmax(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, vint64m2_t op3, size_t op4){
  return vmax_vv_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vmax(vint64m4_t op0, vint64m4_t op1, size_t op2){
  return vmax_vv_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vmax(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, vint64m4_t op3, size_t op4){
  return vmax_vv_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vmax(vint64m8_t op0, vint64m8_t op1, size_t op2){
  return vmax_vv_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vmax(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, vint64m8_t op3, size_t op4){
  return vmax_vv_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vmax(vint8m1_t op0, int8_t op1, size_t op2){
  return vmax_vx_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vmax(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, int8_t op3, size_t op4){
  return vmax_vx_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vmax(vint8m2_t op0, int8_t op1, size_t op2){
  return vmax_vx_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vmax(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, int8_t op3, size_t op4){
  return vmax_vx_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vmax(vint8m4_t op0, int8_t op1, size_t op2){
  return vmax_vx_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vmax(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, int8_t op3, size_t op4){
  return vmax_vx_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vmax(vint8m8_t op0, int8_t op1, size_t op2){
  return vmax_vx_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vmax(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, int8_t op3, size_t op4){
  return vmax_vx_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vmax(vint8mf2_t op0, int8_t op1, size_t op2){
  return vmax_vx_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vmax(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, int8_t op3, size_t op4){
  return vmax_vx_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vmax(vint8mf4_t op0, int8_t op1, size_t op2){
  return vmax_vx_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vmax(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, int8_t op3, size_t op4){
  return vmax_vx_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vmax(vint8mf8_t op0, int8_t op1, size_t op2){
  return vmax_vx_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vmax(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, int8_t op3, size_t op4){
  return vmax_vx_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vmax(vint16m1_t op0, int16_t op1, size_t op2){
  return vmax_vx_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vmax(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, int16_t op3, size_t op4){
  return vmax_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vmax(vint16m2_t op0, int16_t op1, size_t op2){
  return vmax_vx_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vmax(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, int16_t op3, size_t op4){
  return vmax_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vmax(vint16m4_t op0, int16_t op1, size_t op2){
  return vmax_vx_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vmax(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, int16_t op3, size_t op4){
  return vmax_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vmax(vint16m8_t op0, int16_t op1, size_t op2){
  return vmax_vx_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vmax(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, int16_t op3, size_t op4){
  return vmax_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vmax(vint16mf2_t op0, int16_t op1, size_t op2){
  return vmax_vx_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vmax(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, int16_t op3, size_t op4){
  return vmax_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vmax(vint16mf4_t op0, int16_t op1, size_t op2){
  return vmax_vx_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vmax(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, int16_t op3, size_t op4){
  return vmax_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vmax(vint32m1_t op0, int32_t op1, size_t op2){
  return vmax_vx_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vmax(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, int32_t op3, size_t op4){
  return vmax_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vmax(vint32m2_t op0, int32_t op1, size_t op2){
  return vmax_vx_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vmax(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, int32_t op3, size_t op4){
  return vmax_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vmax(vint32m4_t op0, int32_t op1, size_t op2){
  return vmax_vx_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vmax(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, int32_t op3, size_t op4){
  return vmax_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vmax(vint32m8_t op0, int32_t op1, size_t op2){
  return vmax_vx_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vmax(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, int32_t op3, size_t op4){
  return vmax_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vmax(vint32mf2_t op0, int32_t op1, size_t op2){
  return vmax_vx_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vmax(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, int32_t op3, size_t op4){
  return vmax_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vmax(vint64m1_t op0, int64_t op1, size_t op2){
  return vmax_vx_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vmax(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, int64_t op3, size_t op4){
  return vmax_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vmax(vint64m2_t op0, int64_t op1, size_t op2){
  return vmax_vx_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vmax(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, int64_t op3, size_t op4){
  return vmax_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vmax(vint64m4_t op0, int64_t op1, size_t op2){
  return vmax_vx_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vmax(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, int64_t op3, size_t op4){
  return vmax_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vmax(vint64m8_t op0, int64_t op1, size_t op2){
  return vmax_vx_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vmax(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, int64_t op3, size_t op4){
  return vmax_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vmul(vint8m1_t op0, vint8m1_t op1, size_t op2){
  return vmul_vv_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vmul(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, vint8m1_t op3, size_t op4){
  return vmul_vv_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vmul(vint8m2_t op0, vint8m2_t op1, size_t op2){
  return vmul_vv_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vmul(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, vint8m2_t op3, size_t op4){
  return vmul_vv_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vmul(vint8m4_t op0, vint8m4_t op1, size_t op2){
  return vmul_vv_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vmul(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, vint8m4_t op3, size_t op4){
  return vmul_vv_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vmul(vint8m8_t op0, vint8m8_t op1, size_t op2){
  return vmul_vv_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vmul(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, vint8m8_t op3, size_t op4){
  return vmul_vv_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vmul(vint8mf2_t op0, vint8mf2_t op1, size_t op2){
  return vmul_vv_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vmul(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, vint8mf2_t op3, size_t op4){
  return vmul_vv_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vmul(vint8mf4_t op0, vint8mf4_t op1, size_t op2){
  return vmul_vv_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vmul(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, vint8mf4_t op3, size_t op4){
  return vmul_vv_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vmul(vint8mf8_t op0, vint8mf8_t op1, size_t op2){
  return vmul_vv_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vmul(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, vint8mf8_t op3, size_t op4){
  return vmul_vv_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vmul(vint16m1_t op0, vint16m1_t op1, size_t op2){
  return vmul_vv_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vmul(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, vint16m1_t op3, size_t op4){
  return vmul_vv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vmul(vint16m2_t op0, vint16m2_t op1, size_t op2){
  return vmul_vv_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vmul(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, vint16m2_t op3, size_t op4){
  return vmul_vv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vmul(vint16m4_t op0, vint16m4_t op1, size_t op2){
  return vmul_vv_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vmul(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, vint16m4_t op3, size_t op4){
  return vmul_vv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vmul(vint16m8_t op0, vint16m8_t op1, size_t op2){
  return vmul_vv_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vmul(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, vint16m8_t op3, size_t op4){
  return vmul_vv_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vmul(vint16mf2_t op0, vint16mf2_t op1, size_t op2){
  return vmul_vv_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vmul(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, vint16mf2_t op3, size_t op4){
  return vmul_vv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vmul(vint16mf4_t op0, vint16mf4_t op1, size_t op2){
  return vmul_vv_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vmul(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, vint16mf4_t op3, size_t op4){
  return vmul_vv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vmul(vint32m1_t op0, vint32m1_t op1, size_t op2){
  return vmul_vv_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vmul(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, vint32m1_t op3, size_t op4){
  return vmul_vv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vmul(vint32m2_t op0, vint32m2_t op1, size_t op2){
  return vmul_vv_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vmul(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, vint32m2_t op3, size_t op4){
  return vmul_vv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vmul(vint32m4_t op0, vint32m4_t op1, size_t op2){
  return vmul_vv_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vmul(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, vint32m4_t op3, size_t op4){
  return vmul_vv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vmul(vint32m8_t op0, vint32m8_t op1, size_t op2){
  return vmul_vv_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vmul(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, vint32m8_t op3, size_t op4){
  return vmul_vv_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vmul(vint32mf2_t op0, vint32mf2_t op1, size_t op2){
  return vmul_vv_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vmul(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, vint32mf2_t op3, size_t op4){
  return vmul_vv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vmul(vint64m1_t op0, vint64m1_t op1, size_t op2){
  return vmul_vv_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vmul(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, vint64m1_t op3, size_t op4){
  return vmul_vv_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vmul(vint64m2_t op0, vint64m2_t op1, size_t op2){
  return vmul_vv_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vmul(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, vint64m2_t op3, size_t op4){
  return vmul_vv_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vmul(vint64m4_t op0, vint64m4_t op1, size_t op2){
  return vmul_vv_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vmul(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, vint64m4_t op3, size_t op4){
  return vmul_vv_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vmul(vint64m8_t op0, vint64m8_t op1, size_t op2){
  return vmul_vv_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vmul(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, vint64m8_t op3, size_t op4){
  return vmul_vv_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vmul(vint8m1_t op0, int8_t op1, size_t op2){
  return vmul_vx_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vmul(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, int8_t op3, size_t op4){
  return vmul_vx_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vmul(vint8m2_t op0, int8_t op1, size_t op2){
  return vmul_vx_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vmul(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, int8_t op3, size_t op4){
  return vmul_vx_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vmul(vint8m4_t op0, int8_t op1, size_t op2){
  return vmul_vx_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vmul(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, int8_t op3, size_t op4){
  return vmul_vx_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vmul(vint8m8_t op0, int8_t op1, size_t op2){
  return vmul_vx_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vmul(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, int8_t op3, size_t op4){
  return vmul_vx_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vmul(vint8mf2_t op0, int8_t op1, size_t op2){
  return vmul_vx_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vmul(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, int8_t op3, size_t op4){
  return vmul_vx_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vmul(vint8mf4_t op0, int8_t op1, size_t op2){
  return vmul_vx_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vmul(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, int8_t op3, size_t op4){
  return vmul_vx_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vmul(vint8mf8_t op0, int8_t op1, size_t op2){
  return vmul_vx_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vmul(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, int8_t op3, size_t op4){
  return vmul_vx_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vmul(vint16m1_t op0, int16_t op1, size_t op2){
  return vmul_vx_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vmul(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, int16_t op3, size_t op4){
  return vmul_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vmul(vint16m2_t op0, int16_t op1, size_t op2){
  return vmul_vx_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vmul(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, int16_t op3, size_t op4){
  return vmul_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vmul(vint16m4_t op0, int16_t op1, size_t op2){
  return vmul_vx_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vmul(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, int16_t op3, size_t op4){
  return vmul_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vmul(vint16m8_t op0, int16_t op1, size_t op2){
  return vmul_vx_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vmul(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, int16_t op3, size_t op4){
  return vmul_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vmul(vint16mf2_t op0, int16_t op1, size_t op2){
  return vmul_vx_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vmul(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, int16_t op3, size_t op4){
  return vmul_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vmul(vint16mf4_t op0, int16_t op1, size_t op2){
  return vmul_vx_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vmul(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, int16_t op3, size_t op4){
  return vmul_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vmul(vint32m1_t op0, int32_t op1, size_t op2){
  return vmul_vx_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vmul(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, int32_t op3, size_t op4){
  return vmul_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vmul(vint32m2_t op0, int32_t op1, size_t op2){
  return vmul_vx_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vmul(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, int32_t op3, size_t op4){
  return vmul_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vmul(vint32m4_t op0, int32_t op1, size_t op2){
  return vmul_vx_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vmul(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, int32_t op3, size_t op4){
  return vmul_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vmul(vint32m8_t op0, int32_t op1, size_t op2){
  return vmul_vx_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vmul(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, int32_t op3, size_t op4){
  return vmul_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vmul(vint32mf2_t op0, int32_t op1, size_t op2){
  return vmul_vx_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vmul(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, int32_t op3, size_t op4){
  return vmul_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vmul(vint64m1_t op0, int64_t op1, size_t op2){
  return vmul_vx_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vmul(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, int64_t op3, size_t op4){
  return vmul_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vmul(vint64m2_t op0, int64_t op1, size_t op2){
  return vmul_vx_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vmul(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, int64_t op3, size_t op4){
  return vmul_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vmul(vint64m4_t op0, int64_t op1, size_t op2){
  return vmul_vx_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vmul(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, int64_t op3, size_t op4){
  return vmul_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vmul(vint64m8_t op0, int64_t op1, size_t op2){
  return vmul_vx_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vmul(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, int64_t op3, size_t op4){
  return vmul_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vmul(vuint8m1_t op0, vuint8m1_t op1, size_t op2){
  return vmul_vv_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vmul(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vmul_vv_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vmul(vuint8m2_t op0, vuint8m2_t op1, size_t op2){
  return vmul_vv_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vmul(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vmul_vv_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vmul(vuint8m4_t op0, vuint8m4_t op1, size_t op2){
  return vmul_vv_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vmul(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vmul_vv_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vmul(vuint8m8_t op0, vuint8m8_t op1, size_t op2){
  return vmul_vv_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vmul(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, vuint8m8_t op3, size_t op4){
  return vmul_vv_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vmul(vuint8mf2_t op0, vuint8mf2_t op1, size_t op2){
  return vmul_vv_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vmul(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vmul_vv_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vmul(vuint8mf4_t op0, vuint8mf4_t op1, size_t op2){
  return vmul_vv_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vmul(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vmul_vv_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vmul(vuint8mf8_t op0, vuint8mf8_t op1, size_t op2){
  return vmul_vv_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vmul(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vmul_vv_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vmul(vuint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vmul_vv_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vmul(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vmul_vv_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vmul(vuint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vmul_vv_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vmul(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vmul_vv_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vmul(vuint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vmul_vv_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vmul(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vmul_vv_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vmul(vuint16m8_t op0, vuint16m8_t op1, size_t op2){
  return vmul_vv_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vmul(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vmul_vv_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vmul(vuint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vmul_vv_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vmul(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vmul_vv_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vmul(vuint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vmul_vv_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vmul(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vmul_vv_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vmul(vuint32m1_t op0, vuint32m1_t op1, size_t op2){
  return vmul_vv_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vmul(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vmul_vv_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vmul(vuint32m2_t op0, vuint32m2_t op1, size_t op2){
  return vmul_vv_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vmul(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vmul_vv_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vmul(vuint32m4_t op0, vuint32m4_t op1, size_t op2){
  return vmul_vv_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vmul(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vmul_vv_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vmul(vuint32m8_t op0, vuint32m8_t op1, size_t op2){
  return vmul_vv_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vmul(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, vuint32m8_t op3, size_t op4){
  return vmul_vv_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vmul(vuint32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vmul_vv_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vmul(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vmul_vv_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vmul(vuint64m1_t op0, vuint64m1_t op1, size_t op2){
  return vmul_vv_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vmul(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vmul_vv_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vmul(vuint64m2_t op0, vuint64m2_t op1, size_t op2){
  return vmul_vv_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vmul(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, vuint64m2_t op3, size_t op4){
  return vmul_vv_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vmul(vuint64m4_t op0, vuint64m4_t op1, size_t op2){
  return vmul_vv_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vmul(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, vuint64m4_t op3, size_t op4){
  return vmul_vv_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vmul(vuint64m8_t op0, vuint64m8_t op1, size_t op2){
  return vmul_vv_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vmul(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, vuint64m8_t op3, size_t op4){
  return vmul_vv_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vmul(vuint8m1_t op0, uint8_t op1, size_t op2){
  return vmul_vx_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vmul(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, uint8_t op3, size_t op4){
  return vmul_vx_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vmul(vuint8m2_t op0, uint8_t op1, size_t op2){
  return vmul_vx_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vmul(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, uint8_t op3, size_t op4){
  return vmul_vx_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vmul(vuint8m4_t op0, uint8_t op1, size_t op2){
  return vmul_vx_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vmul(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, uint8_t op3, size_t op4){
  return vmul_vx_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vmul(vuint8m8_t op0, uint8_t op1, size_t op2){
  return vmul_vx_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vmul(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, uint8_t op3, size_t op4){
  return vmul_vx_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vmul(vuint8mf2_t op0, uint8_t op1, size_t op2){
  return vmul_vx_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vmul(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, uint8_t op3, size_t op4){
  return vmul_vx_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vmul(vuint8mf4_t op0, uint8_t op1, size_t op2){
  return vmul_vx_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vmul(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, uint8_t op3, size_t op4){
  return vmul_vx_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vmul(vuint8mf8_t op0, uint8_t op1, size_t op2){
  return vmul_vx_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vmul(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, uint8_t op3, size_t op4){
  return vmul_vx_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vmul(vuint16m1_t op0, uint16_t op1, size_t op2){
  return vmul_vx_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vmul(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, uint16_t op3, size_t op4){
  return vmul_vx_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vmul(vuint16m2_t op0, uint16_t op1, size_t op2){
  return vmul_vx_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vmul(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, uint16_t op3, size_t op4){
  return vmul_vx_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vmul(vuint16m4_t op0, uint16_t op1, size_t op2){
  return vmul_vx_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vmul(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, uint16_t op3, size_t op4){
  return vmul_vx_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vmul(vuint16m8_t op0, uint16_t op1, size_t op2){
  return vmul_vx_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vmul(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, uint16_t op3, size_t op4){
  return vmul_vx_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vmul(vuint16mf2_t op0, uint16_t op1, size_t op2){
  return vmul_vx_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vmul(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, uint16_t op3, size_t op4){
  return vmul_vx_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vmul(vuint16mf4_t op0, uint16_t op1, size_t op2){
  return vmul_vx_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vmul(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, uint16_t op3, size_t op4){
  return vmul_vx_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vmul(vuint32m1_t op0, uint32_t op1, size_t op2){
  return vmul_vx_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vmul(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, uint32_t op3, size_t op4){
  return vmul_vx_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vmul(vuint32m2_t op0, uint32_t op1, size_t op2){
  return vmul_vx_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vmul(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, uint32_t op3, size_t op4){
  return vmul_vx_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vmul(vuint32m4_t op0, uint32_t op1, size_t op2){
  return vmul_vx_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vmul(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, uint32_t op3, size_t op4){
  return vmul_vx_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vmul(vuint32m8_t op0, uint32_t op1, size_t op2){
  return vmul_vx_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vmul(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, uint32_t op3, size_t op4){
  return vmul_vx_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vmul(vuint32mf2_t op0, uint32_t op1, size_t op2){
  return vmul_vx_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vmul(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, uint32_t op3, size_t op4){
  return vmul_vx_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vmul(vuint64m1_t op0, uint64_t op1, size_t op2){
  return vmul_vx_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vmul(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, uint64_t op3, size_t op4){
  return vmul_vx_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vmul(vuint64m2_t op0, uint64_t op1, size_t op2){
  return vmul_vx_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vmul(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, uint64_t op3, size_t op4){
  return vmul_vx_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vmul(vuint64m4_t op0, uint64_t op1, size_t op2){
  return vmul_vx_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vmul(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, uint64_t op3, size_t op4){
  return vmul_vx_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vmul(vuint64m8_t op0, uint64_t op1, size_t op2){
  return vmul_vx_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vmul(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, uint64_t op3, size_t op4){
  return vmul_vx_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vmulh(vint8m1_t op0, vint8m1_t op1, size_t op2){
  return vmulh_vv_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vmulh(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, vint8m1_t op3, size_t op4){
  return vmulh_vv_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vmulh(vint8m2_t op0, vint8m2_t op1, size_t op2){
  return vmulh_vv_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vmulh(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, vint8m2_t op3, size_t op4){
  return vmulh_vv_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vmulh(vint8m4_t op0, vint8m4_t op1, size_t op2){
  return vmulh_vv_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vmulh(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, vint8m4_t op3, size_t op4){
  return vmulh_vv_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vmulh(vint8m8_t op0, vint8m8_t op1, size_t op2){
  return vmulh_vv_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vmulh(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, vint8m8_t op3, size_t op4){
  return vmulh_vv_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vmulh(vint8mf2_t op0, vint8mf2_t op1, size_t op2){
  return vmulh_vv_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vmulh(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, vint8mf2_t op3, size_t op4){
  return vmulh_vv_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vmulh(vint8mf4_t op0, vint8mf4_t op1, size_t op2){
  return vmulh_vv_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vmulh(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, vint8mf4_t op3, size_t op4){
  return vmulh_vv_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vmulh(vint8mf8_t op0, vint8mf8_t op1, size_t op2){
  return vmulh_vv_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vmulh(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, vint8mf8_t op3, size_t op4){
  return vmulh_vv_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vmulh(vint16m1_t op0, vint16m1_t op1, size_t op2){
  return vmulh_vv_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vmulh(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, vint16m1_t op3, size_t op4){
  return vmulh_vv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vmulh(vint16m2_t op0, vint16m2_t op1, size_t op2){
  return vmulh_vv_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vmulh(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, vint16m2_t op3, size_t op4){
  return vmulh_vv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vmulh(vint16m4_t op0, vint16m4_t op1, size_t op2){
  return vmulh_vv_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vmulh(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, vint16m4_t op3, size_t op4){
  return vmulh_vv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vmulh(vint16m8_t op0, vint16m8_t op1, size_t op2){
  return vmulh_vv_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vmulh(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, vint16m8_t op3, size_t op4){
  return vmulh_vv_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vmulh(vint16mf2_t op0, vint16mf2_t op1, size_t op2){
  return vmulh_vv_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vmulh(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, vint16mf2_t op3, size_t op4){
  return vmulh_vv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vmulh(vint16mf4_t op0, vint16mf4_t op1, size_t op2){
  return vmulh_vv_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vmulh(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, vint16mf4_t op3, size_t op4){
  return vmulh_vv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vmulh(vint32m1_t op0, vint32m1_t op1, size_t op2){
  return vmulh_vv_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vmulh(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, vint32m1_t op3, size_t op4){
  return vmulh_vv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vmulh(vint32m2_t op0, vint32m2_t op1, size_t op2){
  return vmulh_vv_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vmulh(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, vint32m2_t op3, size_t op4){
  return vmulh_vv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vmulh(vint32m4_t op0, vint32m4_t op1, size_t op2){
  return vmulh_vv_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vmulh(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, vint32m4_t op3, size_t op4){
  return vmulh_vv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vmulh(vint32m8_t op0, vint32m8_t op1, size_t op2){
  return vmulh_vv_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vmulh(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, vint32m8_t op3, size_t op4){
  return vmulh_vv_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vmulh(vint32mf2_t op0, vint32mf2_t op1, size_t op2){
  return vmulh_vv_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vmulh(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, vint32mf2_t op3, size_t op4){
  return vmulh_vv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vmulh(vint64m1_t op0, vint64m1_t op1, size_t op2){
  return vmulh_vv_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vmulh(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, vint64m1_t op3, size_t op4){
  return vmulh_vv_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vmulh(vint64m2_t op0, vint64m2_t op1, size_t op2){
  return vmulh_vv_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vmulh(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, vint64m2_t op3, size_t op4){
  return vmulh_vv_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vmulh(vint64m4_t op0, vint64m4_t op1, size_t op2){
  return vmulh_vv_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vmulh(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, vint64m4_t op3, size_t op4){
  return vmulh_vv_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vmulh(vint64m8_t op0, vint64m8_t op1, size_t op2){
  return vmulh_vv_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vmulh(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, vint64m8_t op3, size_t op4){
  return vmulh_vv_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vmulh(vint8m1_t op0, int8_t op1, size_t op2){
  return vmulh_vx_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vmulh(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, int8_t op3, size_t op4){
  return vmulh_vx_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vmulh(vint8m2_t op0, int8_t op1, size_t op2){
  return vmulh_vx_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vmulh(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, int8_t op3, size_t op4){
  return vmulh_vx_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vmulh(vint8m4_t op0, int8_t op1, size_t op2){
  return vmulh_vx_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vmulh(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, int8_t op3, size_t op4){
  return vmulh_vx_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vmulh(vint8m8_t op0, int8_t op1, size_t op2){
  return vmulh_vx_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vmulh(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, int8_t op3, size_t op4){
  return vmulh_vx_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vmulh(vint8mf2_t op0, int8_t op1, size_t op2){
  return vmulh_vx_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vmulh(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, int8_t op3, size_t op4){
  return vmulh_vx_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vmulh(vint8mf4_t op0, int8_t op1, size_t op2){
  return vmulh_vx_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vmulh(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, int8_t op3, size_t op4){
  return vmulh_vx_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vmulh(vint8mf8_t op0, int8_t op1, size_t op2){
  return vmulh_vx_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vmulh(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, int8_t op3, size_t op4){
  return vmulh_vx_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vmulh(vint16m1_t op0, int16_t op1, size_t op2){
  return vmulh_vx_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vmulh(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, int16_t op3, size_t op4){
  return vmulh_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vmulh(vint16m2_t op0, int16_t op1, size_t op2){
  return vmulh_vx_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vmulh(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, int16_t op3, size_t op4){
  return vmulh_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vmulh(vint16m4_t op0, int16_t op1, size_t op2){
  return vmulh_vx_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vmulh(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, int16_t op3, size_t op4){
  return vmulh_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vmulh(vint16m8_t op0, int16_t op1, size_t op2){
  return vmulh_vx_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vmulh(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, int16_t op3, size_t op4){
  return vmulh_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vmulh(vint16mf2_t op0, int16_t op1, size_t op2){
  return vmulh_vx_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vmulh(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, int16_t op3, size_t op4){
  return vmulh_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vmulh(vint16mf4_t op0, int16_t op1, size_t op2){
  return vmulh_vx_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vmulh(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, int16_t op3, size_t op4){
  return vmulh_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vmulh(vint32m1_t op0, int32_t op1, size_t op2){
  return vmulh_vx_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vmulh(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, int32_t op3, size_t op4){
  return vmulh_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vmulh(vint32m2_t op0, int32_t op1, size_t op2){
  return vmulh_vx_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vmulh(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, int32_t op3, size_t op4){
  return vmulh_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vmulh(vint32m4_t op0, int32_t op1, size_t op2){
  return vmulh_vx_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vmulh(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, int32_t op3, size_t op4){
  return vmulh_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vmulh(vint32m8_t op0, int32_t op1, size_t op2){
  return vmulh_vx_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vmulh(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, int32_t op3, size_t op4){
  return vmulh_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vmulh(vint32mf2_t op0, int32_t op1, size_t op2){
  return vmulh_vx_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vmulh(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, int32_t op3, size_t op4){
  return vmulh_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vmulh(vint64m1_t op0, int64_t op1, size_t op2){
  return vmulh_vx_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vmulh(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, int64_t op3, size_t op4){
  return vmulh_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vmulh(vint64m2_t op0, int64_t op1, size_t op2){
  return vmulh_vx_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vmulh(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, int64_t op3, size_t op4){
  return vmulh_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vmulh(vint64m4_t op0, int64_t op1, size_t op2){
  return vmulh_vx_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vmulh(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, int64_t op3, size_t op4){
  return vmulh_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vmulh(vint64m8_t op0, int64_t op1, size_t op2){
  return vmulh_vx_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vmulh(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, int64_t op3, size_t op4){
  return vmulh_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vmulhu(vuint8m1_t op0, vuint8m1_t op1, size_t op2){
  return vmulhu_vv_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vmulhu(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vmulhu_vv_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vmulhu(vuint8m2_t op0, vuint8m2_t op1, size_t op2){
  return vmulhu_vv_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vmulhu(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vmulhu_vv_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vmulhu(vuint8m4_t op0, vuint8m4_t op1, size_t op2){
  return vmulhu_vv_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vmulhu(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vmulhu_vv_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vmulhu(vuint8m8_t op0, vuint8m8_t op1, size_t op2){
  return vmulhu_vv_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vmulhu(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, vuint8m8_t op3, size_t op4){
  return vmulhu_vv_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vmulhu(vuint8mf2_t op0, vuint8mf2_t op1, size_t op2){
  return vmulhu_vv_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vmulhu(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vmulhu_vv_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vmulhu(vuint8mf4_t op0, vuint8mf4_t op1, size_t op2){
  return vmulhu_vv_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vmulhu(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vmulhu_vv_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vmulhu(vuint8mf8_t op0, vuint8mf8_t op1, size_t op2){
  return vmulhu_vv_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vmulhu(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vmulhu_vv_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vmulhu(vuint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vmulhu_vv_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vmulhu(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vmulhu_vv_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vmulhu(vuint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vmulhu_vv_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vmulhu(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vmulhu_vv_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vmulhu(vuint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vmulhu_vv_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vmulhu(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vmulhu_vv_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vmulhu(vuint16m8_t op0, vuint16m8_t op1, size_t op2){
  return vmulhu_vv_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vmulhu(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vmulhu_vv_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vmulhu(vuint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vmulhu_vv_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vmulhu(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vmulhu_vv_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vmulhu(vuint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vmulhu_vv_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vmulhu(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vmulhu_vv_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vmulhu(vuint32m1_t op0, vuint32m1_t op1, size_t op2){
  return vmulhu_vv_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vmulhu(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vmulhu_vv_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vmulhu(vuint32m2_t op0, vuint32m2_t op1, size_t op2){
  return vmulhu_vv_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vmulhu(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vmulhu_vv_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vmulhu(vuint32m4_t op0, vuint32m4_t op1, size_t op2){
  return vmulhu_vv_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vmulhu(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vmulhu_vv_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vmulhu(vuint32m8_t op0, vuint32m8_t op1, size_t op2){
  return vmulhu_vv_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vmulhu(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, vuint32m8_t op3, size_t op4){
  return vmulhu_vv_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vmulhu(vuint32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vmulhu_vv_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vmulhu(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vmulhu_vv_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vmulhu(vuint64m1_t op0, vuint64m1_t op1, size_t op2){
  return vmulhu_vv_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vmulhu(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vmulhu_vv_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vmulhu(vuint64m2_t op0, vuint64m2_t op1, size_t op2){
  return vmulhu_vv_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vmulhu(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, vuint64m2_t op3, size_t op4){
  return vmulhu_vv_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vmulhu(vuint64m4_t op0, vuint64m4_t op1, size_t op2){
  return vmulhu_vv_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vmulhu(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, vuint64m4_t op3, size_t op4){
  return vmulhu_vv_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vmulhu(vuint64m8_t op0, vuint64m8_t op1, size_t op2){
  return vmulhu_vv_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vmulhu(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, vuint64m8_t op3, size_t op4){
  return vmulhu_vv_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vmulhu(vuint8m1_t op0, uint8_t op1, size_t op2){
  return vmulhu_vx_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vmulhu(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, uint8_t op3, size_t op4){
  return vmulhu_vx_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vmulhu(vuint8m2_t op0, uint8_t op1, size_t op2){
  return vmulhu_vx_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vmulhu(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, uint8_t op3, size_t op4){
  return vmulhu_vx_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vmulhu(vuint8m4_t op0, uint8_t op1, size_t op2){
  return vmulhu_vx_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vmulhu(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, uint8_t op3, size_t op4){
  return vmulhu_vx_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vmulhu(vuint8m8_t op0, uint8_t op1, size_t op2){
  return vmulhu_vx_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vmulhu(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, uint8_t op3, size_t op4){
  return vmulhu_vx_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vmulhu(vuint8mf2_t op0, uint8_t op1, size_t op2){
  return vmulhu_vx_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vmulhu(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, uint8_t op3, size_t op4){
  return vmulhu_vx_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vmulhu(vuint8mf4_t op0, uint8_t op1, size_t op2){
  return vmulhu_vx_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vmulhu(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, uint8_t op3, size_t op4){
  return vmulhu_vx_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vmulhu(vuint8mf8_t op0, uint8_t op1, size_t op2){
  return vmulhu_vx_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vmulhu(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, uint8_t op3, size_t op4){
  return vmulhu_vx_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vmulhu(vuint16m1_t op0, uint16_t op1, size_t op2){
  return vmulhu_vx_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vmulhu(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, uint16_t op3, size_t op4){
  return vmulhu_vx_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vmulhu(vuint16m2_t op0, uint16_t op1, size_t op2){
  return vmulhu_vx_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vmulhu(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, uint16_t op3, size_t op4){
  return vmulhu_vx_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vmulhu(vuint16m4_t op0, uint16_t op1, size_t op2){
  return vmulhu_vx_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vmulhu(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, uint16_t op3, size_t op4){
  return vmulhu_vx_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vmulhu(vuint16m8_t op0, uint16_t op1, size_t op2){
  return vmulhu_vx_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vmulhu(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, uint16_t op3, size_t op4){
  return vmulhu_vx_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vmulhu(vuint16mf2_t op0, uint16_t op1, size_t op2){
  return vmulhu_vx_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vmulhu(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, uint16_t op3, size_t op4){
  return vmulhu_vx_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vmulhu(vuint16mf4_t op0, uint16_t op1, size_t op2){
  return vmulhu_vx_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vmulhu(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, uint16_t op3, size_t op4){
  return vmulhu_vx_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vmulhu(vuint32m1_t op0, uint32_t op1, size_t op2){
  return vmulhu_vx_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vmulhu(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, uint32_t op3, size_t op4){
  return vmulhu_vx_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vmulhu(vuint32m2_t op0, uint32_t op1, size_t op2){
  return vmulhu_vx_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vmulhu(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, uint32_t op3, size_t op4){
  return vmulhu_vx_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vmulhu(vuint32m4_t op0, uint32_t op1, size_t op2){
  return vmulhu_vx_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vmulhu(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, uint32_t op3, size_t op4){
  return vmulhu_vx_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vmulhu(vuint32m8_t op0, uint32_t op1, size_t op2){
  return vmulhu_vx_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vmulhu(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, uint32_t op3, size_t op4){
  return vmulhu_vx_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vmulhu(vuint32mf2_t op0, uint32_t op1, size_t op2){
  return vmulhu_vx_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vmulhu(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, uint32_t op3, size_t op4){
  return vmulhu_vx_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vmulhu(vuint64m1_t op0, uint64_t op1, size_t op2){
  return vmulhu_vx_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vmulhu(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, uint64_t op3, size_t op4){
  return vmulhu_vx_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vmulhu(vuint64m2_t op0, uint64_t op1, size_t op2){
  return vmulhu_vx_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vmulhu(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, uint64_t op3, size_t op4){
  return vmulhu_vx_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vmulhu(vuint64m4_t op0, uint64_t op1, size_t op2){
  return vmulhu_vx_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vmulhu(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, uint64_t op3, size_t op4){
  return vmulhu_vx_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vmulhu(vuint64m8_t op0, uint64_t op1, size_t op2){
  return vmulhu_vx_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vmulhu(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, uint64_t op3, size_t op4){
  return vmulhu_vx_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vle64(vbool64_t op0, vuint64m1_t op1, const uint64_t * op2, size_t op3){
  return vle64_v_u64m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m2_t vle64(vbool32_t op0, vuint64m2_t op1, const uint64_t * op2, size_t op3){
  return vle64_v_u64m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m4_t vle64(vbool16_t op0, vuint64m4_t op1, const uint64_t * op2, size_t op3){
  return vle64_v_u64m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m8_t vle64(vbool8_t op0, vuint64m8_t op1, const uint64_t * op2, size_t op3){
  return vle64_v_u64m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vmulhsu(vint8m1_t op0, vuint8m1_t op1, size_t op2){
  return vmulhsu_vv_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vmulhsu(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vmulhsu_vv_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vmulhsu(vint8m2_t op0, vuint8m2_t op1, size_t op2){
  return vmulhsu_vv_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vmulhsu(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vmulhsu_vv_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vmulhsu(vint8m4_t op0, vuint8m4_t op1, size_t op2){
  return vmulhsu_vv_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vmulhsu(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vmulhsu_vv_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vmulhsu(vint8m8_t op0, vuint8m8_t op1, size_t op2){
  return vmulhsu_vv_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vmulhsu(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, vuint8m8_t op3, size_t op4){
  return vmulhsu_vv_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vmulhsu(vint8mf2_t op0, vuint8mf2_t op1, size_t op2){
  return vmulhsu_vv_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vmulhsu(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vmulhsu_vv_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vmulhsu(vint8mf4_t op0, vuint8mf4_t op1, size_t op2){
  return vmulhsu_vv_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vmulhsu(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vmulhsu_vv_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vmulhsu(vint8mf8_t op0, vuint8mf8_t op1, size_t op2){
  return vmulhsu_vv_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vmulhsu(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vmulhsu_vv_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vmulhsu(vint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vmulhsu_vv_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vmulhsu(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vmulhsu_vv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vmulhsu(vint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vmulhsu_vv_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vmulhsu(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vmulhsu_vv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vmulhsu(vint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vmulhsu_vv_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vmulhsu(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vmulhsu_vv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vmulhsu(vint16m8_t op0, vuint16m8_t op1, size_t op2){
  return vmulhsu_vv_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vmulhsu(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vmulhsu_vv_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vmulhsu(vint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vmulhsu_vv_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vmulhsu(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vmulhsu_vv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vmulhsu(vint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vmulhsu_vv_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vmulhsu(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vmulhsu_vv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vmulhsu(vint32m1_t op0, vuint32m1_t op1, size_t op2){
  return vmulhsu_vv_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vmulhsu(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vmulhsu_vv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vmulhsu(vint32m2_t op0, vuint32m2_t op1, size_t op2){
  return vmulhsu_vv_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vmulhsu(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vmulhsu_vv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vmulhsu(vint32m4_t op0, vuint32m4_t op1, size_t op2){
  return vmulhsu_vv_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vmulhsu(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vmulhsu_vv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vmulhsu(vint32m8_t op0, vuint32m8_t op1, size_t op2){
  return vmulhsu_vv_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vmulhsu(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, vuint32m8_t op3, size_t op4){
  return vmulhsu_vv_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vmulhsu(vint32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vmulhsu_vv_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vmulhsu(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vmulhsu_vv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vmulhsu(vint64m1_t op0, vuint64m1_t op1, size_t op2){
  return vmulhsu_vv_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vmulhsu(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vmulhsu_vv_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vmulhsu(vint64m2_t op0, vuint64m2_t op1, size_t op2){
  return vmulhsu_vv_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vmulhsu(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, vuint64m2_t op3, size_t op4){
  return vmulhsu_vv_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vmulhsu(vint64m4_t op0, vuint64m4_t op1, size_t op2){
  return vmulhsu_vv_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vmulhsu(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, vuint64m4_t op3, size_t op4){
  return vmulhsu_vv_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vmulhsu(vint64m8_t op0, vuint64m8_t op1, size_t op2){
  return vmulhsu_vv_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vmulhsu(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, vuint64m8_t op3, size_t op4){
  return vmulhsu_vv_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vmulhsu(vint8m1_t op0, uint8_t op1, size_t op2){
  return vmulhsu_vx_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vmulhsu(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, uint8_t op3, size_t op4){
  return vmulhsu_vx_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vmulhsu(vint8m2_t op0, uint8_t op1, size_t op2){
  return vmulhsu_vx_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vmulhsu(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, uint8_t op3, size_t op4){
  return vmulhsu_vx_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vmulhsu(vint8m4_t op0, uint8_t op1, size_t op2){
  return vmulhsu_vx_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vmulhsu(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, uint8_t op3, size_t op4){
  return vmulhsu_vx_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vmulhsu(vint8m8_t op0, uint8_t op1, size_t op2){
  return vmulhsu_vx_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vmulhsu(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, uint8_t op3, size_t op4){
  return vmulhsu_vx_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vmulhsu(vint8mf2_t op0, uint8_t op1, size_t op2){
  return vmulhsu_vx_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vmulhsu(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, uint8_t op3, size_t op4){
  return vmulhsu_vx_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vmulhsu(vint8mf4_t op0, uint8_t op1, size_t op2){
  return vmulhsu_vx_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vmulhsu(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, uint8_t op3, size_t op4){
  return vmulhsu_vx_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vmulhsu(vint8mf8_t op0, uint8_t op1, size_t op2){
  return vmulhsu_vx_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vmulhsu(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, uint8_t op3, size_t op4){
  return vmulhsu_vx_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vmulhsu(vint16m1_t op0, uint16_t op1, size_t op2){
  return vmulhsu_vx_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vmulhsu(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, uint16_t op3, size_t op4){
  return vmulhsu_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vmulhsu(vint16m2_t op0, uint16_t op1, size_t op2){
  return vmulhsu_vx_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vmulhsu(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, uint16_t op3, size_t op4){
  return vmulhsu_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vmulhsu(vint16m4_t op0, uint16_t op1, size_t op2){
  return vmulhsu_vx_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vmulhsu(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, uint16_t op3, size_t op4){
  return vmulhsu_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vmulhsu(vint16m8_t op0, uint16_t op1, size_t op2){
  return vmulhsu_vx_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vmulhsu(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, uint16_t op3, size_t op4){
  return vmulhsu_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vmulhsu(vint16mf2_t op0, uint16_t op1, size_t op2){
  return vmulhsu_vx_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vmulhsu(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, uint16_t op3, size_t op4){
  return vmulhsu_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vmulhsu(vint16mf4_t op0, uint16_t op1, size_t op2){
  return vmulhsu_vx_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vmulhsu(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, uint16_t op3, size_t op4){
  return vmulhsu_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vmulhsu(vint32m1_t op0, uint32_t op1, size_t op2){
  return vmulhsu_vx_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vmulhsu(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, uint32_t op3, size_t op4){
  return vmulhsu_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vmulhsu(vint32m2_t op0, uint32_t op1, size_t op2){
  return vmulhsu_vx_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vmulhsu(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, uint32_t op3, size_t op4){
  return vmulhsu_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vmulhsu(vint32m4_t op0, uint32_t op1, size_t op2){
  return vmulhsu_vx_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vmulhsu(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, uint32_t op3, size_t op4){
  return vmulhsu_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vmulhsu(vint32m8_t op0, uint32_t op1, size_t op2){
  return vmulhsu_vx_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vmulhsu(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, uint32_t op3, size_t op4){
  return vmulhsu_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vmulhsu(vint32mf2_t op0, uint32_t op1, size_t op2){
  return vmulhsu_vx_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vmulhsu(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, uint32_t op3, size_t op4){
  return vmulhsu_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vmulhsu(vint64m1_t op0, uint64_t op1, size_t op2){
  return vmulhsu_vx_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vmulhsu(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, uint64_t op3, size_t op4){
  return vmulhsu_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vmulhsu(vint64m2_t op0, uint64_t op1, size_t op2){
  return vmulhsu_vx_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vmulhsu(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, uint64_t op3, size_t op4){
  return vmulhsu_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vmulhsu(vint64m4_t op0, uint64_t op1, size_t op2){
  return vmulhsu_vx_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vmulhsu(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, uint64_t op3, size_t op4){
  return vmulhsu_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vmulhsu(vint64m8_t op0, uint64_t op1, size_t op2){
  return vmulhsu_vx_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vmulhsu(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, uint64_t op3, size_t op4){
  return vmulhsu_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vdivu(vuint8m1_t op0, vuint8m1_t op1, size_t op2){
  return vdivu_vv_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vdivu(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vdivu_vv_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vdivu(vuint8m2_t op0, vuint8m2_t op1, size_t op2){
  return vdivu_vv_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vdivu(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vdivu_vv_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vdivu(vuint8m4_t op0, vuint8m4_t op1, size_t op2){
  return vdivu_vv_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vdivu(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vdivu_vv_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vdivu(vuint8m8_t op0, vuint8m8_t op1, size_t op2){
  return vdivu_vv_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vdivu(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, vuint8m8_t op3, size_t op4){
  return vdivu_vv_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vdivu(vuint8mf2_t op0, vuint8mf2_t op1, size_t op2){
  return vdivu_vv_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vdivu(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vdivu_vv_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vdivu(vuint8mf4_t op0, vuint8mf4_t op1, size_t op2){
  return vdivu_vv_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vdivu(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vdivu_vv_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vdivu(vuint8mf8_t op0, vuint8mf8_t op1, size_t op2){
  return vdivu_vv_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vdivu(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vdivu_vv_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vdivu(vuint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vdivu_vv_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vdivu(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vdivu_vv_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vdivu(vuint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vdivu_vv_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vdivu(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vdivu_vv_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vdivu(vuint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vdivu_vv_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vdivu(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vdivu_vv_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vdivu(vuint16m8_t op0, vuint16m8_t op1, size_t op2){
  return vdivu_vv_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vdivu(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vdivu_vv_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vdivu(vuint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vdivu_vv_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vdivu(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vdivu_vv_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vdivu(vuint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vdivu_vv_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vdivu(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vdivu_vv_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vdivu(vuint32m1_t op0, vuint32m1_t op1, size_t op2){
  return vdivu_vv_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vdivu(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vdivu_vv_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vdivu(vuint32m2_t op0, vuint32m2_t op1, size_t op2){
  return vdivu_vv_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vdivu(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vdivu_vv_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vdivu(vuint32m4_t op0, vuint32m4_t op1, size_t op2){
  return vdivu_vv_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vdivu(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vdivu_vv_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vdivu(vuint32m8_t op0, vuint32m8_t op1, size_t op2){
  return vdivu_vv_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vdivu(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, vuint32m8_t op3, size_t op4){
  return vdivu_vv_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vdivu(vuint32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vdivu_vv_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vdivu(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vdivu_vv_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vdivu(vuint64m1_t op0, vuint64m1_t op1, size_t op2){
  return vdivu_vv_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vdivu(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vdivu_vv_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vdivu(vuint64m2_t op0, vuint64m2_t op1, size_t op2){
  return vdivu_vv_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vdivu(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, vuint64m2_t op3, size_t op4){
  return vdivu_vv_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vdivu(vuint64m4_t op0, vuint64m4_t op1, size_t op2){
  return vdivu_vv_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vdivu(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, vuint64m4_t op3, size_t op4){
  return vdivu_vv_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vdivu(vuint64m8_t op0, vuint64m8_t op1, size_t op2){
  return vdivu_vv_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vdivu(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, vuint64m8_t op3, size_t op4){
  return vdivu_vv_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vdivu(vuint8m1_t op0, uint8_t op1, size_t op2){
  return vdivu_vx_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vdivu(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, uint8_t op3, size_t op4){
  return vdivu_vx_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vdivu(vuint8m2_t op0, uint8_t op1, size_t op2){
  return vdivu_vx_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vdivu(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, uint8_t op3, size_t op4){
  return vdivu_vx_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vdivu(vuint8m4_t op0, uint8_t op1, size_t op2){
  return vdivu_vx_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vdivu(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, uint8_t op3, size_t op4){
  return vdivu_vx_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vdivu(vuint8m8_t op0, uint8_t op1, size_t op2){
  return vdivu_vx_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vdivu(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, uint8_t op3, size_t op4){
  return vdivu_vx_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vdivu(vuint8mf2_t op0, uint8_t op1, size_t op2){
  return vdivu_vx_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vdivu(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, uint8_t op3, size_t op4){
  return vdivu_vx_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vdivu(vuint8mf4_t op0, uint8_t op1, size_t op2){
  return vdivu_vx_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vdivu(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, uint8_t op3, size_t op4){
  return vdivu_vx_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vdivu(vuint8mf8_t op0, uint8_t op1, size_t op2){
  return vdivu_vx_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vdivu(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, uint8_t op3, size_t op4){
  return vdivu_vx_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vdivu(vuint16m1_t op0, uint16_t op1, size_t op2){
  return vdivu_vx_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vdivu(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, uint16_t op3, size_t op4){
  return vdivu_vx_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vdivu(vuint16m2_t op0, uint16_t op1, size_t op2){
  return vdivu_vx_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vdivu(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, uint16_t op3, size_t op4){
  return vdivu_vx_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vdivu(vuint16m4_t op0, uint16_t op1, size_t op2){
  return vdivu_vx_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vdivu(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, uint16_t op3, size_t op4){
  return vdivu_vx_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vdivu(vuint16m8_t op0, uint16_t op1, size_t op2){
  return vdivu_vx_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vdivu(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, uint16_t op3, size_t op4){
  return vdivu_vx_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vdivu(vuint16mf2_t op0, uint16_t op1, size_t op2){
  return vdivu_vx_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vdivu(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, uint16_t op3, size_t op4){
  return vdivu_vx_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vdivu(vuint16mf4_t op0, uint16_t op1, size_t op2){
  return vdivu_vx_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vdivu(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, uint16_t op3, size_t op4){
  return vdivu_vx_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vdivu(vuint32m1_t op0, uint32_t op1, size_t op2){
  return vdivu_vx_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vdivu(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, uint32_t op3, size_t op4){
  return vdivu_vx_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vdivu(vuint32m2_t op0, uint32_t op1, size_t op2){
  return vdivu_vx_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vdivu(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, uint32_t op3, size_t op4){
  return vdivu_vx_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vdivu(vuint32m4_t op0, uint32_t op1, size_t op2){
  return vdivu_vx_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vdivu(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, uint32_t op3, size_t op4){
  return vdivu_vx_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vdivu(vuint32m8_t op0, uint32_t op1, size_t op2){
  return vdivu_vx_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vdivu(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, uint32_t op3, size_t op4){
  return vdivu_vx_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vdivu(vuint32mf2_t op0, uint32_t op1, size_t op2){
  return vdivu_vx_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vdivu(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, uint32_t op3, size_t op4){
  return vdivu_vx_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vdivu(vuint64m1_t op0, uint64_t op1, size_t op2){
  return vdivu_vx_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vdivu(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, uint64_t op3, size_t op4){
  return vdivu_vx_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vdivu(vuint64m2_t op0, uint64_t op1, size_t op2){
  return vdivu_vx_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vdivu(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, uint64_t op3, size_t op4){
  return vdivu_vx_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vdivu(vuint64m4_t op0, uint64_t op1, size_t op2){
  return vdivu_vx_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vdivu(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, uint64_t op3, size_t op4){
  return vdivu_vx_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vdivu(vuint64m8_t op0, uint64_t op1, size_t op2){
  return vdivu_vx_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vdivu(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, uint64_t op3, size_t op4){
  return vdivu_vx_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vdiv(vint8m1_t op0, vint8m1_t op1, size_t op2){
  return vdiv_vv_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vdiv(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, vint8m1_t op3, size_t op4){
  return vdiv_vv_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vdiv(vint8m2_t op0, vint8m2_t op1, size_t op2){
  return vdiv_vv_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vdiv(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, vint8m2_t op3, size_t op4){
  return vdiv_vv_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vdiv(vint8m4_t op0, vint8m4_t op1, size_t op2){
  return vdiv_vv_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vdiv(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, vint8m4_t op3, size_t op4){
  return vdiv_vv_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vdiv(vint8m8_t op0, vint8m8_t op1, size_t op2){
  return vdiv_vv_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vdiv(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, vint8m8_t op3, size_t op4){
  return vdiv_vv_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vdiv(vint8mf2_t op0, vint8mf2_t op1, size_t op2){
  return vdiv_vv_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vdiv(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, vint8mf2_t op3, size_t op4){
  return vdiv_vv_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vdiv(vint8mf4_t op0, vint8mf4_t op1, size_t op2){
  return vdiv_vv_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vdiv(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, vint8mf4_t op3, size_t op4){
  return vdiv_vv_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vdiv(vint8mf8_t op0, vint8mf8_t op1, size_t op2){
  return vdiv_vv_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vdiv(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, vint8mf8_t op3, size_t op4){
  return vdiv_vv_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vdiv(vint16m1_t op0, vint16m1_t op1, size_t op2){
  return vdiv_vv_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vdiv(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, vint16m1_t op3, size_t op4){
  return vdiv_vv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vdiv(vint16m2_t op0, vint16m2_t op1, size_t op2){
  return vdiv_vv_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vdiv(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, vint16m2_t op3, size_t op4){
  return vdiv_vv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vdiv(vint16m4_t op0, vint16m4_t op1, size_t op2){
  return vdiv_vv_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vdiv(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, vint16m4_t op3, size_t op4){
  return vdiv_vv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vdiv(vint16m8_t op0, vint16m8_t op1, size_t op2){
  return vdiv_vv_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vdiv(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, vint16m8_t op3, size_t op4){
  return vdiv_vv_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vdiv(vint16mf2_t op0, vint16mf2_t op1, size_t op2){
  return vdiv_vv_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vdiv(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, vint16mf2_t op3, size_t op4){
  return vdiv_vv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vdiv(vint16mf4_t op0, vint16mf4_t op1, size_t op2){
  return vdiv_vv_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vdiv(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, vint16mf4_t op3, size_t op4){
  return vdiv_vv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vdiv(vint32m1_t op0, vint32m1_t op1, size_t op2){
  return vdiv_vv_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vdiv(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, vint32m1_t op3, size_t op4){
  return vdiv_vv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vdiv(vint32m2_t op0, vint32m2_t op1, size_t op2){
  return vdiv_vv_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vdiv(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, vint32m2_t op3, size_t op4){
  return vdiv_vv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vdiv(vint32m4_t op0, vint32m4_t op1, size_t op2){
  return vdiv_vv_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vdiv(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, vint32m4_t op3, size_t op4){
  return vdiv_vv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vdiv(vint32m8_t op0, vint32m8_t op1, size_t op2){
  return vdiv_vv_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vdiv(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, vint32m8_t op3, size_t op4){
  return vdiv_vv_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vdiv(vint32mf2_t op0, vint32mf2_t op1, size_t op2){
  return vdiv_vv_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vdiv(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, vint32mf2_t op3, size_t op4){
  return vdiv_vv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vdiv(vint64m1_t op0, vint64m1_t op1, size_t op2){
  return vdiv_vv_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vdiv(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, vint64m1_t op3, size_t op4){
  return vdiv_vv_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vdiv(vint64m2_t op0, vint64m2_t op1, size_t op2){
  return vdiv_vv_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vdiv(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, vint64m2_t op3, size_t op4){
  return vdiv_vv_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vdiv(vint64m4_t op0, vint64m4_t op1, size_t op2){
  return vdiv_vv_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vdiv(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, vint64m4_t op3, size_t op4){
  return vdiv_vv_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vdiv(vint64m8_t op0, vint64m8_t op1, size_t op2){
  return vdiv_vv_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vdiv(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, vint64m8_t op3, size_t op4){
  return vdiv_vv_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vdiv(vint8m1_t op0, int8_t op1, size_t op2){
  return vdiv_vx_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vdiv(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, int8_t op3, size_t op4){
  return vdiv_vx_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vdiv(vint8m2_t op0, int8_t op1, size_t op2){
  return vdiv_vx_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vdiv(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, int8_t op3, size_t op4){
  return vdiv_vx_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vdiv(vint8m4_t op0, int8_t op1, size_t op2){
  return vdiv_vx_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vdiv(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, int8_t op3, size_t op4){
  return vdiv_vx_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vdiv(vint8m8_t op0, int8_t op1, size_t op2){
  return vdiv_vx_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vdiv(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, int8_t op3, size_t op4){
  return vdiv_vx_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vdiv(vint8mf2_t op0, int8_t op1, size_t op2){
  return vdiv_vx_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vdiv(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, int8_t op3, size_t op4){
  return vdiv_vx_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vdiv(vint8mf4_t op0, int8_t op1, size_t op2){
  return vdiv_vx_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vdiv(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, int8_t op3, size_t op4){
  return vdiv_vx_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vdiv(vint8mf8_t op0, int8_t op1, size_t op2){
  return vdiv_vx_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vdiv(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, int8_t op3, size_t op4){
  return vdiv_vx_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vdiv(vint16m1_t op0, int16_t op1, size_t op2){
  return vdiv_vx_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vdiv(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, int16_t op3, size_t op4){
  return vdiv_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vdiv(vint16m2_t op0, int16_t op1, size_t op2){
  return vdiv_vx_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vdiv(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, int16_t op3, size_t op4){
  return vdiv_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vdiv(vint16m4_t op0, int16_t op1, size_t op2){
  return vdiv_vx_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vdiv(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, int16_t op3, size_t op4){
  return vdiv_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vdiv(vint16m8_t op0, int16_t op1, size_t op2){
  return vdiv_vx_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vdiv(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, int16_t op3, size_t op4){
  return vdiv_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vdiv(vint16mf2_t op0, int16_t op1, size_t op2){
  return vdiv_vx_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vdiv(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, int16_t op3, size_t op4){
  return vdiv_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vdiv(vint16mf4_t op0, int16_t op1, size_t op2){
  return vdiv_vx_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vdiv(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, int16_t op3, size_t op4){
  return vdiv_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vdiv(vint32m1_t op0, int32_t op1, size_t op2){
  return vdiv_vx_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vdiv(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, int32_t op3, size_t op4){
  return vdiv_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vdiv(vint32m2_t op0, int32_t op1, size_t op2){
  return vdiv_vx_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vdiv(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, int32_t op3, size_t op4){
  return vdiv_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vdiv(vint32m4_t op0, int32_t op1, size_t op2){
  return vdiv_vx_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vdiv(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, int32_t op3, size_t op4){
  return vdiv_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vdiv(vint32m8_t op0, int32_t op1, size_t op2){
  return vdiv_vx_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vdiv(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, int32_t op3, size_t op4){
  return vdiv_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vdiv(vint32mf2_t op0, int32_t op1, size_t op2){
  return vdiv_vx_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vdiv(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, int32_t op3, size_t op4){
  return vdiv_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vdiv(vint64m1_t op0, int64_t op1, size_t op2){
  return vdiv_vx_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vdiv(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, int64_t op3, size_t op4){
  return vdiv_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vdiv(vint64m2_t op0, int64_t op1, size_t op2){
  return vdiv_vx_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vdiv(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, int64_t op3, size_t op4){
  return vdiv_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vdiv(vint64m4_t op0, int64_t op1, size_t op2){
  return vdiv_vx_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vdiv(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, int64_t op3, size_t op4){
  return vdiv_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vdiv(vint64m8_t op0, int64_t op1, size_t op2){
  return vdiv_vx_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vdiv(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, int64_t op3, size_t op4){
  return vdiv_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vremu(vuint8m1_t op0, vuint8m1_t op1, size_t op2){
  return vremu_vv_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vremu(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vremu_vv_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vremu(vuint8m2_t op0, vuint8m2_t op1, size_t op2){
  return vremu_vv_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vremu(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vremu_vv_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vremu(vuint8m4_t op0, vuint8m4_t op1, size_t op2){
  return vremu_vv_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vremu(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vremu_vv_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vremu(vuint8m8_t op0, vuint8m8_t op1, size_t op2){
  return vremu_vv_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vremu(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, vuint8m8_t op3, size_t op4){
  return vremu_vv_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vremu(vuint8mf2_t op0, vuint8mf2_t op1, size_t op2){
  return vremu_vv_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vremu(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vremu_vv_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vremu(vuint8mf4_t op0, vuint8mf4_t op1, size_t op2){
  return vremu_vv_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vremu(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vremu_vv_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vremu(vuint8mf8_t op0, vuint8mf8_t op1, size_t op2){
  return vremu_vv_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vremu(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vremu_vv_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vremu(vuint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vremu_vv_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vremu(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vremu_vv_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vremu(vuint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vremu_vv_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vremu(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vremu_vv_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vremu(vuint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vremu_vv_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vremu(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vremu_vv_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vremu(vuint16m8_t op0, vuint16m8_t op1, size_t op2){
  return vremu_vv_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vremu(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vremu_vv_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vremu(vuint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vremu_vv_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vremu(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vremu_vv_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vremu(vuint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vremu_vv_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vremu(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vremu_vv_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vremu(vuint32m1_t op0, vuint32m1_t op1, size_t op2){
  return vremu_vv_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vremu(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vremu_vv_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vremu(vuint32m2_t op0, vuint32m2_t op1, size_t op2){
  return vremu_vv_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vremu(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vremu_vv_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vremu(vuint32m4_t op0, vuint32m4_t op1, size_t op2){
  return vremu_vv_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vremu(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vremu_vv_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vremu(vuint32m8_t op0, vuint32m8_t op1, size_t op2){
  return vremu_vv_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vremu(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, vuint32m8_t op3, size_t op4){
  return vremu_vv_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vremu(vuint32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vremu_vv_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vremu(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vremu_vv_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vremu(vuint64m1_t op0, vuint64m1_t op1, size_t op2){
  return vremu_vv_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vremu(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vremu_vv_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vremu(vuint64m2_t op0, vuint64m2_t op1, size_t op2){
  return vremu_vv_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vremu(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, vuint64m2_t op3, size_t op4){
  return vremu_vv_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vremu(vuint64m4_t op0, vuint64m4_t op1, size_t op2){
  return vremu_vv_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vremu(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, vuint64m4_t op3, size_t op4){
  return vremu_vv_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vremu(vuint64m8_t op0, vuint64m8_t op1, size_t op2){
  return vremu_vv_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vremu(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, vuint64m8_t op3, size_t op4){
  return vremu_vv_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vremu(vuint8m1_t op0, uint8_t op1, size_t op2){
  return vremu_vx_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vremu(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, uint8_t op3, size_t op4){
  return vremu_vx_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vremu(vuint8m2_t op0, uint8_t op1, size_t op2){
  return vremu_vx_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vremu(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, uint8_t op3, size_t op4){
  return vremu_vx_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vremu(vuint8m4_t op0, uint8_t op1, size_t op2){
  return vremu_vx_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vremu(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, uint8_t op3, size_t op4){
  return vremu_vx_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vremu(vuint8m8_t op0, uint8_t op1, size_t op2){
  return vremu_vx_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vremu(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, uint8_t op3, size_t op4){
  return vremu_vx_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vremu(vuint8mf2_t op0, uint8_t op1, size_t op2){
  return vremu_vx_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vremu(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, uint8_t op3, size_t op4){
  return vremu_vx_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vremu(vuint8mf4_t op0, uint8_t op1, size_t op2){
  return vremu_vx_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vremu(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, uint8_t op3, size_t op4){
  return vremu_vx_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vremu(vuint8mf8_t op0, uint8_t op1, size_t op2){
  return vremu_vx_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vremu(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, uint8_t op3, size_t op4){
  return vremu_vx_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vremu(vuint16m1_t op0, uint16_t op1, size_t op2){
  return vremu_vx_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vremu(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, uint16_t op3, size_t op4){
  return vremu_vx_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vremu(vuint16m2_t op0, uint16_t op1, size_t op2){
  return vremu_vx_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vremu(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, uint16_t op3, size_t op4){
  return vremu_vx_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vremu(vuint16m4_t op0, uint16_t op1, size_t op2){
  return vremu_vx_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vremu(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, uint16_t op3, size_t op4){
  return vremu_vx_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vremu(vuint16m8_t op0, uint16_t op1, size_t op2){
  return vremu_vx_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vremu(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, uint16_t op3, size_t op4){
  return vremu_vx_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vremu(vuint16mf2_t op0, uint16_t op1, size_t op2){
  return vremu_vx_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vremu(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, uint16_t op3, size_t op4){
  return vremu_vx_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vremu(vuint16mf4_t op0, uint16_t op1, size_t op2){
  return vremu_vx_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vremu(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, uint16_t op3, size_t op4){
  return vremu_vx_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vremu(vuint32m1_t op0, uint32_t op1, size_t op2){
  return vremu_vx_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vremu(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, uint32_t op3, size_t op4){
  return vremu_vx_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vremu(vuint32m2_t op0, uint32_t op1, size_t op2){
  return vremu_vx_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vremu(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, uint32_t op3, size_t op4){
  return vremu_vx_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vremu(vuint32m4_t op0, uint32_t op1, size_t op2){
  return vremu_vx_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vremu(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, uint32_t op3, size_t op4){
  return vremu_vx_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vremu(vuint32m8_t op0, uint32_t op1, size_t op2){
  return vremu_vx_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vremu(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, uint32_t op3, size_t op4){
  return vremu_vx_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vremu(vuint32mf2_t op0, uint32_t op1, size_t op2){
  return vremu_vx_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vremu(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, uint32_t op3, size_t op4){
  return vremu_vx_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vremu(vuint64m1_t op0, uint64_t op1, size_t op2){
  return vremu_vx_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vremu(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, uint64_t op3, size_t op4){
  return vremu_vx_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vremu(vuint64m2_t op0, uint64_t op1, size_t op2){
  return vremu_vx_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vremu(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, uint64_t op3, size_t op4){
  return vremu_vx_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vremu(vuint64m4_t op0, uint64_t op1, size_t op2){
  return vremu_vx_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vremu(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, uint64_t op3, size_t op4){
  return vremu_vx_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vremu(vuint64m8_t op0, uint64_t op1, size_t op2){
  return vremu_vx_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vremu(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, uint64_t op3, size_t op4){
  return vremu_vx_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vrem(vint8m1_t op0, vint8m1_t op1, size_t op2){
  return vrem_vv_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vrem(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, vint8m1_t op3, size_t op4){
  return vrem_vv_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vrem(vint8m2_t op0, vint8m2_t op1, size_t op2){
  return vrem_vv_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vrem(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, vint8m2_t op3, size_t op4){
  return vrem_vv_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vrem(vint8m4_t op0, vint8m4_t op1, size_t op2){
  return vrem_vv_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vrem(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, vint8m4_t op3, size_t op4){
  return vrem_vv_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vrem(vint8m8_t op0, vint8m8_t op1, size_t op2){
  return vrem_vv_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vrem(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, vint8m8_t op3, size_t op4){
  return vrem_vv_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vrem(vint8mf2_t op0, vint8mf2_t op1, size_t op2){
  return vrem_vv_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vrem(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, vint8mf2_t op3, size_t op4){
  return vrem_vv_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vrem(vint8mf4_t op0, vint8mf4_t op1, size_t op2){
  return vrem_vv_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vrem(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, vint8mf4_t op3, size_t op4){
  return vrem_vv_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vrem(vint8mf8_t op0, vint8mf8_t op1, size_t op2){
  return vrem_vv_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vrem(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, vint8mf8_t op3, size_t op4){
  return vrem_vv_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vrem(vint16m1_t op0, vint16m1_t op1, size_t op2){
  return vrem_vv_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vrem(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, vint16m1_t op3, size_t op4){
  return vrem_vv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vrem(vint16m2_t op0, vint16m2_t op1, size_t op2){
  return vrem_vv_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vrem(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, vint16m2_t op3, size_t op4){
  return vrem_vv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vrem(vint16m4_t op0, vint16m4_t op1, size_t op2){
  return vrem_vv_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vrem(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, vint16m4_t op3, size_t op4){
  return vrem_vv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vrem(vint16m8_t op0, vint16m8_t op1, size_t op2){
  return vrem_vv_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vrem(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, vint16m8_t op3, size_t op4){
  return vrem_vv_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vrem(vint16mf2_t op0, vint16mf2_t op1, size_t op2){
  return vrem_vv_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vrem(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, vint16mf2_t op3, size_t op4){
  return vrem_vv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vrem(vint16mf4_t op0, vint16mf4_t op1, size_t op2){
  return vrem_vv_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vrem(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, vint16mf4_t op3, size_t op4){
  return vrem_vv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vrem(vint32m1_t op0, vint32m1_t op1, size_t op2){
  return vrem_vv_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vrem(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, vint32m1_t op3, size_t op4){
  return vrem_vv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vrem(vint32m2_t op0, vint32m2_t op1, size_t op2){
  return vrem_vv_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vrem(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, vint32m2_t op3, size_t op4){
  return vrem_vv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vrem(vint32m4_t op0, vint32m4_t op1, size_t op2){
  return vrem_vv_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vrem(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, vint32m4_t op3, size_t op4){
  return vrem_vv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vrem(vint32m8_t op0, vint32m8_t op1, size_t op2){
  return vrem_vv_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vrem(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, vint32m8_t op3, size_t op4){
  return vrem_vv_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vrem(vint32mf2_t op0, vint32mf2_t op1, size_t op2){
  return vrem_vv_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vrem(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, vint32mf2_t op3, size_t op4){
  return vrem_vv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vrem(vint64m1_t op0, vint64m1_t op1, size_t op2){
  return vrem_vv_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vrem(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, vint64m1_t op3, size_t op4){
  return vrem_vv_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vrem(vint64m2_t op0, vint64m2_t op1, size_t op2){
  return vrem_vv_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vrem(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, vint64m2_t op3, size_t op4){
  return vrem_vv_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vrem(vint64m4_t op0, vint64m4_t op1, size_t op2){
  return vrem_vv_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vrem(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, vint64m4_t op3, size_t op4){
  return vrem_vv_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vrem(vint64m8_t op0, vint64m8_t op1, size_t op2){
  return vrem_vv_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vrem(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, vint64m8_t op3, size_t op4){
  return vrem_vv_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vrem(vint8m1_t op0, int8_t op1, size_t op2){
  return vrem_vx_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vrem(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, int8_t op3, size_t op4){
  return vrem_vx_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vrem(vint8m2_t op0, int8_t op1, size_t op2){
  return vrem_vx_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vrem(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, int8_t op3, size_t op4){
  return vrem_vx_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vrem(vint8m4_t op0, int8_t op1, size_t op2){
  return vrem_vx_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vrem(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, int8_t op3, size_t op4){
  return vrem_vx_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vrem(vint8m8_t op0, int8_t op1, size_t op2){
  return vrem_vx_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vrem(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, int8_t op3, size_t op4){
  return vrem_vx_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vrem(vint8mf2_t op0, int8_t op1, size_t op2){
  return vrem_vx_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vrem(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, int8_t op3, size_t op4){
  return vrem_vx_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vrem(vint8mf4_t op0, int8_t op1, size_t op2){
  return vrem_vx_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vrem(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, int8_t op3, size_t op4){
  return vrem_vx_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vrem(vint8mf8_t op0, int8_t op1, size_t op2){
  return vrem_vx_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vrem(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, int8_t op3, size_t op4){
  return vrem_vx_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vrem(vint16m1_t op0, int16_t op1, size_t op2){
  return vrem_vx_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vrem(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, int16_t op3, size_t op4){
  return vrem_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vrem(vint16m2_t op0, int16_t op1, size_t op2){
  return vrem_vx_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vrem(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, int16_t op3, size_t op4){
  return vrem_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vrem(vint16m4_t op0, int16_t op1, size_t op2){
  return vrem_vx_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vrem(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, int16_t op3, size_t op4){
  return vrem_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vrem(vint16m8_t op0, int16_t op1, size_t op2){
  return vrem_vx_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vrem(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, int16_t op3, size_t op4){
  return vrem_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vrem(vint16mf2_t op0, int16_t op1, size_t op2){
  return vrem_vx_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vrem(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, int16_t op3, size_t op4){
  return vrem_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vrem(vint16mf4_t op0, int16_t op1, size_t op2){
  return vrem_vx_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vrem(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, int16_t op3, size_t op4){
  return vrem_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vrem(vint32m1_t op0, int32_t op1, size_t op2){
  return vrem_vx_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vrem(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, int32_t op3, size_t op4){
  return vrem_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vrem(vint32m2_t op0, int32_t op1, size_t op2){
  return vrem_vx_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vrem(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, int32_t op3, size_t op4){
  return vrem_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vrem(vint32m4_t op0, int32_t op1, size_t op2){
  return vrem_vx_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vrem(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, int32_t op3, size_t op4){
  return vrem_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vrem(vint32m8_t op0, int32_t op1, size_t op2){
  return vrem_vx_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vrem(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, int32_t op3, size_t op4){
  return vrem_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vrem(vint32mf2_t op0, int32_t op1, size_t op2){
  return vrem_vx_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vrem(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, int32_t op3, size_t op4){
  return vrem_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vrem(vint64m1_t op0, int64_t op1, size_t op2){
  return vrem_vx_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vrem(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, int64_t op3, size_t op4){
  return vrem_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vrem(vint64m2_t op0, int64_t op1, size_t op2){
  return vrem_vx_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vrem(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, int64_t op3, size_t op4){
  return vrem_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vrem(vint64m4_t op0, int64_t op1, size_t op2){
  return vrem_vx_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vrem(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, int64_t op3, size_t op4){
  return vrem_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vrem(vint64m8_t op0, int64_t op1, size_t op2){
  return vrem_vx_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vrem(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, int64_t op3, size_t op4){
  return vrem_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vwmul(vint8mf8_t op0, vint8mf8_t op1, size_t op2){
  return vwmul_vv_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vwmul(vbool64_t op0, vint16mf4_t op1, vint8mf8_t op2, vint8mf8_t op3, size_t op4){
  return vwmul_vv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vwmul(vint8mf4_t op0, vint8mf4_t op1, size_t op2){
  return vwmul_vv_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vwmul(vbool32_t op0, vint16mf2_t op1, vint8mf4_t op2, vint8mf4_t op3, size_t op4){
  return vwmul_vv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vwmul(vint8mf2_t op0, vint8mf2_t op1, size_t op2){
  return vwmul_vv_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vwmul(vbool16_t op0, vint16m1_t op1, vint8mf2_t op2, vint8mf2_t op3, size_t op4){
  return vwmul_vv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vwmul(vint8m1_t op0, vint8m1_t op1, size_t op2){
  return vwmul_vv_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vwmul(vbool8_t op0, vint16m2_t op1, vint8m1_t op2, vint8m1_t op3, size_t op4){
  return vwmul_vv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vwmul(vint8m2_t op0, vint8m2_t op1, size_t op2){
  return vwmul_vv_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vwmul(vbool4_t op0, vint16m4_t op1, vint8m2_t op2, vint8m2_t op3, size_t op4){
  return vwmul_vv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vwmul(vint8m4_t op0, vint8m4_t op1, size_t op2){
  return vwmul_vv_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vwmul(vbool2_t op0, vint16m8_t op1, vint8m4_t op2, vint8m4_t op3, size_t op4){
  return vwmul_vv_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vwmul(vint16mf4_t op0, vint16mf4_t op1, size_t op2){
  return vwmul_vv_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vwmul(vbool64_t op0, vint32mf2_t op1, vint16mf4_t op2, vint16mf4_t op3, size_t op4){
  return vwmul_vv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vwmul(vint16mf2_t op0, vint16mf2_t op1, size_t op2){
  return vwmul_vv_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vwmul(vbool32_t op0, vint32m1_t op1, vint16mf2_t op2, vint16mf2_t op3, size_t op4){
  return vwmul_vv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vwmul(vint16m1_t op0, vint16m1_t op1, size_t op2){
  return vwmul_vv_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vwmul(vbool16_t op0, vint32m2_t op1, vint16m1_t op2, vint16m1_t op3, size_t op4){
  return vwmul_vv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vwmul(vint16m2_t op0, vint16m2_t op1, size_t op2){
  return vwmul_vv_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vwmul(vbool8_t op0, vint32m4_t op1, vint16m2_t op2, vint16m2_t op3, size_t op4){
  return vwmul_vv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vwmul(vint16m4_t op0, vint16m4_t op1, size_t op2){
  return vwmul_vv_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vwmul(vbool4_t op0, vint32m8_t op1, vint16m4_t op2, vint16m4_t op3, size_t op4){
  return vwmul_vv_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vwmul(vint32mf2_t op0, vint32mf2_t op1, size_t op2){
  return vwmul_vv_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vwmul(vbool64_t op0, vint64m1_t op1, vint32mf2_t op2, vint32mf2_t op3, size_t op4){
  return vwmul_vv_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vwmul(vint32m1_t op0, vint32m1_t op1, size_t op2){
  return vwmul_vv_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vwmul(vbool32_t op0, vint64m2_t op1, vint32m1_t op2, vint32m1_t op3, size_t op4){
  return vwmul_vv_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vwmul(vint32m2_t op0, vint32m2_t op1, size_t op2){
  return vwmul_vv_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vwmul(vbool16_t op0, vint64m4_t op1, vint32m2_t op2, vint32m2_t op3, size_t op4){
  return vwmul_vv_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vwmul(vint32m4_t op0, vint32m4_t op1, size_t op2){
  return vwmul_vv_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vwmul(vbool8_t op0, vint64m8_t op1, vint32m4_t op2, vint32m4_t op3, size_t op4){
  return vwmul_vv_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vwmul(vint8mf8_t op0, int8_t op1, size_t op2){
  return vwmul_vx_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vwmul(vbool64_t op0, vint16mf4_t op1, vint8mf8_t op2, int8_t op3, size_t op4){
  return vwmul_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vwmul(vint8mf4_t op0, int8_t op1, size_t op2){
  return vwmul_vx_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vwmul(vbool32_t op0, vint16mf2_t op1, vint8mf4_t op2, int8_t op3, size_t op4){
  return vwmul_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vwmul(vint8mf2_t op0, int8_t op1, size_t op2){
  return vwmul_vx_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vwmul(vbool16_t op0, vint16m1_t op1, vint8mf2_t op2, int8_t op3, size_t op4){
  return vwmul_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vwmul(vint8m1_t op0, int8_t op1, size_t op2){
  return vwmul_vx_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vwmul(vbool8_t op0, vint16m2_t op1, vint8m1_t op2, int8_t op3, size_t op4){
  return vwmul_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vwmul(vint8m2_t op0, int8_t op1, size_t op2){
  return vwmul_vx_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vwmul(vbool4_t op0, vint16m4_t op1, vint8m2_t op2, int8_t op3, size_t op4){
  return vwmul_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vwmul(vint8m4_t op0, int8_t op1, size_t op2){
  return vwmul_vx_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vwmul(vbool2_t op0, vint16m8_t op1, vint8m4_t op2, int8_t op3, size_t op4){
  return vwmul_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vwmul(vint16mf4_t op0, int16_t op1, size_t op2){
  return vwmul_vx_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vwmul(vbool64_t op0, vint32mf2_t op1, vint16mf4_t op2, int16_t op3, size_t op4){
  return vwmul_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vwmul(vint16mf2_t op0, int16_t op1, size_t op2){
  return vwmul_vx_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vwmul(vbool32_t op0, vint32m1_t op1, vint16mf2_t op2, int16_t op3, size_t op4){
  return vwmul_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vwmul(vint16m1_t op0, int16_t op1, size_t op2){
  return vwmul_vx_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vwmul(vbool16_t op0, vint32m2_t op1, vint16m1_t op2, int16_t op3, size_t op4){
  return vwmul_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vwmul(vint16m2_t op0, int16_t op1, size_t op2){
  return vwmul_vx_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vwmul(vbool8_t op0, vint32m4_t op1, vint16m2_t op2, int16_t op3, size_t op4){
  return vwmul_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vwmul(vint16m4_t op0, int16_t op1, size_t op2){
  return vwmul_vx_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vwmul(vbool4_t op0, vint32m8_t op1, vint16m4_t op2, int16_t op3, size_t op4){
  return vwmul_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vwmul(vint32mf2_t op0, int32_t op1, size_t op2){
  return vwmul_vx_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vwmul(vbool64_t op0, vint64m1_t op1, vint32mf2_t op2, int32_t op3, size_t op4){
  return vwmul_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vwmul(vint32m1_t op0, int32_t op1, size_t op2){
  return vwmul_vx_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vwmul(vbool32_t op0, vint64m2_t op1, vint32m1_t op2, int32_t op3, size_t op4){
  return vwmul_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vwmul(vint32m2_t op0, int32_t op1, size_t op2){
  return vwmul_vx_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vwmul(vbool16_t op0, vint64m4_t op1, vint32m2_t op2, int32_t op3, size_t op4){
  return vwmul_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vwmul(vint32m4_t op0, int32_t op1, size_t op2){
  return vwmul_vx_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vwmul(vbool8_t op0, vint64m8_t op1, vint32m4_t op2, int32_t op3, size_t op4){
  return vwmul_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vwmulu(vuint8mf8_t op0, vuint8mf8_t op1, size_t op2){
  return vwmulu_vv_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vwmulu(vbool64_t op0, vuint16mf4_t op1, vuint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vwmulu_vv_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vwmulu(vuint8mf4_t op0, vuint8mf4_t op1, size_t op2){
  return vwmulu_vv_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vwmulu(vbool32_t op0, vuint16mf2_t op1, vuint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vwmulu_vv_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vwmulu(vuint8mf2_t op0, vuint8mf2_t op1, size_t op2){
  return vwmulu_vv_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vwmulu(vbool16_t op0, vuint16m1_t op1, vuint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vwmulu_vv_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vwmulu(vuint8m1_t op0, vuint8m1_t op1, size_t op2){
  return vwmulu_vv_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vwmulu(vbool8_t op0, vuint16m2_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vwmulu_vv_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vwmulu(vuint8m2_t op0, vuint8m2_t op1, size_t op2){
  return vwmulu_vv_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vwmulu(vbool4_t op0, vuint16m4_t op1, vuint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vwmulu_vv_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vwmulu(vuint8m4_t op0, vuint8m4_t op1, size_t op2){
  return vwmulu_vv_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vwmulu(vbool2_t op0, vuint16m8_t op1, vuint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vwmulu_vv_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vwmulu(vuint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vwmulu_vv_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vwmulu(vbool64_t op0, vuint32mf2_t op1, vuint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vwmulu_vv_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vwmulu(vuint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vwmulu_vv_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vwmulu(vbool32_t op0, vuint32m1_t op1, vuint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vwmulu_vv_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vwmulu(vuint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vwmulu_vv_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vwmulu(vbool16_t op0, vuint32m2_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vwmulu_vv_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vwmulu(vuint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vwmulu_vv_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vwmulu(vbool8_t op0, vuint32m4_t op1, vuint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vwmulu_vv_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vwmulu(vuint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vwmulu_vv_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vwmulu(vbool4_t op0, vuint32m8_t op1, vuint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vwmulu_vv_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vwmulu(vuint32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vwmulu_vv_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vwmulu(vbool64_t op0, vuint64m1_t op1, vuint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vwmulu_vv_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vwmulu(vuint32m1_t op0, vuint32m1_t op1, size_t op2){
  return vwmulu_vv_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vwmulu(vbool32_t op0, vuint64m2_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vwmulu_vv_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vwmulu(vuint32m2_t op0, vuint32m2_t op1, size_t op2){
  return vwmulu_vv_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vwmulu(vbool16_t op0, vuint64m4_t op1, vuint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vwmulu_vv_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vwmulu(vuint32m4_t op0, vuint32m4_t op1, size_t op2){
  return vwmulu_vv_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vwmulu(vbool8_t op0, vuint64m8_t op1, vuint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vwmulu_vv_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vwmulu(vuint8mf8_t op0, uint8_t op1, size_t op2){
  return vwmulu_vx_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vwmulu(vbool64_t op0, vuint16mf4_t op1, vuint8mf8_t op2, uint8_t op3, size_t op4){
  return vwmulu_vx_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vwmulu(vuint8mf4_t op0, uint8_t op1, size_t op2){
  return vwmulu_vx_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vwmulu(vbool32_t op0, vuint16mf2_t op1, vuint8mf4_t op2, uint8_t op3, size_t op4){
  return vwmulu_vx_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vwmulu(vuint8mf2_t op0, uint8_t op1, size_t op2){
  return vwmulu_vx_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vwmulu(vbool16_t op0, vuint16m1_t op1, vuint8mf2_t op2, uint8_t op3, size_t op4){
  return vwmulu_vx_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vwmulu(vuint8m1_t op0, uint8_t op1, size_t op2){
  return vwmulu_vx_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vwmulu(vbool8_t op0, vuint16m2_t op1, vuint8m1_t op2, uint8_t op3, size_t op4){
  return vwmulu_vx_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vwmulu(vuint8m2_t op0, uint8_t op1, size_t op2){
  return vwmulu_vx_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vwmulu(vbool4_t op0, vuint16m4_t op1, vuint8m2_t op2, uint8_t op3, size_t op4){
  return vwmulu_vx_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vwmulu(vuint8m4_t op0, uint8_t op1, size_t op2){
  return vwmulu_vx_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vwmulu(vbool2_t op0, vuint16m8_t op1, vuint8m4_t op2, uint8_t op3, size_t op4){
  return vwmulu_vx_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vwmulu(vuint16mf4_t op0, uint16_t op1, size_t op2){
  return vwmulu_vx_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vwmulu(vbool64_t op0, vuint32mf2_t op1, vuint16mf4_t op2, uint16_t op3, size_t op4){
  return vwmulu_vx_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vwmulu(vuint16mf2_t op0, uint16_t op1, size_t op2){
  return vwmulu_vx_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vwmulu(vbool32_t op0, vuint32m1_t op1, vuint16mf2_t op2, uint16_t op3, size_t op4){
  return vwmulu_vx_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vwmulu(vuint16m1_t op0, uint16_t op1, size_t op2){
  return vwmulu_vx_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vwmulu(vbool16_t op0, vuint32m2_t op1, vuint16m1_t op2, uint16_t op3, size_t op4){
  return vwmulu_vx_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vwmulu(vuint16m2_t op0, uint16_t op1, size_t op2){
  return vwmulu_vx_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vwmulu(vbool8_t op0, vuint32m4_t op1, vuint16m2_t op2, uint16_t op3, size_t op4){
  return vwmulu_vx_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vwmulu(vuint16m4_t op0, uint16_t op1, size_t op2){
  return vwmulu_vx_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vwmulu(vbool4_t op0, vuint32m8_t op1, vuint16m4_t op2, uint16_t op3, size_t op4){
  return vwmulu_vx_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vwmulu(vuint32mf2_t op0, uint32_t op1, size_t op2){
  return vwmulu_vx_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vwmulu(vbool64_t op0, vuint64m1_t op1, vuint32mf2_t op2, uint32_t op3, size_t op4){
  return vwmulu_vx_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vwmulu(vuint32m1_t op0, uint32_t op1, size_t op2){
  return vwmulu_vx_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vwmulu(vbool32_t op0, vuint64m2_t op1, vuint32m1_t op2, uint32_t op3, size_t op4){
  return vwmulu_vx_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vwmulu(vuint32m2_t op0, uint32_t op1, size_t op2){
  return vwmulu_vx_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vwmulu(vbool16_t op0, vuint64m4_t op1, vuint32m2_t op2, uint32_t op3, size_t op4){
  return vwmulu_vx_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vwmulu(vuint32m4_t op0, uint32_t op1, size_t op2){
  return vwmulu_vx_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vwmulu(vbool8_t op0, vuint64m8_t op1, vuint32m4_t op2, uint32_t op3, size_t op4){
  return vwmulu_vx_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vwmulsu(vint8mf8_t op0, vuint8mf8_t op1, size_t op2){
  return vwmulsu_vv_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vwmulsu(vbool64_t op0, vint16mf4_t op1, vint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vwmulsu_vv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vwmulsu(vint8mf4_t op0, vuint8mf4_t op1, size_t op2){
  return vwmulsu_vv_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vwmulsu(vbool32_t op0, vint16mf2_t op1, vint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vwmulsu_vv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vwmulsu(vint8mf2_t op0, vuint8mf2_t op1, size_t op2){
  return vwmulsu_vv_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vwmulsu(vbool16_t op0, vint16m1_t op1, vint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vwmulsu_vv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vwmulsu(vint8m1_t op0, vuint8m1_t op1, size_t op2){
  return vwmulsu_vv_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vwmulsu(vbool8_t op0, vint16m2_t op1, vint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vwmulsu_vv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vwmulsu(vint8m2_t op0, vuint8m2_t op1, size_t op2){
  return vwmulsu_vv_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vwmulsu(vbool4_t op0, vint16m4_t op1, vint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vwmulsu_vv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vwmulsu(vint8m4_t op0, vuint8m4_t op1, size_t op2){
  return vwmulsu_vv_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vwmulsu(vbool2_t op0, vint16m8_t op1, vint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vwmulsu_vv_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vwmulsu(vint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vwmulsu_vv_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vwmulsu(vbool64_t op0, vint32mf2_t op1, vint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vwmulsu_vv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vwmulsu(vint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vwmulsu_vv_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vwmulsu(vbool32_t op0, vint32m1_t op1, vint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vwmulsu_vv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vwmulsu(vint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vwmulsu_vv_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vwmulsu(vbool16_t op0, vint32m2_t op1, vint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vwmulsu_vv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vwmulsu(vint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vwmulsu_vv_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vwmulsu(vbool8_t op0, vint32m4_t op1, vint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vwmulsu_vv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vwmulsu(vint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vwmulsu_vv_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vwmulsu(vbool4_t op0, vint32m8_t op1, vint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vwmulsu_vv_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vwmulsu(vint32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vwmulsu_vv_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vwmulsu(vbool64_t op0, vint64m1_t op1, vint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vwmulsu_vv_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vwmulsu(vint32m1_t op0, vuint32m1_t op1, size_t op2){
  return vwmulsu_vv_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vwmulsu(vbool32_t op0, vint64m2_t op1, vint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vwmulsu_vv_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vwmulsu(vint32m2_t op0, vuint32m2_t op1, size_t op2){
  return vwmulsu_vv_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vwmulsu(vbool16_t op0, vint64m4_t op1, vint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vwmulsu_vv_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vwmulsu(vint32m4_t op0, vuint32m4_t op1, size_t op2){
  return vwmulsu_vv_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vwmulsu(vbool8_t op0, vint64m8_t op1, vint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vwmulsu_vv_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vwmulsu(vint8mf8_t op0, uint8_t op1, size_t op2){
  return vwmulsu_vx_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vwmulsu(vbool64_t op0, vint16mf4_t op1, vint8mf8_t op2, uint8_t op3, size_t op4){
  return vwmulsu_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vwmulsu(vint8mf4_t op0, uint8_t op1, size_t op2){
  return vwmulsu_vx_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vwmulsu(vbool32_t op0, vint16mf2_t op1, vint8mf4_t op2, uint8_t op3, size_t op4){
  return vwmulsu_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vwmulsu(vint8mf2_t op0, uint8_t op1, size_t op2){
  return vwmulsu_vx_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vwmulsu(vbool16_t op0, vint16m1_t op1, vint8mf2_t op2, uint8_t op3, size_t op4){
  return vwmulsu_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vwmulsu(vint8m1_t op0, uint8_t op1, size_t op2){
  return vwmulsu_vx_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vwmulsu(vbool8_t op0, vint16m2_t op1, vint8m1_t op2, uint8_t op3, size_t op4){
  return vwmulsu_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vwmulsu(vint8m2_t op0, uint8_t op1, size_t op2){
  return vwmulsu_vx_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vwmulsu(vbool4_t op0, vint16m4_t op1, vint8m2_t op2, uint8_t op3, size_t op4){
  return vwmulsu_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vwmulsu(vint8m4_t op0, uint8_t op1, size_t op2){
  return vwmulsu_vx_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vwmulsu(vbool2_t op0, vint16m8_t op1, vint8m4_t op2, uint8_t op3, size_t op4){
  return vwmulsu_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vwmulsu(vint16mf4_t op0, uint16_t op1, size_t op2){
  return vwmulsu_vx_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vwmulsu(vbool64_t op0, vint32mf2_t op1, vint16mf4_t op2, uint16_t op3, size_t op4){
  return vwmulsu_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vwmulsu(vint16mf2_t op0, uint16_t op1, size_t op2){
  return vwmulsu_vx_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vwmulsu(vbool32_t op0, vint32m1_t op1, vint16mf2_t op2, uint16_t op3, size_t op4){
  return vwmulsu_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vwmulsu(vint16m1_t op0, uint16_t op1, size_t op2){
  return vwmulsu_vx_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vwmulsu(vbool16_t op0, vint32m2_t op1, vint16m1_t op2, uint16_t op3, size_t op4){
  return vwmulsu_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vwmulsu(vint16m2_t op0, uint16_t op1, size_t op2){
  return vwmulsu_vx_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vwmulsu(vbool8_t op0, vint32m4_t op1, vint16m2_t op2, uint16_t op3, size_t op4){
  return vwmulsu_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vwmulsu(vint16m4_t op0, uint16_t op1, size_t op2){
  return vwmulsu_vx_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vwmulsu(vbool4_t op0, vint32m8_t op1, vint16m4_t op2, uint16_t op3, size_t op4){
  return vwmulsu_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vwmulsu(vint32mf2_t op0, uint32_t op1, size_t op2){
  return vwmulsu_vx_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vwmulsu(vbool64_t op0, vint64m1_t op1, vint32mf2_t op2, uint32_t op3, size_t op4){
  return vwmulsu_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vwmulsu(vint32m1_t op0, uint32_t op1, size_t op2){
  return vwmulsu_vx_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vwmulsu(vbool32_t op0, vint64m2_t op1, vint32m1_t op2, uint32_t op3, size_t op4){
  return vwmulsu_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vwmulsu(vint32m2_t op0, uint32_t op1, size_t op2){
  return vwmulsu_vx_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vwmulsu(vbool16_t op0, vint64m4_t op1, vint32m2_t op2, uint32_t op3, size_t op4){
  return vwmulsu_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vwmulsu(vint32m4_t op0, uint32_t op1, size_t op2){
  return vwmulsu_vx_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vwmulsu(vbool8_t op0, vint64m8_t op1, vint32m4_t op2, uint32_t op3, size_t op4){
  return vwmulsu_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vmacc(vint8m1_t op0, vint8m1_t op1, vint8m1_t op2, size_t op3){
  return vmacc_vv_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vmacc(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, vint8m1_t op3, size_t op4){
  return vmacc_vv_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vmacc(vint8m2_t op0, vint8m2_t op1, vint8m2_t op2, size_t op3){
  return vmacc_vv_i8m2(op0, op1, op2, op3);
}

__rvv_overloaded vint8m2_t vmacc(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, vint8m2_t op3, size_t op4){
  return vmacc_vv_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vmacc(vint8m4_t op0, vint8m4_t op1, vint8m4_t op2, size_t op3){
  return vmacc_vv_i8m4(op0, op1, op2, op3);
}

__rvv_overloaded vint8m4_t vmacc(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, vint8m4_t op3, size_t op4){
  return vmacc_vv_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vmacc(vint8m8_t op0, vint8m8_t op1, vint8m8_t op2, size_t op3){
  return vmacc_vv_i8m8(op0, op1, op2, op3);
}

__rvv_overloaded vint8m8_t vmacc(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, vint8m8_t op3, size_t op4){
  return vmacc_vv_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vmacc(vint8mf2_t op0, vint8mf2_t op1, vint8mf2_t op2, size_t op3){
  return vmacc_vv_i8mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf2_t vmacc(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, vint8mf2_t op3, size_t op4){
  return vmacc_vv_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vmacc(vint8mf4_t op0, vint8mf4_t op1, vint8mf4_t op2, size_t op3){
  return vmacc_vv_i8mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf4_t vmacc(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, vint8mf4_t op3, size_t op4){
  return vmacc_vv_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vmacc(vint8mf8_t op0, vint8mf8_t op1, vint8mf8_t op2, size_t op3){
  return vmacc_vv_i8mf8(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf8_t vmacc(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, vint8mf8_t op3, size_t op4){
  return vmacc_vv_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vmacc(vint16m1_t op0, vint16m1_t op1, vint16m1_t op2, size_t op3){
  return vmacc_vv_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vmacc(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, vint16m1_t op3, size_t op4){
  return vmacc_vv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vmacc(vint16m2_t op0, vint16m2_t op1, vint16m2_t op2, size_t op3){
  return vmacc_vv_i16m2(op0, op1, op2, op3);
}

__rvv_overloaded vint16m2_t vmacc(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, vint16m2_t op3, size_t op4){
  return vmacc_vv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vmacc(vint16m4_t op0, vint16m4_t op1, vint16m4_t op2, size_t op3){
  return vmacc_vv_i16m4(op0, op1, op2, op3);
}

__rvv_overloaded vint16m4_t vmacc(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, vint16m4_t op3, size_t op4){
  return vmacc_vv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vmacc(vint16m8_t op0, vint16m8_t op1, vint16m8_t op2, size_t op3){
  return vmacc_vv_i16m8(op0, op1, op2, op3);
}

__rvv_overloaded vint16m8_t vmacc(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, vint16m8_t op3, size_t op4){
  return vmacc_vv_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vmacc(vint16mf2_t op0, vint16mf2_t op1, vint16mf2_t op2, size_t op3){
  return vmacc_vv_i16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf2_t vmacc(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, vint16mf2_t op3, size_t op4){
  return vmacc_vv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vmacc(vint16mf4_t op0, vint16mf4_t op1, vint16mf4_t op2, size_t op3){
  return vmacc_vv_i16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf4_t vmacc(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, vint16mf4_t op3, size_t op4){
  return vmacc_vv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vmacc(vint32m1_t op0, vint32m1_t op1, vint32m1_t op2, size_t op3){
  return vmacc_vv_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vmacc(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, vint32m1_t op3, size_t op4){
  return vmacc_vv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vmacc(vint32m2_t op0, vint32m2_t op1, vint32m2_t op2, size_t op3){
  return vmacc_vv_i32m2(op0, op1, op2, op3);
}

__rvv_overloaded vint32m2_t vmacc(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, vint32m2_t op3, size_t op4){
  return vmacc_vv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vmacc(vint32m4_t op0, vint32m4_t op1, vint32m4_t op2, size_t op3){
  return vmacc_vv_i32m4(op0, op1, op2, op3);
}

__rvv_overloaded vint32m4_t vmacc(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, vint32m4_t op3, size_t op4){
  return vmacc_vv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vmacc(vint32m8_t op0, vint32m8_t op1, vint32m8_t op2, size_t op3){
  return vmacc_vv_i32m8(op0, op1, op2, op3);
}

__rvv_overloaded vint32m8_t vmacc(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, vint32m8_t op3, size_t op4){
  return vmacc_vv_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vmacc(vint32mf2_t op0, vint32mf2_t op1, vint32mf2_t op2, size_t op3){
  return vmacc_vv_i32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint32mf2_t vmacc(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, vint32mf2_t op3, size_t op4){
  return vmacc_vv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vmacc(vint64m1_t op0, vint64m1_t op1, vint64m1_t op2, size_t op3){
  return vmacc_vv_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vmacc(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, vint64m1_t op3, size_t op4){
  return vmacc_vv_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vmacc(vint64m2_t op0, vint64m2_t op1, vint64m2_t op2, size_t op3){
  return vmacc_vv_i64m2(op0, op1, op2, op3);
}

__rvv_overloaded vint64m2_t vmacc(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, vint64m2_t op3, size_t op4){
  return vmacc_vv_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vmacc(vint64m4_t op0, vint64m4_t op1, vint64m4_t op2, size_t op3){
  return vmacc_vv_i64m4(op0, op1, op2, op3);
}

__rvv_overloaded vint64m4_t vmacc(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, vint64m4_t op3, size_t op4){
  return vmacc_vv_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vmacc(vint64m8_t op0, vint64m8_t op1, vint64m8_t op2, size_t op3){
  return vmacc_vv_i64m8(op0, op1, op2, op3);
}

__rvv_overloaded vint64m8_t vmacc(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, vint64m8_t op3, size_t op4){
  return vmacc_vv_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vmacc(vint8m1_t op0, int8_t op1, vint8m1_t op2, size_t op3){
  return vmacc_vx_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vmacc(vbool8_t op0, vint8m1_t op1, int8_t op2, vint8m1_t op3, size_t op4){
  return vmacc_vx_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vmacc(vint8m2_t op0, int8_t op1, vint8m2_t op2, size_t op3){
  return vmacc_vx_i8m2(op0, op1, op2, op3);
}

__rvv_overloaded vint8m2_t vmacc(vbool4_t op0, vint8m2_t op1, int8_t op2, vint8m2_t op3, size_t op4){
  return vmacc_vx_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vmacc(vint8m4_t op0, int8_t op1, vint8m4_t op2, size_t op3){
  return vmacc_vx_i8m4(op0, op1, op2, op3);
}

__rvv_overloaded vint8m4_t vmacc(vbool2_t op0, vint8m4_t op1, int8_t op2, vint8m4_t op3, size_t op4){
  return vmacc_vx_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vmacc(vint8m8_t op0, int8_t op1, vint8m8_t op2, size_t op3){
  return vmacc_vx_i8m8(op0, op1, op2, op3);
}

__rvv_overloaded vint8m8_t vmacc(vbool1_t op0, vint8m8_t op1, int8_t op2, vint8m8_t op3, size_t op4){
  return vmacc_vx_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vmacc(vint8mf2_t op0, int8_t op1, vint8mf2_t op2, size_t op3){
  return vmacc_vx_i8mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf2_t vmacc(vbool16_t op0, vint8mf2_t op1, int8_t op2, vint8mf2_t op3, size_t op4){
  return vmacc_vx_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vmacc(vint8mf4_t op0, int8_t op1, vint8mf4_t op2, size_t op3){
  return vmacc_vx_i8mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf4_t vmacc(vbool32_t op0, vint8mf4_t op1, int8_t op2, vint8mf4_t op3, size_t op4){
  return vmacc_vx_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vmacc(vint8mf8_t op0, int8_t op1, vint8mf8_t op2, size_t op3){
  return vmacc_vx_i8mf8(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf8_t vmacc(vbool64_t op0, vint8mf8_t op1, int8_t op2, vint8mf8_t op3, size_t op4){
  return vmacc_vx_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vmacc(vint16m1_t op0, int16_t op1, vint16m1_t op2, size_t op3){
  return vmacc_vx_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vmacc(vbool16_t op0, vint16m1_t op1, int16_t op2, vint16m1_t op3, size_t op4){
  return vmacc_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vmacc(vint16m2_t op0, int16_t op1, vint16m2_t op2, size_t op3){
  return vmacc_vx_i16m2(op0, op1, op2, op3);
}

__rvv_overloaded vint16m2_t vmacc(vbool8_t op0, vint16m2_t op1, int16_t op2, vint16m2_t op3, size_t op4){
  return vmacc_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vmacc(vint16m4_t op0, int16_t op1, vint16m4_t op2, size_t op3){
  return vmacc_vx_i16m4(op0, op1, op2, op3);
}

__rvv_overloaded vint16m4_t vmacc(vbool4_t op0, vint16m4_t op1, int16_t op2, vint16m4_t op3, size_t op4){
  return vmacc_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vmacc(vint16m8_t op0, int16_t op1, vint16m8_t op2, size_t op3){
  return vmacc_vx_i16m8(op0, op1, op2, op3);
}

__rvv_overloaded vint16m8_t vmacc(vbool2_t op0, vint16m8_t op1, int16_t op2, vint16m8_t op3, size_t op4){
  return vmacc_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vmacc(vint16mf2_t op0, int16_t op1, vint16mf2_t op2, size_t op3){
  return vmacc_vx_i16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf2_t vmacc(vbool32_t op0, vint16mf2_t op1, int16_t op2, vint16mf2_t op3, size_t op4){
  return vmacc_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vmacc(vint16mf4_t op0, int16_t op1, vint16mf4_t op2, size_t op3){
  return vmacc_vx_i16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf4_t vmacc(vbool64_t op0, vint16mf4_t op1, int16_t op2, vint16mf4_t op3, size_t op4){
  return vmacc_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vmacc(vint32m1_t op0, int32_t op1, vint32m1_t op2, size_t op3){
  return vmacc_vx_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vmacc(vbool32_t op0, vint32m1_t op1, int32_t op2, vint32m1_t op3, size_t op4){
  return vmacc_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vmacc(vint32m2_t op0, int32_t op1, vint32m2_t op2, size_t op3){
  return vmacc_vx_i32m2(op0, op1, op2, op3);
}

__rvv_overloaded vint32m2_t vmacc(vbool16_t op0, vint32m2_t op1, int32_t op2, vint32m2_t op3, size_t op4){
  return vmacc_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vmacc(vint32m4_t op0, int32_t op1, vint32m4_t op2, size_t op3){
  return vmacc_vx_i32m4(op0, op1, op2, op3);
}

__rvv_overloaded vint32m4_t vmacc(vbool8_t op0, vint32m4_t op1, int32_t op2, vint32m4_t op3, size_t op4){
  return vmacc_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vmacc(vint32m8_t op0, int32_t op1, vint32m8_t op2, size_t op3){
  return vmacc_vx_i32m8(op0, op1, op2, op3);
}

__rvv_overloaded vint32m8_t vmacc(vbool4_t op0, vint32m8_t op1, int32_t op2, vint32m8_t op3, size_t op4){
  return vmacc_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vmacc(vint32mf2_t op0, int32_t op1, vint32mf2_t op2, size_t op3){
  return vmacc_vx_i32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint32mf2_t vmacc(vbool64_t op0, vint32mf2_t op1, int32_t op2, vint32mf2_t op3, size_t op4){
  return vmacc_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vmacc(vint64m1_t op0, int64_t op1, vint64m1_t op2, size_t op3){
  return vmacc_vx_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vmacc(vbool64_t op0, vint64m1_t op1, int64_t op2, vint64m1_t op3, size_t op4){
  return vmacc_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vmacc(vint64m2_t op0, int64_t op1, vint64m2_t op2, size_t op3){
  return vmacc_vx_i64m2(op0, op1, op2, op3);
}

__rvv_overloaded vint64m2_t vmacc(vbool32_t op0, vint64m2_t op1, int64_t op2, vint64m2_t op3, size_t op4){
  return vmacc_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vmacc(vint64m4_t op0, int64_t op1, vint64m4_t op2, size_t op3){
  return vmacc_vx_i64m4(op0, op1, op2, op3);
}

__rvv_overloaded vint64m4_t vmacc(vbool16_t op0, vint64m4_t op1, int64_t op2, vint64m4_t op3, size_t op4){
  return vmacc_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vmacc(vint64m8_t op0, int64_t op1, vint64m8_t op2, size_t op3){
  return vmacc_vx_i64m8(op0, op1, op2, op3);
}

__rvv_overloaded vint64m8_t vmacc(vbool8_t op0, vint64m8_t op1, int64_t op2, vint64m8_t op3, size_t op4){
  return vmacc_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vmacc(vuint8m1_t op0, vuint8m1_t op1, vuint8m1_t op2, size_t op3){
  return vmacc_vv_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vmacc(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vmacc_vv_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vmacc(vuint8m2_t op0, vuint8m2_t op1, vuint8m2_t op2, size_t op3){
  return vmacc_vv_u8m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m2_t vmacc(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vmacc_vv_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vmacc(vuint8m4_t op0, vuint8m4_t op1, vuint8m4_t op2, size_t op3){
  return vmacc_vv_u8m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m4_t vmacc(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vmacc_vv_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vmacc(vuint8m8_t op0, vuint8m8_t op1, vuint8m8_t op2, size_t op3){
  return vmacc_vv_u8m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m8_t vmacc(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, vuint8m8_t op3, size_t op4){
  return vmacc_vv_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vmacc(vuint8mf2_t op0, vuint8mf2_t op1, vuint8mf2_t op2, size_t op3){
  return vmacc_vv_u8mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf2_t vmacc(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vmacc_vv_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vmacc(vuint8mf4_t op0, vuint8mf4_t op1, vuint8mf4_t op2, size_t op3){
  return vmacc_vv_u8mf4(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf4_t vmacc(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vmacc_vv_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vmacc(vuint8mf8_t op0, vuint8mf8_t op1, vuint8mf8_t op2, size_t op3){
  return vmacc_vv_u8mf8(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf8_t vmacc(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vmacc_vv_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vmacc(vuint16m1_t op0, vuint16m1_t op1, vuint16m1_t op2, size_t op3){
  return vmacc_vv_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vmacc(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vmacc_vv_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vmacc(vuint16m2_t op0, vuint16m2_t op1, vuint16m2_t op2, size_t op3){
  return vmacc_vv_u16m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m2_t vmacc(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vmacc_vv_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vmacc(vuint16m4_t op0, vuint16m4_t op1, vuint16m4_t op2, size_t op3){
  return vmacc_vv_u16m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m4_t vmacc(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vmacc_vv_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vmacc(vuint16m8_t op0, vuint16m8_t op1, vuint16m8_t op2, size_t op3){
  return vmacc_vv_u16m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m8_t vmacc(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vmacc_vv_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vmacc(vuint16mf2_t op0, vuint16mf2_t op1, vuint16mf2_t op2, size_t op3){
  return vmacc_vv_u16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf2_t vmacc(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vmacc_vv_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vmacc(vuint16mf4_t op0, vuint16mf4_t op1, vuint16mf4_t op2, size_t op3){
  return vmacc_vv_u16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf4_t vmacc(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vmacc_vv_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vmacc(vuint32m1_t op0, vuint32m1_t op1, vuint32m1_t op2, size_t op3){
  return vmacc_vv_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vmacc(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vmacc_vv_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vmacc(vuint32m2_t op0, vuint32m2_t op1, vuint32m2_t op2, size_t op3){
  return vmacc_vv_u32m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m2_t vmacc(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vmacc_vv_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vmacc(vuint32m4_t op0, vuint32m4_t op1, vuint32m4_t op2, size_t op3){
  return vmacc_vv_u32m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m4_t vmacc(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vmacc_vv_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vmacc(vuint32m8_t op0, vuint32m8_t op1, vuint32m8_t op2, size_t op3){
  return vmacc_vv_u32m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m8_t vmacc(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, vuint32m8_t op3, size_t op4){
  return vmacc_vv_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vmacc(vuint32mf2_t op0, vuint32mf2_t op1, vuint32mf2_t op2, size_t op3){
  return vmacc_vv_u32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint32mf2_t vmacc(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vmacc_vv_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vmacc(vuint64m1_t op0, vuint64m1_t op1, vuint64m1_t op2, size_t op3){
  return vmacc_vv_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vmacc(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vmacc_vv_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vmacc(vuint64m2_t op0, vuint64m2_t op1, vuint64m2_t op2, size_t op3){
  return vmacc_vv_u64m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m2_t vmacc(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, vuint64m2_t op3, size_t op4){
  return vmacc_vv_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vmacc(vuint64m4_t op0, vuint64m4_t op1, vuint64m4_t op2, size_t op3){
  return vmacc_vv_u64m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m4_t vmacc(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, vuint64m4_t op3, size_t op4){
  return vmacc_vv_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vmacc(vuint64m8_t op0, vuint64m8_t op1, vuint64m8_t op2, size_t op3){
  return vmacc_vv_u64m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m8_t vmacc(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, vuint64m8_t op3, size_t op4){
  return vmacc_vv_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vmacc(vuint8m1_t op0, uint8_t op1, vuint8m1_t op2, size_t op3){
  return vmacc_vx_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vmacc(vbool8_t op0, vuint8m1_t op1, uint8_t op2, vuint8m1_t op3, size_t op4){
  return vmacc_vx_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vmacc(vuint8m2_t op0, uint8_t op1, vuint8m2_t op2, size_t op3){
  return vmacc_vx_u8m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m2_t vmacc(vbool4_t op0, vuint8m2_t op1, uint8_t op2, vuint8m2_t op3, size_t op4){
  return vmacc_vx_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vmacc(vuint8m4_t op0, uint8_t op1, vuint8m4_t op2, size_t op3){
  return vmacc_vx_u8m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m4_t vmacc(vbool2_t op0, vuint8m4_t op1, uint8_t op2, vuint8m4_t op3, size_t op4){
  return vmacc_vx_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vmacc(vuint8m8_t op0, uint8_t op1, vuint8m8_t op2, size_t op3){
  return vmacc_vx_u8m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m8_t vmacc(vbool1_t op0, vuint8m8_t op1, uint8_t op2, vuint8m8_t op3, size_t op4){
  return vmacc_vx_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vmacc(vuint8mf2_t op0, uint8_t op1, vuint8mf2_t op2, size_t op3){
  return vmacc_vx_u8mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf2_t vmacc(vbool16_t op0, vuint8mf2_t op1, uint8_t op2, vuint8mf2_t op3, size_t op4){
  return vmacc_vx_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vmacc(vuint8mf4_t op0, uint8_t op1, vuint8mf4_t op2, size_t op3){
  return vmacc_vx_u8mf4(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf4_t vmacc(vbool32_t op0, vuint8mf4_t op1, uint8_t op2, vuint8mf4_t op3, size_t op4){
  return vmacc_vx_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vmacc(vuint8mf8_t op0, uint8_t op1, vuint8mf8_t op2, size_t op3){
  return vmacc_vx_u8mf8(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf8_t vmacc(vbool64_t op0, vuint8mf8_t op1, uint8_t op2, vuint8mf8_t op3, size_t op4){
  return vmacc_vx_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vmacc(vuint16m1_t op0, uint16_t op1, vuint16m1_t op2, size_t op3){
  return vmacc_vx_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vmacc(vbool16_t op0, vuint16m1_t op1, uint16_t op2, vuint16m1_t op3, size_t op4){
  return vmacc_vx_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vmacc(vuint16m2_t op0, uint16_t op1, vuint16m2_t op2, size_t op3){
  return vmacc_vx_u16m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m2_t vmacc(vbool8_t op0, vuint16m2_t op1, uint16_t op2, vuint16m2_t op3, size_t op4){
  return vmacc_vx_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vmacc(vuint16m4_t op0, uint16_t op1, vuint16m4_t op2, size_t op3){
  return vmacc_vx_u16m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m4_t vmacc(vbool4_t op0, vuint16m4_t op1, uint16_t op2, vuint16m4_t op3, size_t op4){
  return vmacc_vx_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vmacc(vuint16m8_t op0, uint16_t op1, vuint16m8_t op2, size_t op3){
  return vmacc_vx_u16m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m8_t vmacc(vbool2_t op0, vuint16m8_t op1, uint16_t op2, vuint16m8_t op3, size_t op4){
  return vmacc_vx_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vmacc(vuint16mf2_t op0, uint16_t op1, vuint16mf2_t op2, size_t op3){
  return vmacc_vx_u16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf2_t vmacc(vbool32_t op0, vuint16mf2_t op1, uint16_t op2, vuint16mf2_t op3, size_t op4){
  return vmacc_vx_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vmacc(vuint16mf4_t op0, uint16_t op1, vuint16mf4_t op2, size_t op3){
  return vmacc_vx_u16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf4_t vmacc(vbool64_t op0, vuint16mf4_t op1, uint16_t op2, vuint16mf4_t op3, size_t op4){
  return vmacc_vx_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vmacc(vuint32m1_t op0, uint32_t op1, vuint32m1_t op2, size_t op3){
  return vmacc_vx_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vmacc(vbool32_t op0, vuint32m1_t op1, uint32_t op2, vuint32m1_t op3, size_t op4){
  return vmacc_vx_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vmacc(vuint32m2_t op0, uint32_t op1, vuint32m2_t op2, size_t op3){
  return vmacc_vx_u32m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m2_t vmacc(vbool16_t op0, vuint32m2_t op1, uint32_t op2, vuint32m2_t op3, size_t op4){
  return vmacc_vx_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vmacc(vuint32m4_t op0, uint32_t op1, vuint32m4_t op2, size_t op3){
  return vmacc_vx_u32m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m4_t vmacc(vbool8_t op0, vuint32m4_t op1, uint32_t op2, vuint32m4_t op3, size_t op4){
  return vmacc_vx_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vmacc(vuint32m8_t op0, uint32_t op1, vuint32m8_t op2, size_t op3){
  return vmacc_vx_u32m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m8_t vmacc(vbool4_t op0, vuint32m8_t op1, uint32_t op2, vuint32m8_t op3, size_t op4){
  return vmacc_vx_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vmacc(vuint32mf2_t op0, uint32_t op1, vuint32mf2_t op2, size_t op3){
  return vmacc_vx_u32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint32mf2_t vmacc(vbool64_t op0, vuint32mf2_t op1, uint32_t op2, vuint32mf2_t op3, size_t op4){
  return vmacc_vx_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vmacc(vuint64m1_t op0, uint64_t op1, vuint64m1_t op2, size_t op3){
  return vmacc_vx_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vmacc(vbool64_t op0, vuint64m1_t op1, uint64_t op2, vuint64m1_t op3, size_t op4){
  return vmacc_vx_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vmacc(vuint64m2_t op0, uint64_t op1, vuint64m2_t op2, size_t op3){
  return vmacc_vx_u64m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m2_t vmacc(vbool32_t op0, vuint64m2_t op1, uint64_t op2, vuint64m2_t op3, size_t op4){
  return vmacc_vx_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vmacc(vuint64m4_t op0, uint64_t op1, vuint64m4_t op2, size_t op3){
  return vmacc_vx_u64m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m4_t vmacc(vbool16_t op0, vuint64m4_t op1, uint64_t op2, vuint64m4_t op3, size_t op4){
  return vmacc_vx_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vmacc(vuint64m8_t op0, uint64_t op1, vuint64m8_t op2, size_t op3){
  return vmacc_vx_u64m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m8_t vmacc(vbool8_t op0, vuint64m8_t op1, uint64_t op2, vuint64m8_t op3, size_t op4){
  return vmacc_vx_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vle16ff(vbool16_t op0, vint16m1_t op1, const int16_t * op2, size_t * op3, size_t op4){
  return vle16ff_v_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vle16ff(vbool8_t op0, vint16m2_t op1, const int16_t * op2, size_t * op3, size_t op4){
  return vle16ff_v_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vle16ff(vbool4_t op0, vint16m4_t op1, const int16_t * op2, size_t * op3, size_t op4){
  return vle16ff_v_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vle16ff(vbool2_t op0, vint16m8_t op1, const int16_t * op2, size_t * op3, size_t op4){
  return vle16ff_v_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vle16ff(vbool32_t op0, vint16mf2_t op1, const int16_t * op2, size_t * op3, size_t op4){
  return vle16ff_v_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vle16ff(vbool64_t op0, vint16mf4_t op1, const int16_t * op2, size_t * op3, size_t op4){
  return vle16ff_v_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vnmsac(vint8m1_t op0, vint8m1_t op1, vint8m1_t op2, size_t op3){
  return vnmsac_vv_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vnmsac(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, vint8m1_t op3, size_t op4){
  return vnmsac_vv_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vnmsac(vint8m2_t op0, vint8m2_t op1, vint8m2_t op2, size_t op3){
  return vnmsac_vv_i8m2(op0, op1, op2, op3);
}

__rvv_overloaded vint8m2_t vnmsac(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, vint8m2_t op3, size_t op4){
  return vnmsac_vv_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vnmsac(vint8m4_t op0, vint8m4_t op1, vint8m4_t op2, size_t op3){
  return vnmsac_vv_i8m4(op0, op1, op2, op3);
}

__rvv_overloaded vint8m4_t vnmsac(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, vint8m4_t op3, size_t op4){
  return vnmsac_vv_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vnmsac(vint8m8_t op0, vint8m8_t op1, vint8m8_t op2, size_t op3){
  return vnmsac_vv_i8m8(op0, op1, op2, op3);
}

__rvv_overloaded vint8m8_t vnmsac(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, vint8m8_t op3, size_t op4){
  return vnmsac_vv_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vnmsac(vint8mf2_t op0, vint8mf2_t op1, vint8mf2_t op2, size_t op3){
  return vnmsac_vv_i8mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf2_t vnmsac(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, vint8mf2_t op3, size_t op4){
  return vnmsac_vv_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vnmsac(vint8mf4_t op0, vint8mf4_t op1, vint8mf4_t op2, size_t op3){
  return vnmsac_vv_i8mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf4_t vnmsac(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, vint8mf4_t op3, size_t op4){
  return vnmsac_vv_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vnmsac(vint8mf8_t op0, vint8mf8_t op1, vint8mf8_t op2, size_t op3){
  return vnmsac_vv_i8mf8(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf8_t vnmsac(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, vint8mf8_t op3, size_t op4){
  return vnmsac_vv_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vnmsac(vint16m1_t op0, vint16m1_t op1, vint16m1_t op2, size_t op3){
  return vnmsac_vv_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vnmsac(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, vint16m1_t op3, size_t op4){
  return vnmsac_vv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vnmsac(vint16m2_t op0, vint16m2_t op1, vint16m2_t op2, size_t op3){
  return vnmsac_vv_i16m2(op0, op1, op2, op3);
}

__rvv_overloaded vint16m2_t vnmsac(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, vint16m2_t op3, size_t op4){
  return vnmsac_vv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vnmsac(vint16m4_t op0, vint16m4_t op1, vint16m4_t op2, size_t op3){
  return vnmsac_vv_i16m4(op0, op1, op2, op3);
}

__rvv_overloaded vint16m4_t vnmsac(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, vint16m4_t op3, size_t op4){
  return vnmsac_vv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vnmsac(vint16m8_t op0, vint16m8_t op1, vint16m8_t op2, size_t op3){
  return vnmsac_vv_i16m8(op0, op1, op2, op3);
}

__rvv_overloaded vint16m8_t vnmsac(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, vint16m8_t op3, size_t op4){
  return vnmsac_vv_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vnmsac(vint16mf2_t op0, vint16mf2_t op1, vint16mf2_t op2, size_t op3){
  return vnmsac_vv_i16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf2_t vnmsac(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, vint16mf2_t op3, size_t op4){
  return vnmsac_vv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vnmsac(vint16mf4_t op0, vint16mf4_t op1, vint16mf4_t op2, size_t op3){
  return vnmsac_vv_i16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf4_t vnmsac(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, vint16mf4_t op3, size_t op4){
  return vnmsac_vv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vnmsac(vint32m1_t op0, vint32m1_t op1, vint32m1_t op2, size_t op3){
  return vnmsac_vv_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vnmsac(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, vint32m1_t op3, size_t op4){
  return vnmsac_vv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vnmsac(vint32m2_t op0, vint32m2_t op1, vint32m2_t op2, size_t op3){
  return vnmsac_vv_i32m2(op0, op1, op2, op3);
}

__rvv_overloaded vint32m2_t vnmsac(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, vint32m2_t op3, size_t op4){
  return vnmsac_vv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vnmsac(vint32m4_t op0, vint32m4_t op1, vint32m4_t op2, size_t op3){
  return vnmsac_vv_i32m4(op0, op1, op2, op3);
}

__rvv_overloaded vint32m4_t vnmsac(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, vint32m4_t op3, size_t op4){
  return vnmsac_vv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vnmsac(vint32m8_t op0, vint32m8_t op1, vint32m8_t op2, size_t op3){
  return vnmsac_vv_i32m8(op0, op1, op2, op3);
}

__rvv_overloaded vint32m8_t vnmsac(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, vint32m8_t op3, size_t op4){
  return vnmsac_vv_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vnmsac(vint32mf2_t op0, vint32mf2_t op1, vint32mf2_t op2, size_t op3){
  return vnmsac_vv_i32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint32mf2_t vnmsac(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, vint32mf2_t op3, size_t op4){
  return vnmsac_vv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vnmsac(vint64m1_t op0, vint64m1_t op1, vint64m1_t op2, size_t op3){
  return vnmsac_vv_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vnmsac(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, vint64m1_t op3, size_t op4){
  return vnmsac_vv_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vnmsac(vint64m2_t op0, vint64m2_t op1, vint64m2_t op2, size_t op3){
  return vnmsac_vv_i64m2(op0, op1, op2, op3);
}

__rvv_overloaded vint64m2_t vnmsac(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, vint64m2_t op3, size_t op4){
  return vnmsac_vv_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vnmsac(vint64m4_t op0, vint64m4_t op1, vint64m4_t op2, size_t op3){
  return vnmsac_vv_i64m4(op0, op1, op2, op3);
}

__rvv_overloaded vint64m4_t vnmsac(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, vint64m4_t op3, size_t op4){
  return vnmsac_vv_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vnmsac(vint64m8_t op0, vint64m8_t op1, vint64m8_t op2, size_t op3){
  return vnmsac_vv_i64m8(op0, op1, op2, op3);
}

__rvv_overloaded vint64m8_t vnmsac(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, vint64m8_t op3, size_t op4){
  return vnmsac_vv_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vnmsac(vint8m1_t op0, int8_t op1, vint8m1_t op2, size_t op3){
  return vnmsac_vx_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vnmsac(vbool8_t op0, vint8m1_t op1, int8_t op2, vint8m1_t op3, size_t op4){
  return vnmsac_vx_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vnmsac(vint8m2_t op0, int8_t op1, vint8m2_t op2, size_t op3){
  return vnmsac_vx_i8m2(op0, op1, op2, op3);
}

__rvv_overloaded vint8m2_t vnmsac(vbool4_t op0, vint8m2_t op1, int8_t op2, vint8m2_t op3, size_t op4){
  return vnmsac_vx_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vnmsac(vint8m4_t op0, int8_t op1, vint8m4_t op2, size_t op3){
  return vnmsac_vx_i8m4(op0, op1, op2, op3);
}

__rvv_overloaded vint8m4_t vnmsac(vbool2_t op0, vint8m4_t op1, int8_t op2, vint8m4_t op3, size_t op4){
  return vnmsac_vx_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vnmsac(vint8m8_t op0, int8_t op1, vint8m8_t op2, size_t op3){
  return vnmsac_vx_i8m8(op0, op1, op2, op3);
}

__rvv_overloaded vint8m8_t vnmsac(vbool1_t op0, vint8m8_t op1, int8_t op2, vint8m8_t op3, size_t op4){
  return vnmsac_vx_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vnmsac(vint8mf2_t op0, int8_t op1, vint8mf2_t op2, size_t op3){
  return vnmsac_vx_i8mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf2_t vnmsac(vbool16_t op0, vint8mf2_t op1, int8_t op2, vint8mf2_t op3, size_t op4){
  return vnmsac_vx_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vnmsac(vint8mf4_t op0, int8_t op1, vint8mf4_t op2, size_t op3){
  return vnmsac_vx_i8mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf4_t vnmsac(vbool32_t op0, vint8mf4_t op1, int8_t op2, vint8mf4_t op3, size_t op4){
  return vnmsac_vx_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vnmsac(vint8mf8_t op0, int8_t op1, vint8mf8_t op2, size_t op3){
  return vnmsac_vx_i8mf8(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf8_t vnmsac(vbool64_t op0, vint8mf8_t op1, int8_t op2, vint8mf8_t op3, size_t op4){
  return vnmsac_vx_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vnmsac(vint16m1_t op0, int16_t op1, vint16m1_t op2, size_t op3){
  return vnmsac_vx_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vnmsac(vbool16_t op0, vint16m1_t op1, int16_t op2, vint16m1_t op3, size_t op4){
  return vnmsac_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vnmsac(vint16m2_t op0, int16_t op1, vint16m2_t op2, size_t op3){
  return vnmsac_vx_i16m2(op0, op1, op2, op3);
}

__rvv_overloaded vint16m2_t vnmsac(vbool8_t op0, vint16m2_t op1, int16_t op2, vint16m2_t op3, size_t op4){
  return vnmsac_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vnmsac(vint16m4_t op0, int16_t op1, vint16m4_t op2, size_t op3){
  return vnmsac_vx_i16m4(op0, op1, op2, op3);
}

__rvv_overloaded vint16m4_t vnmsac(vbool4_t op0, vint16m4_t op1, int16_t op2, vint16m4_t op3, size_t op4){
  return vnmsac_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vnmsac(vint16m8_t op0, int16_t op1, vint16m8_t op2, size_t op3){
  return vnmsac_vx_i16m8(op0, op1, op2, op3);
}

__rvv_overloaded vint16m8_t vnmsac(vbool2_t op0, vint16m8_t op1, int16_t op2, vint16m8_t op3, size_t op4){
  return vnmsac_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vnmsac(vint16mf2_t op0, int16_t op1, vint16mf2_t op2, size_t op3){
  return vnmsac_vx_i16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf2_t vnmsac(vbool32_t op0, vint16mf2_t op1, int16_t op2, vint16mf2_t op3, size_t op4){
  return vnmsac_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vnmsac(vint16mf4_t op0, int16_t op1, vint16mf4_t op2, size_t op3){
  return vnmsac_vx_i16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf4_t vnmsac(vbool64_t op0, vint16mf4_t op1, int16_t op2, vint16mf4_t op3, size_t op4){
  return vnmsac_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vnmsac(vint32m1_t op0, int32_t op1, vint32m1_t op2, size_t op3){
  return vnmsac_vx_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vnmsac(vbool32_t op0, vint32m1_t op1, int32_t op2, vint32m1_t op3, size_t op4){
  return vnmsac_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vnmsac(vint32m2_t op0, int32_t op1, vint32m2_t op2, size_t op3){
  return vnmsac_vx_i32m2(op0, op1, op2, op3);
}

__rvv_overloaded vint32m2_t vnmsac(vbool16_t op0, vint32m2_t op1, int32_t op2, vint32m2_t op3, size_t op4){
  return vnmsac_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vnmsac(vint32m4_t op0, int32_t op1, vint32m4_t op2, size_t op3){
  return vnmsac_vx_i32m4(op0, op1, op2, op3);
}

__rvv_overloaded vint32m4_t vnmsac(vbool8_t op0, vint32m4_t op1, int32_t op2, vint32m4_t op3, size_t op4){
  return vnmsac_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vnmsac(vint32m8_t op0, int32_t op1, vint32m8_t op2, size_t op3){
  return vnmsac_vx_i32m8(op0, op1, op2, op3);
}

__rvv_overloaded vint32m8_t vnmsac(vbool4_t op0, vint32m8_t op1, int32_t op2, vint32m8_t op3, size_t op4){
  return vnmsac_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vnmsac(vint32mf2_t op0, int32_t op1, vint32mf2_t op2, size_t op3){
  return vnmsac_vx_i32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint32mf2_t vnmsac(vbool64_t op0, vint32mf2_t op1, int32_t op2, vint32mf2_t op3, size_t op4){
  return vnmsac_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vnmsac(vint64m1_t op0, int64_t op1, vint64m1_t op2, size_t op3){
  return vnmsac_vx_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vnmsac(vbool64_t op0, vint64m1_t op1, int64_t op2, vint64m1_t op3, size_t op4){
  return vnmsac_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vnmsac(vint64m2_t op0, int64_t op1, vint64m2_t op2, size_t op3){
  return vnmsac_vx_i64m2(op0, op1, op2, op3);
}

__rvv_overloaded vint64m2_t vnmsac(vbool32_t op0, vint64m2_t op1, int64_t op2, vint64m2_t op3, size_t op4){
  return vnmsac_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vnmsac(vint64m4_t op0, int64_t op1, vint64m4_t op2, size_t op3){
  return vnmsac_vx_i64m4(op0, op1, op2, op3);
}

__rvv_overloaded vint64m4_t vnmsac(vbool16_t op0, vint64m4_t op1, int64_t op2, vint64m4_t op3, size_t op4){
  return vnmsac_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vnmsac(vint64m8_t op0, int64_t op1, vint64m8_t op2, size_t op3){
  return vnmsac_vx_i64m8(op0, op1, op2, op3);
}

__rvv_overloaded vint64m8_t vnmsac(vbool8_t op0, vint64m8_t op1, int64_t op2, vint64m8_t op3, size_t op4){
  return vnmsac_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vnmsac(vuint8m1_t op0, vuint8m1_t op1, vuint8m1_t op2, size_t op3){
  return vnmsac_vv_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vnmsac(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vnmsac_vv_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vnmsac(vuint8m2_t op0, vuint8m2_t op1, vuint8m2_t op2, size_t op3){
  return vnmsac_vv_u8m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m2_t vnmsac(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vnmsac_vv_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vnmsac(vuint8m4_t op0, vuint8m4_t op1, vuint8m4_t op2, size_t op3){
  return vnmsac_vv_u8m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m4_t vnmsac(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vnmsac_vv_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vnmsac(vuint8m8_t op0, vuint8m8_t op1, vuint8m8_t op2, size_t op3){
  return vnmsac_vv_u8m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m8_t vnmsac(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, vuint8m8_t op3, size_t op4){
  return vnmsac_vv_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vnmsac(vuint8mf2_t op0, vuint8mf2_t op1, vuint8mf2_t op2, size_t op3){
  return vnmsac_vv_u8mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf2_t vnmsac(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vnmsac_vv_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vnmsac(vuint8mf4_t op0, vuint8mf4_t op1, vuint8mf4_t op2, size_t op3){
  return vnmsac_vv_u8mf4(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf4_t vnmsac(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vnmsac_vv_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vnmsac(vuint8mf8_t op0, vuint8mf8_t op1, vuint8mf8_t op2, size_t op3){
  return vnmsac_vv_u8mf8(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf8_t vnmsac(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vnmsac_vv_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vnmsac(vuint16m1_t op0, vuint16m1_t op1, vuint16m1_t op2, size_t op3){
  return vnmsac_vv_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vnmsac(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vnmsac_vv_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vnmsac(vuint16m2_t op0, vuint16m2_t op1, vuint16m2_t op2, size_t op3){
  return vnmsac_vv_u16m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m2_t vnmsac(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vnmsac_vv_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vnmsac(vuint16m4_t op0, vuint16m4_t op1, vuint16m4_t op2, size_t op3){
  return vnmsac_vv_u16m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m4_t vnmsac(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vnmsac_vv_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vnmsac(vuint16m8_t op0, vuint16m8_t op1, vuint16m8_t op2, size_t op3){
  return vnmsac_vv_u16m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m8_t vnmsac(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vnmsac_vv_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vnmsac(vuint16mf2_t op0, vuint16mf2_t op1, vuint16mf2_t op2, size_t op3){
  return vnmsac_vv_u16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf2_t vnmsac(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vnmsac_vv_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vnmsac(vuint16mf4_t op0, vuint16mf4_t op1, vuint16mf4_t op2, size_t op3){
  return vnmsac_vv_u16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf4_t vnmsac(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vnmsac_vv_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vnmsac(vuint32m1_t op0, vuint32m1_t op1, vuint32m1_t op2, size_t op3){
  return vnmsac_vv_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vnmsac(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vnmsac_vv_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vnmsac(vuint32m2_t op0, vuint32m2_t op1, vuint32m2_t op2, size_t op3){
  return vnmsac_vv_u32m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m2_t vnmsac(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vnmsac_vv_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vnmsac(vuint32m4_t op0, vuint32m4_t op1, vuint32m4_t op2, size_t op3){
  return vnmsac_vv_u32m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m4_t vnmsac(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vnmsac_vv_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vnmsac(vuint32m8_t op0, vuint32m8_t op1, vuint32m8_t op2, size_t op3){
  return vnmsac_vv_u32m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m8_t vnmsac(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, vuint32m8_t op3, size_t op4){
  return vnmsac_vv_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vnmsac(vuint32mf2_t op0, vuint32mf2_t op1, vuint32mf2_t op2, size_t op3){
  return vnmsac_vv_u32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint32mf2_t vnmsac(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vnmsac_vv_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vnmsac(vuint64m1_t op0, vuint64m1_t op1, vuint64m1_t op2, size_t op3){
  return vnmsac_vv_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vnmsac(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vnmsac_vv_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vnmsac(vuint64m2_t op0, vuint64m2_t op1, vuint64m2_t op2, size_t op3){
  return vnmsac_vv_u64m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m2_t vnmsac(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, vuint64m2_t op3, size_t op4){
  return vnmsac_vv_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vnmsac(vuint64m4_t op0, vuint64m4_t op1, vuint64m4_t op2, size_t op3){
  return vnmsac_vv_u64m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m4_t vnmsac(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, vuint64m4_t op3, size_t op4){
  return vnmsac_vv_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vnmsac(vuint64m8_t op0, vuint64m8_t op1, vuint64m8_t op2, size_t op3){
  return vnmsac_vv_u64m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m8_t vnmsac(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, vuint64m8_t op3, size_t op4){
  return vnmsac_vv_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vnmsac(vuint8m1_t op0, uint8_t op1, vuint8m1_t op2, size_t op3){
  return vnmsac_vx_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vnmsac(vbool8_t op0, vuint8m1_t op1, uint8_t op2, vuint8m1_t op3, size_t op4){
  return vnmsac_vx_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vnmsac(vuint8m2_t op0, uint8_t op1, vuint8m2_t op2, size_t op3){
  return vnmsac_vx_u8m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m2_t vnmsac(vbool4_t op0, vuint8m2_t op1, uint8_t op2, vuint8m2_t op3, size_t op4){
  return vnmsac_vx_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vnmsac(vuint8m4_t op0, uint8_t op1, vuint8m4_t op2, size_t op3){
  return vnmsac_vx_u8m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m4_t vnmsac(vbool2_t op0, vuint8m4_t op1, uint8_t op2, vuint8m4_t op3, size_t op4){
  return vnmsac_vx_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vnmsac(vuint8m8_t op0, uint8_t op1, vuint8m8_t op2, size_t op3){
  return vnmsac_vx_u8m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m8_t vnmsac(vbool1_t op0, vuint8m8_t op1, uint8_t op2, vuint8m8_t op3, size_t op4){
  return vnmsac_vx_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vnmsac(vuint8mf2_t op0, uint8_t op1, vuint8mf2_t op2, size_t op3){
  return vnmsac_vx_u8mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf2_t vnmsac(vbool16_t op0, vuint8mf2_t op1, uint8_t op2, vuint8mf2_t op3, size_t op4){
  return vnmsac_vx_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vnmsac(vuint8mf4_t op0, uint8_t op1, vuint8mf4_t op2, size_t op3){
  return vnmsac_vx_u8mf4(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf4_t vnmsac(vbool32_t op0, vuint8mf4_t op1, uint8_t op2, vuint8mf4_t op3, size_t op4){
  return vnmsac_vx_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vnmsac(vuint8mf8_t op0, uint8_t op1, vuint8mf8_t op2, size_t op3){
  return vnmsac_vx_u8mf8(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf8_t vnmsac(vbool64_t op0, vuint8mf8_t op1, uint8_t op2, vuint8mf8_t op3, size_t op4){
  return vnmsac_vx_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vnmsac(vuint16m1_t op0, uint16_t op1, vuint16m1_t op2, size_t op3){
  return vnmsac_vx_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vnmsac(vbool16_t op0, vuint16m1_t op1, uint16_t op2, vuint16m1_t op3, size_t op4){
  return vnmsac_vx_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vnmsac(vuint16m2_t op0, uint16_t op1, vuint16m2_t op2, size_t op3){
  return vnmsac_vx_u16m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m2_t vnmsac(vbool8_t op0, vuint16m2_t op1, uint16_t op2, vuint16m2_t op3, size_t op4){
  return vnmsac_vx_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vnmsac(vuint16m4_t op0, uint16_t op1, vuint16m4_t op2, size_t op3){
  return vnmsac_vx_u16m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m4_t vnmsac(vbool4_t op0, vuint16m4_t op1, uint16_t op2, vuint16m4_t op3, size_t op4){
  return vnmsac_vx_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vnmsac(vuint16m8_t op0, uint16_t op1, vuint16m8_t op2, size_t op3){
  return vnmsac_vx_u16m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m8_t vnmsac(vbool2_t op0, vuint16m8_t op1, uint16_t op2, vuint16m8_t op3, size_t op4){
  return vnmsac_vx_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vnmsac(vuint16mf2_t op0, uint16_t op1, vuint16mf2_t op2, size_t op3){
  return vnmsac_vx_u16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf2_t vnmsac(vbool32_t op0, vuint16mf2_t op1, uint16_t op2, vuint16mf2_t op3, size_t op4){
  return vnmsac_vx_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vnmsac(vuint16mf4_t op0, uint16_t op1, vuint16mf4_t op2, size_t op3){
  return vnmsac_vx_u16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf4_t vnmsac(vbool64_t op0, vuint16mf4_t op1, uint16_t op2, vuint16mf4_t op3, size_t op4){
  return vnmsac_vx_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vnmsac(vuint32m1_t op0, uint32_t op1, vuint32m1_t op2, size_t op3){
  return vnmsac_vx_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vnmsac(vbool32_t op0, vuint32m1_t op1, uint32_t op2, vuint32m1_t op3, size_t op4){
  return vnmsac_vx_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vnmsac(vuint32m2_t op0, uint32_t op1, vuint32m2_t op2, size_t op3){
  return vnmsac_vx_u32m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m2_t vnmsac(vbool16_t op0, vuint32m2_t op1, uint32_t op2, vuint32m2_t op3, size_t op4){
  return vnmsac_vx_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vnmsac(vuint32m4_t op0, uint32_t op1, vuint32m4_t op2, size_t op3){
  return vnmsac_vx_u32m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m4_t vnmsac(vbool8_t op0, vuint32m4_t op1, uint32_t op2, vuint32m4_t op3, size_t op4){
  return vnmsac_vx_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vnmsac(vuint32m8_t op0, uint32_t op1, vuint32m8_t op2, size_t op3){
  return vnmsac_vx_u32m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m8_t vnmsac(vbool4_t op0, vuint32m8_t op1, uint32_t op2, vuint32m8_t op3, size_t op4){
  return vnmsac_vx_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vnmsac(vuint32mf2_t op0, uint32_t op1, vuint32mf2_t op2, size_t op3){
  return vnmsac_vx_u32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint32mf2_t vnmsac(vbool64_t op0, vuint32mf2_t op1, uint32_t op2, vuint32mf2_t op3, size_t op4){
  return vnmsac_vx_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vnmsac(vuint64m1_t op0, uint64_t op1, vuint64m1_t op2, size_t op3){
  return vnmsac_vx_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vnmsac(vbool64_t op0, vuint64m1_t op1, uint64_t op2, vuint64m1_t op3, size_t op4){
  return vnmsac_vx_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vnmsac(vuint64m2_t op0, uint64_t op1, vuint64m2_t op2, size_t op3){
  return vnmsac_vx_u64m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m2_t vnmsac(vbool32_t op0, vuint64m2_t op1, uint64_t op2, vuint64m2_t op3, size_t op4){
  return vnmsac_vx_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vnmsac(vuint64m4_t op0, uint64_t op1, vuint64m4_t op2, size_t op3){
  return vnmsac_vx_u64m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m4_t vnmsac(vbool16_t op0, vuint64m4_t op1, uint64_t op2, vuint64m4_t op3, size_t op4){
  return vnmsac_vx_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vnmsac(vuint64m8_t op0, uint64_t op1, vuint64m8_t op2, size_t op3){
  return vnmsac_vx_u64m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m8_t vnmsac(vbool8_t op0, vuint64m8_t op1, uint64_t op2, vuint64m8_t op3, size_t op4){
  return vnmsac_vx_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vmadd(vint8m1_t op0, vint8m1_t op1, vint8m1_t op2, size_t op3){
  return vmadd_vv_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vmadd(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, vint8m1_t op3, size_t op4){
  return vmadd_vv_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vmadd(vint8m2_t op0, vint8m2_t op1, vint8m2_t op2, size_t op3){
  return vmadd_vv_i8m2(op0, op1, op2, op3);
}

__rvv_overloaded vint8m2_t vmadd(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, vint8m2_t op3, size_t op4){
  return vmadd_vv_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vmadd(vint8m4_t op0, vint8m4_t op1, vint8m4_t op2, size_t op3){
  return vmadd_vv_i8m4(op0, op1, op2, op3);
}

__rvv_overloaded vint8m4_t vmadd(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, vint8m4_t op3, size_t op4){
  return vmadd_vv_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vmadd(vint8m8_t op0, vint8m8_t op1, vint8m8_t op2, size_t op3){
  return vmadd_vv_i8m8(op0, op1, op2, op3);
}

__rvv_overloaded vint8m8_t vmadd(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, vint8m8_t op3, size_t op4){
  return vmadd_vv_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vmadd(vint8mf2_t op0, vint8mf2_t op1, vint8mf2_t op2, size_t op3){
  return vmadd_vv_i8mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf2_t vmadd(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, vint8mf2_t op3, size_t op4){
  return vmadd_vv_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vmadd(vint8mf4_t op0, vint8mf4_t op1, vint8mf4_t op2, size_t op3){
  return vmadd_vv_i8mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf4_t vmadd(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, vint8mf4_t op3, size_t op4){
  return vmadd_vv_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vmadd(vint8mf8_t op0, vint8mf8_t op1, vint8mf8_t op2, size_t op3){
  return vmadd_vv_i8mf8(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf8_t vmadd(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, vint8mf8_t op3, size_t op4){
  return vmadd_vv_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vmadd(vint16m1_t op0, vint16m1_t op1, vint16m1_t op2, size_t op3){
  return vmadd_vv_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vmadd(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, vint16m1_t op3, size_t op4){
  return vmadd_vv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vmadd(vint16m2_t op0, vint16m2_t op1, vint16m2_t op2, size_t op3){
  return vmadd_vv_i16m2(op0, op1, op2, op3);
}

__rvv_overloaded vint16m2_t vmadd(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, vint16m2_t op3, size_t op4){
  return vmadd_vv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vmadd(vint16m4_t op0, vint16m4_t op1, vint16m4_t op2, size_t op3){
  return vmadd_vv_i16m4(op0, op1, op2, op3);
}

__rvv_overloaded vint16m4_t vmadd(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, vint16m4_t op3, size_t op4){
  return vmadd_vv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vmadd(vint16m8_t op0, vint16m8_t op1, vint16m8_t op2, size_t op3){
  return vmadd_vv_i16m8(op0, op1, op2, op3);
}

__rvv_overloaded vint16m8_t vmadd(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, vint16m8_t op3, size_t op4){
  return vmadd_vv_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vmadd(vint16mf2_t op0, vint16mf2_t op1, vint16mf2_t op2, size_t op3){
  return vmadd_vv_i16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf2_t vmadd(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, vint16mf2_t op3, size_t op4){
  return vmadd_vv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vmadd(vint16mf4_t op0, vint16mf4_t op1, vint16mf4_t op2, size_t op3){
  return vmadd_vv_i16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf4_t vmadd(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, vint16mf4_t op3, size_t op4){
  return vmadd_vv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vmadd(vint32m1_t op0, vint32m1_t op1, vint32m1_t op2, size_t op3){
  return vmadd_vv_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vmadd(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, vint32m1_t op3, size_t op4){
  return vmadd_vv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vmadd(vint32m2_t op0, vint32m2_t op1, vint32m2_t op2, size_t op3){
  return vmadd_vv_i32m2(op0, op1, op2, op3);
}

__rvv_overloaded vint32m2_t vmadd(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, vint32m2_t op3, size_t op4){
  return vmadd_vv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vmadd(vint32m4_t op0, vint32m4_t op1, vint32m4_t op2, size_t op3){
  return vmadd_vv_i32m4(op0, op1, op2, op3);
}

__rvv_overloaded vint32m4_t vmadd(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, vint32m4_t op3, size_t op4){
  return vmadd_vv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vmadd(vint32m8_t op0, vint32m8_t op1, vint32m8_t op2, size_t op3){
  return vmadd_vv_i32m8(op0, op1, op2, op3);
}

__rvv_overloaded vint32m8_t vmadd(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, vint32m8_t op3, size_t op4){
  return vmadd_vv_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vmadd(vint32mf2_t op0, vint32mf2_t op1, vint32mf2_t op2, size_t op3){
  return vmadd_vv_i32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint32mf2_t vmadd(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, vint32mf2_t op3, size_t op4){
  return vmadd_vv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vmadd(vint64m1_t op0, vint64m1_t op1, vint64m1_t op2, size_t op3){
  return vmadd_vv_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vmadd(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, vint64m1_t op3, size_t op4){
  return vmadd_vv_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vmadd(vint64m2_t op0, vint64m2_t op1, vint64m2_t op2, size_t op3){
  return vmadd_vv_i64m2(op0, op1, op2, op3);
}

__rvv_overloaded vint64m2_t vmadd(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, vint64m2_t op3, size_t op4){
  return vmadd_vv_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vmadd(vint64m4_t op0, vint64m4_t op1, vint64m4_t op2, size_t op3){
  return vmadd_vv_i64m4(op0, op1, op2, op3);
}

__rvv_overloaded vint64m4_t vmadd(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, vint64m4_t op3, size_t op4){
  return vmadd_vv_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vmadd(vint64m8_t op0, vint64m8_t op1, vint64m8_t op2, size_t op3){
  return vmadd_vv_i64m8(op0, op1, op2, op3);
}

__rvv_overloaded vint64m8_t vmadd(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, vint64m8_t op3, size_t op4){
  return vmadd_vv_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vmadd(vint8m1_t op0, int8_t op1, vint8m1_t op2, size_t op3){
  return vmadd_vx_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vmadd(vbool8_t op0, vint8m1_t op1, int8_t op2, vint8m1_t op3, size_t op4){
  return vmadd_vx_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vmadd(vint8m2_t op0, int8_t op1, vint8m2_t op2, size_t op3){
  return vmadd_vx_i8m2(op0, op1, op2, op3);
}

__rvv_overloaded vint8m2_t vmadd(vbool4_t op0, vint8m2_t op1, int8_t op2, vint8m2_t op3, size_t op4){
  return vmadd_vx_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vmadd(vint8m4_t op0, int8_t op1, vint8m4_t op2, size_t op3){
  return vmadd_vx_i8m4(op0, op1, op2, op3);
}

__rvv_overloaded vint8m4_t vmadd(vbool2_t op0, vint8m4_t op1, int8_t op2, vint8m4_t op3, size_t op4){
  return vmadd_vx_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vmadd(vint8m8_t op0, int8_t op1, vint8m8_t op2, size_t op3){
  return vmadd_vx_i8m8(op0, op1, op2, op3);
}

__rvv_overloaded vint8m8_t vmadd(vbool1_t op0, vint8m8_t op1, int8_t op2, vint8m8_t op3, size_t op4){
  return vmadd_vx_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vmadd(vint8mf2_t op0, int8_t op1, vint8mf2_t op2, size_t op3){
  return vmadd_vx_i8mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf2_t vmadd(vbool16_t op0, vint8mf2_t op1, int8_t op2, vint8mf2_t op3, size_t op4){
  return vmadd_vx_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vmadd(vint8mf4_t op0, int8_t op1, vint8mf4_t op2, size_t op3){
  return vmadd_vx_i8mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf4_t vmadd(vbool32_t op0, vint8mf4_t op1, int8_t op2, vint8mf4_t op3, size_t op4){
  return vmadd_vx_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vmadd(vint8mf8_t op0, int8_t op1, vint8mf8_t op2, size_t op3){
  return vmadd_vx_i8mf8(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf8_t vmadd(vbool64_t op0, vint8mf8_t op1, int8_t op2, vint8mf8_t op3, size_t op4){
  return vmadd_vx_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vmadd(vint16m1_t op0, int16_t op1, vint16m1_t op2, size_t op3){
  return vmadd_vx_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vmadd(vbool16_t op0, vint16m1_t op1, int16_t op2, vint16m1_t op3, size_t op4){
  return vmadd_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vmadd(vint16m2_t op0, int16_t op1, vint16m2_t op2, size_t op3){
  return vmadd_vx_i16m2(op0, op1, op2, op3);
}

__rvv_overloaded vint16m2_t vmadd(vbool8_t op0, vint16m2_t op1, int16_t op2, vint16m2_t op3, size_t op4){
  return vmadd_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vmadd(vint16m4_t op0, int16_t op1, vint16m4_t op2, size_t op3){
  return vmadd_vx_i16m4(op0, op1, op2, op3);
}

__rvv_overloaded vint16m4_t vmadd(vbool4_t op0, vint16m4_t op1, int16_t op2, vint16m4_t op3, size_t op4){
  return vmadd_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vmadd(vint16m8_t op0, int16_t op1, vint16m8_t op2, size_t op3){
  return vmadd_vx_i16m8(op0, op1, op2, op3);
}

__rvv_overloaded vint16m8_t vmadd(vbool2_t op0, vint16m8_t op1, int16_t op2, vint16m8_t op3, size_t op4){
  return vmadd_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vmadd(vint16mf2_t op0, int16_t op1, vint16mf2_t op2, size_t op3){
  return vmadd_vx_i16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf2_t vmadd(vbool32_t op0, vint16mf2_t op1, int16_t op2, vint16mf2_t op3, size_t op4){
  return vmadd_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vmadd(vint16mf4_t op0, int16_t op1, vint16mf4_t op2, size_t op3){
  return vmadd_vx_i16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf4_t vmadd(vbool64_t op0, vint16mf4_t op1, int16_t op2, vint16mf4_t op3, size_t op4){
  return vmadd_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vmadd(vint32m1_t op0, int32_t op1, vint32m1_t op2, size_t op3){
  return vmadd_vx_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vmadd(vbool32_t op0, vint32m1_t op1, int32_t op2, vint32m1_t op3, size_t op4){
  return vmadd_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vmadd(vint32m2_t op0, int32_t op1, vint32m2_t op2, size_t op3){
  return vmadd_vx_i32m2(op0, op1, op2, op3);
}

__rvv_overloaded vint32m2_t vmadd(vbool16_t op0, vint32m2_t op1, int32_t op2, vint32m2_t op3, size_t op4){
  return vmadd_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vmadd(vint32m4_t op0, int32_t op1, vint32m4_t op2, size_t op3){
  return vmadd_vx_i32m4(op0, op1, op2, op3);
}

__rvv_overloaded vint32m4_t vmadd(vbool8_t op0, vint32m4_t op1, int32_t op2, vint32m4_t op3, size_t op4){
  return vmadd_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vmadd(vint32m8_t op0, int32_t op1, vint32m8_t op2, size_t op3){
  return vmadd_vx_i32m8(op0, op1, op2, op3);
}

__rvv_overloaded vint32m8_t vmadd(vbool4_t op0, vint32m8_t op1, int32_t op2, vint32m8_t op3, size_t op4){
  return vmadd_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vmadd(vint32mf2_t op0, int32_t op1, vint32mf2_t op2, size_t op3){
  return vmadd_vx_i32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint32mf2_t vmadd(vbool64_t op0, vint32mf2_t op1, int32_t op2, vint32mf2_t op3, size_t op4){
  return vmadd_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vmadd(vint64m1_t op0, int64_t op1, vint64m1_t op2, size_t op3){
  return vmadd_vx_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vmadd(vbool64_t op0, vint64m1_t op1, int64_t op2, vint64m1_t op3, size_t op4){
  return vmadd_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vmadd(vint64m2_t op0, int64_t op1, vint64m2_t op2, size_t op3){
  return vmadd_vx_i64m2(op0, op1, op2, op3);
}

__rvv_overloaded vint64m2_t vmadd(vbool32_t op0, vint64m2_t op1, int64_t op2, vint64m2_t op3, size_t op4){
  return vmadd_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vmadd(vint64m4_t op0, int64_t op1, vint64m4_t op2, size_t op3){
  return vmadd_vx_i64m4(op0, op1, op2, op3);
}

__rvv_overloaded vint64m4_t vmadd(vbool16_t op0, vint64m4_t op1, int64_t op2, vint64m4_t op3, size_t op4){
  return vmadd_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vmadd(vint64m8_t op0, int64_t op1, vint64m8_t op2, size_t op3){
  return vmadd_vx_i64m8(op0, op1, op2, op3);
}

__rvv_overloaded vint64m8_t vmadd(vbool8_t op0, vint64m8_t op1, int64_t op2, vint64m8_t op3, size_t op4){
  return vmadd_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vmadd(vuint8m1_t op0, vuint8m1_t op1, vuint8m1_t op2, size_t op3){
  return vmadd_vv_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vmadd(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vmadd_vv_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vmadd(vuint8m2_t op0, vuint8m2_t op1, vuint8m2_t op2, size_t op3){
  return vmadd_vv_u8m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m2_t vmadd(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vmadd_vv_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vmadd(vuint8m4_t op0, vuint8m4_t op1, vuint8m4_t op2, size_t op3){
  return vmadd_vv_u8m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m4_t vmadd(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vmadd_vv_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vmadd(vuint8m8_t op0, vuint8m8_t op1, vuint8m8_t op2, size_t op3){
  return vmadd_vv_u8m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m8_t vmadd(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, vuint8m8_t op3, size_t op4){
  return vmadd_vv_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vmadd(vuint8mf2_t op0, vuint8mf2_t op1, vuint8mf2_t op2, size_t op3){
  return vmadd_vv_u8mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf2_t vmadd(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vmadd_vv_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vmadd(vuint8mf4_t op0, vuint8mf4_t op1, vuint8mf4_t op2, size_t op3){
  return vmadd_vv_u8mf4(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf4_t vmadd(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vmadd_vv_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vmadd(vuint8mf8_t op0, vuint8mf8_t op1, vuint8mf8_t op2, size_t op3){
  return vmadd_vv_u8mf8(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf8_t vmadd(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vmadd_vv_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vmadd(vuint16m1_t op0, vuint16m1_t op1, vuint16m1_t op2, size_t op3){
  return vmadd_vv_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vmadd(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vmadd_vv_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vmadd(vuint16m2_t op0, vuint16m2_t op1, vuint16m2_t op2, size_t op3){
  return vmadd_vv_u16m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m2_t vmadd(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vmadd_vv_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vmadd(vuint16m4_t op0, vuint16m4_t op1, vuint16m4_t op2, size_t op3){
  return vmadd_vv_u16m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m4_t vmadd(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vmadd_vv_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vmadd(vuint16m8_t op0, vuint16m8_t op1, vuint16m8_t op2, size_t op3){
  return vmadd_vv_u16m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m8_t vmadd(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vmadd_vv_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vmadd(vuint16mf2_t op0, vuint16mf2_t op1, vuint16mf2_t op2, size_t op3){
  return vmadd_vv_u16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf2_t vmadd(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vmadd_vv_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vmadd(vuint16mf4_t op0, vuint16mf4_t op1, vuint16mf4_t op2, size_t op3){
  return vmadd_vv_u16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf4_t vmadd(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vmadd_vv_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vmadd(vuint32m1_t op0, vuint32m1_t op1, vuint32m1_t op2, size_t op3){
  return vmadd_vv_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vmadd(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vmadd_vv_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vmadd(vuint32m2_t op0, vuint32m2_t op1, vuint32m2_t op2, size_t op3){
  return vmadd_vv_u32m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m2_t vmadd(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vmadd_vv_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vmadd(vuint32m4_t op0, vuint32m4_t op1, vuint32m4_t op2, size_t op3){
  return vmadd_vv_u32m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m4_t vmadd(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vmadd_vv_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vmadd(vuint32m8_t op0, vuint32m8_t op1, vuint32m8_t op2, size_t op3){
  return vmadd_vv_u32m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m8_t vmadd(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, vuint32m8_t op3, size_t op4){
  return vmadd_vv_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vmadd(vuint32mf2_t op0, vuint32mf2_t op1, vuint32mf2_t op2, size_t op3){
  return vmadd_vv_u32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint32mf2_t vmadd(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vmadd_vv_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vmadd(vuint64m1_t op0, vuint64m1_t op1, vuint64m1_t op2, size_t op3){
  return vmadd_vv_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vmadd(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vmadd_vv_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vmadd(vuint64m2_t op0, vuint64m2_t op1, vuint64m2_t op2, size_t op3){
  return vmadd_vv_u64m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m2_t vmadd(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, vuint64m2_t op3, size_t op4){
  return vmadd_vv_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vmadd(vuint64m4_t op0, vuint64m4_t op1, vuint64m4_t op2, size_t op3){
  return vmadd_vv_u64m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m4_t vmadd(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, vuint64m4_t op3, size_t op4){
  return vmadd_vv_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vmadd(vuint64m8_t op0, vuint64m8_t op1, vuint64m8_t op2, size_t op3){
  return vmadd_vv_u64m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m8_t vmadd(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, vuint64m8_t op3, size_t op4){
  return vmadd_vv_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vmadd(vuint8m1_t op0, uint8_t op1, vuint8m1_t op2, size_t op3){
  return vmadd_vx_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vmadd(vbool8_t op0, vuint8m1_t op1, uint8_t op2, vuint8m1_t op3, size_t op4){
  return vmadd_vx_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vmadd(vuint8m2_t op0, uint8_t op1, vuint8m2_t op2, size_t op3){
  return vmadd_vx_u8m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m2_t vmadd(vbool4_t op0, vuint8m2_t op1, uint8_t op2, vuint8m2_t op3, size_t op4){
  return vmadd_vx_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vmadd(vuint8m4_t op0, uint8_t op1, vuint8m4_t op2, size_t op3){
  return vmadd_vx_u8m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m4_t vmadd(vbool2_t op0, vuint8m4_t op1, uint8_t op2, vuint8m4_t op3, size_t op4){
  return vmadd_vx_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vmadd(vuint8m8_t op0, uint8_t op1, vuint8m8_t op2, size_t op3){
  return vmadd_vx_u8m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m8_t vmadd(vbool1_t op0, vuint8m8_t op1, uint8_t op2, vuint8m8_t op3, size_t op4){
  return vmadd_vx_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vmadd(vuint8mf2_t op0, uint8_t op1, vuint8mf2_t op2, size_t op3){
  return vmadd_vx_u8mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf2_t vmadd(vbool16_t op0, vuint8mf2_t op1, uint8_t op2, vuint8mf2_t op3, size_t op4){
  return vmadd_vx_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vmadd(vuint8mf4_t op0, uint8_t op1, vuint8mf4_t op2, size_t op3){
  return vmadd_vx_u8mf4(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf4_t vmadd(vbool32_t op0, vuint8mf4_t op1, uint8_t op2, vuint8mf4_t op3, size_t op4){
  return vmadd_vx_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vmadd(vuint8mf8_t op0, uint8_t op1, vuint8mf8_t op2, size_t op3){
  return vmadd_vx_u8mf8(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf8_t vmadd(vbool64_t op0, vuint8mf8_t op1, uint8_t op2, vuint8mf8_t op3, size_t op4){
  return vmadd_vx_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vmadd(vuint16m1_t op0, uint16_t op1, vuint16m1_t op2, size_t op3){
  return vmadd_vx_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vmadd(vbool16_t op0, vuint16m1_t op1, uint16_t op2, vuint16m1_t op3, size_t op4){
  return vmadd_vx_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vmadd(vuint16m2_t op0, uint16_t op1, vuint16m2_t op2, size_t op3){
  return vmadd_vx_u16m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m2_t vmadd(vbool8_t op0, vuint16m2_t op1, uint16_t op2, vuint16m2_t op3, size_t op4){
  return vmadd_vx_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vmadd(vuint16m4_t op0, uint16_t op1, vuint16m4_t op2, size_t op3){
  return vmadd_vx_u16m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m4_t vmadd(vbool4_t op0, vuint16m4_t op1, uint16_t op2, vuint16m4_t op3, size_t op4){
  return vmadd_vx_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vmadd(vuint16m8_t op0, uint16_t op1, vuint16m8_t op2, size_t op3){
  return vmadd_vx_u16m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m8_t vmadd(vbool2_t op0, vuint16m8_t op1, uint16_t op2, vuint16m8_t op3, size_t op4){
  return vmadd_vx_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vmadd(vuint16mf2_t op0, uint16_t op1, vuint16mf2_t op2, size_t op3){
  return vmadd_vx_u16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf2_t vmadd(vbool32_t op0, vuint16mf2_t op1, uint16_t op2, vuint16mf2_t op3, size_t op4){
  return vmadd_vx_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vmadd(vuint16mf4_t op0, uint16_t op1, vuint16mf4_t op2, size_t op3){
  return vmadd_vx_u16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf4_t vmadd(vbool64_t op0, vuint16mf4_t op1, uint16_t op2, vuint16mf4_t op3, size_t op4){
  return vmadd_vx_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vmadd(vuint32m1_t op0, uint32_t op1, vuint32m1_t op2, size_t op3){
  return vmadd_vx_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vmadd(vbool32_t op0, vuint32m1_t op1, uint32_t op2, vuint32m1_t op3, size_t op4){
  return vmadd_vx_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vmadd(vuint32m2_t op0, uint32_t op1, vuint32m2_t op2, size_t op3){
  return vmadd_vx_u32m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m2_t vmadd(vbool16_t op0, vuint32m2_t op1, uint32_t op2, vuint32m2_t op3, size_t op4){
  return vmadd_vx_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vmadd(vuint32m4_t op0, uint32_t op1, vuint32m4_t op2, size_t op3){
  return vmadd_vx_u32m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m4_t vmadd(vbool8_t op0, vuint32m4_t op1, uint32_t op2, vuint32m4_t op3, size_t op4){
  return vmadd_vx_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vmadd(vuint32m8_t op0, uint32_t op1, vuint32m8_t op2, size_t op3){
  return vmadd_vx_u32m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m8_t vmadd(vbool4_t op0, vuint32m8_t op1, uint32_t op2, vuint32m8_t op3, size_t op4){
  return vmadd_vx_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vmadd(vuint32mf2_t op0, uint32_t op1, vuint32mf2_t op2, size_t op3){
  return vmadd_vx_u32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint32mf2_t vmadd(vbool64_t op0, vuint32mf2_t op1, uint32_t op2, vuint32mf2_t op3, size_t op4){
  return vmadd_vx_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vmadd(vuint64m1_t op0, uint64_t op1, vuint64m1_t op2, size_t op3){
  return vmadd_vx_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vmadd(vbool64_t op0, vuint64m1_t op1, uint64_t op2, vuint64m1_t op3, size_t op4){
  return vmadd_vx_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vmadd(vuint64m2_t op0, uint64_t op1, vuint64m2_t op2, size_t op3){
  return vmadd_vx_u64m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m2_t vmadd(vbool32_t op0, vuint64m2_t op1, uint64_t op2, vuint64m2_t op3, size_t op4){
  return vmadd_vx_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vmadd(vuint64m4_t op0, uint64_t op1, vuint64m4_t op2, size_t op3){
  return vmadd_vx_u64m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m4_t vmadd(vbool16_t op0, vuint64m4_t op1, uint64_t op2, vuint64m4_t op3, size_t op4){
  return vmadd_vx_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vmadd(vuint64m8_t op0, uint64_t op1, vuint64m8_t op2, size_t op3){
  return vmadd_vx_u64m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m8_t vmadd(vbool8_t op0, vuint64m8_t op1, uint64_t op2, vuint64m8_t op3, size_t op4){
  return vmadd_vx_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vnmsub(vint8m1_t op0, vint8m1_t op1, vint8m1_t op2, size_t op3){
  return vnmsub_vv_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vnmsub(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, vint8m1_t op3, size_t op4){
  return vnmsub_vv_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vnmsub(vint8m2_t op0, vint8m2_t op1, vint8m2_t op2, size_t op3){
  return vnmsub_vv_i8m2(op0, op1, op2, op3);
}

__rvv_overloaded vint8m2_t vnmsub(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, vint8m2_t op3, size_t op4){
  return vnmsub_vv_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vnmsub(vint8m4_t op0, vint8m4_t op1, vint8m4_t op2, size_t op3){
  return vnmsub_vv_i8m4(op0, op1, op2, op3);
}

__rvv_overloaded vint8m4_t vnmsub(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, vint8m4_t op3, size_t op4){
  return vnmsub_vv_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vnmsub(vint8m8_t op0, vint8m8_t op1, vint8m8_t op2, size_t op3){
  return vnmsub_vv_i8m8(op0, op1, op2, op3);
}

__rvv_overloaded vint8m8_t vnmsub(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, vint8m8_t op3, size_t op4){
  return vnmsub_vv_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vnmsub(vint8mf2_t op0, vint8mf2_t op1, vint8mf2_t op2, size_t op3){
  return vnmsub_vv_i8mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf2_t vnmsub(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, vint8mf2_t op3, size_t op4){
  return vnmsub_vv_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vnmsub(vint8mf4_t op0, vint8mf4_t op1, vint8mf4_t op2, size_t op3){
  return vnmsub_vv_i8mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf4_t vnmsub(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, vint8mf4_t op3, size_t op4){
  return vnmsub_vv_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vnmsub(vint8mf8_t op0, vint8mf8_t op1, vint8mf8_t op2, size_t op3){
  return vnmsub_vv_i8mf8(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf8_t vnmsub(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, vint8mf8_t op3, size_t op4){
  return vnmsub_vv_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vnmsub(vint16m1_t op0, vint16m1_t op1, vint16m1_t op2, size_t op3){
  return vnmsub_vv_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vnmsub(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, vint16m1_t op3, size_t op4){
  return vnmsub_vv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vnmsub(vint16m2_t op0, vint16m2_t op1, vint16m2_t op2, size_t op3){
  return vnmsub_vv_i16m2(op0, op1, op2, op3);
}

__rvv_overloaded vint16m2_t vnmsub(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, vint16m2_t op3, size_t op4){
  return vnmsub_vv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vnmsub(vint16m4_t op0, vint16m4_t op1, vint16m4_t op2, size_t op3){
  return vnmsub_vv_i16m4(op0, op1, op2, op3);
}

__rvv_overloaded vint16m4_t vnmsub(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, vint16m4_t op3, size_t op4){
  return vnmsub_vv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vnmsub(vint16m8_t op0, vint16m8_t op1, vint16m8_t op2, size_t op3){
  return vnmsub_vv_i16m8(op0, op1, op2, op3);
}

__rvv_overloaded vint16m8_t vnmsub(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, vint16m8_t op3, size_t op4){
  return vnmsub_vv_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vnmsub(vint16mf2_t op0, vint16mf2_t op1, vint16mf2_t op2, size_t op3){
  return vnmsub_vv_i16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf2_t vnmsub(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, vint16mf2_t op3, size_t op4){
  return vnmsub_vv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vnmsub(vint16mf4_t op0, vint16mf4_t op1, vint16mf4_t op2, size_t op3){
  return vnmsub_vv_i16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf4_t vnmsub(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, vint16mf4_t op3, size_t op4){
  return vnmsub_vv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vnmsub(vint32m1_t op0, vint32m1_t op1, vint32m1_t op2, size_t op3){
  return vnmsub_vv_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vnmsub(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, vint32m1_t op3, size_t op4){
  return vnmsub_vv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vnmsub(vint32m2_t op0, vint32m2_t op1, vint32m2_t op2, size_t op3){
  return vnmsub_vv_i32m2(op0, op1, op2, op3);
}

__rvv_overloaded vint32m2_t vnmsub(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, vint32m2_t op3, size_t op4){
  return vnmsub_vv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vnmsub(vint32m4_t op0, vint32m4_t op1, vint32m4_t op2, size_t op3){
  return vnmsub_vv_i32m4(op0, op1, op2, op3);
}

__rvv_overloaded vint32m4_t vnmsub(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, vint32m4_t op3, size_t op4){
  return vnmsub_vv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vnmsub(vint32m8_t op0, vint32m8_t op1, vint32m8_t op2, size_t op3){
  return vnmsub_vv_i32m8(op0, op1, op2, op3);
}

__rvv_overloaded vint32m8_t vnmsub(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, vint32m8_t op3, size_t op4){
  return vnmsub_vv_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vnmsub(vint32mf2_t op0, vint32mf2_t op1, vint32mf2_t op2, size_t op3){
  return vnmsub_vv_i32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint32mf2_t vnmsub(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, vint32mf2_t op3, size_t op4){
  return vnmsub_vv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vnmsub(vint64m1_t op0, vint64m1_t op1, vint64m1_t op2, size_t op3){
  return vnmsub_vv_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vnmsub(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, vint64m1_t op3, size_t op4){
  return vnmsub_vv_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vnmsub(vint64m2_t op0, vint64m2_t op1, vint64m2_t op2, size_t op3){
  return vnmsub_vv_i64m2(op0, op1, op2, op3);
}

__rvv_overloaded vint64m2_t vnmsub(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, vint64m2_t op3, size_t op4){
  return vnmsub_vv_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vnmsub(vint64m4_t op0, vint64m4_t op1, vint64m4_t op2, size_t op3){
  return vnmsub_vv_i64m4(op0, op1, op2, op3);
}

__rvv_overloaded vint64m4_t vnmsub(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, vint64m4_t op3, size_t op4){
  return vnmsub_vv_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vnmsub(vint64m8_t op0, vint64m8_t op1, vint64m8_t op2, size_t op3){
  return vnmsub_vv_i64m8(op0, op1, op2, op3);
}

__rvv_overloaded vint64m8_t vnmsub(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, vint64m8_t op3, size_t op4){
  return vnmsub_vv_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vnmsub(vint8m1_t op0, int8_t op1, vint8m1_t op2, size_t op3){
  return vnmsub_vx_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vnmsub(vbool8_t op0, vint8m1_t op1, int8_t op2, vint8m1_t op3, size_t op4){
  return vnmsub_vx_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vnmsub(vint8m2_t op0, int8_t op1, vint8m2_t op2, size_t op3){
  return vnmsub_vx_i8m2(op0, op1, op2, op3);
}

__rvv_overloaded vint8m2_t vnmsub(vbool4_t op0, vint8m2_t op1, int8_t op2, vint8m2_t op3, size_t op4){
  return vnmsub_vx_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vnmsub(vint8m4_t op0, int8_t op1, vint8m4_t op2, size_t op3){
  return vnmsub_vx_i8m4(op0, op1, op2, op3);
}

__rvv_overloaded vint8m4_t vnmsub(vbool2_t op0, vint8m4_t op1, int8_t op2, vint8m4_t op3, size_t op4){
  return vnmsub_vx_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vnmsub(vint8m8_t op0, int8_t op1, vint8m8_t op2, size_t op3){
  return vnmsub_vx_i8m8(op0, op1, op2, op3);
}

__rvv_overloaded vint8m8_t vnmsub(vbool1_t op0, vint8m8_t op1, int8_t op2, vint8m8_t op3, size_t op4){
  return vnmsub_vx_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vnmsub(vint8mf2_t op0, int8_t op1, vint8mf2_t op2, size_t op3){
  return vnmsub_vx_i8mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf2_t vnmsub(vbool16_t op0, vint8mf2_t op1, int8_t op2, vint8mf2_t op3, size_t op4){
  return vnmsub_vx_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vnmsub(vint8mf4_t op0, int8_t op1, vint8mf4_t op2, size_t op3){
  return vnmsub_vx_i8mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf4_t vnmsub(vbool32_t op0, vint8mf4_t op1, int8_t op2, vint8mf4_t op3, size_t op4){
  return vnmsub_vx_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vnmsub(vint8mf8_t op0, int8_t op1, vint8mf8_t op2, size_t op3){
  return vnmsub_vx_i8mf8(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf8_t vnmsub(vbool64_t op0, vint8mf8_t op1, int8_t op2, vint8mf8_t op3, size_t op4){
  return vnmsub_vx_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vnmsub(vint16m1_t op0, int16_t op1, vint16m1_t op2, size_t op3){
  return vnmsub_vx_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vnmsub(vbool16_t op0, vint16m1_t op1, int16_t op2, vint16m1_t op3, size_t op4){
  return vnmsub_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vnmsub(vint16m2_t op0, int16_t op1, vint16m2_t op2, size_t op3){
  return vnmsub_vx_i16m2(op0, op1, op2, op3);
}

__rvv_overloaded vint16m2_t vnmsub(vbool8_t op0, vint16m2_t op1, int16_t op2, vint16m2_t op3, size_t op4){
  return vnmsub_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vnmsub(vint16m4_t op0, int16_t op1, vint16m4_t op2, size_t op3){
  return vnmsub_vx_i16m4(op0, op1, op2, op3);
}

__rvv_overloaded vint16m4_t vnmsub(vbool4_t op0, vint16m4_t op1, int16_t op2, vint16m4_t op3, size_t op4){
  return vnmsub_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vnmsub(vint16m8_t op0, int16_t op1, vint16m8_t op2, size_t op3){
  return vnmsub_vx_i16m8(op0, op1, op2, op3);
}

__rvv_overloaded vint16m8_t vnmsub(vbool2_t op0, vint16m8_t op1, int16_t op2, vint16m8_t op3, size_t op4){
  return vnmsub_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vnmsub(vint16mf2_t op0, int16_t op1, vint16mf2_t op2, size_t op3){
  return vnmsub_vx_i16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf2_t vnmsub(vbool32_t op0, vint16mf2_t op1, int16_t op2, vint16mf2_t op3, size_t op4){
  return vnmsub_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vnmsub(vint16mf4_t op0, int16_t op1, vint16mf4_t op2, size_t op3){
  return vnmsub_vx_i16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf4_t vnmsub(vbool64_t op0, vint16mf4_t op1, int16_t op2, vint16mf4_t op3, size_t op4){
  return vnmsub_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vnmsub(vint32m1_t op0, int32_t op1, vint32m1_t op2, size_t op3){
  return vnmsub_vx_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vnmsub(vbool32_t op0, vint32m1_t op1, int32_t op2, vint32m1_t op3, size_t op4){
  return vnmsub_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vnmsub(vint32m2_t op0, int32_t op1, vint32m2_t op2, size_t op3){
  return vnmsub_vx_i32m2(op0, op1, op2, op3);
}

__rvv_overloaded vint32m2_t vnmsub(vbool16_t op0, vint32m2_t op1, int32_t op2, vint32m2_t op3, size_t op4){
  return vnmsub_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vnmsub(vint32m4_t op0, int32_t op1, vint32m4_t op2, size_t op3){
  return vnmsub_vx_i32m4(op0, op1, op2, op3);
}

__rvv_overloaded vint32m4_t vnmsub(vbool8_t op0, vint32m4_t op1, int32_t op2, vint32m4_t op3, size_t op4){
  return vnmsub_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vnmsub(vint32m8_t op0, int32_t op1, vint32m8_t op2, size_t op3){
  return vnmsub_vx_i32m8(op0, op1, op2, op3);
}

__rvv_overloaded vint32m8_t vnmsub(vbool4_t op0, vint32m8_t op1, int32_t op2, vint32m8_t op3, size_t op4){
  return vnmsub_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vnmsub(vint32mf2_t op0, int32_t op1, vint32mf2_t op2, size_t op3){
  return vnmsub_vx_i32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint32mf2_t vnmsub(vbool64_t op0, vint32mf2_t op1, int32_t op2, vint32mf2_t op3, size_t op4){
  return vnmsub_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vnmsub(vint64m1_t op0, int64_t op1, vint64m1_t op2, size_t op3){
  return vnmsub_vx_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vnmsub(vbool64_t op0, vint64m1_t op1, int64_t op2, vint64m1_t op3, size_t op4){
  return vnmsub_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vnmsub(vint64m2_t op0, int64_t op1, vint64m2_t op2, size_t op3){
  return vnmsub_vx_i64m2(op0, op1, op2, op3);
}

__rvv_overloaded vint64m2_t vnmsub(vbool32_t op0, vint64m2_t op1, int64_t op2, vint64m2_t op3, size_t op4){
  return vnmsub_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vnmsub(vint64m4_t op0, int64_t op1, vint64m4_t op2, size_t op3){
  return vnmsub_vx_i64m4(op0, op1, op2, op3);
}

__rvv_overloaded vint64m4_t vnmsub(vbool16_t op0, vint64m4_t op1, int64_t op2, vint64m4_t op3, size_t op4){
  return vnmsub_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vnmsub(vint64m8_t op0, int64_t op1, vint64m8_t op2, size_t op3){
  return vnmsub_vx_i64m8(op0, op1, op2, op3);
}

__rvv_overloaded vint64m8_t vnmsub(vbool8_t op0, vint64m8_t op1, int64_t op2, vint64m8_t op3, size_t op4){
  return vnmsub_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vle16ff(vbool16_t op0, vuint16m1_t op1, const uint16_t * op2, size_t * op3, size_t op4){
  return vle16ff_v_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vle16ff(vbool8_t op0, vuint16m2_t op1, const uint16_t * op2, size_t * op3, size_t op4){
  return vle16ff_v_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vle16ff(vbool4_t op0, vuint16m4_t op1, const uint16_t * op2, size_t * op3, size_t op4){
  return vle16ff_v_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vle16ff(vbool2_t op0, vuint16m8_t op1, const uint16_t * op2, size_t * op3, size_t op4){
  return vle16ff_v_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vle16ff(vbool32_t op0, vuint16mf2_t op1, const uint16_t * op2, size_t * op3, size_t op4){
  return vle16ff_v_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vle16ff(vbool64_t op0, vuint16mf4_t op1, const uint16_t * op2, size_t * op3, size_t op4){
  return vle16ff_v_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vnmsub(vuint8m1_t op0, vuint8m1_t op1, vuint8m1_t op2, size_t op3){
  return vnmsub_vv_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vnmsub(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vnmsub_vv_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vnmsub(vuint8m2_t op0, vuint8m2_t op1, vuint8m2_t op2, size_t op3){
  return vnmsub_vv_u8m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m2_t vnmsub(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vnmsub_vv_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vnmsub(vuint8m4_t op0, vuint8m4_t op1, vuint8m4_t op2, size_t op3){
  return vnmsub_vv_u8m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m4_t vnmsub(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vnmsub_vv_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vnmsub(vuint8m8_t op0, vuint8m8_t op1, vuint8m8_t op2, size_t op3){
  return vnmsub_vv_u8m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m8_t vnmsub(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, vuint8m8_t op3, size_t op4){
  return vnmsub_vv_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vnmsub(vuint8mf2_t op0, vuint8mf2_t op1, vuint8mf2_t op2, size_t op3){
  return vnmsub_vv_u8mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf2_t vnmsub(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vnmsub_vv_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vnmsub(vuint8mf4_t op0, vuint8mf4_t op1, vuint8mf4_t op2, size_t op3){
  return vnmsub_vv_u8mf4(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf4_t vnmsub(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vnmsub_vv_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vnmsub(vuint8mf8_t op0, vuint8mf8_t op1, vuint8mf8_t op2, size_t op3){
  return vnmsub_vv_u8mf8(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf8_t vnmsub(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vnmsub_vv_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vnmsub(vuint16m1_t op0, vuint16m1_t op1, vuint16m1_t op2, size_t op3){
  return vnmsub_vv_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vnmsub(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vnmsub_vv_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vnmsub(vuint16m2_t op0, vuint16m2_t op1, vuint16m2_t op2, size_t op3){
  return vnmsub_vv_u16m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m2_t vnmsub(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vnmsub_vv_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vnmsub(vuint16m4_t op0, vuint16m4_t op1, vuint16m4_t op2, size_t op3){
  return vnmsub_vv_u16m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m4_t vnmsub(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vnmsub_vv_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vnmsub(vuint16m8_t op0, vuint16m8_t op1, vuint16m8_t op2, size_t op3){
  return vnmsub_vv_u16m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m8_t vnmsub(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vnmsub_vv_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vnmsub(vuint16mf2_t op0, vuint16mf2_t op1, vuint16mf2_t op2, size_t op3){
  return vnmsub_vv_u16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf2_t vnmsub(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vnmsub_vv_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vnmsub(vuint16mf4_t op0, vuint16mf4_t op1, vuint16mf4_t op2, size_t op3){
  return vnmsub_vv_u16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf4_t vnmsub(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vnmsub_vv_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vnmsub(vuint32m1_t op0, vuint32m1_t op1, vuint32m1_t op2, size_t op3){
  return vnmsub_vv_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vnmsub(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vnmsub_vv_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vnmsub(vuint32m2_t op0, vuint32m2_t op1, vuint32m2_t op2, size_t op3){
  return vnmsub_vv_u32m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m2_t vnmsub(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vnmsub_vv_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vnmsub(vuint32m4_t op0, vuint32m4_t op1, vuint32m4_t op2, size_t op3){
  return vnmsub_vv_u32m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m4_t vnmsub(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vnmsub_vv_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vnmsub(vuint32m8_t op0, vuint32m8_t op1, vuint32m8_t op2, size_t op3){
  return vnmsub_vv_u32m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m8_t vnmsub(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, vuint32m8_t op3, size_t op4){
  return vnmsub_vv_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vnmsub(vuint32mf2_t op0, vuint32mf2_t op1, vuint32mf2_t op2, size_t op3){
  return vnmsub_vv_u32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint32mf2_t vnmsub(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vnmsub_vv_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vnmsub(vuint64m1_t op0, vuint64m1_t op1, vuint64m1_t op2, size_t op3){
  return vnmsub_vv_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vnmsub(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vnmsub_vv_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vnmsub(vuint64m2_t op0, vuint64m2_t op1, vuint64m2_t op2, size_t op3){
  return vnmsub_vv_u64m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m2_t vnmsub(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, vuint64m2_t op3, size_t op4){
  return vnmsub_vv_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vnmsub(vuint64m4_t op0, vuint64m4_t op1, vuint64m4_t op2, size_t op3){
  return vnmsub_vv_u64m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m4_t vnmsub(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, vuint64m4_t op3, size_t op4){
  return vnmsub_vv_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vnmsub(vuint64m8_t op0, vuint64m8_t op1, vuint64m8_t op2, size_t op3){
  return vnmsub_vv_u64m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m8_t vnmsub(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, vuint64m8_t op3, size_t op4){
  return vnmsub_vv_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vnmsub(vuint8m1_t op0, uint8_t op1, vuint8m1_t op2, size_t op3){
  return vnmsub_vx_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vnmsub(vbool8_t op0, vuint8m1_t op1, uint8_t op2, vuint8m1_t op3, size_t op4){
  return vnmsub_vx_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vnmsub(vuint8m2_t op0, uint8_t op1, vuint8m2_t op2, size_t op3){
  return vnmsub_vx_u8m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m2_t vnmsub(vbool4_t op0, vuint8m2_t op1, uint8_t op2, vuint8m2_t op3, size_t op4){
  return vnmsub_vx_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vnmsub(vuint8m4_t op0, uint8_t op1, vuint8m4_t op2, size_t op3){
  return vnmsub_vx_u8m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m4_t vnmsub(vbool2_t op0, vuint8m4_t op1, uint8_t op2, vuint8m4_t op3, size_t op4){
  return vnmsub_vx_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vnmsub(vuint8m8_t op0, uint8_t op1, vuint8m8_t op2, size_t op3){
  return vnmsub_vx_u8m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m8_t vnmsub(vbool1_t op0, vuint8m8_t op1, uint8_t op2, vuint8m8_t op3, size_t op4){
  return vnmsub_vx_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vnmsub(vuint8mf2_t op0, uint8_t op1, vuint8mf2_t op2, size_t op3){
  return vnmsub_vx_u8mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf2_t vnmsub(vbool16_t op0, vuint8mf2_t op1, uint8_t op2, vuint8mf2_t op3, size_t op4){
  return vnmsub_vx_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vnmsub(vuint8mf4_t op0, uint8_t op1, vuint8mf4_t op2, size_t op3){
  return vnmsub_vx_u8mf4(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf4_t vnmsub(vbool32_t op0, vuint8mf4_t op1, uint8_t op2, vuint8mf4_t op3, size_t op4){
  return vnmsub_vx_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vnmsub(vuint8mf8_t op0, uint8_t op1, vuint8mf8_t op2, size_t op3){
  return vnmsub_vx_u8mf8(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf8_t vnmsub(vbool64_t op0, vuint8mf8_t op1, uint8_t op2, vuint8mf8_t op3, size_t op4){
  return vnmsub_vx_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vnmsub(vuint16m1_t op0, uint16_t op1, vuint16m1_t op2, size_t op3){
  return vnmsub_vx_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vnmsub(vbool16_t op0, vuint16m1_t op1, uint16_t op2, vuint16m1_t op3, size_t op4){
  return vnmsub_vx_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vnmsub(vuint16m2_t op0, uint16_t op1, vuint16m2_t op2, size_t op3){
  return vnmsub_vx_u16m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m2_t vnmsub(vbool8_t op0, vuint16m2_t op1, uint16_t op2, vuint16m2_t op3, size_t op4){
  return vnmsub_vx_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vnmsub(vuint16m4_t op0, uint16_t op1, vuint16m4_t op2, size_t op3){
  return vnmsub_vx_u16m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m4_t vnmsub(vbool4_t op0, vuint16m4_t op1, uint16_t op2, vuint16m4_t op3, size_t op4){
  return vnmsub_vx_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vnmsub(vuint16m8_t op0, uint16_t op1, vuint16m8_t op2, size_t op3){
  return vnmsub_vx_u16m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m8_t vnmsub(vbool2_t op0, vuint16m8_t op1, uint16_t op2, vuint16m8_t op3, size_t op4){
  return vnmsub_vx_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vnmsub(vuint16mf2_t op0, uint16_t op1, vuint16mf2_t op2, size_t op3){
  return vnmsub_vx_u16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf2_t vnmsub(vbool32_t op0, vuint16mf2_t op1, uint16_t op2, vuint16mf2_t op3, size_t op4){
  return vnmsub_vx_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vnmsub(vuint16mf4_t op0, uint16_t op1, vuint16mf4_t op2, size_t op3){
  return vnmsub_vx_u16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf4_t vnmsub(vbool64_t op0, vuint16mf4_t op1, uint16_t op2, vuint16mf4_t op3, size_t op4){
  return vnmsub_vx_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vnmsub(vuint32m1_t op0, uint32_t op1, vuint32m1_t op2, size_t op3){
  return vnmsub_vx_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vnmsub(vbool32_t op0, vuint32m1_t op1, uint32_t op2, vuint32m1_t op3, size_t op4){
  return vnmsub_vx_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vnmsub(vuint32m2_t op0, uint32_t op1, vuint32m2_t op2, size_t op3){
  return vnmsub_vx_u32m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m2_t vnmsub(vbool16_t op0, vuint32m2_t op1, uint32_t op2, vuint32m2_t op3, size_t op4){
  return vnmsub_vx_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vnmsub(vuint32m4_t op0, uint32_t op1, vuint32m4_t op2, size_t op3){
  return vnmsub_vx_u32m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m4_t vnmsub(vbool8_t op0, vuint32m4_t op1, uint32_t op2, vuint32m4_t op3, size_t op4){
  return vnmsub_vx_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vnmsub(vuint32m8_t op0, uint32_t op1, vuint32m8_t op2, size_t op3){
  return vnmsub_vx_u32m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m8_t vnmsub(vbool4_t op0, vuint32m8_t op1, uint32_t op2, vuint32m8_t op3, size_t op4){
  return vnmsub_vx_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vnmsub(vuint32mf2_t op0, uint32_t op1, vuint32mf2_t op2, size_t op3){
  return vnmsub_vx_u32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint32mf2_t vnmsub(vbool64_t op0, vuint32mf2_t op1, uint32_t op2, vuint32mf2_t op3, size_t op4){
  return vnmsub_vx_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vnmsub(vuint64m1_t op0, uint64_t op1, vuint64m1_t op2, size_t op3){
  return vnmsub_vx_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vnmsub(vbool64_t op0, vuint64m1_t op1, uint64_t op2, vuint64m1_t op3, size_t op4){
  return vnmsub_vx_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vnmsub(vuint64m2_t op0, uint64_t op1, vuint64m2_t op2, size_t op3){
  return vnmsub_vx_u64m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m2_t vnmsub(vbool32_t op0, vuint64m2_t op1, uint64_t op2, vuint64m2_t op3, size_t op4){
  return vnmsub_vx_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vnmsub(vuint64m4_t op0, uint64_t op1, vuint64m4_t op2, size_t op3){
  return vnmsub_vx_u64m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m4_t vnmsub(vbool16_t op0, vuint64m4_t op1, uint64_t op2, vuint64m4_t op3, size_t op4){
  return vnmsub_vx_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vnmsub(vuint64m8_t op0, uint64_t op1, vuint64m8_t op2, size_t op3){
  return vnmsub_vx_u64m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m8_t vnmsub(vbool8_t op0, vuint64m8_t op1, uint64_t op2, vuint64m8_t op3, size_t op4){
  return vnmsub_vx_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vwmaccu(vuint16mf4_t op0, vuint8mf8_t op1, vuint8mf8_t op2, size_t op3){
  return vwmaccu_vv_u16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf4_t vwmaccu(vbool64_t op0, vuint16mf4_t op1, vuint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vwmaccu_vv_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vwmaccu(vuint16mf2_t op0, vuint8mf4_t op1, vuint8mf4_t op2, size_t op3){
  return vwmaccu_vv_u16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf2_t vwmaccu(vbool32_t op0, vuint16mf2_t op1, vuint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vwmaccu_vv_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vwmaccu(vuint16m1_t op0, vuint8mf2_t op1, vuint8mf2_t op2, size_t op3){
  return vwmaccu_vv_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vwmaccu(vbool16_t op0, vuint16m1_t op1, vuint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vwmaccu_vv_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vwmaccu(vuint16m2_t op0, vuint8m1_t op1, vuint8m1_t op2, size_t op3){
  return vwmaccu_vv_u16m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m2_t vwmaccu(vbool8_t op0, vuint16m2_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vwmaccu_vv_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vwmaccu(vuint16m4_t op0, vuint8m2_t op1, vuint8m2_t op2, size_t op3){
  return vwmaccu_vv_u16m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m4_t vwmaccu(vbool4_t op0, vuint16m4_t op1, vuint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vwmaccu_vv_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vwmaccu(vuint16m8_t op0, vuint8m4_t op1, vuint8m4_t op2, size_t op3){
  return vwmaccu_vv_u16m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m8_t vwmaccu(vbool2_t op0, vuint16m8_t op1, vuint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vwmaccu_vv_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vwmaccu(vuint32mf2_t op0, vuint16mf4_t op1, vuint16mf4_t op2, size_t op3){
  return vwmaccu_vv_u32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint32mf2_t vwmaccu(vbool64_t op0, vuint32mf2_t op1, vuint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vwmaccu_vv_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vwmaccu(vuint32m1_t op0, vuint16mf2_t op1, vuint16mf2_t op2, size_t op3){
  return vwmaccu_vv_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vwmaccu(vbool32_t op0, vuint32m1_t op1, vuint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vwmaccu_vv_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vwmaccu(vuint32m2_t op0, vuint16m1_t op1, vuint16m1_t op2, size_t op3){
  return vwmaccu_vv_u32m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m2_t vwmaccu(vbool16_t op0, vuint32m2_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vwmaccu_vv_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vwmaccu(vuint32m4_t op0, vuint16m2_t op1, vuint16m2_t op2, size_t op3){
  return vwmaccu_vv_u32m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m4_t vwmaccu(vbool8_t op0, vuint32m4_t op1, vuint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vwmaccu_vv_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vwmaccu(vuint32m8_t op0, vuint16m4_t op1, vuint16m4_t op2, size_t op3){
  return vwmaccu_vv_u32m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m8_t vwmaccu(vbool4_t op0, vuint32m8_t op1, vuint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vwmaccu_vv_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vwmaccu(vuint64m1_t op0, vuint32mf2_t op1, vuint32mf2_t op2, size_t op3){
  return vwmaccu_vv_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vwmaccu(vbool64_t op0, vuint64m1_t op1, vuint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vwmaccu_vv_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vwmaccu(vuint64m2_t op0, vuint32m1_t op1, vuint32m1_t op2, size_t op3){
  return vwmaccu_vv_u64m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m2_t vwmaccu(vbool32_t op0, vuint64m2_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vwmaccu_vv_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vwmaccu(vuint64m4_t op0, vuint32m2_t op1, vuint32m2_t op2, size_t op3){
  return vwmaccu_vv_u64m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m4_t vwmaccu(vbool16_t op0, vuint64m4_t op1, vuint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vwmaccu_vv_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vwmaccu(vuint64m8_t op0, vuint32m4_t op1, vuint32m4_t op2, size_t op3){
  return vwmaccu_vv_u64m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m8_t vwmaccu(vbool8_t op0, vuint64m8_t op1, vuint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vwmaccu_vv_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vwmaccu(vuint16mf4_t op0, uint8_t op1, vuint8mf8_t op2, size_t op3){
  return vwmaccu_vx_u16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf4_t vwmaccu(vbool64_t op0, vuint16mf4_t op1, uint8_t op2, vuint8mf8_t op3, size_t op4){
  return vwmaccu_vx_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vwmaccu(vuint16mf2_t op0, uint8_t op1, vuint8mf4_t op2, size_t op3){
  return vwmaccu_vx_u16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf2_t vwmaccu(vbool32_t op0, vuint16mf2_t op1, uint8_t op2, vuint8mf4_t op3, size_t op4){
  return vwmaccu_vx_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vwmaccu(vuint16m1_t op0, uint8_t op1, vuint8mf2_t op2, size_t op3){
  return vwmaccu_vx_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vwmaccu(vbool16_t op0, vuint16m1_t op1, uint8_t op2, vuint8mf2_t op3, size_t op4){
  return vwmaccu_vx_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vwmaccu(vuint16m2_t op0, uint8_t op1, vuint8m1_t op2, size_t op3){
  return vwmaccu_vx_u16m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m2_t vwmaccu(vbool8_t op0, vuint16m2_t op1, uint8_t op2, vuint8m1_t op3, size_t op4){
  return vwmaccu_vx_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vwmaccu(vuint16m4_t op0, uint8_t op1, vuint8m2_t op2, size_t op3){
  return vwmaccu_vx_u16m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m4_t vwmaccu(vbool4_t op0, vuint16m4_t op1, uint8_t op2, vuint8m2_t op3, size_t op4){
  return vwmaccu_vx_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vwmaccu(vuint16m8_t op0, uint8_t op1, vuint8m4_t op2, size_t op3){
  return vwmaccu_vx_u16m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m8_t vwmaccu(vbool2_t op0, vuint16m8_t op1, uint8_t op2, vuint8m4_t op3, size_t op4){
  return vwmaccu_vx_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vwmaccu(vuint32mf2_t op0, uint16_t op1, vuint16mf4_t op2, size_t op3){
  return vwmaccu_vx_u32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint32mf2_t vwmaccu(vbool64_t op0, vuint32mf2_t op1, uint16_t op2, vuint16mf4_t op3, size_t op4){
  return vwmaccu_vx_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vwmaccu(vuint32m1_t op0, uint16_t op1, vuint16mf2_t op2, size_t op3){
  return vwmaccu_vx_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vwmaccu(vbool32_t op0, vuint32m1_t op1, uint16_t op2, vuint16mf2_t op3, size_t op4){
  return vwmaccu_vx_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vwmaccu(vuint32m2_t op0, uint16_t op1, vuint16m1_t op2, size_t op3){
  return vwmaccu_vx_u32m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m2_t vwmaccu(vbool16_t op0, vuint32m2_t op1, uint16_t op2, vuint16m1_t op3, size_t op4){
  return vwmaccu_vx_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vwmaccu(vuint32m4_t op0, uint16_t op1, vuint16m2_t op2, size_t op3){
  return vwmaccu_vx_u32m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m4_t vwmaccu(vbool8_t op0, vuint32m4_t op1, uint16_t op2, vuint16m2_t op3, size_t op4){
  return vwmaccu_vx_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vwmaccu(vuint32m8_t op0, uint16_t op1, vuint16m4_t op2, size_t op3){
  return vwmaccu_vx_u32m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m8_t vwmaccu(vbool4_t op0, vuint32m8_t op1, uint16_t op2, vuint16m4_t op3, size_t op4){
  return vwmaccu_vx_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vwmaccu(vuint64m1_t op0, uint32_t op1, vuint32mf2_t op2, size_t op3){
  return vwmaccu_vx_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vwmaccu(vbool64_t op0, vuint64m1_t op1, uint32_t op2, vuint32mf2_t op3, size_t op4){
  return vwmaccu_vx_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vwmaccu(vuint64m2_t op0, uint32_t op1, vuint32m1_t op2, size_t op3){
  return vwmaccu_vx_u64m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m2_t vwmaccu(vbool32_t op0, vuint64m2_t op1, uint32_t op2, vuint32m1_t op3, size_t op4){
  return vwmaccu_vx_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vwmaccu(vuint64m4_t op0, uint32_t op1, vuint32m2_t op2, size_t op3){
  return vwmaccu_vx_u64m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m4_t vwmaccu(vbool16_t op0, vuint64m4_t op1, uint32_t op2, vuint32m2_t op3, size_t op4){
  return vwmaccu_vx_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vwmaccu(vuint64m8_t op0, uint32_t op1, vuint32m4_t op2, size_t op3){
  return vwmaccu_vx_u64m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m8_t vwmaccu(vbool8_t op0, vuint64m8_t op1, uint32_t op2, vuint32m4_t op3, size_t op4){
  return vwmaccu_vx_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vwmacc(vint16mf4_t op0, vint8mf8_t op1, vint8mf8_t op2, size_t op3){
  return vwmacc_vv_i16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf4_t vwmacc(vbool64_t op0, vint16mf4_t op1, vint8mf8_t op2, vint8mf8_t op3, size_t op4){
  return vwmacc_vv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vwmacc(vint16mf2_t op0, vint8mf4_t op1, vint8mf4_t op2, size_t op3){
  return vwmacc_vv_i16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf2_t vwmacc(vbool32_t op0, vint16mf2_t op1, vint8mf4_t op2, vint8mf4_t op3, size_t op4){
  return vwmacc_vv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vwmacc(vint16m1_t op0, vint8mf2_t op1, vint8mf2_t op2, size_t op3){
  return vwmacc_vv_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vwmacc(vbool16_t op0, vint16m1_t op1, vint8mf2_t op2, vint8mf2_t op3, size_t op4){
  return vwmacc_vv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vwmacc(vint16m2_t op0, vint8m1_t op1, vint8m1_t op2, size_t op3){
  return vwmacc_vv_i16m2(op0, op1, op2, op3);
}

__rvv_overloaded vint16m2_t vwmacc(vbool8_t op0, vint16m2_t op1, vint8m1_t op2, vint8m1_t op3, size_t op4){
  return vwmacc_vv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vwmacc(vint16m4_t op0, vint8m2_t op1, vint8m2_t op2, size_t op3){
  return vwmacc_vv_i16m4(op0, op1, op2, op3);
}

__rvv_overloaded vint16m4_t vwmacc(vbool4_t op0, vint16m4_t op1, vint8m2_t op2, vint8m2_t op3, size_t op4){
  return vwmacc_vv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vwmacc(vint16m8_t op0, vint8m4_t op1, vint8m4_t op2, size_t op3){
  return vwmacc_vv_i16m8(op0, op1, op2, op3);
}

__rvv_overloaded vint16m8_t vwmacc(vbool2_t op0, vint16m8_t op1, vint8m4_t op2, vint8m4_t op3, size_t op4){
  return vwmacc_vv_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vwmacc(vint32mf2_t op0, vint16mf4_t op1, vint16mf4_t op2, size_t op3){
  return vwmacc_vv_i32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint32mf2_t vwmacc(vbool64_t op0, vint32mf2_t op1, vint16mf4_t op2, vint16mf4_t op3, size_t op4){
  return vwmacc_vv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vwmacc(vint32m1_t op0, vint16mf2_t op1, vint16mf2_t op2, size_t op3){
  return vwmacc_vv_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vwmacc(vbool32_t op0, vint32m1_t op1, vint16mf2_t op2, vint16mf2_t op3, size_t op4){
  return vwmacc_vv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vwmacc(vint32m2_t op0, vint16m1_t op1, vint16m1_t op2, size_t op3){
  return vwmacc_vv_i32m2(op0, op1, op2, op3);
}

__rvv_overloaded vint32m2_t vwmacc(vbool16_t op0, vint32m2_t op1, vint16m1_t op2, vint16m1_t op3, size_t op4){
  return vwmacc_vv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vwmacc(vint32m4_t op0, vint16m2_t op1, vint16m2_t op2, size_t op3){
  return vwmacc_vv_i32m4(op0, op1, op2, op3);
}

__rvv_overloaded vint32m4_t vwmacc(vbool8_t op0, vint32m4_t op1, vint16m2_t op2, vint16m2_t op3, size_t op4){
  return vwmacc_vv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vwmacc(vint32m8_t op0, vint16m4_t op1, vint16m4_t op2, size_t op3){
  return vwmacc_vv_i32m8(op0, op1, op2, op3);
}

__rvv_overloaded vint32m8_t vwmacc(vbool4_t op0, vint32m8_t op1, vint16m4_t op2, vint16m4_t op3, size_t op4){
  return vwmacc_vv_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vwmacc(vint64m1_t op0, vint32mf2_t op1, vint32mf2_t op2, size_t op3){
  return vwmacc_vv_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vwmacc(vbool64_t op0, vint64m1_t op1, vint32mf2_t op2, vint32mf2_t op3, size_t op4){
  return vwmacc_vv_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vwmacc(vint64m2_t op0, vint32m1_t op1, vint32m1_t op2, size_t op3){
  return vwmacc_vv_i64m2(op0, op1, op2, op3);
}

__rvv_overloaded vint64m2_t vwmacc(vbool32_t op0, vint64m2_t op1, vint32m1_t op2, vint32m1_t op3, size_t op4){
  return vwmacc_vv_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vwmacc(vint64m4_t op0, vint32m2_t op1, vint32m2_t op2, size_t op3){
  return vwmacc_vv_i64m4(op0, op1, op2, op3);
}

__rvv_overloaded vint64m4_t vwmacc(vbool16_t op0, vint64m4_t op1, vint32m2_t op2, vint32m2_t op3, size_t op4){
  return vwmacc_vv_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vwmacc(vint64m8_t op0, vint32m4_t op1, vint32m4_t op2, size_t op3){
  return vwmacc_vv_i64m8(op0, op1, op2, op3);
}

__rvv_overloaded vint64m8_t vwmacc(vbool8_t op0, vint64m8_t op1, vint32m4_t op2, vint32m4_t op3, size_t op4){
  return vwmacc_vv_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vwmacc(vint16mf4_t op0, int8_t op1, vint8mf8_t op2, size_t op3){
  return vwmacc_vx_i16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf4_t vwmacc(vbool64_t op0, vint16mf4_t op1, int8_t op2, vint8mf8_t op3, size_t op4){
  return vwmacc_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vwmacc(vint16mf2_t op0, int8_t op1, vint8mf4_t op2, size_t op3){
  return vwmacc_vx_i16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf2_t vwmacc(vbool32_t op0, vint16mf2_t op1, int8_t op2, vint8mf4_t op3, size_t op4){
  return vwmacc_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vwmacc(vint16m1_t op0, int8_t op1, vint8mf2_t op2, size_t op3){
  return vwmacc_vx_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vwmacc(vbool16_t op0, vint16m1_t op1, int8_t op2, vint8mf2_t op3, size_t op4){
  return vwmacc_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vwmacc(vint16m2_t op0, int8_t op1, vint8m1_t op2, size_t op3){
  return vwmacc_vx_i16m2(op0, op1, op2, op3);
}

__rvv_overloaded vint16m2_t vwmacc(vbool8_t op0, vint16m2_t op1, int8_t op2, vint8m1_t op3, size_t op4){
  return vwmacc_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vwmacc(vint16m4_t op0, int8_t op1, vint8m2_t op2, size_t op3){
  return vwmacc_vx_i16m4(op0, op1, op2, op3);
}

__rvv_overloaded vint16m4_t vwmacc(vbool4_t op0, vint16m4_t op1, int8_t op2, vint8m2_t op3, size_t op4){
  return vwmacc_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vwmacc(vint16m8_t op0, int8_t op1, vint8m4_t op2, size_t op3){
  return vwmacc_vx_i16m8(op0, op1, op2, op3);
}

__rvv_overloaded vint16m8_t vwmacc(vbool2_t op0, vint16m8_t op1, int8_t op2, vint8m4_t op3, size_t op4){
  return vwmacc_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vwmacc(vint32mf2_t op0, int16_t op1, vint16mf4_t op2, size_t op3){
  return vwmacc_vx_i32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint32mf2_t vwmacc(vbool64_t op0, vint32mf2_t op1, int16_t op2, vint16mf4_t op3, size_t op4){
  return vwmacc_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vwmacc(vint32m1_t op0, int16_t op1, vint16mf2_t op2, size_t op3){
  return vwmacc_vx_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vwmacc(vbool32_t op0, vint32m1_t op1, int16_t op2, vint16mf2_t op3, size_t op4){
  return vwmacc_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vwmacc(vint32m2_t op0, int16_t op1, vint16m1_t op2, size_t op3){
  return vwmacc_vx_i32m2(op0, op1, op2, op3);
}

__rvv_overloaded vint32m2_t vwmacc(vbool16_t op0, vint32m2_t op1, int16_t op2, vint16m1_t op3, size_t op4){
  return vwmacc_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vwmacc(vint32m4_t op0, int16_t op1, vint16m2_t op2, size_t op3){
  return vwmacc_vx_i32m4(op0, op1, op2, op3);
}

__rvv_overloaded vint32m4_t vwmacc(vbool8_t op0, vint32m4_t op1, int16_t op2, vint16m2_t op3, size_t op4){
  return vwmacc_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vwmacc(vint32m8_t op0, int16_t op1, vint16m4_t op2, size_t op3){
  return vwmacc_vx_i32m8(op0, op1, op2, op3);
}

__rvv_overloaded vint32m8_t vwmacc(vbool4_t op0, vint32m8_t op1, int16_t op2, vint16m4_t op3, size_t op4){
  return vwmacc_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vwmacc(vint64m1_t op0, int32_t op1, vint32mf2_t op2, size_t op3){
  return vwmacc_vx_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vwmacc(vbool64_t op0, vint64m1_t op1, int32_t op2, vint32mf2_t op3, size_t op4){
  return vwmacc_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vwmacc(vint64m2_t op0, int32_t op1, vint32m1_t op2, size_t op3){
  return vwmacc_vx_i64m2(op0, op1, op2, op3);
}

__rvv_overloaded vint64m2_t vwmacc(vbool32_t op0, vint64m2_t op1, int32_t op2, vint32m1_t op3, size_t op4){
  return vwmacc_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vwmacc(vint64m4_t op0, int32_t op1, vint32m2_t op2, size_t op3){
  return vwmacc_vx_i64m4(op0, op1, op2, op3);
}

__rvv_overloaded vint64m4_t vwmacc(vbool16_t op0, vint64m4_t op1, int32_t op2, vint32m2_t op3, size_t op4){
  return vwmacc_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vwmacc(vint64m8_t op0, int32_t op1, vint32m4_t op2, size_t op3){
  return vwmacc_vx_i64m8(op0, op1, op2, op3);
}

__rvv_overloaded vint64m8_t vwmacc(vbool8_t op0, vint64m8_t op1, int32_t op2, vint32m4_t op3, size_t op4){
  return vwmacc_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vwmaccsu(vint16mf4_t op0, vint8mf8_t op1, vuint8mf8_t op2, size_t op3){
  return vwmaccsu_vv_i16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf4_t vwmaccsu(vbool64_t op0, vint16mf4_t op1, vint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vwmaccsu_vv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vwmaccsu(vint16mf2_t op0, vint8mf4_t op1, vuint8mf4_t op2, size_t op3){
  return vwmaccsu_vv_i16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf2_t vwmaccsu(vbool32_t op0, vint16mf2_t op1, vint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vwmaccsu_vv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vwmaccsu(vint16m1_t op0, vint8mf2_t op1, vuint8mf2_t op2, size_t op3){
  return vwmaccsu_vv_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vwmaccsu(vbool16_t op0, vint16m1_t op1, vint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vwmaccsu_vv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vwmaccsu(vint16m2_t op0, vint8m1_t op1, vuint8m1_t op2, size_t op3){
  return vwmaccsu_vv_i16m2(op0, op1, op2, op3);
}

__rvv_overloaded vint16m2_t vwmaccsu(vbool8_t op0, vint16m2_t op1, vint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vwmaccsu_vv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vwmaccsu(vint16m4_t op0, vint8m2_t op1, vuint8m2_t op2, size_t op3){
  return vwmaccsu_vv_i16m4(op0, op1, op2, op3);
}

__rvv_overloaded vint16m4_t vwmaccsu(vbool4_t op0, vint16m4_t op1, vint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vwmaccsu_vv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vwmaccsu(vint16m8_t op0, vint8m4_t op1, vuint8m4_t op2, size_t op3){
  return vwmaccsu_vv_i16m8(op0, op1, op2, op3);
}

__rvv_overloaded vint16m8_t vwmaccsu(vbool2_t op0, vint16m8_t op1, vint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vwmaccsu_vv_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vwmaccsu(vint32mf2_t op0, vint16mf4_t op1, vuint16mf4_t op2, size_t op3){
  return vwmaccsu_vv_i32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint32mf2_t vwmaccsu(vbool64_t op0, vint32mf2_t op1, vint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vwmaccsu_vv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vwmaccsu(vint32m1_t op0, vint16mf2_t op1, vuint16mf2_t op2, size_t op3){
  return vwmaccsu_vv_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vwmaccsu(vbool32_t op0, vint32m1_t op1, vint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vwmaccsu_vv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vwmaccsu(vint32m2_t op0, vint16m1_t op1, vuint16m1_t op2, size_t op3){
  return vwmaccsu_vv_i32m2(op0, op1, op2, op3);
}

__rvv_overloaded vint32m2_t vwmaccsu(vbool16_t op0, vint32m2_t op1, vint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vwmaccsu_vv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vwmaccsu(vint32m4_t op0, vint16m2_t op1, vuint16m2_t op2, size_t op3){
  return vwmaccsu_vv_i32m4(op0, op1, op2, op3);
}

__rvv_overloaded vint32m4_t vwmaccsu(vbool8_t op0, vint32m4_t op1, vint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vwmaccsu_vv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vwmaccsu(vint32m8_t op0, vint16m4_t op1, vuint16m4_t op2, size_t op3){
  return vwmaccsu_vv_i32m8(op0, op1, op2, op3);
}

__rvv_overloaded vint32m8_t vwmaccsu(vbool4_t op0, vint32m8_t op1, vint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vwmaccsu_vv_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vwmaccsu(vint64m1_t op0, vint32mf2_t op1, vuint32mf2_t op2, size_t op3){
  return vwmaccsu_vv_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vwmaccsu(vbool64_t op0, vint64m1_t op1, vint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vwmaccsu_vv_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vwmaccsu(vint64m2_t op0, vint32m1_t op1, vuint32m1_t op2, size_t op3){
  return vwmaccsu_vv_i64m2(op0, op1, op2, op3);
}

__rvv_overloaded vint64m2_t vwmaccsu(vbool32_t op0, vint64m2_t op1, vint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vwmaccsu_vv_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vwmaccsu(vint64m4_t op0, vint32m2_t op1, vuint32m2_t op2, size_t op3){
  return vwmaccsu_vv_i64m4(op0, op1, op2, op3);
}

__rvv_overloaded vint64m4_t vwmaccsu(vbool16_t op0, vint64m4_t op1, vint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vwmaccsu_vv_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vwmaccsu(vint64m8_t op0, vint32m4_t op1, vuint32m4_t op2, size_t op3){
  return vwmaccsu_vv_i64m8(op0, op1, op2, op3);
}

__rvv_overloaded vint64m8_t vwmaccsu(vbool8_t op0, vint64m8_t op1, vint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vwmaccsu_vv_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vwmaccsu(vint16mf4_t op0, int8_t op1, vuint8mf8_t op2, size_t op3){
  return vwmaccsu_vx_i16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf4_t vwmaccsu(vbool64_t op0, vint16mf4_t op1, int8_t op2, vuint8mf8_t op3, size_t op4){
  return vwmaccsu_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vwmaccsu(vint16mf2_t op0, int8_t op1, vuint8mf4_t op2, size_t op3){
  return vwmaccsu_vx_i16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf2_t vwmaccsu(vbool32_t op0, vint16mf2_t op1, int8_t op2, vuint8mf4_t op3, size_t op4){
  return vwmaccsu_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vwmaccsu(vint16m1_t op0, int8_t op1, vuint8mf2_t op2, size_t op3){
  return vwmaccsu_vx_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vwmaccsu(vbool16_t op0, vint16m1_t op1, int8_t op2, vuint8mf2_t op3, size_t op4){
  return vwmaccsu_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vwmaccsu(vint16m2_t op0, int8_t op1, vuint8m1_t op2, size_t op3){
  return vwmaccsu_vx_i16m2(op0, op1, op2, op3);
}

__rvv_overloaded vint16m2_t vwmaccsu(vbool8_t op0, vint16m2_t op1, int8_t op2, vuint8m1_t op3, size_t op4){
  return vwmaccsu_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vwmaccsu(vint16m4_t op0, int8_t op1, vuint8m2_t op2, size_t op3){
  return vwmaccsu_vx_i16m4(op0, op1, op2, op3);
}

__rvv_overloaded vint16m4_t vwmaccsu(vbool4_t op0, vint16m4_t op1, int8_t op2, vuint8m2_t op3, size_t op4){
  return vwmaccsu_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vwmaccsu(vint16m8_t op0, int8_t op1, vuint8m4_t op2, size_t op3){
  return vwmaccsu_vx_i16m8(op0, op1, op2, op3);
}

__rvv_overloaded vint16m8_t vwmaccsu(vbool2_t op0, vint16m8_t op1, int8_t op2, vuint8m4_t op3, size_t op4){
  return vwmaccsu_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vwmaccsu(vint32mf2_t op0, int16_t op1, vuint16mf4_t op2, size_t op3){
  return vwmaccsu_vx_i32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint32mf2_t vwmaccsu(vbool64_t op0, vint32mf2_t op1, int16_t op2, vuint16mf4_t op3, size_t op4){
  return vwmaccsu_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vwmaccsu(vint32m1_t op0, int16_t op1, vuint16mf2_t op2, size_t op3){
  return vwmaccsu_vx_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vwmaccsu(vbool32_t op0, vint32m1_t op1, int16_t op2, vuint16mf2_t op3, size_t op4){
  return vwmaccsu_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vwmaccsu(vint32m2_t op0, int16_t op1, vuint16m1_t op2, size_t op3){
  return vwmaccsu_vx_i32m2(op0, op1, op2, op3);
}

__rvv_overloaded vint32m2_t vwmaccsu(vbool16_t op0, vint32m2_t op1, int16_t op2, vuint16m1_t op3, size_t op4){
  return vwmaccsu_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vwmaccsu(vint32m4_t op0, int16_t op1, vuint16m2_t op2, size_t op3){
  return vwmaccsu_vx_i32m4(op0, op1, op2, op3);
}

__rvv_overloaded vint32m4_t vwmaccsu(vbool8_t op0, vint32m4_t op1, int16_t op2, vuint16m2_t op3, size_t op4){
  return vwmaccsu_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vwmaccsu(vint32m8_t op0, int16_t op1, vuint16m4_t op2, size_t op3){
  return vwmaccsu_vx_i32m8(op0, op1, op2, op3);
}

__rvv_overloaded vint32m8_t vwmaccsu(vbool4_t op0, vint32m8_t op1, int16_t op2, vuint16m4_t op3, size_t op4){
  return vwmaccsu_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vwmaccsu(vint64m1_t op0, int32_t op1, vuint32mf2_t op2, size_t op3){
  return vwmaccsu_vx_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vwmaccsu(vbool64_t op0, vint64m1_t op1, int32_t op2, vuint32mf2_t op3, size_t op4){
  return vwmaccsu_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vwmaccsu(vint64m2_t op0, int32_t op1, vuint32m1_t op2, size_t op3){
  return vwmaccsu_vx_i64m2(op0, op1, op2, op3);
}

__rvv_overloaded vint64m2_t vwmaccsu(vbool32_t op0, vint64m2_t op1, int32_t op2, vuint32m1_t op3, size_t op4){
  return vwmaccsu_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vwmaccsu(vint64m4_t op0, int32_t op1, vuint32m2_t op2, size_t op3){
  return vwmaccsu_vx_i64m4(op0, op1, op2, op3);
}

__rvv_overloaded vint64m4_t vwmaccsu(vbool16_t op0, vint64m4_t op1, int32_t op2, vuint32m2_t op3, size_t op4){
  return vwmaccsu_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vwmaccsu(vint64m8_t op0, int32_t op1, vuint32m4_t op2, size_t op3){
  return vwmaccsu_vx_i64m8(op0, op1, op2, op3);
}

__rvv_overloaded vint64m8_t vwmaccsu(vbool8_t op0, vint64m8_t op1, int32_t op2, vuint32m4_t op3, size_t op4){
  return vwmaccsu_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vwmaccus(vint16mf4_t op0, uint8_t op1, vint8mf8_t op2, size_t op3){
  return vwmaccus_vx_i16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf4_t vwmaccus(vbool64_t op0, vint16mf4_t op1, uint8_t op2, vint8mf8_t op3, size_t op4){
  return vwmaccus_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vwmaccus(vint16mf2_t op0, uint8_t op1, vint8mf4_t op2, size_t op3){
  return vwmaccus_vx_i16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf2_t vwmaccus(vbool32_t op0, vint16mf2_t op1, uint8_t op2, vint8mf4_t op3, size_t op4){
  return vwmaccus_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vwmaccus(vint16m1_t op0, uint8_t op1, vint8mf2_t op2, size_t op3){
  return vwmaccus_vx_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vwmaccus(vbool16_t op0, vint16m1_t op1, uint8_t op2, vint8mf2_t op3, size_t op4){
  return vwmaccus_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vwmaccus(vint16m2_t op0, uint8_t op1, vint8m1_t op2, size_t op3){
  return vwmaccus_vx_i16m2(op0, op1, op2, op3);
}

__rvv_overloaded vint16m2_t vwmaccus(vbool8_t op0, vint16m2_t op1, uint8_t op2, vint8m1_t op3, size_t op4){
  return vwmaccus_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vwmaccus(vint16m4_t op0, uint8_t op1, vint8m2_t op2, size_t op3){
  return vwmaccus_vx_i16m4(op0, op1, op2, op3);
}

__rvv_overloaded vint16m4_t vwmaccus(vbool4_t op0, vint16m4_t op1, uint8_t op2, vint8m2_t op3, size_t op4){
  return vwmaccus_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vwmaccus(vint16m8_t op0, uint8_t op1, vint8m4_t op2, size_t op3){
  return vwmaccus_vx_i16m8(op0, op1, op2, op3);
}

__rvv_overloaded vint16m8_t vwmaccus(vbool2_t op0, vint16m8_t op1, uint8_t op2, vint8m4_t op3, size_t op4){
  return vwmaccus_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vwmaccus(vint32mf2_t op0, uint16_t op1, vint16mf4_t op2, size_t op3){
  return vwmaccus_vx_i32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint32mf2_t vwmaccus(vbool64_t op0, vint32mf2_t op1, uint16_t op2, vint16mf4_t op3, size_t op4){
  return vwmaccus_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vwmaccus(vint32m1_t op0, uint16_t op1, vint16mf2_t op2, size_t op3){
  return vwmaccus_vx_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vwmaccus(vbool32_t op0, vint32m1_t op1, uint16_t op2, vint16mf2_t op3, size_t op4){
  return vwmaccus_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vwmaccus(vint32m2_t op0, uint16_t op1, vint16m1_t op2, size_t op3){
  return vwmaccus_vx_i32m2(op0, op1, op2, op3);
}

__rvv_overloaded vint32m2_t vwmaccus(vbool16_t op0, vint32m2_t op1, uint16_t op2, vint16m1_t op3, size_t op4){
  return vwmaccus_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vwmaccus(vint32m4_t op0, uint16_t op1, vint16m2_t op2, size_t op3){
  return vwmaccus_vx_i32m4(op0, op1, op2, op3);
}

__rvv_overloaded vint32m4_t vwmaccus(vbool8_t op0, vint32m4_t op1, uint16_t op2, vint16m2_t op3, size_t op4){
  return vwmaccus_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vwmaccus(vint32m8_t op0, uint16_t op1, vint16m4_t op2, size_t op3){
  return vwmaccus_vx_i32m8(op0, op1, op2, op3);
}

__rvv_overloaded vint32m8_t vwmaccus(vbool4_t op0, vint32m8_t op1, uint16_t op2, vint16m4_t op3, size_t op4){
  return vwmaccus_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vwmaccus(vint64m1_t op0, uint32_t op1, vint32mf2_t op2, size_t op3){
  return vwmaccus_vx_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vwmaccus(vbool64_t op0, vint64m1_t op1, uint32_t op2, vint32mf2_t op3, size_t op4){
  return vwmaccus_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vwmaccus(vint64m2_t op0, uint32_t op1, vint32m1_t op2, size_t op3){
  return vwmaccus_vx_i64m2(op0, op1, op2, op3);
}

__rvv_overloaded vint64m2_t vwmaccus(vbool32_t op0, vint64m2_t op1, uint32_t op2, vint32m1_t op3, size_t op4){
  return vwmaccus_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vwmaccus(vint64m4_t op0, uint32_t op1, vint32m2_t op2, size_t op3){
  return vwmaccus_vx_i64m4(op0, op1, op2, op3);
}

__rvv_overloaded vint64m4_t vwmaccus(vbool16_t op0, vint64m4_t op1, uint32_t op2, vint32m2_t op3, size_t op4){
  return vwmaccus_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vwmaccus(vint64m8_t op0, uint32_t op1, vint32m4_t op2, size_t op3){
  return vwmaccus_vx_i64m8(op0, op1, op2, op3);
}

__rvv_overloaded vint64m8_t vwmaccus(vbool8_t op0, vint64m8_t op1, uint32_t op2, vint32m4_t op3, size_t op4){
  return vwmaccus_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vsaddu(vuint8m1_t op0, vuint8m1_t op1, size_t op2){
  return vsaddu_vv_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vsaddu(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vsaddu_vv_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vsaddu(vuint8m2_t op0, vuint8m2_t op1, size_t op2){
  return vsaddu_vv_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vsaddu(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vsaddu_vv_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vsaddu(vuint8m4_t op0, vuint8m4_t op1, size_t op2){
  return vsaddu_vv_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vsaddu(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vsaddu_vv_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vsaddu(vuint8m8_t op0, vuint8m8_t op1, size_t op2){
  return vsaddu_vv_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vsaddu(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, vuint8m8_t op3, size_t op4){
  return vsaddu_vv_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vsaddu(vuint8mf2_t op0, vuint8mf2_t op1, size_t op2){
  return vsaddu_vv_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vsaddu(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vsaddu_vv_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vsaddu(vuint8mf4_t op0, vuint8mf4_t op1, size_t op2){
  return vsaddu_vv_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vsaddu(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vsaddu_vv_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vsaddu(vuint8mf8_t op0, vuint8mf8_t op1, size_t op2){
  return vsaddu_vv_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vsaddu(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vsaddu_vv_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vsaddu(vuint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vsaddu_vv_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vsaddu(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vsaddu_vv_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vsaddu(vuint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vsaddu_vv_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vsaddu(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vsaddu_vv_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vsaddu(vuint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vsaddu_vv_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vsaddu(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vsaddu_vv_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vsaddu(vuint16m8_t op0, vuint16m8_t op1, size_t op2){
  return vsaddu_vv_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vsaddu(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vsaddu_vv_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vsaddu(vuint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vsaddu_vv_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vsaddu(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vsaddu_vv_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vsaddu(vuint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vsaddu_vv_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vsaddu(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vsaddu_vv_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vsaddu(vuint32m1_t op0, vuint32m1_t op1, size_t op2){
  return vsaddu_vv_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vsaddu(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vsaddu_vv_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vsaddu(vuint32m2_t op0, vuint32m2_t op1, size_t op2){
  return vsaddu_vv_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vsaddu(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vsaddu_vv_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vsaddu(vuint32m4_t op0, vuint32m4_t op1, size_t op2){
  return vsaddu_vv_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vsaddu(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vsaddu_vv_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vsaddu(vuint32m8_t op0, vuint32m8_t op1, size_t op2){
  return vsaddu_vv_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vsaddu(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, vuint32m8_t op3, size_t op4){
  return vsaddu_vv_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vsaddu(vuint32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vsaddu_vv_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vsaddu(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vsaddu_vv_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vsaddu(vuint64m1_t op0, vuint64m1_t op1, size_t op2){
  return vsaddu_vv_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vsaddu(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vsaddu_vv_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vsaddu(vuint64m2_t op0, vuint64m2_t op1, size_t op2){
  return vsaddu_vv_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vsaddu(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, vuint64m2_t op3, size_t op4){
  return vsaddu_vv_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vsaddu(vuint64m4_t op0, vuint64m4_t op1, size_t op2){
  return vsaddu_vv_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vsaddu(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, vuint64m4_t op3, size_t op4){
  return vsaddu_vv_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vsaddu(vuint64m8_t op0, vuint64m8_t op1, size_t op2){
  return vsaddu_vv_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vsaddu(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, vuint64m8_t op3, size_t op4){
  return vsaddu_vv_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vle32ff(vbool32_t op0, vint32m1_t op1, const int32_t * op2, size_t * op3, size_t op4){
  return vle32ff_v_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vle32ff(vbool16_t op0, vint32m2_t op1, const int32_t * op2, size_t * op3, size_t op4){
  return vle32ff_v_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vle32ff(vbool8_t op0, vint32m4_t op1, const int32_t * op2, size_t * op3, size_t op4){
  return vle32ff_v_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vle32ff(vbool4_t op0, vint32m8_t op1, const int32_t * op2, size_t * op3, size_t op4){
  return vle32ff_v_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vle32ff(vbool64_t op0, vint32mf2_t op1, const int32_t * op2, size_t * op3, size_t op4){
  return vle32ff_v_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vsaddu(vuint8m1_t op0, uint8_t op1, size_t op2){
  return vsaddu_vx_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vsaddu(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, uint8_t op3, size_t op4){
  return vsaddu_vx_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vsaddu(vuint8m2_t op0, uint8_t op1, size_t op2){
  return vsaddu_vx_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vsaddu(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, uint8_t op3, size_t op4){
  return vsaddu_vx_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vsaddu(vuint8m4_t op0, uint8_t op1, size_t op2){
  return vsaddu_vx_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vsaddu(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, uint8_t op3, size_t op4){
  return vsaddu_vx_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vsaddu(vuint8m8_t op0, uint8_t op1, size_t op2){
  return vsaddu_vx_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vsaddu(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, uint8_t op3, size_t op4){
  return vsaddu_vx_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vsaddu(vuint8mf2_t op0, uint8_t op1, size_t op2){
  return vsaddu_vx_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vsaddu(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, uint8_t op3, size_t op4){
  return vsaddu_vx_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vsaddu(vuint8mf4_t op0, uint8_t op1, size_t op2){
  return vsaddu_vx_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vsaddu(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, uint8_t op3, size_t op4){
  return vsaddu_vx_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vsaddu(vuint8mf8_t op0, uint8_t op1, size_t op2){
  return vsaddu_vx_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vsaddu(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, uint8_t op3, size_t op4){
  return vsaddu_vx_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vsaddu(vuint16m1_t op0, uint16_t op1, size_t op2){
  return vsaddu_vx_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vsaddu(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, uint16_t op3, size_t op4){
  return vsaddu_vx_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vsaddu(vuint16m2_t op0, uint16_t op1, size_t op2){
  return vsaddu_vx_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vsaddu(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, uint16_t op3, size_t op4){
  return vsaddu_vx_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vsaddu(vuint16m4_t op0, uint16_t op1, size_t op2){
  return vsaddu_vx_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vsaddu(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, uint16_t op3, size_t op4){
  return vsaddu_vx_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vsaddu(vuint16m8_t op0, uint16_t op1, size_t op2){
  return vsaddu_vx_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vsaddu(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, uint16_t op3, size_t op4){
  return vsaddu_vx_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vsaddu(vuint16mf2_t op0, uint16_t op1, size_t op2){
  return vsaddu_vx_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vsaddu(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, uint16_t op3, size_t op4){
  return vsaddu_vx_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vsaddu(vuint16mf4_t op0, uint16_t op1, size_t op2){
  return vsaddu_vx_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vsaddu(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, uint16_t op3, size_t op4){
  return vsaddu_vx_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vsaddu(vuint32m1_t op0, uint32_t op1, size_t op2){
  return vsaddu_vx_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vsaddu(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, uint32_t op3, size_t op4){
  return vsaddu_vx_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vsaddu(vuint32m2_t op0, uint32_t op1, size_t op2){
  return vsaddu_vx_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vsaddu(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, uint32_t op3, size_t op4){
  return vsaddu_vx_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vsaddu(vuint32m4_t op0, uint32_t op1, size_t op2){
  return vsaddu_vx_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vsaddu(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, uint32_t op3, size_t op4){
  return vsaddu_vx_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vsaddu(vuint32m8_t op0, uint32_t op1, size_t op2){
  return vsaddu_vx_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vsaddu(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, uint32_t op3, size_t op4){
  return vsaddu_vx_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vsaddu(vuint32mf2_t op0, uint32_t op1, size_t op2){
  return vsaddu_vx_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vsaddu(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, uint32_t op3, size_t op4){
  return vsaddu_vx_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vsaddu(vuint64m1_t op0, uint64_t op1, size_t op2){
  return vsaddu_vx_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vsaddu(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, uint64_t op3, size_t op4){
  return vsaddu_vx_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vsaddu(vuint64m2_t op0, uint64_t op1, size_t op2){
  return vsaddu_vx_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vsaddu(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, uint64_t op3, size_t op4){
  return vsaddu_vx_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vsaddu(vuint64m4_t op0, uint64_t op1, size_t op2){
  return vsaddu_vx_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vsaddu(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, uint64_t op3, size_t op4){
  return vsaddu_vx_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vsaddu(vuint64m8_t op0, uint64_t op1, size_t op2){
  return vsaddu_vx_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vsaddu(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, uint64_t op3, size_t op4){
  return vsaddu_vx_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vsadd(vint8m1_t op0, vint8m1_t op1, size_t op2){
  return vsadd_vv_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vsadd(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, vint8m1_t op3, size_t op4){
  return vsadd_vv_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vsadd(vint8m2_t op0, vint8m2_t op1, size_t op2){
  return vsadd_vv_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vsadd(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, vint8m2_t op3, size_t op4){
  return vsadd_vv_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vsadd(vint8m4_t op0, vint8m4_t op1, size_t op2){
  return vsadd_vv_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vsadd(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, vint8m4_t op3, size_t op4){
  return vsadd_vv_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vsadd(vint8m8_t op0, vint8m8_t op1, size_t op2){
  return vsadd_vv_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vsadd(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, vint8m8_t op3, size_t op4){
  return vsadd_vv_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vsadd(vint8mf2_t op0, vint8mf2_t op1, size_t op2){
  return vsadd_vv_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vsadd(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, vint8mf2_t op3, size_t op4){
  return vsadd_vv_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vsadd(vint8mf4_t op0, vint8mf4_t op1, size_t op2){
  return vsadd_vv_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vsadd(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, vint8mf4_t op3, size_t op4){
  return vsadd_vv_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vsadd(vint8mf8_t op0, vint8mf8_t op1, size_t op2){
  return vsadd_vv_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vsadd(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, vint8mf8_t op3, size_t op4){
  return vsadd_vv_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vsadd(vint16m1_t op0, vint16m1_t op1, size_t op2){
  return vsadd_vv_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vsadd(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, vint16m1_t op3, size_t op4){
  return vsadd_vv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vsadd(vint16m2_t op0, vint16m2_t op1, size_t op2){
  return vsadd_vv_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vsadd(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, vint16m2_t op3, size_t op4){
  return vsadd_vv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vsadd(vint16m4_t op0, vint16m4_t op1, size_t op2){
  return vsadd_vv_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vsadd(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, vint16m4_t op3, size_t op4){
  return vsadd_vv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vsadd(vint16m8_t op0, vint16m8_t op1, size_t op2){
  return vsadd_vv_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vsadd(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, vint16m8_t op3, size_t op4){
  return vsadd_vv_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vsadd(vint16mf2_t op0, vint16mf2_t op1, size_t op2){
  return vsadd_vv_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vsadd(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, vint16mf2_t op3, size_t op4){
  return vsadd_vv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vsadd(vint16mf4_t op0, vint16mf4_t op1, size_t op2){
  return vsadd_vv_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vsadd(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, vint16mf4_t op3, size_t op4){
  return vsadd_vv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vsadd(vint32m1_t op0, vint32m1_t op1, size_t op2){
  return vsadd_vv_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vsadd(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, vint32m1_t op3, size_t op4){
  return vsadd_vv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vsadd(vint32m2_t op0, vint32m2_t op1, size_t op2){
  return vsadd_vv_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vsadd(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, vint32m2_t op3, size_t op4){
  return vsadd_vv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vsadd(vint32m4_t op0, vint32m4_t op1, size_t op2){
  return vsadd_vv_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vsadd(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, vint32m4_t op3, size_t op4){
  return vsadd_vv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vsadd(vint32m8_t op0, vint32m8_t op1, size_t op2){
  return vsadd_vv_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vsadd(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, vint32m8_t op3, size_t op4){
  return vsadd_vv_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vsadd(vint32mf2_t op0, vint32mf2_t op1, size_t op2){
  return vsadd_vv_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vsadd(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, vint32mf2_t op3, size_t op4){
  return vsadd_vv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vsadd(vint64m1_t op0, vint64m1_t op1, size_t op2){
  return vsadd_vv_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vsadd(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, vint64m1_t op3, size_t op4){
  return vsadd_vv_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vsadd(vint64m2_t op0, vint64m2_t op1, size_t op2){
  return vsadd_vv_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vsadd(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, vint64m2_t op3, size_t op4){
  return vsadd_vv_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vsadd(vint64m4_t op0, vint64m4_t op1, size_t op2){
  return vsadd_vv_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vsadd(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, vint64m4_t op3, size_t op4){
  return vsadd_vv_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vsadd(vint64m8_t op0, vint64m8_t op1, size_t op2){
  return vsadd_vv_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vsadd(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, vint64m8_t op3, size_t op4){
  return vsadd_vv_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vsadd(vint8m1_t op0, int8_t op1, size_t op2){
  return vsadd_vx_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vsadd(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, int8_t op3, size_t op4){
  return vsadd_vx_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vsadd(vint8m2_t op0, int8_t op1, size_t op2){
  return vsadd_vx_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vsadd(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, int8_t op3, size_t op4){
  return vsadd_vx_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vsadd(vint8m4_t op0, int8_t op1, size_t op2){
  return vsadd_vx_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vsadd(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, int8_t op3, size_t op4){
  return vsadd_vx_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vsadd(vint8m8_t op0, int8_t op1, size_t op2){
  return vsadd_vx_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vsadd(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, int8_t op3, size_t op4){
  return vsadd_vx_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vsadd(vint8mf2_t op0, int8_t op1, size_t op2){
  return vsadd_vx_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vsadd(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, int8_t op3, size_t op4){
  return vsadd_vx_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vsadd(vint8mf4_t op0, int8_t op1, size_t op2){
  return vsadd_vx_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vsadd(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, int8_t op3, size_t op4){
  return vsadd_vx_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vsadd(vint8mf8_t op0, int8_t op1, size_t op2){
  return vsadd_vx_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vsadd(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, int8_t op3, size_t op4){
  return vsadd_vx_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vsadd(vint16m1_t op0, int16_t op1, size_t op2){
  return vsadd_vx_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vsadd(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, int16_t op3, size_t op4){
  return vsadd_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vsadd(vint16m2_t op0, int16_t op1, size_t op2){
  return vsadd_vx_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vsadd(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, int16_t op3, size_t op4){
  return vsadd_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vsadd(vint16m4_t op0, int16_t op1, size_t op2){
  return vsadd_vx_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vsadd(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, int16_t op3, size_t op4){
  return vsadd_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vsadd(vint16m8_t op0, int16_t op1, size_t op2){
  return vsadd_vx_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vsadd(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, int16_t op3, size_t op4){
  return vsadd_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vsadd(vint16mf2_t op0, int16_t op1, size_t op2){
  return vsadd_vx_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vsadd(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, int16_t op3, size_t op4){
  return vsadd_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vsadd(vint16mf4_t op0, int16_t op1, size_t op2){
  return vsadd_vx_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vsadd(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, int16_t op3, size_t op4){
  return vsadd_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vsadd(vint32m1_t op0, int32_t op1, size_t op2){
  return vsadd_vx_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vsadd(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, int32_t op3, size_t op4){
  return vsadd_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vsadd(vint32m2_t op0, int32_t op1, size_t op2){
  return vsadd_vx_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vsadd(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, int32_t op3, size_t op4){
  return vsadd_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vsadd(vint32m4_t op0, int32_t op1, size_t op2){
  return vsadd_vx_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vsadd(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, int32_t op3, size_t op4){
  return vsadd_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vsadd(vint32m8_t op0, int32_t op1, size_t op2){
  return vsadd_vx_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vsadd(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, int32_t op3, size_t op4){
  return vsadd_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vsadd(vint32mf2_t op0, int32_t op1, size_t op2){
  return vsadd_vx_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vsadd(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, int32_t op3, size_t op4){
  return vsadd_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vsadd(vint64m1_t op0, int64_t op1, size_t op2){
  return vsadd_vx_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vsadd(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, int64_t op3, size_t op4){
  return vsadd_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vsadd(vint64m2_t op0, int64_t op1, size_t op2){
  return vsadd_vx_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vsadd(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, int64_t op3, size_t op4){
  return vsadd_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vsadd(vint64m4_t op0, int64_t op1, size_t op2){
  return vsadd_vx_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vsadd(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, int64_t op3, size_t op4){
  return vsadd_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vsadd(vint64m8_t op0, int64_t op1, size_t op2){
  return vsadd_vx_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vsadd(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, int64_t op3, size_t op4){
  return vsadd_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vssubu(vuint8m1_t op0, vuint8m1_t op1, size_t op2){
  return vssubu_vv_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vssubu(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vssubu_vv_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vssubu(vuint8m2_t op0, vuint8m2_t op1, size_t op2){
  return vssubu_vv_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vssubu(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vssubu_vv_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vssubu(vuint8m4_t op0, vuint8m4_t op1, size_t op2){
  return vssubu_vv_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vssubu(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vssubu_vv_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vssubu(vuint8m8_t op0, vuint8m8_t op1, size_t op2){
  return vssubu_vv_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vssubu(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, vuint8m8_t op3, size_t op4){
  return vssubu_vv_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vssubu(vuint8mf2_t op0, vuint8mf2_t op1, size_t op2){
  return vssubu_vv_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vssubu(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vssubu_vv_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vssubu(vuint8mf4_t op0, vuint8mf4_t op1, size_t op2){
  return vssubu_vv_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vssubu(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vssubu_vv_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vssubu(vuint8mf8_t op0, vuint8mf8_t op1, size_t op2){
  return vssubu_vv_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vssubu(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vssubu_vv_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vssubu(vuint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vssubu_vv_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vssubu(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vssubu_vv_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vssubu(vuint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vssubu_vv_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vssubu(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vssubu_vv_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vssubu(vuint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vssubu_vv_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vssubu(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vssubu_vv_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vssubu(vuint16m8_t op0, vuint16m8_t op1, size_t op2){
  return vssubu_vv_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vssubu(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vssubu_vv_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vssubu(vuint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vssubu_vv_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vssubu(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vssubu_vv_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vssubu(vuint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vssubu_vv_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vssubu(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vssubu_vv_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vssubu(vuint32m1_t op0, vuint32m1_t op1, size_t op2){
  return vssubu_vv_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vssubu(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vssubu_vv_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vssubu(vuint32m2_t op0, vuint32m2_t op1, size_t op2){
  return vssubu_vv_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vssubu(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vssubu_vv_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vssubu(vuint32m4_t op0, vuint32m4_t op1, size_t op2){
  return vssubu_vv_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vssubu(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vssubu_vv_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vssubu(vuint32m8_t op0, vuint32m8_t op1, size_t op2){
  return vssubu_vv_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vssubu(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, vuint32m8_t op3, size_t op4){
  return vssubu_vv_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vssubu(vuint32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vssubu_vv_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vssubu(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vssubu_vv_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vssubu(vuint64m1_t op0, vuint64m1_t op1, size_t op2){
  return vssubu_vv_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vssubu(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vssubu_vv_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vssubu(vuint64m2_t op0, vuint64m2_t op1, size_t op2){
  return vssubu_vv_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vssubu(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, vuint64m2_t op3, size_t op4){
  return vssubu_vv_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vssubu(vuint64m4_t op0, vuint64m4_t op1, size_t op2){
  return vssubu_vv_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vssubu(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, vuint64m4_t op3, size_t op4){
  return vssubu_vv_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vssubu(vuint64m8_t op0, vuint64m8_t op1, size_t op2){
  return vssubu_vv_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vssubu(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, vuint64m8_t op3, size_t op4){
  return vssubu_vv_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vssubu(vuint8m1_t op0, uint8_t op1, size_t op2){
  return vssubu_vx_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vssubu(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, uint8_t op3, size_t op4){
  return vssubu_vx_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vssubu(vuint8m2_t op0, uint8_t op1, size_t op2){
  return vssubu_vx_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vssubu(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, uint8_t op3, size_t op4){
  return vssubu_vx_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vssubu(vuint8m4_t op0, uint8_t op1, size_t op2){
  return vssubu_vx_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vssubu(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, uint8_t op3, size_t op4){
  return vssubu_vx_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vssubu(vuint8m8_t op0, uint8_t op1, size_t op2){
  return vssubu_vx_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vssubu(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, uint8_t op3, size_t op4){
  return vssubu_vx_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vssubu(vuint8mf2_t op0, uint8_t op1, size_t op2){
  return vssubu_vx_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vssubu(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, uint8_t op3, size_t op4){
  return vssubu_vx_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vssubu(vuint8mf4_t op0, uint8_t op1, size_t op2){
  return vssubu_vx_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vssubu(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, uint8_t op3, size_t op4){
  return vssubu_vx_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vssubu(vuint8mf8_t op0, uint8_t op1, size_t op2){
  return vssubu_vx_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vssubu(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, uint8_t op3, size_t op4){
  return vssubu_vx_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vssubu(vuint16m1_t op0, uint16_t op1, size_t op2){
  return vssubu_vx_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vssubu(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, uint16_t op3, size_t op4){
  return vssubu_vx_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vssubu(vuint16m2_t op0, uint16_t op1, size_t op2){
  return vssubu_vx_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vssubu(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, uint16_t op3, size_t op4){
  return vssubu_vx_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vssubu(vuint16m4_t op0, uint16_t op1, size_t op2){
  return vssubu_vx_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vssubu(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, uint16_t op3, size_t op4){
  return vssubu_vx_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vssubu(vuint16m8_t op0, uint16_t op1, size_t op2){
  return vssubu_vx_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vssubu(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, uint16_t op3, size_t op4){
  return vssubu_vx_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vssubu(vuint16mf2_t op0, uint16_t op1, size_t op2){
  return vssubu_vx_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vssubu(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, uint16_t op3, size_t op4){
  return vssubu_vx_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vssubu(vuint16mf4_t op0, uint16_t op1, size_t op2){
  return vssubu_vx_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vssubu(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, uint16_t op3, size_t op4){
  return vssubu_vx_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vssubu(vuint32m1_t op0, uint32_t op1, size_t op2){
  return vssubu_vx_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vssubu(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, uint32_t op3, size_t op4){
  return vssubu_vx_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vssubu(vuint32m2_t op0, uint32_t op1, size_t op2){
  return vssubu_vx_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vssubu(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, uint32_t op3, size_t op4){
  return vssubu_vx_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vssubu(vuint32m4_t op0, uint32_t op1, size_t op2){
  return vssubu_vx_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vssubu(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, uint32_t op3, size_t op4){
  return vssubu_vx_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vssubu(vuint32m8_t op0, uint32_t op1, size_t op2){
  return vssubu_vx_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vssubu(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, uint32_t op3, size_t op4){
  return vssubu_vx_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vssubu(vuint32mf2_t op0, uint32_t op1, size_t op2){
  return vssubu_vx_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vssubu(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, uint32_t op3, size_t op4){
  return vssubu_vx_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vssubu(vuint64m1_t op0, uint64_t op1, size_t op2){
  return vssubu_vx_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vssubu(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, uint64_t op3, size_t op4){
  return vssubu_vx_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vssubu(vuint64m2_t op0, uint64_t op1, size_t op2){
  return vssubu_vx_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vssubu(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, uint64_t op3, size_t op4){
  return vssubu_vx_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vssubu(vuint64m4_t op0, uint64_t op1, size_t op2){
  return vssubu_vx_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vssubu(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, uint64_t op3, size_t op4){
  return vssubu_vx_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vssubu(vuint64m8_t op0, uint64_t op1, size_t op2){
  return vssubu_vx_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vssubu(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, uint64_t op3, size_t op4){
  return vssubu_vx_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vssub(vint8m1_t op0, vint8m1_t op1, size_t op2){
  return vssub_vv_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vssub(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, vint8m1_t op3, size_t op4){
  return vssub_vv_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vssub(vint8m2_t op0, vint8m2_t op1, size_t op2){
  return vssub_vv_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vssub(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, vint8m2_t op3, size_t op4){
  return vssub_vv_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vssub(vint8m4_t op0, vint8m4_t op1, size_t op2){
  return vssub_vv_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vssub(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, vint8m4_t op3, size_t op4){
  return vssub_vv_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vssub(vint8m8_t op0, vint8m8_t op1, size_t op2){
  return vssub_vv_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vssub(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, vint8m8_t op3, size_t op4){
  return vssub_vv_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vssub(vint8mf2_t op0, vint8mf2_t op1, size_t op2){
  return vssub_vv_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vssub(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, vint8mf2_t op3, size_t op4){
  return vssub_vv_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vssub(vint8mf4_t op0, vint8mf4_t op1, size_t op2){
  return vssub_vv_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vssub(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, vint8mf4_t op3, size_t op4){
  return vssub_vv_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vssub(vint8mf8_t op0, vint8mf8_t op1, size_t op2){
  return vssub_vv_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vssub(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, vint8mf8_t op3, size_t op4){
  return vssub_vv_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vssub(vint16m1_t op0, vint16m1_t op1, size_t op2){
  return vssub_vv_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vssub(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, vint16m1_t op3, size_t op4){
  return vssub_vv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vssub(vint16m2_t op0, vint16m2_t op1, size_t op2){
  return vssub_vv_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vssub(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, vint16m2_t op3, size_t op4){
  return vssub_vv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vssub(vint16m4_t op0, vint16m4_t op1, size_t op2){
  return vssub_vv_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vssub(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, vint16m4_t op3, size_t op4){
  return vssub_vv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vssub(vint16m8_t op0, vint16m8_t op1, size_t op2){
  return vssub_vv_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vssub(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, vint16m8_t op3, size_t op4){
  return vssub_vv_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vssub(vint16mf2_t op0, vint16mf2_t op1, size_t op2){
  return vssub_vv_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vssub(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, vint16mf2_t op3, size_t op4){
  return vssub_vv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vssub(vint16mf4_t op0, vint16mf4_t op1, size_t op2){
  return vssub_vv_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vssub(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, vint16mf4_t op3, size_t op4){
  return vssub_vv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vssub(vint32m1_t op0, vint32m1_t op1, size_t op2){
  return vssub_vv_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vssub(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, vint32m1_t op3, size_t op4){
  return vssub_vv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vssub(vint32m2_t op0, vint32m2_t op1, size_t op2){
  return vssub_vv_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vssub(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, vint32m2_t op3, size_t op4){
  return vssub_vv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vssub(vint32m4_t op0, vint32m4_t op1, size_t op2){
  return vssub_vv_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vssub(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, vint32m4_t op3, size_t op4){
  return vssub_vv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vssub(vint32m8_t op0, vint32m8_t op1, size_t op2){
  return vssub_vv_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vssub(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, vint32m8_t op3, size_t op4){
  return vssub_vv_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vssub(vint32mf2_t op0, vint32mf2_t op1, size_t op2){
  return vssub_vv_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vssub(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, vint32mf2_t op3, size_t op4){
  return vssub_vv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vssub(vint64m1_t op0, vint64m1_t op1, size_t op2){
  return vssub_vv_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vssub(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, vint64m1_t op3, size_t op4){
  return vssub_vv_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vssub(vint64m2_t op0, vint64m2_t op1, size_t op2){
  return vssub_vv_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vssub(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, vint64m2_t op3, size_t op4){
  return vssub_vv_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vssub(vint64m4_t op0, vint64m4_t op1, size_t op2){
  return vssub_vv_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vssub(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, vint64m4_t op3, size_t op4){
  return vssub_vv_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vssub(vint64m8_t op0, vint64m8_t op1, size_t op2){
  return vssub_vv_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vssub(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, vint64m8_t op3, size_t op4){
  return vssub_vv_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vssub(vint8m1_t op0, int8_t op1, size_t op2){
  return vssub_vx_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vssub(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, int8_t op3, size_t op4){
  return vssub_vx_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vssub(vint8m2_t op0, int8_t op1, size_t op2){
  return vssub_vx_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vssub(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, int8_t op3, size_t op4){
  return vssub_vx_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vssub(vint8m4_t op0, int8_t op1, size_t op2){
  return vssub_vx_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vssub(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, int8_t op3, size_t op4){
  return vssub_vx_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vssub(vint8m8_t op0, int8_t op1, size_t op2){
  return vssub_vx_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vssub(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, int8_t op3, size_t op4){
  return vssub_vx_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vssub(vint8mf2_t op0, int8_t op1, size_t op2){
  return vssub_vx_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vssub(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, int8_t op3, size_t op4){
  return vssub_vx_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vssub(vint8mf4_t op0, int8_t op1, size_t op2){
  return vssub_vx_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vssub(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, int8_t op3, size_t op4){
  return vssub_vx_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vssub(vint8mf8_t op0, int8_t op1, size_t op2){
  return vssub_vx_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vssub(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, int8_t op3, size_t op4){
  return vssub_vx_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vssub(vint16m1_t op0, int16_t op1, size_t op2){
  return vssub_vx_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vssub(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, int16_t op3, size_t op4){
  return vssub_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vssub(vint16m2_t op0, int16_t op1, size_t op2){
  return vssub_vx_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vssub(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, int16_t op3, size_t op4){
  return vssub_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vssub(vint16m4_t op0, int16_t op1, size_t op2){
  return vssub_vx_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vssub(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, int16_t op3, size_t op4){
  return vssub_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vssub(vint16m8_t op0, int16_t op1, size_t op2){
  return vssub_vx_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vssub(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, int16_t op3, size_t op4){
  return vssub_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vssub(vint16mf2_t op0, int16_t op1, size_t op2){
  return vssub_vx_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vssub(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, int16_t op3, size_t op4){
  return vssub_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vssub(vint16mf4_t op0, int16_t op1, size_t op2){
  return vssub_vx_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vssub(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, int16_t op3, size_t op4){
  return vssub_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vssub(vint32m1_t op0, int32_t op1, size_t op2){
  return vssub_vx_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vssub(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, int32_t op3, size_t op4){
  return vssub_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vssub(vint32m2_t op0, int32_t op1, size_t op2){
  return vssub_vx_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vssub(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, int32_t op3, size_t op4){
  return vssub_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vssub(vint32m4_t op0, int32_t op1, size_t op2){
  return vssub_vx_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vssub(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, int32_t op3, size_t op4){
  return vssub_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vssub(vint32m8_t op0, int32_t op1, size_t op2){
  return vssub_vx_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vssub(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, int32_t op3, size_t op4){
  return vssub_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vssub(vint32mf2_t op0, int32_t op1, size_t op2){
  return vssub_vx_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vssub(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, int32_t op3, size_t op4){
  return vssub_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vssub(vint64m1_t op0, int64_t op1, size_t op2){
  return vssub_vx_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vssub(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, int64_t op3, size_t op4){
  return vssub_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vssub(vint64m2_t op0, int64_t op1, size_t op2){
  return vssub_vx_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vssub(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, int64_t op3, size_t op4){
  return vssub_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vssub(vint64m4_t op0, int64_t op1, size_t op2){
  return vssub_vx_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vssub(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, int64_t op3, size_t op4){
  return vssub_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vssub(vint64m8_t op0, int64_t op1, size_t op2){
  return vssub_vx_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vssub(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, int64_t op3, size_t op4){
  return vssub_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vaaddu(vuint8m1_t op0, vuint8m1_t op1, size_t op2){
  return vaaddu_vv_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vaaddu(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vaaddu_vv_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vaaddu(vuint8m2_t op0, vuint8m2_t op1, size_t op2){
  return vaaddu_vv_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vaaddu(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vaaddu_vv_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vaaddu(vuint8m4_t op0, vuint8m4_t op1, size_t op2){
  return vaaddu_vv_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vaaddu(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vaaddu_vv_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vaaddu(vuint8m8_t op0, vuint8m8_t op1, size_t op2){
  return vaaddu_vv_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vaaddu(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, vuint8m8_t op3, size_t op4){
  return vaaddu_vv_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vaaddu(vuint8mf2_t op0, vuint8mf2_t op1, size_t op2){
  return vaaddu_vv_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vaaddu(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vaaddu_vv_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vaaddu(vuint8mf4_t op0, vuint8mf4_t op1, size_t op2){
  return vaaddu_vv_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vaaddu(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vaaddu_vv_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vaaddu(vuint8mf8_t op0, vuint8mf8_t op1, size_t op2){
  return vaaddu_vv_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vaaddu(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vaaddu_vv_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vaaddu(vuint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vaaddu_vv_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vaaddu(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vaaddu_vv_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vaaddu(vuint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vaaddu_vv_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vaaddu(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vaaddu_vv_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vaaddu(vuint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vaaddu_vv_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vaaddu(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vaaddu_vv_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vaaddu(vuint16m8_t op0, vuint16m8_t op1, size_t op2){
  return vaaddu_vv_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vaaddu(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vaaddu_vv_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vaaddu(vuint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vaaddu_vv_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vaaddu(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vaaddu_vv_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vaaddu(vuint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vaaddu_vv_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vaaddu(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vaaddu_vv_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vaaddu(vuint32m1_t op0, vuint32m1_t op1, size_t op2){
  return vaaddu_vv_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vaaddu(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vaaddu_vv_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vaaddu(vuint32m2_t op0, vuint32m2_t op1, size_t op2){
  return vaaddu_vv_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vaaddu(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vaaddu_vv_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vaaddu(vuint32m4_t op0, vuint32m4_t op1, size_t op2){
  return vaaddu_vv_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vaaddu(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vaaddu_vv_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vaaddu(vuint32m8_t op0, vuint32m8_t op1, size_t op2){
  return vaaddu_vv_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vaaddu(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, vuint32m8_t op3, size_t op4){
  return vaaddu_vv_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vaaddu(vuint32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vaaddu_vv_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vaaddu(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vaaddu_vv_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vaaddu(vuint64m1_t op0, vuint64m1_t op1, size_t op2){
  return vaaddu_vv_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vaaddu(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vaaddu_vv_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vaaddu(vuint64m2_t op0, vuint64m2_t op1, size_t op2){
  return vaaddu_vv_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vaaddu(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, vuint64m2_t op3, size_t op4){
  return vaaddu_vv_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vaaddu(vuint64m4_t op0, vuint64m4_t op1, size_t op2){
  return vaaddu_vv_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vaaddu(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, vuint64m4_t op3, size_t op4){
  return vaaddu_vv_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vaaddu(vuint64m8_t op0, vuint64m8_t op1, size_t op2){
  return vaaddu_vv_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vaaddu(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, vuint64m8_t op3, size_t op4){
  return vaaddu_vv_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vaaddu(vuint8m1_t op0, uint8_t op1, size_t op2){
  return vaaddu_vx_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vaaddu(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, uint8_t op3, size_t op4){
  return vaaddu_vx_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vaaddu(vuint8m2_t op0, uint8_t op1, size_t op2){
  return vaaddu_vx_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vaaddu(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, uint8_t op3, size_t op4){
  return vaaddu_vx_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vaaddu(vuint8m4_t op0, uint8_t op1, size_t op2){
  return vaaddu_vx_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vaaddu(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, uint8_t op3, size_t op4){
  return vaaddu_vx_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vaaddu(vuint8m8_t op0, uint8_t op1, size_t op2){
  return vaaddu_vx_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vaaddu(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, uint8_t op3, size_t op4){
  return vaaddu_vx_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vaaddu(vuint8mf2_t op0, uint8_t op1, size_t op2){
  return vaaddu_vx_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vaaddu(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, uint8_t op3, size_t op4){
  return vaaddu_vx_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vaaddu(vuint8mf4_t op0, uint8_t op1, size_t op2){
  return vaaddu_vx_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vaaddu(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, uint8_t op3, size_t op4){
  return vaaddu_vx_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vaaddu(vuint8mf8_t op0, uint8_t op1, size_t op2){
  return vaaddu_vx_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vaaddu(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, uint8_t op3, size_t op4){
  return vaaddu_vx_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vaaddu(vuint16m1_t op0, uint16_t op1, size_t op2){
  return vaaddu_vx_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vaaddu(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, uint16_t op3, size_t op4){
  return vaaddu_vx_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vaaddu(vuint16m2_t op0, uint16_t op1, size_t op2){
  return vaaddu_vx_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vaaddu(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, uint16_t op3, size_t op4){
  return vaaddu_vx_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vaaddu(vuint16m4_t op0, uint16_t op1, size_t op2){
  return vaaddu_vx_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vaaddu(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, uint16_t op3, size_t op4){
  return vaaddu_vx_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vaaddu(vuint16m8_t op0, uint16_t op1, size_t op2){
  return vaaddu_vx_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vaaddu(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, uint16_t op3, size_t op4){
  return vaaddu_vx_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vaaddu(vuint16mf2_t op0, uint16_t op1, size_t op2){
  return vaaddu_vx_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vaaddu(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, uint16_t op3, size_t op4){
  return vaaddu_vx_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vaaddu(vuint16mf4_t op0, uint16_t op1, size_t op2){
  return vaaddu_vx_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vaaddu(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, uint16_t op3, size_t op4){
  return vaaddu_vx_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vaaddu(vuint32m1_t op0, uint32_t op1, size_t op2){
  return vaaddu_vx_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vaaddu(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, uint32_t op3, size_t op4){
  return vaaddu_vx_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vaaddu(vuint32m2_t op0, uint32_t op1, size_t op2){
  return vaaddu_vx_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vaaddu(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, uint32_t op3, size_t op4){
  return vaaddu_vx_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vaaddu(vuint32m4_t op0, uint32_t op1, size_t op2){
  return vaaddu_vx_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vaaddu(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, uint32_t op3, size_t op4){
  return vaaddu_vx_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vaaddu(vuint32m8_t op0, uint32_t op1, size_t op2){
  return vaaddu_vx_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vaaddu(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, uint32_t op3, size_t op4){
  return vaaddu_vx_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vaaddu(vuint32mf2_t op0, uint32_t op1, size_t op2){
  return vaaddu_vx_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vaaddu(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, uint32_t op3, size_t op4){
  return vaaddu_vx_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vaaddu(vuint64m1_t op0, uint64_t op1, size_t op2){
  return vaaddu_vx_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vaaddu(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, uint64_t op3, size_t op4){
  return vaaddu_vx_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vaaddu(vuint64m2_t op0, uint64_t op1, size_t op2){
  return vaaddu_vx_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vaaddu(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, uint64_t op3, size_t op4){
  return vaaddu_vx_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vaaddu(vuint64m4_t op0, uint64_t op1, size_t op2){
  return vaaddu_vx_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vaaddu(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, uint64_t op3, size_t op4){
  return vaaddu_vx_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vaaddu(vuint64m8_t op0, uint64_t op1, size_t op2){
  return vaaddu_vx_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vaaddu(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, uint64_t op3, size_t op4){
  return vaaddu_vx_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vaadd(vint8m1_t op0, vint8m1_t op1, size_t op2){
  return vaadd_vv_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vaadd(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, vint8m1_t op3, size_t op4){
  return vaadd_vv_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vaadd(vint8m2_t op0, vint8m2_t op1, size_t op2){
  return vaadd_vv_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vaadd(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, vint8m2_t op3, size_t op4){
  return vaadd_vv_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vaadd(vint8m4_t op0, vint8m4_t op1, size_t op2){
  return vaadd_vv_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vaadd(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, vint8m4_t op3, size_t op4){
  return vaadd_vv_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vaadd(vint8m8_t op0, vint8m8_t op1, size_t op2){
  return vaadd_vv_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vaadd(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, vint8m8_t op3, size_t op4){
  return vaadd_vv_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vaadd(vint8mf2_t op0, vint8mf2_t op1, size_t op2){
  return vaadd_vv_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vaadd(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, vint8mf2_t op3, size_t op4){
  return vaadd_vv_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vaadd(vint8mf4_t op0, vint8mf4_t op1, size_t op2){
  return vaadd_vv_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vaadd(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, vint8mf4_t op3, size_t op4){
  return vaadd_vv_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vaadd(vint8mf8_t op0, vint8mf8_t op1, size_t op2){
  return vaadd_vv_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vaadd(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, vint8mf8_t op3, size_t op4){
  return vaadd_vv_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vaadd(vint16m1_t op0, vint16m1_t op1, size_t op2){
  return vaadd_vv_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vaadd(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, vint16m1_t op3, size_t op4){
  return vaadd_vv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vaadd(vint16m2_t op0, vint16m2_t op1, size_t op2){
  return vaadd_vv_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vaadd(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, vint16m2_t op3, size_t op4){
  return vaadd_vv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vaadd(vint16m4_t op0, vint16m4_t op1, size_t op2){
  return vaadd_vv_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vaadd(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, vint16m4_t op3, size_t op4){
  return vaadd_vv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vaadd(vint16m8_t op0, vint16m8_t op1, size_t op2){
  return vaadd_vv_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vaadd(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, vint16m8_t op3, size_t op4){
  return vaadd_vv_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vaadd(vint16mf2_t op0, vint16mf2_t op1, size_t op2){
  return vaadd_vv_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vaadd(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, vint16mf2_t op3, size_t op4){
  return vaadd_vv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vaadd(vint16mf4_t op0, vint16mf4_t op1, size_t op2){
  return vaadd_vv_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vaadd(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, vint16mf4_t op3, size_t op4){
  return vaadd_vv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vaadd(vint32m1_t op0, vint32m1_t op1, size_t op2){
  return vaadd_vv_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vaadd(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, vint32m1_t op3, size_t op4){
  return vaadd_vv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vaadd(vint32m2_t op0, vint32m2_t op1, size_t op2){
  return vaadd_vv_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vaadd(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, vint32m2_t op3, size_t op4){
  return vaadd_vv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vaadd(vint32m4_t op0, vint32m4_t op1, size_t op2){
  return vaadd_vv_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vaadd(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, vint32m4_t op3, size_t op4){
  return vaadd_vv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vaadd(vint32m8_t op0, vint32m8_t op1, size_t op2){
  return vaadd_vv_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vaadd(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, vint32m8_t op3, size_t op4){
  return vaadd_vv_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vaadd(vint32mf2_t op0, vint32mf2_t op1, size_t op2){
  return vaadd_vv_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vaadd(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, vint32mf2_t op3, size_t op4){
  return vaadd_vv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vaadd(vint64m1_t op0, vint64m1_t op1, size_t op2){
  return vaadd_vv_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vaadd(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, vint64m1_t op3, size_t op4){
  return vaadd_vv_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vaadd(vint64m2_t op0, vint64m2_t op1, size_t op2){
  return vaadd_vv_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vaadd(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, vint64m2_t op3, size_t op4){
  return vaadd_vv_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vaadd(vint64m4_t op0, vint64m4_t op1, size_t op2){
  return vaadd_vv_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vaadd(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, vint64m4_t op3, size_t op4){
  return vaadd_vv_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vaadd(vint64m8_t op0, vint64m8_t op1, size_t op2){
  return vaadd_vv_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vaadd(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, vint64m8_t op3, size_t op4){
  return vaadd_vv_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vle32ff(vbool32_t op0, vuint32m1_t op1, const uint32_t * op2, size_t * op3, size_t op4){
  return vle32ff_v_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vle32ff(vbool16_t op0, vuint32m2_t op1, const uint32_t * op2, size_t * op3, size_t op4){
  return vle32ff_v_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vle32ff(vbool8_t op0, vuint32m4_t op1, const uint32_t * op2, size_t * op3, size_t op4){
  return vle32ff_v_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vle32ff(vbool4_t op0, vuint32m8_t op1, const uint32_t * op2, size_t * op3, size_t op4){
  return vle32ff_v_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vle32ff(vbool64_t op0, vuint32mf2_t op1, const uint32_t * op2, size_t * op3, size_t op4){
  return vle32ff_v_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vaadd(vint8m1_t op0, int8_t op1, size_t op2){
  return vaadd_vx_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vaadd(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, int8_t op3, size_t op4){
  return vaadd_vx_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vaadd(vint8m2_t op0, int8_t op1, size_t op2){
  return vaadd_vx_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vaadd(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, int8_t op3, size_t op4){
  return vaadd_vx_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vaadd(vint8m4_t op0, int8_t op1, size_t op2){
  return vaadd_vx_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vaadd(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, int8_t op3, size_t op4){
  return vaadd_vx_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vaadd(vint8m8_t op0, int8_t op1, size_t op2){
  return vaadd_vx_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vaadd(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, int8_t op3, size_t op4){
  return vaadd_vx_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vaadd(vint8mf2_t op0, int8_t op1, size_t op2){
  return vaadd_vx_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vaadd(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, int8_t op3, size_t op4){
  return vaadd_vx_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vaadd(vint8mf4_t op0, int8_t op1, size_t op2){
  return vaadd_vx_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vaadd(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, int8_t op3, size_t op4){
  return vaadd_vx_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vaadd(vint8mf8_t op0, int8_t op1, size_t op2){
  return vaadd_vx_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vaadd(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, int8_t op3, size_t op4){
  return vaadd_vx_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vaadd(vint16m1_t op0, int16_t op1, size_t op2){
  return vaadd_vx_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vaadd(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, int16_t op3, size_t op4){
  return vaadd_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vaadd(vint16m2_t op0, int16_t op1, size_t op2){
  return vaadd_vx_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vaadd(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, int16_t op3, size_t op4){
  return vaadd_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vaadd(vint16m4_t op0, int16_t op1, size_t op2){
  return vaadd_vx_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vaadd(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, int16_t op3, size_t op4){
  return vaadd_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vaadd(vint16m8_t op0, int16_t op1, size_t op2){
  return vaadd_vx_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vaadd(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, int16_t op3, size_t op4){
  return vaadd_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vaadd(vint16mf2_t op0, int16_t op1, size_t op2){
  return vaadd_vx_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vaadd(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, int16_t op3, size_t op4){
  return vaadd_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vaadd(vint16mf4_t op0, int16_t op1, size_t op2){
  return vaadd_vx_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vaadd(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, int16_t op3, size_t op4){
  return vaadd_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vaadd(vint32m1_t op0, int32_t op1, size_t op2){
  return vaadd_vx_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vaadd(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, int32_t op3, size_t op4){
  return vaadd_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vaadd(vint32m2_t op0, int32_t op1, size_t op2){
  return vaadd_vx_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vaadd(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, int32_t op3, size_t op4){
  return vaadd_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vaadd(vint32m4_t op0, int32_t op1, size_t op2){
  return vaadd_vx_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vaadd(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, int32_t op3, size_t op4){
  return vaadd_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vaadd(vint32m8_t op0, int32_t op1, size_t op2){
  return vaadd_vx_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vaadd(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, int32_t op3, size_t op4){
  return vaadd_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vaadd(vint32mf2_t op0, int32_t op1, size_t op2){
  return vaadd_vx_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vaadd(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, int32_t op3, size_t op4){
  return vaadd_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vaadd(vint64m1_t op0, int64_t op1, size_t op2){
  return vaadd_vx_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vaadd(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, int64_t op3, size_t op4){
  return vaadd_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vaadd(vint64m2_t op0, int64_t op1, size_t op2){
  return vaadd_vx_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vaadd(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, int64_t op3, size_t op4){
  return vaadd_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vaadd(vint64m4_t op0, int64_t op1, size_t op2){
  return vaadd_vx_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vaadd(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, int64_t op3, size_t op4){
  return vaadd_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vaadd(vint64m8_t op0, int64_t op1, size_t op2){
  return vaadd_vx_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vaadd(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, int64_t op3, size_t op4){
  return vaadd_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vasubu(vuint8m1_t op0, vuint8m1_t op1, size_t op2){
  return vasubu_vv_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vasubu(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vasubu_vv_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vasubu(vuint8m2_t op0, vuint8m2_t op1, size_t op2){
  return vasubu_vv_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vasubu(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vasubu_vv_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vasubu(vuint8m4_t op0, vuint8m4_t op1, size_t op2){
  return vasubu_vv_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vasubu(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vasubu_vv_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vasubu(vuint8m8_t op0, vuint8m8_t op1, size_t op2){
  return vasubu_vv_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vasubu(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, vuint8m8_t op3, size_t op4){
  return vasubu_vv_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vasubu(vuint8mf2_t op0, vuint8mf2_t op1, size_t op2){
  return vasubu_vv_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vasubu(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vasubu_vv_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vasubu(vuint8mf4_t op0, vuint8mf4_t op1, size_t op2){
  return vasubu_vv_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vasubu(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vasubu_vv_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vasubu(vuint8mf8_t op0, vuint8mf8_t op1, size_t op2){
  return vasubu_vv_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vasubu(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vasubu_vv_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vasubu(vuint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vasubu_vv_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vasubu(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vasubu_vv_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vasubu(vuint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vasubu_vv_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vasubu(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vasubu_vv_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vasubu(vuint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vasubu_vv_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vasubu(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vasubu_vv_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vasubu(vuint16m8_t op0, vuint16m8_t op1, size_t op2){
  return vasubu_vv_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vasubu(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vasubu_vv_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vasubu(vuint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vasubu_vv_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vasubu(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vasubu_vv_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vasubu(vuint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vasubu_vv_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vasubu(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vasubu_vv_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vasubu(vuint32m1_t op0, vuint32m1_t op1, size_t op2){
  return vasubu_vv_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vasubu(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vasubu_vv_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vasubu(vuint32m2_t op0, vuint32m2_t op1, size_t op2){
  return vasubu_vv_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vasubu(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vasubu_vv_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vasubu(vuint32m4_t op0, vuint32m4_t op1, size_t op2){
  return vasubu_vv_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vasubu(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vasubu_vv_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vasubu(vuint32m8_t op0, vuint32m8_t op1, size_t op2){
  return vasubu_vv_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vasubu(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, vuint32m8_t op3, size_t op4){
  return vasubu_vv_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vasubu(vuint32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vasubu_vv_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vasubu(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vasubu_vv_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vasubu(vuint64m1_t op0, vuint64m1_t op1, size_t op2){
  return vasubu_vv_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vasubu(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vasubu_vv_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vasubu(vuint64m2_t op0, vuint64m2_t op1, size_t op2){
  return vasubu_vv_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vasubu(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, vuint64m2_t op3, size_t op4){
  return vasubu_vv_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vasubu(vuint64m4_t op0, vuint64m4_t op1, size_t op2){
  return vasubu_vv_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vasubu(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, vuint64m4_t op3, size_t op4){
  return vasubu_vv_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vasubu(vuint64m8_t op0, vuint64m8_t op1, size_t op2){
  return vasubu_vv_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vasubu(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, vuint64m8_t op3, size_t op4){
  return vasubu_vv_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vasubu(vuint8m1_t op0, uint8_t op1, size_t op2){
  return vasubu_vx_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vasubu(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, uint8_t op3, size_t op4){
  return vasubu_vx_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vasubu(vuint8m2_t op0, uint8_t op1, size_t op2){
  return vasubu_vx_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vasubu(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, uint8_t op3, size_t op4){
  return vasubu_vx_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vasubu(vuint8m4_t op0, uint8_t op1, size_t op2){
  return vasubu_vx_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vasubu(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, uint8_t op3, size_t op4){
  return vasubu_vx_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vasubu(vuint8m8_t op0, uint8_t op1, size_t op2){
  return vasubu_vx_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vasubu(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, uint8_t op3, size_t op4){
  return vasubu_vx_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vasubu(vuint8mf2_t op0, uint8_t op1, size_t op2){
  return vasubu_vx_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vasubu(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, uint8_t op3, size_t op4){
  return vasubu_vx_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vasubu(vuint8mf4_t op0, uint8_t op1, size_t op2){
  return vasubu_vx_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vasubu(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, uint8_t op3, size_t op4){
  return vasubu_vx_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vasubu(vuint8mf8_t op0, uint8_t op1, size_t op2){
  return vasubu_vx_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vasubu(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, uint8_t op3, size_t op4){
  return vasubu_vx_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vasubu(vuint16m1_t op0, uint16_t op1, size_t op2){
  return vasubu_vx_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vasubu(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, uint16_t op3, size_t op4){
  return vasubu_vx_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vasubu(vuint16m2_t op0, uint16_t op1, size_t op2){
  return vasubu_vx_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vasubu(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, uint16_t op3, size_t op4){
  return vasubu_vx_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vasubu(vuint16m4_t op0, uint16_t op1, size_t op2){
  return vasubu_vx_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vasubu(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, uint16_t op3, size_t op4){
  return vasubu_vx_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vasubu(vuint16m8_t op0, uint16_t op1, size_t op2){
  return vasubu_vx_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vasubu(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, uint16_t op3, size_t op4){
  return vasubu_vx_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vasubu(vuint16mf2_t op0, uint16_t op1, size_t op2){
  return vasubu_vx_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vasubu(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, uint16_t op3, size_t op4){
  return vasubu_vx_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vasubu(vuint16mf4_t op0, uint16_t op1, size_t op2){
  return vasubu_vx_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vasubu(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, uint16_t op3, size_t op4){
  return vasubu_vx_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vasubu(vuint32m1_t op0, uint32_t op1, size_t op2){
  return vasubu_vx_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vasubu(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, uint32_t op3, size_t op4){
  return vasubu_vx_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vasubu(vuint32m2_t op0, uint32_t op1, size_t op2){
  return vasubu_vx_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vasubu(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, uint32_t op3, size_t op4){
  return vasubu_vx_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vasubu(vuint32m4_t op0, uint32_t op1, size_t op2){
  return vasubu_vx_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vasubu(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, uint32_t op3, size_t op4){
  return vasubu_vx_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vasubu(vuint32m8_t op0, uint32_t op1, size_t op2){
  return vasubu_vx_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vasubu(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, uint32_t op3, size_t op4){
  return vasubu_vx_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vasubu(vuint32mf2_t op0, uint32_t op1, size_t op2){
  return vasubu_vx_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vasubu(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, uint32_t op3, size_t op4){
  return vasubu_vx_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vasubu(vuint64m1_t op0, uint64_t op1, size_t op2){
  return vasubu_vx_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vasubu(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, uint64_t op3, size_t op4){
  return vasubu_vx_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vasubu(vuint64m2_t op0, uint64_t op1, size_t op2){
  return vasubu_vx_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vasubu(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, uint64_t op3, size_t op4){
  return vasubu_vx_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vasubu(vuint64m4_t op0, uint64_t op1, size_t op2){
  return vasubu_vx_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vasubu(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, uint64_t op3, size_t op4){
  return vasubu_vx_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vasubu(vuint64m8_t op0, uint64_t op1, size_t op2){
  return vasubu_vx_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vasubu(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, uint64_t op3, size_t op4){
  return vasubu_vx_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vasub(vint8m1_t op0, vint8m1_t op1, size_t op2){
  return vasub_vv_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vasub(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, vint8m1_t op3, size_t op4){
  return vasub_vv_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vasub(vint8m2_t op0, vint8m2_t op1, size_t op2){
  return vasub_vv_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vasub(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, vint8m2_t op3, size_t op4){
  return vasub_vv_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vasub(vint8m4_t op0, vint8m4_t op1, size_t op2){
  return vasub_vv_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vasub(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, vint8m4_t op3, size_t op4){
  return vasub_vv_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vasub(vint8m8_t op0, vint8m8_t op1, size_t op2){
  return vasub_vv_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vasub(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, vint8m8_t op3, size_t op4){
  return vasub_vv_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vasub(vint8mf2_t op0, vint8mf2_t op1, size_t op2){
  return vasub_vv_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vasub(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, vint8mf2_t op3, size_t op4){
  return vasub_vv_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vasub(vint8mf4_t op0, vint8mf4_t op1, size_t op2){
  return vasub_vv_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vasub(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, vint8mf4_t op3, size_t op4){
  return vasub_vv_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vasub(vint8mf8_t op0, vint8mf8_t op1, size_t op2){
  return vasub_vv_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vasub(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, vint8mf8_t op3, size_t op4){
  return vasub_vv_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vasub(vint16m1_t op0, vint16m1_t op1, size_t op2){
  return vasub_vv_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vasub(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, vint16m1_t op3, size_t op4){
  return vasub_vv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vasub(vint16m2_t op0, vint16m2_t op1, size_t op2){
  return vasub_vv_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vasub(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, vint16m2_t op3, size_t op4){
  return vasub_vv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vasub(vint16m4_t op0, vint16m4_t op1, size_t op2){
  return vasub_vv_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vasub(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, vint16m4_t op3, size_t op4){
  return vasub_vv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vasub(vint16m8_t op0, vint16m8_t op1, size_t op2){
  return vasub_vv_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vasub(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, vint16m8_t op3, size_t op4){
  return vasub_vv_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vasub(vint16mf2_t op0, vint16mf2_t op1, size_t op2){
  return vasub_vv_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vasub(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, vint16mf2_t op3, size_t op4){
  return vasub_vv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vasub(vint16mf4_t op0, vint16mf4_t op1, size_t op2){
  return vasub_vv_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vasub(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, vint16mf4_t op3, size_t op4){
  return vasub_vv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vasub(vint32m1_t op0, vint32m1_t op1, size_t op2){
  return vasub_vv_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vasub(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, vint32m1_t op3, size_t op4){
  return vasub_vv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vasub(vint32m2_t op0, vint32m2_t op1, size_t op2){
  return vasub_vv_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vasub(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, vint32m2_t op3, size_t op4){
  return vasub_vv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vasub(vint32m4_t op0, vint32m4_t op1, size_t op2){
  return vasub_vv_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vasub(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, vint32m4_t op3, size_t op4){
  return vasub_vv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vasub(vint32m8_t op0, vint32m8_t op1, size_t op2){
  return vasub_vv_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vasub(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, vint32m8_t op3, size_t op4){
  return vasub_vv_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vasub(vint32mf2_t op0, vint32mf2_t op1, size_t op2){
  return vasub_vv_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vasub(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, vint32mf2_t op3, size_t op4){
  return vasub_vv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vasub(vint64m1_t op0, vint64m1_t op1, size_t op2){
  return vasub_vv_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vasub(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, vint64m1_t op3, size_t op4){
  return vasub_vv_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vasub(vint64m2_t op0, vint64m2_t op1, size_t op2){
  return vasub_vv_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vasub(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, vint64m2_t op3, size_t op4){
  return vasub_vv_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vasub(vint64m4_t op0, vint64m4_t op1, size_t op2){
  return vasub_vv_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vasub(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, vint64m4_t op3, size_t op4){
  return vasub_vv_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vasub(vint64m8_t op0, vint64m8_t op1, size_t op2){
  return vasub_vv_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vasub(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, vint64m8_t op3, size_t op4){
  return vasub_vv_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vasub(vint8m1_t op0, int8_t op1, size_t op2){
  return vasub_vx_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vasub(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, int8_t op3, size_t op4){
  return vasub_vx_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vasub(vint8m2_t op0, int8_t op1, size_t op2){
  return vasub_vx_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vasub(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, int8_t op3, size_t op4){
  return vasub_vx_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vasub(vint8m4_t op0, int8_t op1, size_t op2){
  return vasub_vx_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vasub(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, int8_t op3, size_t op4){
  return vasub_vx_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vasub(vint8m8_t op0, int8_t op1, size_t op2){
  return vasub_vx_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vasub(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, int8_t op3, size_t op4){
  return vasub_vx_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vasub(vint8mf2_t op0, int8_t op1, size_t op2){
  return vasub_vx_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vasub(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, int8_t op3, size_t op4){
  return vasub_vx_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vasub(vint8mf4_t op0, int8_t op1, size_t op2){
  return vasub_vx_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vasub(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, int8_t op3, size_t op4){
  return vasub_vx_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vasub(vint8mf8_t op0, int8_t op1, size_t op2){
  return vasub_vx_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vasub(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, int8_t op3, size_t op4){
  return vasub_vx_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vasub(vint16m1_t op0, int16_t op1, size_t op2){
  return vasub_vx_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vasub(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, int16_t op3, size_t op4){
  return vasub_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vasub(vint16m2_t op0, int16_t op1, size_t op2){
  return vasub_vx_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vasub(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, int16_t op3, size_t op4){
  return vasub_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vasub(vint16m4_t op0, int16_t op1, size_t op2){
  return vasub_vx_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vasub(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, int16_t op3, size_t op4){
  return vasub_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vasub(vint16m8_t op0, int16_t op1, size_t op2){
  return vasub_vx_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vasub(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, int16_t op3, size_t op4){
  return vasub_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vasub(vint16mf2_t op0, int16_t op1, size_t op2){
  return vasub_vx_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vasub(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, int16_t op3, size_t op4){
  return vasub_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vasub(vint16mf4_t op0, int16_t op1, size_t op2){
  return vasub_vx_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vasub(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, int16_t op3, size_t op4){
  return vasub_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vasub(vint32m1_t op0, int32_t op1, size_t op2){
  return vasub_vx_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vasub(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, int32_t op3, size_t op4){
  return vasub_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vasub(vint32m2_t op0, int32_t op1, size_t op2){
  return vasub_vx_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vasub(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, int32_t op3, size_t op4){
  return vasub_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vasub(vint32m4_t op0, int32_t op1, size_t op2){
  return vasub_vx_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vasub(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, int32_t op3, size_t op4){
  return vasub_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vasub(vint32m8_t op0, int32_t op1, size_t op2){
  return vasub_vx_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vasub(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, int32_t op3, size_t op4){
  return vasub_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vasub(vint32mf2_t op0, int32_t op1, size_t op2){
  return vasub_vx_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vasub(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, int32_t op3, size_t op4){
  return vasub_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vasub(vint64m1_t op0, int64_t op1, size_t op2){
  return vasub_vx_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vasub(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, int64_t op3, size_t op4){
  return vasub_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vasub(vint64m2_t op0, int64_t op1, size_t op2){
  return vasub_vx_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vasub(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, int64_t op3, size_t op4){
  return vasub_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vasub(vint64m4_t op0, int64_t op1, size_t op2){
  return vasub_vx_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vasub(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, int64_t op3, size_t op4){
  return vasub_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vasub(vint64m8_t op0, int64_t op1, size_t op2){
  return vasub_vx_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vasub(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, int64_t op3, size_t op4){
  return vasub_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vsmul(vint8m1_t op0, vint8m1_t op1, size_t op2){
  return vsmul_vv_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vsmul(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, vint8m1_t op3, size_t op4){
  return vsmul_vv_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vsmul(vint8m2_t op0, vint8m2_t op1, size_t op2){
  return vsmul_vv_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vsmul(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, vint8m2_t op3, size_t op4){
  return vsmul_vv_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vsmul(vint8m4_t op0, vint8m4_t op1, size_t op2){
  return vsmul_vv_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vsmul(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, vint8m4_t op3, size_t op4){
  return vsmul_vv_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vsmul(vint8m8_t op0, vint8m8_t op1, size_t op2){
  return vsmul_vv_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vsmul(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, vint8m8_t op3, size_t op4){
  return vsmul_vv_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vsmul(vint8mf2_t op0, vint8mf2_t op1, size_t op2){
  return vsmul_vv_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vsmul(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, vint8mf2_t op3, size_t op4){
  return vsmul_vv_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vsmul(vint8mf4_t op0, vint8mf4_t op1, size_t op2){
  return vsmul_vv_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vsmul(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, vint8mf4_t op3, size_t op4){
  return vsmul_vv_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vsmul(vint8mf8_t op0, vint8mf8_t op1, size_t op2){
  return vsmul_vv_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vsmul(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, vint8mf8_t op3, size_t op4){
  return vsmul_vv_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vsmul(vint16m1_t op0, vint16m1_t op1, size_t op2){
  return vsmul_vv_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vsmul(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, vint16m1_t op3, size_t op4){
  return vsmul_vv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vsmul(vint16m2_t op0, vint16m2_t op1, size_t op2){
  return vsmul_vv_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vsmul(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, vint16m2_t op3, size_t op4){
  return vsmul_vv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vsmul(vint16m4_t op0, vint16m4_t op1, size_t op2){
  return vsmul_vv_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vsmul(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, vint16m4_t op3, size_t op4){
  return vsmul_vv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vsmul(vint16m8_t op0, vint16m8_t op1, size_t op2){
  return vsmul_vv_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vsmul(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, vint16m8_t op3, size_t op4){
  return vsmul_vv_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vsmul(vint16mf2_t op0, vint16mf2_t op1, size_t op2){
  return vsmul_vv_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vsmul(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, vint16mf2_t op3, size_t op4){
  return vsmul_vv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vsmul(vint16mf4_t op0, vint16mf4_t op1, size_t op2){
  return vsmul_vv_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vsmul(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, vint16mf4_t op3, size_t op4){
  return vsmul_vv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vsmul(vint32m1_t op0, vint32m1_t op1, size_t op2){
  return vsmul_vv_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vsmul(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, vint32m1_t op3, size_t op4){
  return vsmul_vv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vsmul(vint32m2_t op0, vint32m2_t op1, size_t op2){
  return vsmul_vv_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vsmul(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, vint32m2_t op3, size_t op4){
  return vsmul_vv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vsmul(vint32m4_t op0, vint32m4_t op1, size_t op2){
  return vsmul_vv_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vsmul(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, vint32m4_t op3, size_t op4){
  return vsmul_vv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vsmul(vint32m8_t op0, vint32m8_t op1, size_t op2){
  return vsmul_vv_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vsmul(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, vint32m8_t op3, size_t op4){
  return vsmul_vv_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vsmul(vint32mf2_t op0, vint32mf2_t op1, size_t op2){
  return vsmul_vv_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vsmul(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, vint32mf2_t op3, size_t op4){
  return vsmul_vv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vsmul(vint64m1_t op0, vint64m1_t op1, size_t op2){
  return vsmul_vv_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vsmul(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, vint64m1_t op3, size_t op4){
  return vsmul_vv_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vsmul(vint64m2_t op0, vint64m2_t op1, size_t op2){
  return vsmul_vv_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vsmul(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, vint64m2_t op3, size_t op4){
  return vsmul_vv_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vsmul(vint64m4_t op0, vint64m4_t op1, size_t op2){
  return vsmul_vv_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vsmul(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, vint64m4_t op3, size_t op4){
  return vsmul_vv_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vsmul(vint64m8_t op0, vint64m8_t op1, size_t op2){
  return vsmul_vv_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vsmul(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, vint64m8_t op3, size_t op4){
  return vsmul_vv_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vsmul(vint8m1_t op0, int8_t op1, size_t op2){
  return vsmul_vx_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vsmul(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, int8_t op3, size_t op4){
  return vsmul_vx_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vsmul(vint8m2_t op0, int8_t op1, size_t op2){
  return vsmul_vx_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vsmul(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, int8_t op3, size_t op4){
  return vsmul_vx_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vsmul(vint8m4_t op0, int8_t op1, size_t op2){
  return vsmul_vx_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vsmul(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, int8_t op3, size_t op4){
  return vsmul_vx_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vsmul(vint8m8_t op0, int8_t op1, size_t op2){
  return vsmul_vx_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vsmul(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, int8_t op3, size_t op4){
  return vsmul_vx_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vsmul(vint8mf2_t op0, int8_t op1, size_t op2){
  return vsmul_vx_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vsmul(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, int8_t op3, size_t op4){
  return vsmul_vx_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vsmul(vint8mf4_t op0, int8_t op1, size_t op2){
  return vsmul_vx_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vsmul(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, int8_t op3, size_t op4){
  return vsmul_vx_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vsmul(vint8mf8_t op0, int8_t op1, size_t op2){
  return vsmul_vx_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vsmul(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, int8_t op3, size_t op4){
  return vsmul_vx_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vsmul(vint16m1_t op0, int16_t op1, size_t op2){
  return vsmul_vx_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vsmul(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, int16_t op3, size_t op4){
  return vsmul_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vsmul(vint16m2_t op0, int16_t op1, size_t op2){
  return vsmul_vx_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vsmul(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, int16_t op3, size_t op4){
  return vsmul_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vsmul(vint16m4_t op0, int16_t op1, size_t op2){
  return vsmul_vx_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vsmul(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, int16_t op3, size_t op4){
  return vsmul_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vsmul(vint16m8_t op0, int16_t op1, size_t op2){
  return vsmul_vx_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vsmul(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, int16_t op3, size_t op4){
  return vsmul_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vsmul(vint16mf2_t op0, int16_t op1, size_t op2){
  return vsmul_vx_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vsmul(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, int16_t op3, size_t op4){
  return vsmul_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vsmul(vint16mf4_t op0, int16_t op1, size_t op2){
  return vsmul_vx_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vsmul(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, int16_t op3, size_t op4){
  return vsmul_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vsmul(vint32m1_t op0, int32_t op1, size_t op2){
  return vsmul_vx_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vsmul(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, int32_t op3, size_t op4){
  return vsmul_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vsmul(vint32m2_t op0, int32_t op1, size_t op2){
  return vsmul_vx_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vsmul(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, int32_t op3, size_t op4){
  return vsmul_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vsmul(vint32m4_t op0, int32_t op1, size_t op2){
  return vsmul_vx_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vsmul(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, int32_t op3, size_t op4){
  return vsmul_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vsmul(vint32m8_t op0, int32_t op1, size_t op2){
  return vsmul_vx_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vsmul(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, int32_t op3, size_t op4){
  return vsmul_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vsmul(vint32mf2_t op0, int32_t op1, size_t op2){
  return vsmul_vx_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vsmul(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, int32_t op3, size_t op4){
  return vsmul_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vsmul(vint64m1_t op0, int64_t op1, size_t op2){
  return vsmul_vx_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vsmul(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, int64_t op3, size_t op4){
  return vsmul_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vsmul(vint64m2_t op0, int64_t op1, size_t op2){
  return vsmul_vx_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vsmul(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, int64_t op3, size_t op4){
  return vsmul_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vsmul(vint64m4_t op0, int64_t op1, size_t op2){
  return vsmul_vx_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vsmul(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, int64_t op3, size_t op4){
  return vsmul_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vsmul(vint64m8_t op0, int64_t op1, size_t op2){
  return vsmul_vx_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vsmul(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, int64_t op3, size_t op4){
  return vsmul_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vssrl(vuint8m1_t op0, vuint8m1_t op1, size_t op2){
  return vssrl_vv_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vssrl(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vssrl_vv_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vssrl(vuint8m2_t op0, vuint8m2_t op1, size_t op2){
  return vssrl_vv_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vssrl(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vssrl_vv_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vssrl(vuint8m4_t op0, vuint8m4_t op1, size_t op2){
  return vssrl_vv_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vssrl(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vssrl_vv_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vssrl(vuint8m8_t op0, vuint8m8_t op1, size_t op2){
  return vssrl_vv_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vssrl(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, vuint8m8_t op3, size_t op4){
  return vssrl_vv_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vssrl(vuint8mf2_t op0, vuint8mf2_t op1, size_t op2){
  return vssrl_vv_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vssrl(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vssrl_vv_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vssrl(vuint8mf4_t op0, vuint8mf4_t op1, size_t op2){
  return vssrl_vv_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vssrl(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vssrl_vv_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vssrl(vuint8mf8_t op0, vuint8mf8_t op1, size_t op2){
  return vssrl_vv_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vssrl(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vssrl_vv_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vssrl(vuint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vssrl_vv_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vssrl(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vssrl_vv_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vssrl(vuint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vssrl_vv_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vssrl(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vssrl_vv_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vssrl(vuint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vssrl_vv_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vssrl(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vssrl_vv_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vssrl(vuint16m8_t op0, vuint16m8_t op1, size_t op2){
  return vssrl_vv_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vssrl(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vssrl_vv_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vssrl(vuint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vssrl_vv_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vssrl(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vssrl_vv_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vssrl(vuint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vssrl_vv_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vssrl(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vssrl_vv_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vssrl(vuint32m1_t op0, vuint32m1_t op1, size_t op2){
  return vssrl_vv_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vssrl(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vssrl_vv_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vssrl(vuint32m2_t op0, vuint32m2_t op1, size_t op2){
  return vssrl_vv_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vssrl(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vssrl_vv_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vssrl(vuint32m4_t op0, vuint32m4_t op1, size_t op2){
  return vssrl_vv_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vssrl(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vssrl_vv_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vssrl(vuint32m8_t op0, vuint32m8_t op1, size_t op2){
  return vssrl_vv_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vssrl(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, vuint32m8_t op3, size_t op4){
  return vssrl_vv_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vssrl(vuint32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vssrl_vv_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vssrl(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vssrl_vv_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vssrl(vuint64m1_t op0, vuint64m1_t op1, size_t op2){
  return vssrl_vv_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vssrl(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vssrl_vv_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vssrl(vuint64m2_t op0, vuint64m2_t op1, size_t op2){
  return vssrl_vv_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vssrl(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, vuint64m2_t op3, size_t op4){
  return vssrl_vv_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vssrl(vuint64m4_t op0, vuint64m4_t op1, size_t op2){
  return vssrl_vv_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vssrl(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, vuint64m4_t op3, size_t op4){
  return vssrl_vv_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vssrl(vuint64m8_t op0, vuint64m8_t op1, size_t op2){
  return vssrl_vv_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vssrl(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, vuint64m8_t op3, size_t op4){
  return vssrl_vv_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vssrl(vuint8m1_t op0, size_t op1, size_t op2){
  return vssrl_vx_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vssrl(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, size_t op3, size_t op4){
  return vssrl_vx_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vssrl(vuint8m2_t op0, size_t op1, size_t op2){
  return vssrl_vx_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vssrl(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, size_t op3, size_t op4){
  return vssrl_vx_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vssrl(vuint8m4_t op0, size_t op1, size_t op2){
  return vssrl_vx_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vssrl(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, size_t op3, size_t op4){
  return vssrl_vx_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vssrl(vuint8m8_t op0, size_t op1, size_t op2){
  return vssrl_vx_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vssrl(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, size_t op3, size_t op4){
  return vssrl_vx_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vssrl(vuint8mf2_t op0, size_t op1, size_t op2){
  return vssrl_vx_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vssrl(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, size_t op3, size_t op4){
  return vssrl_vx_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vssrl(vuint8mf4_t op0, size_t op1, size_t op2){
  return vssrl_vx_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vssrl(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, size_t op3, size_t op4){
  return vssrl_vx_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vssrl(vuint8mf8_t op0, size_t op1, size_t op2){
  return vssrl_vx_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vssrl(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, size_t op3, size_t op4){
  return vssrl_vx_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vssrl(vuint16m1_t op0, size_t op1, size_t op2){
  return vssrl_vx_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vssrl(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, size_t op3, size_t op4){
  return vssrl_vx_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vssrl(vuint16m2_t op0, size_t op1, size_t op2){
  return vssrl_vx_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vssrl(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, size_t op3, size_t op4){
  return vssrl_vx_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vssrl(vuint16m4_t op0, size_t op1, size_t op2){
  return vssrl_vx_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vssrl(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, size_t op3, size_t op4){
  return vssrl_vx_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vssrl(vuint16m8_t op0, size_t op1, size_t op2){
  return vssrl_vx_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vssrl(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, size_t op3, size_t op4){
  return vssrl_vx_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vssrl(vuint16mf2_t op0, size_t op1, size_t op2){
  return vssrl_vx_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vssrl(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, size_t op3, size_t op4){
  return vssrl_vx_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vssrl(vuint16mf4_t op0, size_t op1, size_t op2){
  return vssrl_vx_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vssrl(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, size_t op3, size_t op4){
  return vssrl_vx_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vssrl(vuint32m1_t op0, size_t op1, size_t op2){
  return vssrl_vx_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vssrl(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, size_t op3, size_t op4){
  return vssrl_vx_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vssrl(vuint32m2_t op0, size_t op1, size_t op2){
  return vssrl_vx_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vssrl(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, size_t op3, size_t op4){
  return vssrl_vx_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vssrl(vuint32m4_t op0, size_t op1, size_t op2){
  return vssrl_vx_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vssrl(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, size_t op3, size_t op4){
  return vssrl_vx_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vssrl(vuint32m8_t op0, size_t op1, size_t op2){
  return vssrl_vx_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vssrl(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, size_t op3, size_t op4){
  return vssrl_vx_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vssrl(vuint32mf2_t op0, size_t op1, size_t op2){
  return vssrl_vx_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vssrl(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, size_t op3, size_t op4){
  return vssrl_vx_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vssrl(vuint64m1_t op0, size_t op1, size_t op2){
  return vssrl_vx_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vssrl(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, size_t op3, size_t op4){
  return vssrl_vx_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vssrl(vuint64m2_t op0, size_t op1, size_t op2){
  return vssrl_vx_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vssrl(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, size_t op3, size_t op4){
  return vssrl_vx_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vssrl(vuint64m4_t op0, size_t op1, size_t op2){
  return vssrl_vx_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vssrl(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, size_t op3, size_t op4){
  return vssrl_vx_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vssrl(vuint64m8_t op0, size_t op1, size_t op2){
  return vssrl_vx_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vssrl(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, size_t op3, size_t op4){
  return vssrl_vx_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vssra(vint8m1_t op0, vuint8m1_t op1, size_t op2){
  return vssra_vv_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vssra(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vssra_vv_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vssra(vint8m2_t op0, vuint8m2_t op1, size_t op2){
  return vssra_vv_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vssra(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vssra_vv_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vssra(vint8m4_t op0, vuint8m4_t op1, size_t op2){
  return vssra_vv_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vssra(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vssra_vv_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vssra(vint8m8_t op0, vuint8m8_t op1, size_t op2){
  return vssra_vv_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vssra(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, vuint8m8_t op3, size_t op4){
  return vssra_vv_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vssra(vint8mf2_t op0, vuint8mf2_t op1, size_t op2){
  return vssra_vv_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vssra(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vssra_vv_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vssra(vint8mf4_t op0, vuint8mf4_t op1, size_t op2){
  return vssra_vv_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vssra(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vssra_vv_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vssra(vint8mf8_t op0, vuint8mf8_t op1, size_t op2){
  return vssra_vv_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vssra(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vssra_vv_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vssra(vint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vssra_vv_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vssra(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vssra_vv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vssra(vint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vssra_vv_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vssra(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vssra_vv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vssra(vint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vssra_vv_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vssra(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vssra_vv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vssra(vint16m8_t op0, vuint16m8_t op1, size_t op2){
  return vssra_vv_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vssra(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vssra_vv_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vssra(vint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vssra_vv_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vssra(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vssra_vv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vssra(vint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vssra_vv_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vssra(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vssra_vv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vssra(vint32m1_t op0, vuint32m1_t op1, size_t op2){
  return vssra_vv_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vssra(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vssra_vv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vssra(vint32m2_t op0, vuint32m2_t op1, size_t op2){
  return vssra_vv_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vssra(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vssra_vv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vssra(vint32m4_t op0, vuint32m4_t op1, size_t op2){
  return vssra_vv_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vssra(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vssra_vv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vssra(vint32m8_t op0, vuint32m8_t op1, size_t op2){
  return vssra_vv_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vssra(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, vuint32m8_t op3, size_t op4){
  return vssra_vv_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vssra(vint32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vssra_vv_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vssra(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vssra_vv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vssra(vint64m1_t op0, vuint64m1_t op1, size_t op2){
  return vssra_vv_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vssra(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vssra_vv_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vssra(vint64m2_t op0, vuint64m2_t op1, size_t op2){
  return vssra_vv_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vssra(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, vuint64m2_t op3, size_t op4){
  return vssra_vv_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vssra(vint64m4_t op0, vuint64m4_t op1, size_t op2){
  return vssra_vv_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vssra(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, vuint64m4_t op3, size_t op4){
  return vssra_vv_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vssra(vint64m8_t op0, vuint64m8_t op1, size_t op2){
  return vssra_vv_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vssra(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, vuint64m8_t op3, size_t op4){
  return vssra_vv_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vssra(vint8m1_t op0, size_t op1, size_t op2){
  return vssra_vx_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vssra(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, size_t op3, size_t op4){
  return vssra_vx_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vssra(vint8m2_t op0, size_t op1, size_t op2){
  return vssra_vx_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vssra(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, size_t op3, size_t op4){
  return vssra_vx_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vssra(vint8m4_t op0, size_t op1, size_t op2){
  return vssra_vx_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vssra(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, size_t op3, size_t op4){
  return vssra_vx_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vssra(vint8m8_t op0, size_t op1, size_t op2){
  return vssra_vx_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vssra(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, size_t op3, size_t op4){
  return vssra_vx_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vssra(vint8mf2_t op0, size_t op1, size_t op2){
  return vssra_vx_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vssra(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, size_t op3, size_t op4){
  return vssra_vx_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vssra(vint8mf4_t op0, size_t op1, size_t op2){
  return vssra_vx_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vssra(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, size_t op3, size_t op4){
  return vssra_vx_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vssra(vint8mf8_t op0, size_t op1, size_t op2){
  return vssra_vx_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vssra(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, size_t op3, size_t op4){
  return vssra_vx_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vssra(vint16m1_t op0, size_t op1, size_t op2){
  return vssra_vx_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vssra(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, size_t op3, size_t op4){
  return vssra_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vssra(vint16m2_t op0, size_t op1, size_t op2){
  return vssra_vx_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vssra(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, size_t op3, size_t op4){
  return vssra_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vssra(vint16m4_t op0, size_t op1, size_t op2){
  return vssra_vx_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vssra(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, size_t op3, size_t op4){
  return vssra_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vssra(vint16m8_t op0, size_t op1, size_t op2){
  return vssra_vx_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vssra(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, size_t op3, size_t op4){
  return vssra_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vssra(vint16mf2_t op0, size_t op1, size_t op2){
  return vssra_vx_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vssra(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, size_t op3, size_t op4){
  return vssra_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vssra(vint16mf4_t op0, size_t op1, size_t op2){
  return vssra_vx_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vssra(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, size_t op3, size_t op4){
  return vssra_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vssra(vint32m1_t op0, size_t op1, size_t op2){
  return vssra_vx_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vssra(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, size_t op3, size_t op4){
  return vssra_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vssra(vint32m2_t op0, size_t op1, size_t op2){
  return vssra_vx_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vssra(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, size_t op3, size_t op4){
  return vssra_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vssra(vint32m4_t op0, size_t op1, size_t op2){
  return vssra_vx_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vssra(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, size_t op3, size_t op4){
  return vssra_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vssra(vint32m8_t op0, size_t op1, size_t op2){
  return vssra_vx_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vssra(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, size_t op3, size_t op4){
  return vssra_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vssra(vint32mf2_t op0, size_t op1, size_t op2){
  return vssra_vx_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vssra(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, size_t op3, size_t op4){
  return vssra_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vssra(vint64m1_t op0, size_t op1, size_t op2){
  return vssra_vx_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vssra(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, size_t op3, size_t op4){
  return vssra_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vssra(vint64m2_t op0, size_t op1, size_t op2){
  return vssra_vx_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vssra(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, size_t op3, size_t op4){
  return vssra_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vssra(vint64m4_t op0, size_t op1, size_t op2){
  return vssra_vx_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vssra(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, size_t op3, size_t op4){
  return vssra_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vssra(vint64m8_t op0, size_t op1, size_t op2){
  return vssra_vx_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vssra(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, size_t op3, size_t op4){
  return vssra_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vnclipu(vuint16m2_t op0, vuint8m1_t op1, size_t op2){
  return vnclipu_wv_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vnclipu(vbool8_t op0, vuint8m1_t op1, vuint16m2_t op2, vuint8m1_t op3, size_t op4){
  return vnclipu_wv_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vnclipu(vuint16m4_t op0, vuint8m2_t op1, size_t op2){
  return vnclipu_wv_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vnclipu(vbool4_t op0, vuint8m2_t op1, vuint16m4_t op2, vuint8m2_t op3, size_t op4){
  return vnclipu_wv_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vnclipu(vuint16m8_t op0, vuint8m4_t op1, size_t op2){
  return vnclipu_wv_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vnclipu(vbool2_t op0, vuint8m4_t op1, vuint16m8_t op2, vuint8m4_t op3, size_t op4){
  return vnclipu_wv_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vnclipu(vuint16m1_t op0, vuint8mf2_t op1, size_t op2){
  return vnclipu_wv_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vnclipu(vbool16_t op0, vuint8mf2_t op1, vuint16m1_t op2, vuint8mf2_t op3, size_t op4){
  return vnclipu_wv_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vnclipu(vuint16mf2_t op0, vuint8mf4_t op1, size_t op2){
  return vnclipu_wv_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vnclipu(vbool32_t op0, vuint8mf4_t op1, vuint16mf2_t op2, vuint8mf4_t op3, size_t op4){
  return vnclipu_wv_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vnclipu(vuint16mf4_t op0, vuint8mf8_t op1, size_t op2){
  return vnclipu_wv_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vnclipu(vbool64_t op0, vuint8mf8_t op1, vuint16mf4_t op2, vuint8mf8_t op3, size_t op4){
  return vnclipu_wv_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vnclipu(vuint32m2_t op0, vuint16m1_t op1, size_t op2){
  return vnclipu_wv_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vnclipu(vbool16_t op0, vuint16m1_t op1, vuint32m2_t op2, vuint16m1_t op3, size_t op4){
  return vnclipu_wv_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vnclipu(vuint32m4_t op0, vuint16m2_t op1, size_t op2){
  return vnclipu_wv_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vnclipu(vbool8_t op0, vuint16m2_t op1, vuint32m4_t op2, vuint16m2_t op3, size_t op4){
  return vnclipu_wv_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vnclipu(vuint32m8_t op0, vuint16m4_t op1, size_t op2){
  return vnclipu_wv_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vnclipu(vbool4_t op0, vuint16m4_t op1, vuint32m8_t op2, vuint16m4_t op3, size_t op4){
  return vnclipu_wv_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vnclipu(vuint32m1_t op0, vuint16mf2_t op1, size_t op2){
  return vnclipu_wv_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vnclipu(vbool32_t op0, vuint16mf2_t op1, vuint32m1_t op2, vuint16mf2_t op3, size_t op4){
  return vnclipu_wv_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vnclipu(vuint32mf2_t op0, vuint16mf4_t op1, size_t op2){
  return vnclipu_wv_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vnclipu(vbool64_t op0, vuint16mf4_t op1, vuint32mf2_t op2, vuint16mf4_t op3, size_t op4){
  return vnclipu_wv_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vnclipu(vuint64m2_t op0, vuint32m1_t op1, size_t op2){
  return vnclipu_wv_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vnclipu(vbool32_t op0, vuint32m1_t op1, vuint64m2_t op2, vuint32m1_t op3, size_t op4){
  return vnclipu_wv_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vnclipu(vuint64m4_t op0, vuint32m2_t op1, size_t op2){
  return vnclipu_wv_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vnclipu(vbool16_t op0, vuint32m2_t op1, vuint64m4_t op2, vuint32m2_t op3, size_t op4){
  return vnclipu_wv_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vnclipu(vuint64m8_t op0, vuint32m4_t op1, size_t op2){
  return vnclipu_wv_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vnclipu(vbool8_t op0, vuint32m4_t op1, vuint64m8_t op2, vuint32m4_t op3, size_t op4){
  return vnclipu_wv_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vnclipu(vuint64m1_t op0, vuint32mf2_t op1, size_t op2){
  return vnclipu_wv_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vnclipu(vbool64_t op0, vuint32mf2_t op1, vuint64m1_t op2, vuint32mf2_t op3, size_t op4){
  return vnclipu_wv_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vnclipu(vuint16m2_t op0, size_t op1, size_t op2){
  return vnclipu_wx_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vnclipu(vbool8_t op0, vuint8m1_t op1, vuint16m2_t op2, size_t op3, size_t op4){
  return vnclipu_wx_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vnclipu(vuint16m4_t op0, size_t op1, size_t op2){
  return vnclipu_wx_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vnclipu(vbool4_t op0, vuint8m2_t op1, vuint16m4_t op2, size_t op3, size_t op4){
  return vnclipu_wx_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vnclipu(vuint16m8_t op0, size_t op1, size_t op2){
  return vnclipu_wx_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vnclipu(vbool2_t op0, vuint8m4_t op1, vuint16m8_t op2, size_t op3, size_t op4){
  return vnclipu_wx_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vnclipu(vuint16m1_t op0, size_t op1, size_t op2){
  return vnclipu_wx_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vnclipu(vbool16_t op0, vuint8mf2_t op1, vuint16m1_t op2, size_t op3, size_t op4){
  return vnclipu_wx_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vnclipu(vuint16mf2_t op0, size_t op1, size_t op2){
  return vnclipu_wx_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vnclipu(vbool32_t op0, vuint8mf4_t op1, vuint16mf2_t op2, size_t op3, size_t op4){
  return vnclipu_wx_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vnclipu(vuint16mf4_t op0, size_t op1, size_t op2){
  return vnclipu_wx_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vnclipu(vbool64_t op0, vuint8mf8_t op1, vuint16mf4_t op2, size_t op3, size_t op4){
  return vnclipu_wx_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vnclipu(vuint32m2_t op0, size_t op1, size_t op2){
  return vnclipu_wx_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vnclipu(vbool16_t op0, vuint16m1_t op1, vuint32m2_t op2, size_t op3, size_t op4){
  return vnclipu_wx_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vnclipu(vuint32m4_t op0, size_t op1, size_t op2){
  return vnclipu_wx_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vnclipu(vbool8_t op0, vuint16m2_t op1, vuint32m4_t op2, size_t op3, size_t op4){
  return vnclipu_wx_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vnclipu(vuint32m8_t op0, size_t op1, size_t op2){
  return vnclipu_wx_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vnclipu(vbool4_t op0, vuint16m4_t op1, vuint32m8_t op2, size_t op3, size_t op4){
  return vnclipu_wx_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vnclipu(vuint32m1_t op0, size_t op1, size_t op2){
  return vnclipu_wx_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vnclipu(vbool32_t op0, vuint16mf2_t op1, vuint32m1_t op2, size_t op3, size_t op4){
  return vnclipu_wx_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vnclipu(vuint32mf2_t op0, size_t op1, size_t op2){
  return vnclipu_wx_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vnclipu(vbool64_t op0, vuint16mf4_t op1, vuint32mf2_t op2, size_t op3, size_t op4){
  return vnclipu_wx_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vnclipu(vuint64m2_t op0, size_t op1, size_t op2){
  return vnclipu_wx_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vnclipu(vbool32_t op0, vuint32m1_t op1, vuint64m2_t op2, size_t op3, size_t op4){
  return vnclipu_wx_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vnclipu(vuint64m4_t op0, size_t op1, size_t op2){
  return vnclipu_wx_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vnclipu(vbool16_t op0, vuint32m2_t op1, vuint64m4_t op2, size_t op3, size_t op4){
  return vnclipu_wx_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vnclipu(vuint64m8_t op0, size_t op1, size_t op2){
  return vnclipu_wx_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vnclipu(vbool8_t op0, vuint32m4_t op1, vuint64m8_t op2, size_t op3, size_t op4){
  return vnclipu_wx_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vnclipu(vuint64m1_t op0, size_t op1, size_t op2){
  return vnclipu_wx_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vnclipu(vbool64_t op0, vuint32mf2_t op1, vuint64m1_t op2, size_t op3, size_t op4){
  return vnclipu_wx_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vnclip(vint16m2_t op0, vuint8m1_t op1, size_t op2){
  return vnclip_wv_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vnclip(vbool8_t op0, vint8m1_t op1, vint16m2_t op2, vuint8m1_t op3, size_t op4){
  return vnclip_wv_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vnclip(vint16m4_t op0, vuint8m2_t op1, size_t op2){
  return vnclip_wv_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vnclip(vbool4_t op0, vint8m2_t op1, vint16m4_t op2, vuint8m2_t op3, size_t op4){
  return vnclip_wv_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vnclip(vint16m8_t op0, vuint8m4_t op1, size_t op2){
  return vnclip_wv_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vnclip(vbool2_t op0, vint8m4_t op1, vint16m8_t op2, vuint8m4_t op3, size_t op4){
  return vnclip_wv_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vnclip(vint16m1_t op0, vuint8mf2_t op1, size_t op2){
  return vnclip_wv_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vnclip(vbool16_t op0, vint8mf2_t op1, vint16m1_t op2, vuint8mf2_t op3, size_t op4){
  return vnclip_wv_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vnclip(vint16mf2_t op0, vuint8mf4_t op1, size_t op2){
  return vnclip_wv_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vnclip(vbool32_t op0, vint8mf4_t op1, vint16mf2_t op2, vuint8mf4_t op3, size_t op4){
  return vnclip_wv_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vnclip(vint16mf4_t op0, vuint8mf8_t op1, size_t op2){
  return vnclip_wv_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vnclip(vbool64_t op0, vint8mf8_t op1, vint16mf4_t op2, vuint8mf8_t op3, size_t op4){
  return vnclip_wv_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vnclip(vint32m2_t op0, vuint16m1_t op1, size_t op2){
  return vnclip_wv_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vnclip(vbool16_t op0, vint16m1_t op1, vint32m2_t op2, vuint16m1_t op3, size_t op4){
  return vnclip_wv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vnclip(vint32m4_t op0, vuint16m2_t op1, size_t op2){
  return vnclip_wv_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vnclip(vbool8_t op0, vint16m2_t op1, vint32m4_t op2, vuint16m2_t op3, size_t op4){
  return vnclip_wv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vnclip(vint32m8_t op0, vuint16m4_t op1, size_t op2){
  return vnclip_wv_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vnclip(vbool4_t op0, vint16m4_t op1, vint32m8_t op2, vuint16m4_t op3, size_t op4){
  return vnclip_wv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vnclip(vint32m1_t op0, vuint16mf2_t op1, size_t op2){
  return vnclip_wv_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vnclip(vbool32_t op0, vint16mf2_t op1, vint32m1_t op2, vuint16mf2_t op3, size_t op4){
  return vnclip_wv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vnclip(vint32mf2_t op0, vuint16mf4_t op1, size_t op2){
  return vnclip_wv_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vnclip(vbool64_t op0, vint16mf4_t op1, vint32mf2_t op2, vuint16mf4_t op3, size_t op4){
  return vnclip_wv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vnclip(vint64m2_t op0, vuint32m1_t op1, size_t op2){
  return vnclip_wv_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vnclip(vbool32_t op0, vint32m1_t op1, vint64m2_t op2, vuint32m1_t op3, size_t op4){
  return vnclip_wv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vnclip(vint64m4_t op0, vuint32m2_t op1, size_t op2){
  return vnclip_wv_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vnclip(vbool16_t op0, vint32m2_t op1, vint64m4_t op2, vuint32m2_t op3, size_t op4){
  return vnclip_wv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vnclip(vint64m8_t op0, vuint32m4_t op1, size_t op2){
  return vnclip_wv_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vnclip(vbool8_t op0, vint32m4_t op1, vint64m8_t op2, vuint32m4_t op3, size_t op4){
  return vnclip_wv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vnclip(vint64m1_t op0, vuint32mf2_t op1, size_t op2){
  return vnclip_wv_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vnclip(vbool64_t op0, vint32mf2_t op1, vint64m1_t op2, vuint32mf2_t op3, size_t op4){
  return vnclip_wv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vnclip(vint16m2_t op0, size_t op1, size_t op2){
  return vnclip_wx_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vnclip(vbool8_t op0, vint8m1_t op1, vint16m2_t op2, size_t op3, size_t op4){
  return vnclip_wx_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vnclip(vint16m4_t op0, size_t op1, size_t op2){
  return vnclip_wx_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vnclip(vbool4_t op0, vint8m2_t op1, vint16m4_t op2, size_t op3, size_t op4){
  return vnclip_wx_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vnclip(vint16m8_t op0, size_t op1, size_t op2){
  return vnclip_wx_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vnclip(vbool2_t op0, vint8m4_t op1, vint16m8_t op2, size_t op3, size_t op4){
  return vnclip_wx_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vnclip(vint16m1_t op0, size_t op1, size_t op2){
  return vnclip_wx_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vnclip(vbool16_t op0, vint8mf2_t op1, vint16m1_t op2, size_t op3, size_t op4){
  return vnclip_wx_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vnclip(vint16mf2_t op0, size_t op1, size_t op2){
  return vnclip_wx_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vnclip(vbool32_t op0, vint8mf4_t op1, vint16mf2_t op2, size_t op3, size_t op4){
  return vnclip_wx_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vnclip(vint16mf4_t op0, size_t op1, size_t op2){
  return vnclip_wx_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vnclip(vbool64_t op0, vint8mf8_t op1, vint16mf4_t op2, size_t op3, size_t op4){
  return vnclip_wx_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vnclip(vint32m2_t op0, size_t op1, size_t op2){
  return vnclip_wx_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vnclip(vbool16_t op0, vint16m1_t op1, vint32m2_t op2, size_t op3, size_t op4){
  return vnclip_wx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vnclip(vint32m4_t op0, size_t op1, size_t op2){
  return vnclip_wx_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vnclip(vbool8_t op0, vint16m2_t op1, vint32m4_t op2, size_t op3, size_t op4){
  return vnclip_wx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vnclip(vint32m8_t op0, size_t op1, size_t op2){
  return vnclip_wx_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vnclip(vbool4_t op0, vint16m4_t op1, vint32m8_t op2, size_t op3, size_t op4){
  return vnclip_wx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vnclip(vint32m1_t op0, size_t op1, size_t op2){
  return vnclip_wx_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vnclip(vbool32_t op0, vint16mf2_t op1, vint32m1_t op2, size_t op3, size_t op4){
  return vnclip_wx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vnclip(vint32mf2_t op0, size_t op1, size_t op2){
  return vnclip_wx_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vnclip(vbool64_t op0, vint16mf4_t op1, vint32mf2_t op2, size_t op3, size_t op4){
  return vnclip_wx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vnclip(vint64m2_t op0, size_t op1, size_t op2){
  return vnclip_wx_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vnclip(vbool32_t op0, vint32m1_t op1, vint64m2_t op2, size_t op3, size_t op4){
  return vnclip_wx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vnclip(vint64m4_t op0, size_t op1, size_t op2){
  return vnclip_wx_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vnclip(vbool16_t op0, vint32m2_t op1, vint64m4_t op2, size_t op3, size_t op4){
  return vnclip_wx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vnclip(vint64m8_t op0, size_t op1, size_t op2){
  return vnclip_wx_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vnclip(vbool8_t op0, vint32m4_t op1, vint64m8_t op2, size_t op3, size_t op4){
  return vnclip_wx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vnclip(vint64m1_t op0, size_t op1, size_t op2){
  return vnclip_wx_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vnclip(vbool64_t op0, vint32mf2_t op1, vint64m1_t op2, size_t op3, size_t op4){
  return vnclip_wx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vle64ff(vbool64_t op0, vint64m1_t op1, const int64_t * op2, size_t * op3, size_t op4){
  return vle64ff_v_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vle64ff(vbool32_t op0, vint64m2_t op1, const int64_t * op2, size_t * op3, size_t op4){
  return vle64ff_v_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vle64ff(vbool16_t op0, vint64m4_t op1, const int64_t * op2, size_t * op3, size_t op4){
  return vle64ff_v_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vle64ff(vbool8_t op0, vint64m8_t op1, const int64_t * op2, size_t * op3, size_t op4){
  return vle64ff_v_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vle64ff(vbool64_t op0, vuint64m1_t op1, const uint64_t * op2, size_t * op3, size_t op4){
  return vle64ff_v_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vle64ff(vbool32_t op0, vuint64m2_t op1, const uint64_t * op2, size_t * op3, size_t op4){
  return vle64ff_v_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vle64ff(vbool16_t op0, vuint64m4_t op1, const uint64_t * op2, size_t * op3, size_t op4){
  return vle64ff_v_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vle64ff(vbool8_t op0, vuint64m8_t op1, const uint64_t * op2, size_t * op3, size_t op4){
  return vle64ff_v_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vluxei8(const int8_t * op0, vuint8m1_t op1, size_t op2){
  return vluxei8_v_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vluxei8(vbool8_t op0, vint8m1_t op1, const int8_t * op2, vuint8m1_t op3, size_t op4){
  return vluxei8_v_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vluxei8(const int8_t * op0, vuint8m2_t op1, size_t op2){
  return vluxei8_v_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vluxei8(vbool4_t op0, vint8m2_t op1, const int8_t * op2, vuint8m2_t op3, size_t op4){
  return vluxei8_v_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vluxei8(const int8_t * op0, vuint8m4_t op1, size_t op2){
  return vluxei8_v_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vluxei8(vbool2_t op0, vint8m4_t op1, const int8_t * op2, vuint8m4_t op3, size_t op4){
  return vluxei8_v_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vluxei8(const int8_t * op0, vuint8m8_t op1, size_t op2){
  return vluxei8_v_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vluxei8(vbool1_t op0, vint8m8_t op1, const int8_t * op2, vuint8m8_t op3, size_t op4){
  return vluxei8_v_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vluxei8(const int8_t * op0, vuint8mf2_t op1, size_t op2){
  return vluxei8_v_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vluxei8(vbool16_t op0, vint8mf2_t op1, const int8_t * op2, vuint8mf2_t op3, size_t op4){
  return vluxei8_v_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vluxei8(const int8_t * op0, vuint8mf4_t op1, size_t op2){
  return vluxei8_v_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vluxei8(vbool32_t op0, vint8mf4_t op1, const int8_t * op2, vuint8mf4_t op3, size_t op4){
  return vluxei8_v_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vluxei8(const int8_t * op0, vuint8mf8_t op1, size_t op2){
  return vluxei8_v_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vluxei8(vbool64_t op0, vint8mf8_t op1, const int8_t * op2, vuint8mf8_t op3, size_t op4){
  return vluxei8_v_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vse16(int16_t * op0, vint16m1_t op1, size_t op2){
  return vse16_v_i16m1(op0, op1, op2);
}

__rvv_overloaded void vse16(vbool16_t op0, int16_t * op1, vint16m1_t op2, size_t op3){
  return vse16_v_i16m1_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse16(int16_t * op0, vint16m2_t op1, size_t op2){
  return vse16_v_i16m2(op0, op1, op2);
}

__rvv_overloaded void vse16(vbool8_t op0, int16_t * op1, vint16m2_t op2, size_t op3){
  return vse16_v_i16m2_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse16(int16_t * op0, vint16m4_t op1, size_t op2){
  return vse16_v_i16m4(op0, op1, op2);
}

__rvv_overloaded void vse16(vbool4_t op0, int16_t * op1, vint16m4_t op2, size_t op3){
  return vse16_v_i16m4_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse16(int16_t * op0, vint16m8_t op1, size_t op2){
  return vse16_v_i16m8(op0, op1, op2);
}

__rvv_overloaded void vse16(vbool2_t op0, int16_t * op1, vint16m8_t op2, size_t op3){
  return vse16_v_i16m8_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse16(int16_t * op0, vint16mf2_t op1, size_t op2){
  return vse16_v_i16mf2(op0, op1, op2);
}

__rvv_overloaded void vse16(vbool32_t op0, int16_t * op1, vint16mf2_t op2, size_t op3){
  return vse16_v_i16mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse16(int16_t * op0, vint16mf4_t op1, size_t op2){
  return vse16_v_i16mf4(op0, op1, op2);
}

__rvv_overloaded void vse16(vbool64_t op0, int16_t * op1, vint16mf4_t op2, size_t op3){
  return vse16_v_i16mf4_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse16(uint16_t * op0, vuint16m1_t op1, size_t op2){
  return vse16_v_u16m1(op0, op1, op2);
}

__rvv_overloaded void vse16(vbool16_t op0, uint16_t * op1, vuint16m1_t op2, size_t op3){
  return vse16_v_u16m1_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse16(uint16_t * op0, vuint16m2_t op1, size_t op2){
  return vse16_v_u16m2(op0, op1, op2);
}

__rvv_overloaded void vse16(vbool8_t op0, uint16_t * op1, vuint16m2_t op2, size_t op3){
  return vse16_v_u16m2_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse16(uint16_t * op0, vuint16m4_t op1, size_t op2){
  return vse16_v_u16m4(op0, op1, op2);
}

__rvv_overloaded void vse16(vbool4_t op0, uint16_t * op1, vuint16m4_t op2, size_t op3){
  return vse16_v_u16m4_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse16(uint16_t * op0, vuint16m8_t op1, size_t op2){
  return vse16_v_u16m8(op0, op1, op2);
}

__rvv_overloaded void vse16(vbool2_t op0, uint16_t * op1, vuint16m8_t op2, size_t op3){
  return vse16_v_u16m8_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse16(uint16_t * op0, vuint16mf2_t op1, size_t op2){
  return vse16_v_u16mf2(op0, op1, op2);
}

__rvv_overloaded void vse16(vbool32_t op0, uint16_t * op1, vuint16mf2_t op2, size_t op3){
  return vse16_v_u16mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse16(uint16_t * op0, vuint16mf4_t op1, size_t op2){
  return vse16_v_u16mf4(op0, op1, op2);
}

__rvv_overloaded void vse16(vbool64_t op0, uint16_t * op1, vuint16mf4_t op2, size_t op3){
  return vse16_v_u16mf4_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse32(int32_t * op0, vint32m1_t op1, size_t op2){
  return vse32_v_i32m1(op0, op1, op2);
}

__rvv_overloaded void vse32(vbool32_t op0, int32_t * op1, vint32m1_t op2, size_t op3){
  return vse32_v_i32m1_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse32(int32_t * op0, vint32m2_t op1, size_t op2){
  return vse32_v_i32m2(op0, op1, op2);
}

__rvv_overloaded void vse32(vbool16_t op0, int32_t * op1, vint32m2_t op2, size_t op3){
  return vse32_v_i32m2_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse32(int32_t * op0, vint32m4_t op1, size_t op2){
  return vse32_v_i32m4(op0, op1, op2);
}

__rvv_overloaded void vse32(vbool8_t op0, int32_t * op1, vint32m4_t op2, size_t op3){
  return vse32_v_i32m4_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse32(int32_t * op0, vint32m8_t op1, size_t op2){
  return vse32_v_i32m8(op0, op1, op2);
}

__rvv_overloaded void vse32(vbool4_t op0, int32_t * op1, vint32m8_t op2, size_t op3){
  return vse32_v_i32m8_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse32(int32_t * op0, vint32mf2_t op1, size_t op2){
  return vse32_v_i32mf2(op0, op1, op2);
}

__rvv_overloaded void vse32(vbool64_t op0, int32_t * op1, vint32mf2_t op2, size_t op3){
  return vse32_v_i32mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse32(uint32_t * op0, vuint32m1_t op1, size_t op2){
  return vse32_v_u32m1(op0, op1, op2);
}

__rvv_overloaded void vse32(vbool32_t op0, uint32_t * op1, vuint32m1_t op2, size_t op3){
  return vse32_v_u32m1_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse32(uint32_t * op0, vuint32m2_t op1, size_t op2){
  return vse32_v_u32m2(op0, op1, op2);
}

__rvv_overloaded void vse32(vbool16_t op0, uint32_t * op1, vuint32m2_t op2, size_t op3){
  return vse32_v_u32m2_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse32(uint32_t * op0, vuint32m4_t op1, size_t op2){
  return vse32_v_u32m4(op0, op1, op2);
}

__rvv_overloaded void vse32(vbool8_t op0, uint32_t * op1, vuint32m4_t op2, size_t op3){
  return vse32_v_u32m4_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse32(uint32_t * op0, vuint32m8_t op1, size_t op2){
  return vse32_v_u32m8(op0, op1, op2);
}

__rvv_overloaded void vse32(vbool4_t op0, uint32_t * op1, vuint32m8_t op2, size_t op3){
  return vse32_v_u32m8_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse32(uint32_t * op0, vuint32mf2_t op1, size_t op2){
  return vse32_v_u32mf2(op0, op1, op2);
}

__rvv_overloaded void vse32(vbool64_t op0, uint32_t * op1, vuint32mf2_t op2, size_t op3){
  return vse32_v_u32mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse64(int64_t * op0, vint64m1_t op1, size_t op2){
  return vse64_v_i64m1(op0, op1, op2);
}

__rvv_overloaded void vse64(vbool64_t op0, int64_t * op1, vint64m1_t op2, size_t op3){
  return vse64_v_i64m1_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse64(int64_t * op0, vint64m2_t op1, size_t op2){
  return vse64_v_i64m2(op0, op1, op2);
}

__rvv_overloaded void vse64(vbool32_t op0, int64_t * op1, vint64m2_t op2, size_t op3){
  return vse64_v_i64m2_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse64(int64_t * op0, vint64m4_t op1, size_t op2){
  return vse64_v_i64m4(op0, op1, op2);
}

__rvv_overloaded void vse64(vbool16_t op0, int64_t * op1, vint64m4_t op2, size_t op3){
  return vse64_v_i64m4_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse64(int64_t * op0, vint64m8_t op1, size_t op2){
  return vse64_v_i64m8(op0, op1, op2);
}

__rvv_overloaded void vse64(vbool8_t op0, int64_t * op1, vint64m8_t op2, size_t op3){
  return vse64_v_i64m8_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse64(uint64_t * op0, vuint64m1_t op1, size_t op2){
  return vse64_v_u64m1(op0, op1, op2);
}

__rvv_overloaded void vse64(vbool64_t op0, uint64_t * op1, vuint64m1_t op2, size_t op3){
  return vse64_v_u64m1_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse64(uint64_t * op0, vuint64m2_t op1, size_t op2){
  return vse64_v_u64m2(op0, op1, op2);
}

__rvv_overloaded void vse64(vbool32_t op0, uint64_t * op1, vuint64m2_t op2, size_t op3){
  return vse64_v_u64m2_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse64(uint64_t * op0, vuint64m4_t op1, size_t op2){
  return vse64_v_u64m4(op0, op1, op2);
}

__rvv_overloaded void vse64(vbool16_t op0, uint64_t * op1, vuint64m4_t op2, size_t op3){
  return vse64_v_u64m4_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse64(uint64_t * op0, vuint64m8_t op1, size_t op2){
  return vse64_v_u64m8(op0, op1, op2);
}

__rvv_overloaded void vse64(vbool8_t op0, uint64_t * op1, vuint64m8_t op2, size_t op3){
  return vse64_v_u64m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vluxei8(const uint8_t * op0, vuint8m1_t op1, size_t op2){
  return vluxei8_v_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vluxei8(vbool8_t op0, vuint8m1_t op1, const uint8_t * op2, vuint8m1_t op3, size_t op4){
  return vluxei8_v_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vluxei8(const uint8_t * op0, vuint8m2_t op1, size_t op2){
  return vluxei8_v_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vluxei8(vbool4_t op0, vuint8m2_t op1, const uint8_t * op2, vuint8m2_t op3, size_t op4){
  return vluxei8_v_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vluxei8(const uint8_t * op0, vuint8m4_t op1, size_t op2){
  return vluxei8_v_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vluxei8(vbool2_t op0, vuint8m4_t op1, const uint8_t * op2, vuint8m4_t op3, size_t op4){
  return vluxei8_v_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vluxei8(const uint8_t * op0, vuint8m8_t op1, size_t op2){
  return vluxei8_v_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vluxei8(vbool1_t op0, vuint8m8_t op1, const uint8_t * op2, vuint8m8_t op3, size_t op4){
  return vluxei8_v_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vluxei8(const uint8_t * op0, vuint8mf2_t op1, size_t op2){
  return vluxei8_v_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vluxei8(vbool16_t op0, vuint8mf2_t op1, const uint8_t * op2, vuint8mf2_t op3, size_t op4){
  return vluxei8_v_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vluxei8(const uint8_t * op0, vuint8mf4_t op1, size_t op2){
  return vluxei8_v_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vluxei8(vbool32_t op0, vuint8mf4_t op1, const uint8_t * op2, vuint8mf4_t op3, size_t op4){
  return vluxei8_v_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vluxei8(const uint8_t * op0, vuint8mf8_t op1, size_t op2){
  return vluxei8_v_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vluxei8(vbool64_t op0, vuint8mf8_t op1, const uint8_t * op2, vuint8mf8_t op3, size_t op4){
  return vluxei8_v_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vluxei16(const int8_t * op0, vuint16m2_t op1, size_t op2){
  return vluxei16_v_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vluxei16(vbool8_t op0, vint8m1_t op1, const int8_t * op2, vuint16m2_t op3, size_t op4){
  return vluxei16_v_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vluxei16(const int8_t * op0, vuint16m4_t op1, size_t op2){
  return vluxei16_v_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vluxei16(vbool4_t op0, vint8m2_t op1, const int8_t * op2, vuint16m4_t op3, size_t op4){
  return vluxei16_v_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vluxei16(const int8_t * op0, vuint16m8_t op1, size_t op2){
  return vluxei16_v_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vluxei16(vbool2_t op0, vint8m4_t op1, const int8_t * op2, vuint16m8_t op3, size_t op4){
  return vluxei16_v_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vluxei16(const int8_t * op0, vuint16m1_t op1, size_t op2){
  return vluxei16_v_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vluxei16(vbool16_t op0, vint8mf2_t op1, const int8_t * op2, vuint16m1_t op3, size_t op4){
  return vluxei16_v_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vluxei16(const int8_t * op0, vuint16mf2_t op1, size_t op2){
  return vluxei16_v_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vluxei16(vbool32_t op0, vint8mf4_t op1, const int8_t * op2, vuint16mf2_t op3, size_t op4){
  return vluxei16_v_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vluxei16(const int8_t * op0, vuint16mf4_t op1, size_t op2){
  return vluxei16_v_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vluxei16(vbool64_t op0, vint8mf8_t op1, const int8_t * op2, vuint16mf4_t op3, size_t op4){
  return vluxei16_v_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vluxei16(const uint8_t * op0, vuint16m2_t op1, size_t op2){
  return vluxei16_v_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vluxei16(vbool8_t op0, vuint8m1_t op1, const uint8_t * op2, vuint16m2_t op3, size_t op4){
  return vluxei16_v_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vluxei16(const uint8_t * op0, vuint16m4_t op1, size_t op2){
  return vluxei16_v_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vluxei16(vbool4_t op0, vuint8m2_t op1, const uint8_t * op2, vuint16m4_t op3, size_t op4){
  return vluxei16_v_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vluxei16(const uint8_t * op0, vuint16m8_t op1, size_t op2){
  return vluxei16_v_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vluxei16(vbool2_t op0, vuint8m4_t op1, const uint8_t * op2, vuint16m8_t op3, size_t op4){
  return vluxei16_v_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vluxei16(const uint8_t * op0, vuint16m1_t op1, size_t op2){
  return vluxei16_v_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vluxei16(vbool16_t op0, vuint8mf2_t op1, const uint8_t * op2, vuint16m1_t op3, size_t op4){
  return vluxei16_v_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vluxei16(const uint8_t * op0, vuint16mf2_t op1, size_t op2){
  return vluxei16_v_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vluxei16(vbool32_t op0, vuint8mf4_t op1, const uint8_t * op2, vuint16mf2_t op3, size_t op4){
  return vluxei16_v_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vluxei16(const uint8_t * op0, vuint16mf4_t op1, size_t op2){
  return vluxei16_v_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vluxei16(vbool64_t op0, vuint8mf8_t op1, const uint8_t * op2, vuint16mf4_t op3, size_t op4){
  return vluxei16_v_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vluxei32(const int8_t * op0, vuint32m4_t op1, size_t op2){
  return vluxei32_v_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vluxei32(vbool8_t op0, vint8m1_t op1, const int8_t * op2, vuint32m4_t op3, size_t op4){
  return vluxei32_v_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vluxei32(const int8_t * op0, vuint32m8_t op1, size_t op2){
  return vluxei32_v_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vluxei32(vbool4_t op0, vint8m2_t op1, const int8_t * op2, vuint32m8_t op3, size_t op4){
  return vluxei32_v_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vluxei32(const int8_t * op0, vuint32m2_t op1, size_t op2){
  return vluxei32_v_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vluxei32(vbool16_t op0, vint8mf2_t op1, const int8_t * op2, vuint32m2_t op3, size_t op4){
  return vluxei32_v_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vluxei32(const int8_t * op0, vuint32m1_t op1, size_t op2){
  return vluxei32_v_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vluxei32(vbool32_t op0, vint8mf4_t op1, const int8_t * op2, vuint32m1_t op3, size_t op4){
  return vluxei32_v_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vluxei32(const int8_t * op0, vuint32mf2_t op1, size_t op2){
  return vluxei32_v_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vluxei32(vbool64_t op0, vint8mf8_t op1, const int8_t * op2, vuint32mf2_t op3, size_t op4){
  return vluxei32_v_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vluxei32(const uint8_t * op0, vuint32m4_t op1, size_t op2){
  return vluxei32_v_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vluxei32(vbool8_t op0, vuint8m1_t op1, const uint8_t * op2, vuint32m4_t op3, size_t op4){
  return vluxei32_v_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vluxei32(const uint8_t * op0, vuint32m8_t op1, size_t op2){
  return vluxei32_v_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vluxei32(vbool4_t op0, vuint8m2_t op1, const uint8_t * op2, vuint32m8_t op3, size_t op4){
  return vluxei32_v_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vluxei32(const uint8_t * op0, vuint32m2_t op1, size_t op2){
  return vluxei32_v_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vluxei32(vbool16_t op0, vuint8mf2_t op1, const uint8_t * op2, vuint32m2_t op3, size_t op4){
  return vluxei32_v_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vluxei32(const uint8_t * op0, vuint32m1_t op1, size_t op2){
  return vluxei32_v_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vluxei32(vbool32_t op0, vuint8mf4_t op1, const uint8_t * op2, vuint32m1_t op3, size_t op4){
  return vluxei32_v_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vluxei32(const uint8_t * op0, vuint32mf2_t op1, size_t op2){
  return vluxei32_v_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vluxei32(vbool64_t op0, vuint8mf8_t op1, const uint8_t * op2, vuint32mf2_t op3, size_t op4){
  return vluxei32_v_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vluxei64(const int8_t * op0, vuint64m8_t op1, size_t op2){
  return vluxei64_v_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vluxei64(vbool8_t op0, vint8m1_t op1, const int8_t * op2, vuint64m8_t op3, size_t op4){
  return vluxei64_v_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vluxei64(const int8_t * op0, vuint64m4_t op1, size_t op2){
  return vluxei64_v_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vluxei64(vbool16_t op0, vint8mf2_t op1, const int8_t * op2, vuint64m4_t op3, size_t op4){
  return vluxei64_v_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vluxei64(const int8_t * op0, vuint64m2_t op1, size_t op2){
  return vluxei64_v_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vluxei64(vbool32_t op0, vint8mf4_t op1, const int8_t * op2, vuint64m2_t op3, size_t op4){
  return vluxei64_v_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vluxei64(const int8_t * op0, vuint64m1_t op1, size_t op2){
  return vluxei64_v_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vluxei64(vbool64_t op0, vint8mf8_t op1, const int8_t * op2, vuint64m1_t op3, size_t op4){
  return vluxei64_v_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vluxei64(const uint8_t * op0, vuint64m8_t op1, size_t op2){
  return vluxei64_v_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vluxei64(vbool8_t op0, vuint8m1_t op1, const uint8_t * op2, vuint64m8_t op3, size_t op4){
  return vluxei64_v_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vluxei64(const uint8_t * op0, vuint64m4_t op1, size_t op2){
  return vluxei64_v_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vluxei64(vbool16_t op0, vuint8mf2_t op1, const uint8_t * op2, vuint64m4_t op3, size_t op4){
  return vluxei64_v_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vluxei64(const uint8_t * op0, vuint64m2_t op1, size_t op2){
  return vluxei64_v_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vluxei64(vbool32_t op0, vuint8mf4_t op1, const uint8_t * op2, vuint64m2_t op3, size_t op4){
  return vluxei64_v_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vluxei64(const uint8_t * op0, vuint64m1_t op1, size_t op2){
  return vluxei64_v_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vluxei64(vbool64_t op0, vuint8mf8_t op1, const uint8_t * op2, vuint64m1_t op3, size_t op4){
  return vluxei64_v_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vluxei8(const int16_t * op0, vuint8mf2_t op1, size_t op2){
  return vluxei8_v_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vluxei8(vbool16_t op0, vint16m1_t op1, const int16_t * op2, vuint8mf2_t op3, size_t op4){
  return vluxei8_v_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vluxei8(const int16_t * op0, vuint8m1_t op1, size_t op2){
  return vluxei8_v_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vluxei8(vbool8_t op0, vint16m2_t op1, const int16_t * op2, vuint8m1_t op3, size_t op4){
  return vluxei8_v_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vluxei8(const int16_t * op0, vuint8m2_t op1, size_t op2){
  return vluxei8_v_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vluxei8(vbool4_t op0, vint16m4_t op1, const int16_t * op2, vuint8m2_t op3, size_t op4){
  return vluxei8_v_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vluxei8(const int16_t * op0, vuint8m4_t op1, size_t op2){
  return vluxei8_v_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vluxei8(vbool2_t op0, vint16m8_t op1, const int16_t * op2, vuint8m4_t op3, size_t op4){
  return vluxei8_v_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vluxei8(const int16_t * op0, vuint8mf4_t op1, size_t op2){
  return vluxei8_v_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vluxei8(vbool32_t op0, vint16mf2_t op1, const int16_t * op2, vuint8mf4_t op3, size_t op4){
  return vluxei8_v_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vluxei8(const int16_t * op0, vuint8mf8_t op1, size_t op2){
  return vluxei8_v_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vluxei8(vbool64_t op0, vint16mf4_t op1, const int16_t * op2, vuint8mf8_t op3, size_t op4){
  return vluxei8_v_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vluxei8(const uint16_t * op0, vuint8mf2_t op1, size_t op2){
  return vluxei8_v_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vluxei8(vbool16_t op0, vuint16m1_t op1, const uint16_t * op2, vuint8mf2_t op3, size_t op4){
  return vluxei8_v_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vluxei8(const uint16_t * op0, vuint8m1_t op1, size_t op2){
  return vluxei8_v_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vluxei8(vbool8_t op0, vuint16m2_t op1, const uint16_t * op2, vuint8m1_t op3, size_t op4){
  return vluxei8_v_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vluxei8(const uint16_t * op0, vuint8m2_t op1, size_t op2){
  return vluxei8_v_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vluxei8(vbool4_t op0, vuint16m4_t op1, const uint16_t * op2, vuint8m2_t op3, size_t op4){
  return vluxei8_v_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vluxei8(const uint16_t * op0, vuint8m4_t op1, size_t op2){
  return vluxei8_v_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vluxei8(vbool2_t op0, vuint16m8_t op1, const uint16_t * op2, vuint8m4_t op3, size_t op4){
  return vluxei8_v_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vluxei8(const uint16_t * op0, vuint8mf4_t op1, size_t op2){
  return vluxei8_v_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vluxei8(vbool32_t op0, vuint16mf2_t op1, const uint16_t * op2, vuint8mf4_t op3, size_t op4){
  return vluxei8_v_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vluxei8(const uint16_t * op0, vuint8mf8_t op1, size_t op2){
  return vluxei8_v_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vluxei8(vbool64_t op0, vuint16mf4_t op1, const uint16_t * op2, vuint8mf8_t op3, size_t op4){
  return vluxei8_v_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vluxei16(const int16_t * op0, vuint16m1_t op1, size_t op2){
  return vluxei16_v_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vluxei16(vbool16_t op0, vint16m1_t op1, const int16_t * op2, vuint16m1_t op3, size_t op4){
  return vluxei16_v_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vluxei16(const int16_t * op0, vuint16m2_t op1, size_t op2){
  return vluxei16_v_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vluxei16(vbool8_t op0, vint16m2_t op1, const int16_t * op2, vuint16m2_t op3, size_t op4){
  return vluxei16_v_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vluxei16(const int16_t * op0, vuint16m4_t op1, size_t op2){
  return vluxei16_v_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vluxei16(vbool4_t op0, vint16m4_t op1, const int16_t * op2, vuint16m4_t op3, size_t op4){
  return vluxei16_v_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vluxei16(const int16_t * op0, vuint16m8_t op1, size_t op2){
  return vluxei16_v_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vluxei16(vbool2_t op0, vint16m8_t op1, const int16_t * op2, vuint16m8_t op3, size_t op4){
  return vluxei16_v_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vluxei16(const int16_t * op0, vuint16mf2_t op1, size_t op2){
  return vluxei16_v_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vluxei16(vbool32_t op0, vint16mf2_t op1, const int16_t * op2, vuint16mf2_t op3, size_t op4){
  return vluxei16_v_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vluxei16(const int16_t * op0, vuint16mf4_t op1, size_t op2){
  return vluxei16_v_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vluxei16(vbool64_t op0, vint16mf4_t op1, const int16_t * op2, vuint16mf4_t op3, size_t op4){
  return vluxei16_v_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vluxei16(const uint16_t * op0, vuint16m1_t op1, size_t op2){
  return vluxei16_v_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vluxei16(vbool16_t op0, vuint16m1_t op1, const uint16_t * op2, vuint16m1_t op3, size_t op4){
  return vluxei16_v_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vluxei16(const uint16_t * op0, vuint16m2_t op1, size_t op2){
  return vluxei16_v_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vluxei16(vbool8_t op0, vuint16m2_t op1, const uint16_t * op2, vuint16m2_t op3, size_t op4){
  return vluxei16_v_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vluxei16(const uint16_t * op0, vuint16m4_t op1, size_t op2){
  return vluxei16_v_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vluxei16(vbool4_t op0, vuint16m4_t op1, const uint16_t * op2, vuint16m4_t op3, size_t op4){
  return vluxei16_v_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vluxei16(const uint16_t * op0, vuint16m8_t op1, size_t op2){
  return vluxei16_v_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vluxei16(vbool2_t op0, vuint16m8_t op1, const uint16_t * op2, vuint16m8_t op3, size_t op4){
  return vluxei16_v_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vluxei16(const uint16_t * op0, vuint16mf2_t op1, size_t op2){
  return vluxei16_v_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vluxei16(vbool32_t op0, vuint16mf2_t op1, const uint16_t * op2, vuint16mf2_t op3, size_t op4){
  return vluxei16_v_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vluxei16(const uint16_t * op0, vuint16mf4_t op1, size_t op2){
  return vluxei16_v_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vluxei16(vbool64_t op0, vuint16mf4_t op1, const uint16_t * op2, vuint16mf4_t op3, size_t op4){
  return vluxei16_v_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vluxei32(const int16_t * op0, vuint32m2_t op1, size_t op2){
  return vluxei32_v_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vluxei32(vbool16_t op0, vint16m1_t op1, const int16_t * op2, vuint32m2_t op3, size_t op4){
  return vluxei32_v_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vluxei32(const int16_t * op0, vuint32m4_t op1, size_t op2){
  return vluxei32_v_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vluxei32(vbool8_t op0, vint16m2_t op1, const int16_t * op2, vuint32m4_t op3, size_t op4){
  return vluxei32_v_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vluxei32(const int16_t * op0, vuint32m8_t op1, size_t op2){
  return vluxei32_v_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vluxei32(vbool4_t op0, vint16m4_t op1, const int16_t * op2, vuint32m8_t op3, size_t op4){
  return vluxei32_v_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vluxei32(const int16_t * op0, vuint32m1_t op1, size_t op2){
  return vluxei32_v_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vluxei32(vbool32_t op0, vint16mf2_t op1, const int16_t * op2, vuint32m1_t op3, size_t op4){
  return vluxei32_v_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vluxei32(const int16_t * op0, vuint32mf2_t op1, size_t op2){
  return vluxei32_v_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vluxei32(vbool64_t op0, vint16mf4_t op1, const int16_t * op2, vuint32mf2_t op3, size_t op4){
  return vluxei32_v_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vluxei32(const uint16_t * op0, vuint32m2_t op1, size_t op2){
  return vluxei32_v_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vluxei32(vbool16_t op0, vuint16m1_t op1, const uint16_t * op2, vuint32m2_t op3, size_t op4){
  return vluxei32_v_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vluxei32(const uint16_t * op0, vuint32m4_t op1, size_t op2){
  return vluxei32_v_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vluxei32(vbool8_t op0, vuint16m2_t op1, const uint16_t * op2, vuint32m4_t op3, size_t op4){
  return vluxei32_v_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vluxei32(const uint16_t * op0, vuint32m8_t op1, size_t op2){
  return vluxei32_v_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vluxei32(vbool4_t op0, vuint16m4_t op1, const uint16_t * op2, vuint32m8_t op3, size_t op4){
  return vluxei32_v_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vluxei32(const uint16_t * op0, vuint32m1_t op1, size_t op2){
  return vluxei32_v_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vluxei32(vbool32_t op0, vuint16mf2_t op1, const uint16_t * op2, vuint32m1_t op3, size_t op4){
  return vluxei32_v_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vluxei32(const uint16_t * op0, vuint32mf2_t op1, size_t op2){
  return vluxei32_v_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vluxei32(vbool64_t op0, vuint16mf4_t op1, const uint16_t * op2, vuint32mf2_t op3, size_t op4){
  return vluxei32_v_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vluxei64(const int16_t * op0, vuint64m4_t op1, size_t op2){
  return vluxei64_v_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vluxei64(vbool16_t op0, vint16m1_t op1, const int16_t * op2, vuint64m4_t op3, size_t op4){
  return vluxei64_v_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vluxei64(const int16_t * op0, vuint64m8_t op1, size_t op2){
  return vluxei64_v_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vluxei64(vbool8_t op0, vint16m2_t op1, const int16_t * op2, vuint64m8_t op3, size_t op4){
  return vluxei64_v_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vluxei64(const int16_t * op0, vuint64m2_t op1, size_t op2){
  return vluxei64_v_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vluxei64(vbool32_t op0, vint16mf2_t op1, const int16_t * op2, vuint64m2_t op3, size_t op4){
  return vluxei64_v_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vluxei64(const int16_t * op0, vuint64m1_t op1, size_t op2){
  return vluxei64_v_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vluxei64(vbool64_t op0, vint16mf4_t op1, const int16_t * op2, vuint64m1_t op3, size_t op4){
  return vluxei64_v_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vluxei64(const uint16_t * op0, vuint64m4_t op1, size_t op2){
  return vluxei64_v_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vluxei64(vbool16_t op0, vuint16m1_t op1, const uint16_t * op2, vuint64m4_t op3, size_t op4){
  return vluxei64_v_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vluxei64(const uint16_t * op0, vuint64m8_t op1, size_t op2){
  return vluxei64_v_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vluxei64(vbool8_t op0, vuint16m2_t op1, const uint16_t * op2, vuint64m8_t op3, size_t op4){
  return vluxei64_v_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vluxei64(const uint16_t * op0, vuint64m2_t op1, size_t op2){
  return vluxei64_v_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vluxei64(vbool32_t op0, vuint16mf2_t op1, const uint16_t * op2, vuint64m2_t op3, size_t op4){
  return vluxei64_v_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vluxei64(const uint16_t * op0, vuint64m1_t op1, size_t op2){
  return vluxei64_v_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vluxei64(vbool64_t op0, vuint16mf4_t op1, const uint16_t * op2, vuint64m1_t op3, size_t op4){
  return vluxei64_v_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vluxei8(const int32_t * op0, vuint8mf4_t op1, size_t op2){
  return vluxei8_v_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vluxei8(vbool32_t op0, vint32m1_t op1, const int32_t * op2, vuint8mf4_t op3, size_t op4){
  return vluxei8_v_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vluxei8(const int32_t * op0, vuint8mf2_t op1, size_t op2){
  return vluxei8_v_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vluxei8(vbool16_t op0, vint32m2_t op1, const int32_t * op2, vuint8mf2_t op3, size_t op4){
  return vluxei8_v_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vluxei8(const int32_t * op0, vuint8m1_t op1, size_t op2){
  return vluxei8_v_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vluxei8(vbool8_t op0, vint32m4_t op1, const int32_t * op2, vuint8m1_t op3, size_t op4){
  return vluxei8_v_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vluxei8(const int32_t * op0, vuint8m2_t op1, size_t op2){
  return vluxei8_v_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vluxei8(vbool4_t op0, vint32m8_t op1, const int32_t * op2, vuint8m2_t op3, size_t op4){
  return vluxei8_v_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vluxei8(const int32_t * op0, vuint8mf8_t op1, size_t op2){
  return vluxei8_v_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vluxei8(vbool64_t op0, vint32mf2_t op1, const int32_t * op2, vuint8mf8_t op3, size_t op4){
  return vluxei8_v_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vluxei8(const uint32_t * op0, vuint8mf4_t op1, size_t op2){
  return vluxei8_v_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vluxei8(vbool32_t op0, vuint32m1_t op1, const uint32_t * op2, vuint8mf4_t op3, size_t op4){
  return vluxei8_v_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vluxei8(const uint32_t * op0, vuint8mf2_t op1, size_t op2){
  return vluxei8_v_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vluxei8(vbool16_t op0, vuint32m2_t op1, const uint32_t * op2, vuint8mf2_t op3, size_t op4){
  return vluxei8_v_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vluxei8(const uint32_t * op0, vuint8m1_t op1, size_t op2){
  return vluxei8_v_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vluxei8(vbool8_t op0, vuint32m4_t op1, const uint32_t * op2, vuint8m1_t op3, size_t op4){
  return vluxei8_v_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vluxei8(const uint32_t * op0, vuint8m2_t op1, size_t op2){
  return vluxei8_v_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vluxei8(vbool4_t op0, vuint32m8_t op1, const uint32_t * op2, vuint8m2_t op3, size_t op4){
  return vluxei8_v_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vluxei8(const uint32_t * op0, vuint8mf8_t op1, size_t op2){
  return vluxei8_v_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vluxei8(vbool64_t op0, vuint32mf2_t op1, const uint32_t * op2, vuint8mf8_t op3, size_t op4){
  return vluxei8_v_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vluxei16(const int32_t * op0, vuint16mf2_t op1, size_t op2){
  return vluxei16_v_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vluxei16(vbool32_t op0, vint32m1_t op1, const int32_t * op2, vuint16mf2_t op3, size_t op4){
  return vluxei16_v_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vluxei16(const int32_t * op0, vuint16m1_t op1, size_t op2){
  return vluxei16_v_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vluxei16(vbool16_t op0, vint32m2_t op1, const int32_t * op2, vuint16m1_t op3, size_t op4){
  return vluxei16_v_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vluxei16(const int32_t * op0, vuint16m2_t op1, size_t op2){
  return vluxei16_v_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vluxei16(vbool8_t op0, vint32m4_t op1, const int32_t * op2, vuint16m2_t op3, size_t op4){
  return vluxei16_v_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vluxei16(const int32_t * op0, vuint16m4_t op1, size_t op2){
  return vluxei16_v_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vluxei16(vbool4_t op0, vint32m8_t op1, const int32_t * op2, vuint16m4_t op3, size_t op4){
  return vluxei16_v_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vluxei16(const int32_t * op0, vuint16mf4_t op1, size_t op2){
  return vluxei16_v_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vluxei16(vbool64_t op0, vint32mf2_t op1, const int32_t * op2, vuint16mf4_t op3, size_t op4){
  return vluxei16_v_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vluxei16(const uint32_t * op0, vuint16mf2_t op1, size_t op2){
  return vluxei16_v_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vluxei16(vbool32_t op0, vuint32m1_t op1, const uint32_t * op2, vuint16mf2_t op3, size_t op4){
  return vluxei16_v_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vluxei16(const uint32_t * op0, vuint16m1_t op1, size_t op2){
  return vluxei16_v_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vluxei16(vbool16_t op0, vuint32m2_t op1, const uint32_t * op2, vuint16m1_t op3, size_t op4){
  return vluxei16_v_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vluxei16(const uint32_t * op0, vuint16m2_t op1, size_t op2){
  return vluxei16_v_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vluxei16(vbool8_t op0, vuint32m4_t op1, const uint32_t * op2, vuint16m2_t op3, size_t op4){
  return vluxei16_v_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vluxei16(const uint32_t * op0, vuint16m4_t op1, size_t op2){
  return vluxei16_v_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vluxei16(vbool4_t op0, vuint32m8_t op1, const uint32_t * op2, vuint16m4_t op3, size_t op4){
  return vluxei16_v_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vluxei16(const uint32_t * op0, vuint16mf4_t op1, size_t op2){
  return vluxei16_v_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vluxei16(vbool64_t op0, vuint32mf2_t op1, const uint32_t * op2, vuint16mf4_t op3, size_t op4){
  return vluxei16_v_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vluxei32(const int32_t * op0, vuint32m1_t op1, size_t op2){
  return vluxei32_v_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vluxei32(vbool32_t op0, vint32m1_t op1, const int32_t * op2, vuint32m1_t op3, size_t op4){
  return vluxei32_v_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vluxei32(const int32_t * op0, vuint32m2_t op1, size_t op2){
  return vluxei32_v_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vluxei32(vbool16_t op0, vint32m2_t op1, const int32_t * op2, vuint32m2_t op3, size_t op4){
  return vluxei32_v_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vluxei32(const int32_t * op0, vuint32m4_t op1, size_t op2){
  return vluxei32_v_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vluxei32(vbool8_t op0, vint32m4_t op1, const int32_t * op2, vuint32m4_t op3, size_t op4){
  return vluxei32_v_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vluxei32(const int32_t * op0, vuint32m8_t op1, size_t op2){
  return vluxei32_v_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vluxei32(vbool4_t op0, vint32m8_t op1, const int32_t * op2, vuint32m8_t op3, size_t op4){
  return vluxei32_v_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vluxei32(const int32_t * op0, vuint32mf2_t op1, size_t op2){
  return vluxei32_v_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vluxei32(vbool64_t op0, vint32mf2_t op1, const int32_t * op2, vuint32mf2_t op3, size_t op4){
  return vluxei32_v_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vluxei32(const uint32_t * op0, vuint32m1_t op1, size_t op2){
  return vluxei32_v_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vluxei32(vbool32_t op0, vuint32m1_t op1, const uint32_t * op2, vuint32m1_t op3, size_t op4){
  return vluxei32_v_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vluxei32(const uint32_t * op0, vuint32m2_t op1, size_t op2){
  return vluxei32_v_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vluxei32(vbool16_t op0, vuint32m2_t op1, const uint32_t * op2, vuint32m2_t op3, size_t op4){
  return vluxei32_v_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vluxei32(const uint32_t * op0, vuint32m4_t op1, size_t op2){
  return vluxei32_v_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vluxei32(vbool8_t op0, vuint32m4_t op1, const uint32_t * op2, vuint32m4_t op3, size_t op4){
  return vluxei32_v_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vluxei32(const uint32_t * op0, vuint32m8_t op1, size_t op2){
  return vluxei32_v_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vluxei32(vbool4_t op0, vuint32m8_t op1, const uint32_t * op2, vuint32m8_t op3, size_t op4){
  return vluxei32_v_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vluxei32(const uint32_t * op0, vuint32mf2_t op1, size_t op2){
  return vluxei32_v_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vluxei32(vbool64_t op0, vuint32mf2_t op1, const uint32_t * op2, vuint32mf2_t op3, size_t op4){
  return vluxei32_v_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vluxei64(const int32_t * op0, vuint64m2_t op1, size_t op2){
  return vluxei64_v_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vluxei64(vbool32_t op0, vint32m1_t op1, const int32_t * op2, vuint64m2_t op3, size_t op4){
  return vluxei64_v_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vluxei64(const int32_t * op0, vuint64m4_t op1, size_t op2){
  return vluxei64_v_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vluxei64(vbool16_t op0, vint32m2_t op1, const int32_t * op2, vuint64m4_t op3, size_t op4){
  return vluxei64_v_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vluxei64(const int32_t * op0, vuint64m8_t op1, size_t op2){
  return vluxei64_v_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vluxei64(vbool8_t op0, vint32m4_t op1, const int32_t * op2, vuint64m8_t op3, size_t op4){
  return vluxei64_v_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vluxei64(const int32_t * op0, vuint64m1_t op1, size_t op2){
  return vluxei64_v_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vluxei64(vbool64_t op0, vint32mf2_t op1, const int32_t * op2, vuint64m1_t op3, size_t op4){
  return vluxei64_v_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vluxei64(const uint32_t * op0, vuint64m2_t op1, size_t op2){
  return vluxei64_v_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vluxei64(vbool32_t op0, vuint32m1_t op1, const uint32_t * op2, vuint64m2_t op3, size_t op4){
  return vluxei64_v_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vluxei64(const uint32_t * op0, vuint64m4_t op1, size_t op2){
  return vluxei64_v_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vluxei64(vbool16_t op0, vuint32m2_t op1, const uint32_t * op2, vuint64m4_t op3, size_t op4){
  return vluxei64_v_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vluxei64(const uint32_t * op0, vuint64m8_t op1, size_t op2){
  return vluxei64_v_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vluxei64(vbool8_t op0, vuint32m4_t op1, const uint32_t * op2, vuint64m8_t op3, size_t op4){
  return vluxei64_v_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vluxei64(const uint32_t * op0, vuint64m1_t op1, size_t op2){
  return vluxei64_v_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vluxei64(vbool64_t op0, vuint32mf2_t op1, const uint32_t * op2, vuint64m1_t op3, size_t op4){
  return vluxei64_v_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vluxei8(const int64_t * op0, vuint8mf8_t op1, size_t op2){
  return vluxei8_v_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vluxei8(vbool64_t op0, vint64m1_t op1, const int64_t * op2, vuint8mf8_t op3, size_t op4){
  return vluxei8_v_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vluxei8(const int64_t * op0, vuint8mf4_t op1, size_t op2){
  return vluxei8_v_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vluxei8(vbool32_t op0, vint64m2_t op1, const int64_t * op2, vuint8mf4_t op3, size_t op4){
  return vluxei8_v_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vluxei8(const int64_t * op0, vuint8mf2_t op1, size_t op2){
  return vluxei8_v_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vluxei8(vbool16_t op0, vint64m4_t op1, const int64_t * op2, vuint8mf2_t op3, size_t op4){
  return vluxei8_v_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vluxei8(const int64_t * op0, vuint8m1_t op1, size_t op2){
  return vluxei8_v_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vluxei8(vbool8_t op0, vint64m8_t op1, const int64_t * op2, vuint8m1_t op3, size_t op4){
  return vluxei8_v_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vluxei8(const uint64_t * op0, vuint8mf8_t op1, size_t op2){
  return vluxei8_v_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vluxei8(vbool64_t op0, vuint64m1_t op1, const uint64_t * op2, vuint8mf8_t op3, size_t op4){
  return vluxei8_v_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vluxei8(const uint64_t * op0, vuint8mf4_t op1, size_t op2){
  return vluxei8_v_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vluxei8(vbool32_t op0, vuint64m2_t op1, const uint64_t * op2, vuint8mf4_t op3, size_t op4){
  return vluxei8_v_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vluxei8(const uint64_t * op0, vuint8mf2_t op1, size_t op2){
  return vluxei8_v_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vluxei8(vbool16_t op0, vuint64m4_t op1, const uint64_t * op2, vuint8mf2_t op3, size_t op4){
  return vluxei8_v_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vluxei8(const uint64_t * op0, vuint8m1_t op1, size_t op2){
  return vluxei8_v_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vluxei8(vbool8_t op0, vuint64m8_t op1, const uint64_t * op2, vuint8m1_t op3, size_t op4){
  return vluxei8_v_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vluxei16(const int64_t * op0, vuint16mf4_t op1, size_t op2){
  return vluxei16_v_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vluxei16(vbool64_t op0, vint64m1_t op1, const int64_t * op2, vuint16mf4_t op3, size_t op4){
  return vluxei16_v_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vluxei16(const int64_t * op0, vuint16mf2_t op1, size_t op2){
  return vluxei16_v_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vluxei16(vbool32_t op0, vint64m2_t op1, const int64_t * op2, vuint16mf2_t op3, size_t op4){
  return vluxei16_v_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vluxei16(const int64_t * op0, vuint16m1_t op1, size_t op2){
  return vluxei16_v_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vluxei16(vbool16_t op0, vint64m4_t op1, const int64_t * op2, vuint16m1_t op3, size_t op4){
  return vluxei16_v_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vluxei16(const int64_t * op0, vuint16m2_t op1, size_t op2){
  return vluxei16_v_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vluxei16(vbool8_t op0, vint64m8_t op1, const int64_t * op2, vuint16m2_t op3, size_t op4){
  return vluxei16_v_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vluxei16(const uint64_t * op0, vuint16mf4_t op1, size_t op2){
  return vluxei16_v_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vluxei16(vbool64_t op0, vuint64m1_t op1, const uint64_t * op2, vuint16mf4_t op3, size_t op4){
  return vluxei16_v_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vluxei16(const uint64_t * op0, vuint16mf2_t op1, size_t op2){
  return vluxei16_v_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vluxei16(vbool32_t op0, vuint64m2_t op1, const uint64_t * op2, vuint16mf2_t op3, size_t op4){
  return vluxei16_v_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vluxei16(const uint64_t * op0, vuint16m1_t op1, size_t op2){
  return vluxei16_v_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vluxei16(vbool16_t op0, vuint64m4_t op1, const uint64_t * op2, vuint16m1_t op3, size_t op4){
  return vluxei16_v_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vluxei16(const uint64_t * op0, vuint16m2_t op1, size_t op2){
  return vluxei16_v_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vluxei16(vbool8_t op0, vuint64m8_t op1, const uint64_t * op2, vuint16m2_t op3, size_t op4){
  return vluxei16_v_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vluxei32(const int64_t * op0, vuint32mf2_t op1, size_t op2){
  return vluxei32_v_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vluxei32(vbool64_t op0, vint64m1_t op1, const int64_t * op2, vuint32mf2_t op3, size_t op4){
  return vluxei32_v_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vluxei32(const int64_t * op0, vuint32m1_t op1, size_t op2){
  return vluxei32_v_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vluxei32(vbool32_t op0, vint64m2_t op1, const int64_t * op2, vuint32m1_t op3, size_t op4){
  return vluxei32_v_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vluxei32(const int64_t * op0, vuint32m2_t op1, size_t op2){
  return vluxei32_v_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vluxei32(vbool16_t op0, vint64m4_t op1, const int64_t * op2, vuint32m2_t op3, size_t op4){
  return vluxei32_v_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vluxei32(const int64_t * op0, vuint32m4_t op1, size_t op2){
  return vluxei32_v_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vluxei32(vbool8_t op0, vint64m8_t op1, const int64_t * op2, vuint32m4_t op3, size_t op4){
  return vluxei32_v_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vluxei32(const uint64_t * op0, vuint32mf2_t op1, size_t op2){
  return vluxei32_v_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vluxei32(vbool64_t op0, vuint64m1_t op1, const uint64_t * op2, vuint32mf2_t op3, size_t op4){
  return vluxei32_v_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vluxei32(const uint64_t * op0, vuint32m1_t op1, size_t op2){
  return vluxei32_v_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vluxei32(vbool32_t op0, vuint64m2_t op1, const uint64_t * op2, vuint32m1_t op3, size_t op4){
  return vluxei32_v_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vluxei32(const uint64_t * op0, vuint32m2_t op1, size_t op2){
  return vluxei32_v_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vluxei32(vbool16_t op0, vuint64m4_t op1, const uint64_t * op2, vuint32m2_t op3, size_t op4){
  return vluxei32_v_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vluxei32(const uint64_t * op0, vuint32m4_t op1, size_t op2){
  return vluxei32_v_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vluxei32(vbool8_t op0, vuint64m8_t op1, const uint64_t * op2, vuint32m4_t op3, size_t op4){
  return vluxei32_v_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vluxei64(const int64_t * op0, vuint64m1_t op1, size_t op2){
  return vluxei64_v_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vluxei64(vbool64_t op0, vint64m1_t op1, const int64_t * op2, vuint64m1_t op3, size_t op4){
  return vluxei64_v_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vluxei64(const int64_t * op0, vuint64m2_t op1, size_t op2){
  return vluxei64_v_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vluxei64(vbool32_t op0, vint64m2_t op1, const int64_t * op2, vuint64m2_t op3, size_t op4){
  return vluxei64_v_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vluxei64(const int64_t * op0, vuint64m4_t op1, size_t op2){
  return vluxei64_v_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vluxei64(vbool16_t op0, vint64m4_t op1, const int64_t * op2, vuint64m4_t op3, size_t op4){
  return vluxei64_v_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vluxei64(const int64_t * op0, vuint64m8_t op1, size_t op2){
  return vluxei64_v_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vluxei64(vbool8_t op0, vint64m8_t op1, const int64_t * op2, vuint64m8_t op3, size_t op4){
  return vluxei64_v_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vluxei64(const uint64_t * op0, vuint64m1_t op1, size_t op2){
  return vluxei64_v_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vluxei64(vbool64_t op0, vuint64m1_t op1, const uint64_t * op2, vuint64m1_t op3, size_t op4){
  return vluxei64_v_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vluxei64(const uint64_t * op0, vuint64m2_t op1, size_t op2){
  return vluxei64_v_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vluxei64(vbool32_t op0, vuint64m2_t op1, const uint64_t * op2, vuint64m2_t op3, size_t op4){
  return vluxei64_v_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vluxei64(const uint64_t * op0, vuint64m4_t op1, size_t op2){
  return vluxei64_v_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vluxei64(vbool16_t op0, vuint64m4_t op1, const uint64_t * op2, vuint64m4_t op3, size_t op4){
  return vluxei64_v_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vluxei64(const uint64_t * op0, vuint64m8_t op1, size_t op2){
  return vluxei64_v_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vluxei64(vbool8_t op0, vuint64m8_t op1, const uint64_t * op2, vuint64m8_t op3, size_t op4){
  return vluxei64_v_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vloxei8(const int8_t * op0, vuint8m1_t op1, size_t op2){
  return vloxei8_v_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vloxei8(vbool8_t op0, vint8m1_t op1, const int8_t * op2, vuint8m1_t op3, size_t op4){
  return vloxei8_v_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vloxei8(const int8_t * op0, vuint8m2_t op1, size_t op2){
  return vloxei8_v_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vloxei8(vbool4_t op0, vint8m2_t op1, const int8_t * op2, vuint8m2_t op3, size_t op4){
  return vloxei8_v_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vloxei8(const int8_t * op0, vuint8m4_t op1, size_t op2){
  return vloxei8_v_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vloxei8(vbool2_t op0, vint8m4_t op1, const int8_t * op2, vuint8m4_t op3, size_t op4){
  return vloxei8_v_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vloxei8(const int8_t * op0, vuint8m8_t op1, size_t op2){
  return vloxei8_v_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vloxei8(vbool1_t op0, vint8m8_t op1, const int8_t * op2, vuint8m8_t op3, size_t op4){
  return vloxei8_v_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vloxei8(const int8_t * op0, vuint8mf2_t op1, size_t op2){
  return vloxei8_v_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vloxei8(vbool16_t op0, vint8mf2_t op1, const int8_t * op2, vuint8mf2_t op3, size_t op4){
  return vloxei8_v_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vloxei8(const int8_t * op0, vuint8mf4_t op1, size_t op2){
  return vloxei8_v_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vloxei8(vbool32_t op0, vint8mf4_t op1, const int8_t * op2, vuint8mf4_t op3, size_t op4){
  return vloxei8_v_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vloxei8(const int8_t * op0, vuint8mf8_t op1, size_t op2){
  return vloxei8_v_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vloxei8(vbool64_t op0, vint8mf8_t op1, const int8_t * op2, vuint8mf8_t op3, size_t op4){
  return vloxei8_v_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vloxei8(const uint8_t * op0, vuint8m1_t op1, size_t op2){
  return vloxei8_v_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vloxei8(vbool8_t op0, vuint8m1_t op1, const uint8_t * op2, vuint8m1_t op3, size_t op4){
  return vloxei8_v_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vloxei8(const uint8_t * op0, vuint8m2_t op1, size_t op2){
  return vloxei8_v_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vloxei8(vbool4_t op0, vuint8m2_t op1, const uint8_t * op2, vuint8m2_t op3, size_t op4){
  return vloxei8_v_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vloxei8(const uint8_t * op0, vuint8m4_t op1, size_t op2){
  return vloxei8_v_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vloxei8(vbool2_t op0, vuint8m4_t op1, const uint8_t * op2, vuint8m4_t op3, size_t op4){
  return vloxei8_v_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vloxei8(const uint8_t * op0, vuint8m8_t op1, size_t op2){
  return vloxei8_v_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vloxei8(vbool1_t op0, vuint8m8_t op1, const uint8_t * op2, vuint8m8_t op3, size_t op4){
  return vloxei8_v_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vloxei8(const uint8_t * op0, vuint8mf2_t op1, size_t op2){
  return vloxei8_v_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vloxei8(vbool16_t op0, vuint8mf2_t op1, const uint8_t * op2, vuint8mf2_t op3, size_t op4){
  return vloxei8_v_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vloxei8(const uint8_t * op0, vuint8mf4_t op1, size_t op2){
  return vloxei8_v_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vloxei8(vbool32_t op0, vuint8mf4_t op1, const uint8_t * op2, vuint8mf4_t op3, size_t op4){
  return vloxei8_v_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vloxei8(const uint8_t * op0, vuint8mf8_t op1, size_t op2){
  return vloxei8_v_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vloxei8(vbool64_t op0, vuint8mf8_t op1, const uint8_t * op2, vuint8mf8_t op3, size_t op4){
  return vloxei8_v_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vloxei16(const int8_t * op0, vuint16m2_t op1, size_t op2){
  return vloxei16_v_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vloxei16(vbool8_t op0, vint8m1_t op1, const int8_t * op2, vuint16m2_t op3, size_t op4){
  return vloxei16_v_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vloxei16(const int8_t * op0, vuint16m4_t op1, size_t op2){
  return vloxei16_v_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vloxei16(vbool4_t op0, vint8m2_t op1, const int8_t * op2, vuint16m4_t op3, size_t op4){
  return vloxei16_v_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vloxei16(const int8_t * op0, vuint16m8_t op1, size_t op2){
  return vloxei16_v_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vloxei16(vbool2_t op0, vint8m4_t op1, const int8_t * op2, vuint16m8_t op3, size_t op4){
  return vloxei16_v_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vloxei16(const int8_t * op0, vuint16m1_t op1, size_t op2){
  return vloxei16_v_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vloxei16(vbool16_t op0, vint8mf2_t op1, const int8_t * op2, vuint16m1_t op3, size_t op4){
  return vloxei16_v_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vloxei16(const int8_t * op0, vuint16mf2_t op1, size_t op2){
  return vloxei16_v_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vloxei16(vbool32_t op0, vint8mf4_t op1, const int8_t * op2, vuint16mf2_t op3, size_t op4){
  return vloxei16_v_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vloxei16(const int8_t * op0, vuint16mf4_t op1, size_t op2){
  return vloxei16_v_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vloxei16(vbool64_t op0, vint8mf8_t op1, const int8_t * op2, vuint16mf4_t op3, size_t op4){
  return vloxei16_v_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vloxei16(const uint8_t * op0, vuint16m2_t op1, size_t op2){
  return vloxei16_v_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vloxei16(vbool8_t op0, vuint8m1_t op1, const uint8_t * op2, vuint16m2_t op3, size_t op4){
  return vloxei16_v_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vloxei16(const uint8_t * op0, vuint16m4_t op1, size_t op2){
  return vloxei16_v_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vloxei16(vbool4_t op0, vuint8m2_t op1, const uint8_t * op2, vuint16m4_t op3, size_t op4){
  return vloxei16_v_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vloxei16(const uint8_t * op0, vuint16m8_t op1, size_t op2){
  return vloxei16_v_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vloxei16(vbool2_t op0, vuint8m4_t op1, const uint8_t * op2, vuint16m8_t op3, size_t op4){
  return vloxei16_v_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vloxei16(const uint8_t * op0, vuint16m1_t op1, size_t op2){
  return vloxei16_v_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vloxei16(vbool16_t op0, vuint8mf2_t op1, const uint8_t * op2, vuint16m1_t op3, size_t op4){
  return vloxei16_v_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vloxei16(const uint8_t * op0, vuint16mf2_t op1, size_t op2){
  return vloxei16_v_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vloxei16(vbool32_t op0, vuint8mf4_t op1, const uint8_t * op2, vuint16mf2_t op3, size_t op4){
  return vloxei16_v_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vloxei16(const uint8_t * op0, vuint16mf4_t op1, size_t op2){
  return vloxei16_v_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vloxei16(vbool64_t op0, vuint8mf8_t op1, const uint8_t * op2, vuint16mf4_t op3, size_t op4){
  return vloxei16_v_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vloxei32(const int8_t * op0, vuint32m4_t op1, size_t op2){
  return vloxei32_v_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vloxei32(vbool8_t op0, vint8m1_t op1, const int8_t * op2, vuint32m4_t op3, size_t op4){
  return vloxei32_v_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vloxei32(const int8_t * op0, vuint32m8_t op1, size_t op2){
  return vloxei32_v_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vloxei32(vbool4_t op0, vint8m2_t op1, const int8_t * op2, vuint32m8_t op3, size_t op4){
  return vloxei32_v_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vloxei32(const int8_t * op0, vuint32m2_t op1, size_t op2){
  return vloxei32_v_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vloxei32(vbool16_t op0, vint8mf2_t op1, const int8_t * op2, vuint32m2_t op3, size_t op4){
  return vloxei32_v_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vloxei32(const int8_t * op0, vuint32m1_t op1, size_t op2){
  return vloxei32_v_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vloxei32(vbool32_t op0, vint8mf4_t op1, const int8_t * op2, vuint32m1_t op3, size_t op4){
  return vloxei32_v_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vloxei32(const int8_t * op0, vuint32mf2_t op1, size_t op2){
  return vloxei32_v_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vloxei32(vbool64_t op0, vint8mf8_t op1, const int8_t * op2, vuint32mf2_t op3, size_t op4){
  return vloxei32_v_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vloxei32(const uint8_t * op0, vuint32m4_t op1, size_t op2){
  return vloxei32_v_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vloxei32(vbool8_t op0, vuint8m1_t op1, const uint8_t * op2, vuint32m4_t op3, size_t op4){
  return vloxei32_v_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vloxei32(const uint8_t * op0, vuint32m8_t op1, size_t op2){
  return vloxei32_v_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vloxei32(vbool4_t op0, vuint8m2_t op1, const uint8_t * op2, vuint32m8_t op3, size_t op4){
  return vloxei32_v_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vloxei32(const uint8_t * op0, vuint32m2_t op1, size_t op2){
  return vloxei32_v_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vloxei32(vbool16_t op0, vuint8mf2_t op1, const uint8_t * op2, vuint32m2_t op3, size_t op4){
  return vloxei32_v_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vloxei32(const uint8_t * op0, vuint32m1_t op1, size_t op2){
  return vloxei32_v_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vloxei32(vbool32_t op0, vuint8mf4_t op1, const uint8_t * op2, vuint32m1_t op3, size_t op4){
  return vloxei32_v_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vloxei32(const uint8_t * op0, vuint32mf2_t op1, size_t op2){
  return vloxei32_v_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vloxei32(vbool64_t op0, vuint8mf8_t op1, const uint8_t * op2, vuint32mf2_t op3, size_t op4){
  return vloxei32_v_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vloxei64(const int8_t * op0, vuint64m8_t op1, size_t op2){
  return vloxei64_v_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vloxei64(vbool8_t op0, vint8m1_t op1, const int8_t * op2, vuint64m8_t op3, size_t op4){
  return vloxei64_v_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vloxei64(const int8_t * op0, vuint64m4_t op1, size_t op2){
  return vloxei64_v_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vloxei64(vbool16_t op0, vint8mf2_t op1, const int8_t * op2, vuint64m4_t op3, size_t op4){
  return vloxei64_v_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vloxei64(const int8_t * op0, vuint64m2_t op1, size_t op2){
  return vloxei64_v_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vloxei64(vbool32_t op0, vint8mf4_t op1, const int8_t * op2, vuint64m2_t op3, size_t op4){
  return vloxei64_v_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vloxei64(const int8_t * op0, vuint64m1_t op1, size_t op2){
  return vloxei64_v_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vloxei64(vbool64_t op0, vint8mf8_t op1, const int8_t * op2, vuint64m1_t op3, size_t op4){
  return vloxei64_v_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vloxei64(const uint8_t * op0, vuint64m8_t op1, size_t op2){
  return vloxei64_v_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vloxei64(vbool8_t op0, vuint8m1_t op1, const uint8_t * op2, vuint64m8_t op3, size_t op4){
  return vloxei64_v_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vloxei64(const uint8_t * op0, vuint64m4_t op1, size_t op2){
  return vloxei64_v_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vloxei64(vbool16_t op0, vuint8mf2_t op1, const uint8_t * op2, vuint64m4_t op3, size_t op4){
  return vloxei64_v_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vloxei64(const uint8_t * op0, vuint64m2_t op1, size_t op2){
  return vloxei64_v_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vloxei64(vbool32_t op0, vuint8mf4_t op1, const uint8_t * op2, vuint64m2_t op3, size_t op4){
  return vloxei64_v_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vloxei64(const uint8_t * op0, vuint64m1_t op1, size_t op2){
  return vloxei64_v_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vloxei64(vbool64_t op0, vuint8mf8_t op1, const uint8_t * op2, vuint64m1_t op3, size_t op4){
  return vloxei64_v_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vloxei8(const int16_t * op0, vuint8mf2_t op1, size_t op2){
  return vloxei8_v_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vloxei8(vbool16_t op0, vint16m1_t op1, const int16_t * op2, vuint8mf2_t op3, size_t op4){
  return vloxei8_v_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vloxei8(const int16_t * op0, vuint8m1_t op1, size_t op2){
  return vloxei8_v_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vloxei8(vbool8_t op0, vint16m2_t op1, const int16_t * op2, vuint8m1_t op3, size_t op4){
  return vloxei8_v_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vloxei8(const int16_t * op0, vuint8m2_t op1, size_t op2){
  return vloxei8_v_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vloxei8(vbool4_t op0, vint16m4_t op1, const int16_t * op2, vuint8m2_t op3, size_t op4){
  return vloxei8_v_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vloxei8(const int16_t * op0, vuint8m4_t op1, size_t op2){
  return vloxei8_v_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vloxei8(vbool2_t op0, vint16m8_t op1, const int16_t * op2, vuint8m4_t op3, size_t op4){
  return vloxei8_v_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vloxei8(const int16_t * op0, vuint8mf4_t op1, size_t op2){
  return vloxei8_v_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vloxei8(vbool32_t op0, vint16mf2_t op1, const int16_t * op2, vuint8mf4_t op3, size_t op4){
  return vloxei8_v_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vloxei8(const int16_t * op0, vuint8mf8_t op1, size_t op2){
  return vloxei8_v_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vloxei8(vbool64_t op0, vint16mf4_t op1, const int16_t * op2, vuint8mf8_t op3, size_t op4){
  return vloxei8_v_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vloxei8(const uint16_t * op0, vuint8mf2_t op1, size_t op2){
  return vloxei8_v_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vloxei8(vbool16_t op0, vuint16m1_t op1, const uint16_t * op2, vuint8mf2_t op3, size_t op4){
  return vloxei8_v_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vloxei8(const uint16_t * op0, vuint8m1_t op1, size_t op2){
  return vloxei8_v_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vloxei8(vbool8_t op0, vuint16m2_t op1, const uint16_t * op2, vuint8m1_t op3, size_t op4){
  return vloxei8_v_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vloxei8(const uint16_t * op0, vuint8m2_t op1, size_t op2){
  return vloxei8_v_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vloxei8(vbool4_t op0, vuint16m4_t op1, const uint16_t * op2, vuint8m2_t op3, size_t op4){
  return vloxei8_v_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vloxei8(const uint16_t * op0, vuint8m4_t op1, size_t op2){
  return vloxei8_v_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vloxei8(vbool2_t op0, vuint16m8_t op1, const uint16_t * op2, vuint8m4_t op3, size_t op4){
  return vloxei8_v_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vloxei8(const uint16_t * op0, vuint8mf4_t op1, size_t op2){
  return vloxei8_v_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vloxei8(vbool32_t op0, vuint16mf2_t op1, const uint16_t * op2, vuint8mf4_t op3, size_t op4){
  return vloxei8_v_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vloxei8(const uint16_t * op0, vuint8mf8_t op1, size_t op2){
  return vloxei8_v_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vloxei8(vbool64_t op0, vuint16mf4_t op1, const uint16_t * op2, vuint8mf8_t op3, size_t op4){
  return vloxei8_v_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vloxei16(const int16_t * op0, vuint16m1_t op1, size_t op2){
  return vloxei16_v_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vloxei16(vbool16_t op0, vint16m1_t op1, const int16_t * op2, vuint16m1_t op3, size_t op4){
  return vloxei16_v_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vloxei16(const int16_t * op0, vuint16m2_t op1, size_t op2){
  return vloxei16_v_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vloxei16(vbool8_t op0, vint16m2_t op1, const int16_t * op2, vuint16m2_t op3, size_t op4){
  return vloxei16_v_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vloxei16(const int16_t * op0, vuint16m4_t op1, size_t op2){
  return vloxei16_v_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vloxei16(vbool4_t op0, vint16m4_t op1, const int16_t * op2, vuint16m4_t op3, size_t op4){
  return vloxei16_v_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vloxei16(const int16_t * op0, vuint16m8_t op1, size_t op2){
  return vloxei16_v_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vloxei16(vbool2_t op0, vint16m8_t op1, const int16_t * op2, vuint16m8_t op3, size_t op4){
  return vloxei16_v_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vloxei16(const int16_t * op0, vuint16mf2_t op1, size_t op2){
  return vloxei16_v_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vloxei16(vbool32_t op0, vint16mf2_t op1, const int16_t * op2, vuint16mf2_t op3, size_t op4){
  return vloxei16_v_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vloxei16(const int16_t * op0, vuint16mf4_t op1, size_t op2){
  return vloxei16_v_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vloxei16(vbool64_t op0, vint16mf4_t op1, const int16_t * op2, vuint16mf4_t op3, size_t op4){
  return vloxei16_v_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vloxei16(const uint16_t * op0, vuint16m1_t op1, size_t op2){
  return vloxei16_v_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vloxei16(vbool16_t op0, vuint16m1_t op1, const uint16_t * op2, vuint16m1_t op3, size_t op4){
  return vloxei16_v_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vloxei16(const uint16_t * op0, vuint16m2_t op1, size_t op2){
  return vloxei16_v_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vloxei16(vbool8_t op0, vuint16m2_t op1, const uint16_t * op2, vuint16m2_t op3, size_t op4){
  return vloxei16_v_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vloxei16(const uint16_t * op0, vuint16m4_t op1, size_t op2){
  return vloxei16_v_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vloxei16(vbool4_t op0, vuint16m4_t op1, const uint16_t * op2, vuint16m4_t op3, size_t op4){
  return vloxei16_v_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vloxei16(const uint16_t * op0, vuint16m8_t op1, size_t op2){
  return vloxei16_v_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vloxei16(vbool2_t op0, vuint16m8_t op1, const uint16_t * op2, vuint16m8_t op3, size_t op4){
  return vloxei16_v_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vloxei16(const uint16_t * op0, vuint16mf2_t op1, size_t op2){
  return vloxei16_v_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vloxei16(vbool32_t op0, vuint16mf2_t op1, const uint16_t * op2, vuint16mf2_t op3, size_t op4){
  return vloxei16_v_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vloxei16(const uint16_t * op0, vuint16mf4_t op1, size_t op2){
  return vloxei16_v_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vloxei16(vbool64_t op0, vuint16mf4_t op1, const uint16_t * op2, vuint16mf4_t op3, size_t op4){
  return vloxei16_v_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vloxei32(const int16_t * op0, vuint32m2_t op1, size_t op2){
  return vloxei32_v_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vloxei32(vbool16_t op0, vint16m1_t op1, const int16_t * op2, vuint32m2_t op3, size_t op4){
  return vloxei32_v_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vloxei32(const int16_t * op0, vuint32m4_t op1, size_t op2){
  return vloxei32_v_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vloxei32(vbool8_t op0, vint16m2_t op1, const int16_t * op2, vuint32m4_t op3, size_t op4){
  return vloxei32_v_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vloxei32(const int16_t * op0, vuint32m8_t op1, size_t op2){
  return vloxei32_v_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vloxei32(vbool4_t op0, vint16m4_t op1, const int16_t * op2, vuint32m8_t op3, size_t op4){
  return vloxei32_v_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vloxei32(const int16_t * op0, vuint32m1_t op1, size_t op2){
  return vloxei32_v_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vloxei32(vbool32_t op0, vint16mf2_t op1, const int16_t * op2, vuint32m1_t op3, size_t op4){
  return vloxei32_v_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vloxei32(const int16_t * op0, vuint32mf2_t op1, size_t op2){
  return vloxei32_v_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vloxei32(vbool64_t op0, vint16mf4_t op1, const int16_t * op2, vuint32mf2_t op3, size_t op4){
  return vloxei32_v_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vloxei32(const uint16_t * op0, vuint32m2_t op1, size_t op2){
  return vloxei32_v_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vloxei32(vbool16_t op0, vuint16m1_t op1, const uint16_t * op2, vuint32m2_t op3, size_t op4){
  return vloxei32_v_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vloxei32(const uint16_t * op0, vuint32m4_t op1, size_t op2){
  return vloxei32_v_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vloxei32(vbool8_t op0, vuint16m2_t op1, const uint16_t * op2, vuint32m4_t op3, size_t op4){
  return vloxei32_v_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vloxei32(const uint16_t * op0, vuint32m8_t op1, size_t op2){
  return vloxei32_v_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vloxei32(vbool4_t op0, vuint16m4_t op1, const uint16_t * op2, vuint32m8_t op3, size_t op4){
  return vloxei32_v_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vloxei32(const uint16_t * op0, vuint32m1_t op1, size_t op2){
  return vloxei32_v_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vloxei32(vbool32_t op0, vuint16mf2_t op1, const uint16_t * op2, vuint32m1_t op3, size_t op4){
  return vloxei32_v_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vloxei32(const uint16_t * op0, vuint32mf2_t op1, size_t op2){
  return vloxei32_v_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vloxei32(vbool64_t op0, vuint16mf4_t op1, const uint16_t * op2, vuint32mf2_t op3, size_t op4){
  return vloxei32_v_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vloxei64(const int16_t * op0, vuint64m4_t op1, size_t op2){
  return vloxei64_v_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vloxei64(vbool16_t op0, vint16m1_t op1, const int16_t * op2, vuint64m4_t op3, size_t op4){
  return vloxei64_v_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vloxei64(const int16_t * op0, vuint64m8_t op1, size_t op2){
  return vloxei64_v_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vloxei64(vbool8_t op0, vint16m2_t op1, const int16_t * op2, vuint64m8_t op3, size_t op4){
  return vloxei64_v_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vloxei64(const int16_t * op0, vuint64m2_t op1, size_t op2){
  return vloxei64_v_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vloxei64(vbool32_t op0, vint16mf2_t op1, const int16_t * op2, vuint64m2_t op3, size_t op4){
  return vloxei64_v_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vloxei64(const int16_t * op0, vuint64m1_t op1, size_t op2){
  return vloxei64_v_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vloxei64(vbool64_t op0, vint16mf4_t op1, const int16_t * op2, vuint64m1_t op3, size_t op4){
  return vloxei64_v_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vloxei64(const uint16_t * op0, vuint64m4_t op1, size_t op2){
  return vloxei64_v_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vloxei64(vbool16_t op0, vuint16m1_t op1, const uint16_t * op2, vuint64m4_t op3, size_t op4){
  return vloxei64_v_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vloxei64(const uint16_t * op0, vuint64m8_t op1, size_t op2){
  return vloxei64_v_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vloxei64(vbool8_t op0, vuint16m2_t op1, const uint16_t * op2, vuint64m8_t op3, size_t op4){
  return vloxei64_v_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vloxei64(const uint16_t * op0, vuint64m2_t op1, size_t op2){
  return vloxei64_v_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vloxei64(vbool32_t op0, vuint16mf2_t op1, const uint16_t * op2, vuint64m2_t op3, size_t op4){
  return vloxei64_v_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vloxei64(const uint16_t * op0, vuint64m1_t op1, size_t op2){
  return vloxei64_v_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vloxei64(vbool64_t op0, vuint16mf4_t op1, const uint16_t * op2, vuint64m1_t op3, size_t op4){
  return vloxei64_v_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vloxei8(const int32_t * op0, vuint8mf4_t op1, size_t op2){
  return vloxei8_v_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vloxei8(vbool32_t op0, vint32m1_t op1, const int32_t * op2, vuint8mf4_t op3, size_t op4){
  return vloxei8_v_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vloxei8(const int32_t * op0, vuint8mf2_t op1, size_t op2){
  return vloxei8_v_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vloxei8(vbool16_t op0, vint32m2_t op1, const int32_t * op2, vuint8mf2_t op3, size_t op4){
  return vloxei8_v_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vloxei8(const int32_t * op0, vuint8m1_t op1, size_t op2){
  return vloxei8_v_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vloxei8(vbool8_t op0, vint32m4_t op1, const int32_t * op2, vuint8m1_t op3, size_t op4){
  return vloxei8_v_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vloxei8(const int32_t * op0, vuint8m2_t op1, size_t op2){
  return vloxei8_v_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vloxei8(vbool4_t op0, vint32m8_t op1, const int32_t * op2, vuint8m2_t op3, size_t op4){
  return vloxei8_v_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vloxei8(const int32_t * op0, vuint8mf8_t op1, size_t op2){
  return vloxei8_v_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vloxei8(vbool64_t op0, vint32mf2_t op1, const int32_t * op2, vuint8mf8_t op3, size_t op4){
  return vloxei8_v_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vloxei8(const uint32_t * op0, vuint8mf4_t op1, size_t op2){
  return vloxei8_v_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vloxei8(vbool32_t op0, vuint32m1_t op1, const uint32_t * op2, vuint8mf4_t op3, size_t op4){
  return vloxei8_v_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vloxei8(const uint32_t * op0, vuint8mf2_t op1, size_t op2){
  return vloxei8_v_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vloxei8(vbool16_t op0, vuint32m2_t op1, const uint32_t * op2, vuint8mf2_t op3, size_t op4){
  return vloxei8_v_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vloxei8(const uint32_t * op0, vuint8m1_t op1, size_t op2){
  return vloxei8_v_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vloxei8(vbool8_t op0, vuint32m4_t op1, const uint32_t * op2, vuint8m1_t op3, size_t op4){
  return vloxei8_v_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vloxei8(const uint32_t * op0, vuint8m2_t op1, size_t op2){
  return vloxei8_v_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vloxei8(vbool4_t op0, vuint32m8_t op1, const uint32_t * op2, vuint8m2_t op3, size_t op4){
  return vloxei8_v_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vloxei8(const uint32_t * op0, vuint8mf8_t op1, size_t op2){
  return vloxei8_v_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vloxei8(vbool64_t op0, vuint32mf2_t op1, const uint32_t * op2, vuint8mf8_t op3, size_t op4){
  return vloxei8_v_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vloxei16(const int32_t * op0, vuint16mf2_t op1, size_t op2){
  return vloxei16_v_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vloxei16(vbool32_t op0, vint32m1_t op1, const int32_t * op2, vuint16mf2_t op3, size_t op4){
  return vloxei16_v_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vloxei16(const int32_t * op0, vuint16m1_t op1, size_t op2){
  return vloxei16_v_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vloxei16(vbool16_t op0, vint32m2_t op1, const int32_t * op2, vuint16m1_t op3, size_t op4){
  return vloxei16_v_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vloxei16(const int32_t * op0, vuint16m2_t op1, size_t op2){
  return vloxei16_v_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vloxei16(vbool8_t op0, vint32m4_t op1, const int32_t * op2, vuint16m2_t op3, size_t op4){
  return vloxei16_v_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vloxei16(const int32_t * op0, vuint16m4_t op1, size_t op2){
  return vloxei16_v_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vloxei16(vbool4_t op0, vint32m8_t op1, const int32_t * op2, vuint16m4_t op3, size_t op4){
  return vloxei16_v_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vloxei16(const int32_t * op0, vuint16mf4_t op1, size_t op2){
  return vloxei16_v_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vloxei16(vbool64_t op0, vint32mf2_t op1, const int32_t * op2, vuint16mf4_t op3, size_t op4){
  return vloxei16_v_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vloxei16(const uint32_t * op0, vuint16mf2_t op1, size_t op2){
  return vloxei16_v_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vloxei16(vbool32_t op0, vuint32m1_t op1, const uint32_t * op2, vuint16mf2_t op3, size_t op4){
  return vloxei16_v_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vloxei16(const uint32_t * op0, vuint16m1_t op1, size_t op2){
  return vloxei16_v_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vloxei16(vbool16_t op0, vuint32m2_t op1, const uint32_t * op2, vuint16m1_t op3, size_t op4){
  return vloxei16_v_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vloxei16(const uint32_t * op0, vuint16m2_t op1, size_t op2){
  return vloxei16_v_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vloxei16(vbool8_t op0, vuint32m4_t op1, const uint32_t * op2, vuint16m2_t op3, size_t op4){
  return vloxei16_v_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vloxei16(const uint32_t * op0, vuint16m4_t op1, size_t op2){
  return vloxei16_v_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vloxei16(vbool4_t op0, vuint32m8_t op1, const uint32_t * op2, vuint16m4_t op3, size_t op4){
  return vloxei16_v_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vloxei16(const uint32_t * op0, vuint16mf4_t op1, size_t op2){
  return vloxei16_v_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vloxei16(vbool64_t op0, vuint32mf2_t op1, const uint32_t * op2, vuint16mf4_t op3, size_t op4){
  return vloxei16_v_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vloxei32(const int32_t * op0, vuint32m1_t op1, size_t op2){
  return vloxei32_v_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vloxei32(vbool32_t op0, vint32m1_t op1, const int32_t * op2, vuint32m1_t op3, size_t op4){
  return vloxei32_v_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vloxei32(const int32_t * op0, vuint32m2_t op1, size_t op2){
  return vloxei32_v_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vloxei32(vbool16_t op0, vint32m2_t op1, const int32_t * op2, vuint32m2_t op3, size_t op4){
  return vloxei32_v_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vloxei32(const int32_t * op0, vuint32m4_t op1, size_t op2){
  return vloxei32_v_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vloxei32(vbool8_t op0, vint32m4_t op1, const int32_t * op2, vuint32m4_t op3, size_t op4){
  return vloxei32_v_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vloxei32(const int32_t * op0, vuint32m8_t op1, size_t op2){
  return vloxei32_v_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vloxei32(vbool4_t op0, vint32m8_t op1, const int32_t * op2, vuint32m8_t op3, size_t op4){
  return vloxei32_v_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vloxei32(const int32_t * op0, vuint32mf2_t op1, size_t op2){
  return vloxei32_v_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vloxei32(vbool64_t op0, vint32mf2_t op1, const int32_t * op2, vuint32mf2_t op3, size_t op4){
  return vloxei32_v_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vsext_vf2(vint8mf8_t op0, size_t op1){
  return vsext_vf2_i16mf4(op0, op1);
}

__rvv_overloaded vint16mf4_t vsext_vf2(vbool64_t op0, vint16mf4_t op1, vint8mf8_t op2, size_t op3){
  return vsext_vf2_i16mf4_m(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf2_t vsext_vf2(vint8mf4_t op0, size_t op1){
  return vsext_vf2_i16mf2(op0, op1);
}

__rvv_overloaded vint16mf2_t vsext_vf2(vbool32_t op0, vint16mf2_t op1, vint8mf4_t op2, size_t op3){
  return vsext_vf2_i16mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vsext_vf2(vint8mf2_t op0, size_t op1){
  return vsext_vf2_i16m1(op0, op1);
}

__rvv_overloaded vint16m1_t vsext_vf2(vbool16_t op0, vint16m1_t op1, vint8mf2_t op2, size_t op3){
  return vsext_vf2_i16m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vint16m2_t vsext_vf2(vint8m1_t op0, size_t op1){
  return vsext_vf2_i16m2(op0, op1);
}

__rvv_overloaded vint16m2_t vsext_vf2(vbool8_t op0, vint16m2_t op1, vint8m1_t op2, size_t op3){
  return vsext_vf2_i16m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vint16m4_t vsext_vf2(vint8m2_t op0, size_t op1){
  return vsext_vf2_i16m4(op0, op1);
}

__rvv_overloaded vint16m4_t vsext_vf2(vbool4_t op0, vint16m4_t op1, vint8m2_t op2, size_t op3){
  return vsext_vf2_i16m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vint16m8_t vsext_vf2(vint8m4_t op0, size_t op1){
  return vsext_vf2_i16m8(op0, op1);
}

__rvv_overloaded vint16m8_t vsext_vf2(vbool2_t op0, vint16m8_t op1, vint8m4_t op2, size_t op3){
  return vsext_vf2_i16m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vint32mf2_t vsext_vf2(vint16mf4_t op0, size_t op1){
  return vsext_vf2_i32mf2(op0, op1);
}

__rvv_overloaded vint32mf2_t vsext_vf2(vbool64_t op0, vint32mf2_t op1, vint16mf4_t op2, size_t op3){
  return vsext_vf2_i32mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vsext_vf2(vint16mf2_t op0, size_t op1){
  return vsext_vf2_i32m1(op0, op1);
}

__rvv_overloaded vint32m1_t vsext_vf2(vbool32_t op0, vint32m1_t op1, vint16mf2_t op2, size_t op3){
  return vsext_vf2_i32m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vint32m2_t vsext_vf2(vint16m1_t op0, size_t op1){
  return vsext_vf2_i32m2(op0, op1);
}

__rvv_overloaded vint32m2_t vsext_vf2(vbool16_t op0, vint32m2_t op1, vint16m1_t op2, size_t op3){
  return vsext_vf2_i32m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vint32m4_t vsext_vf2(vint16m2_t op0, size_t op1){
  return vsext_vf2_i32m4(op0, op1);
}

__rvv_overloaded vint32m4_t vsext_vf2(vbool8_t op0, vint32m4_t op1, vint16m2_t op2, size_t op3){
  return vsext_vf2_i32m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vint32m8_t vsext_vf2(vint16m4_t op0, size_t op1){
  return vsext_vf2_i32m8(op0, op1);
}

__rvv_overloaded vint32m8_t vsext_vf2(vbool4_t op0, vint32m8_t op1, vint16m4_t op2, size_t op3){
  return vsext_vf2_i32m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vsext_vf2(vint32mf2_t op0, size_t op1){
  return vsext_vf2_i64m1(op0, op1);
}

__rvv_overloaded vint64m1_t vsext_vf2(vbool64_t op0, vint64m1_t op1, vint32mf2_t op2, size_t op3){
  return vsext_vf2_i64m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vint64m2_t vsext_vf2(vint32m1_t op0, size_t op1){
  return vsext_vf2_i64m2(op0, op1);
}

__rvv_overloaded vint64m2_t vsext_vf2(vbool32_t op0, vint64m2_t op1, vint32m1_t op2, size_t op3){
  return vsext_vf2_i64m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vint64m4_t vsext_vf2(vint32m2_t op0, size_t op1){
  return vsext_vf2_i64m4(op0, op1);
}

__rvv_overloaded vint64m4_t vsext_vf2(vbool16_t op0, vint64m4_t op1, vint32m2_t op2, size_t op3){
  return vsext_vf2_i64m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vint64m8_t vsext_vf2(vint32m4_t op0, size_t op1){
  return vsext_vf2_i64m8(op0, op1);
}

__rvv_overloaded vint64m8_t vsext_vf2(vbool8_t op0, vint64m8_t op1, vint32m4_t op2, size_t op3){
  return vsext_vf2_i64m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vint32mf2_t vsext_vf4(vint8mf8_t op0, size_t op1){
  return vsext_vf4_i32mf2(op0, op1);
}

__rvv_overloaded vint32mf2_t vsext_vf4(vbool64_t op0, vint32mf2_t op1, vint8mf8_t op2, size_t op3){
  return vsext_vf4_i32mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vsext_vf4(vint8mf4_t op0, size_t op1){
  return vsext_vf4_i32m1(op0, op1);
}

__rvv_overloaded vint32m1_t vsext_vf4(vbool32_t op0, vint32m1_t op1, vint8mf4_t op2, size_t op3){
  return vsext_vf4_i32m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vint32m2_t vsext_vf4(vint8mf2_t op0, size_t op1){
  return vsext_vf4_i32m2(op0, op1);
}

__rvv_overloaded vint32m2_t vsext_vf4(vbool16_t op0, vint32m2_t op1, vint8mf2_t op2, size_t op3){
  return vsext_vf4_i32m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vint32m4_t vsext_vf4(vint8m1_t op0, size_t op1){
  return vsext_vf4_i32m4(op0, op1);
}

__rvv_overloaded vint32m4_t vsext_vf4(vbool8_t op0, vint32m4_t op1, vint8m1_t op2, size_t op3){
  return vsext_vf4_i32m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vint32m8_t vsext_vf4(vint8m2_t op0, size_t op1){
  return vsext_vf4_i32m8(op0, op1);
}

__rvv_overloaded vint32m8_t vsext_vf4(vbool4_t op0, vint32m8_t op1, vint8m2_t op2, size_t op3){
  return vsext_vf4_i32m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vsext_vf4(vint16mf4_t op0, size_t op1){
  return vsext_vf4_i64m1(op0, op1);
}

__rvv_overloaded vint64m1_t vsext_vf4(vbool64_t op0, vint64m1_t op1, vint16mf4_t op2, size_t op3){
  return vsext_vf4_i64m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vint64m2_t vsext_vf4(vint16mf2_t op0, size_t op1){
  return vsext_vf4_i64m2(op0, op1);
}

__rvv_overloaded vint64m2_t vsext_vf4(vbool32_t op0, vint64m2_t op1, vint16mf2_t op2, size_t op3){
  return vsext_vf4_i64m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vint64m4_t vsext_vf4(vint16m1_t op0, size_t op1){
  return vsext_vf4_i64m4(op0, op1);
}

__rvv_overloaded vint64m4_t vsext_vf4(vbool16_t op0, vint64m4_t op1, vint16m1_t op2, size_t op3){
  return vsext_vf4_i64m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vint64m8_t vsext_vf4(vint16m2_t op0, size_t op1){
  return vsext_vf4_i64m8(op0, op1);
}

__rvv_overloaded vint64m8_t vsext_vf4(vbool8_t op0, vint64m8_t op1, vint16m2_t op2, size_t op3){
  return vsext_vf4_i64m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vsext_vf8(vint8mf8_t op0, size_t op1){
  return vsext_vf8_i64m1(op0, op1);
}

__rvv_overloaded vint64m1_t vsext_vf8(vbool64_t op0, vint64m1_t op1, vint8mf8_t op2, size_t op3){
  return vsext_vf8_i64m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vint64m2_t vsext_vf8(vint8mf4_t op0, size_t op1){
  return vsext_vf8_i64m2(op0, op1);
}

__rvv_overloaded vint64m2_t vsext_vf8(vbool32_t op0, vint64m2_t op1, vint8mf4_t op2, size_t op3){
  return vsext_vf8_i64m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vint64m4_t vsext_vf8(vint8mf2_t op0, size_t op1){
  return vsext_vf8_i64m4(op0, op1);
}

__rvv_overloaded vint64m4_t vsext_vf8(vbool16_t op0, vint64m4_t op1, vint8mf2_t op2, size_t op3){
  return vsext_vf8_i64m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vint64m8_t vsext_vf8(vint8m1_t op0, size_t op1){
  return vsext_vf8_i64m8(op0, op1);
}

__rvv_overloaded vint64m8_t vsext_vf8(vbool8_t op0, vint64m8_t op1, vint8m1_t op2, size_t op3){
  return vsext_vf8_i64m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf4_t vzext_vf2(vuint8mf8_t op0, size_t op1){
  return vzext_vf2_u16mf4(op0, op1);
}

__rvv_overloaded vuint16mf4_t vzext_vf2(vbool64_t op0, vuint16mf4_t op1, vuint8mf8_t op2, size_t op3){
  return vzext_vf2_u16mf4_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf2_t vzext_vf2(vuint8mf4_t op0, size_t op1){
  return vzext_vf2_u16mf2(op0, op1);
}

__rvv_overloaded vuint16mf2_t vzext_vf2(vbool32_t op0, vuint16mf2_t op1, vuint8mf4_t op2, size_t op3){
  return vzext_vf2_u16mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vzext_vf2(vuint8mf2_t op0, size_t op1){
  return vzext_vf2_u16m1(op0, op1);
}

__rvv_overloaded vuint16m1_t vzext_vf2(vbool16_t op0, vuint16m1_t op1, vuint8mf2_t op2, size_t op3){
  return vzext_vf2_u16m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m2_t vzext_vf2(vuint8m1_t op0, size_t op1){
  return vzext_vf2_u16m2(op0, op1);
}

__rvv_overloaded vuint16m2_t vzext_vf2(vbool8_t op0, vuint16m2_t op1, vuint8m1_t op2, size_t op3){
  return vzext_vf2_u16m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m4_t vzext_vf2(vuint8m2_t op0, size_t op1){
  return vzext_vf2_u16m4(op0, op1);
}

__rvv_overloaded vuint16m4_t vzext_vf2(vbool4_t op0, vuint16m4_t op1, vuint8m2_t op2, size_t op3){
  return vzext_vf2_u16m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m8_t vzext_vf2(vuint8m4_t op0, size_t op1){
  return vzext_vf2_u16m8(op0, op1);
}

__rvv_overloaded vuint16m8_t vzext_vf2(vbool2_t op0, vuint16m8_t op1, vuint8m4_t op2, size_t op3){
  return vzext_vf2_u16m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint32mf2_t vzext_vf2(vuint16mf4_t op0, size_t op1){
  return vzext_vf2_u32mf2(op0, op1);
}

__rvv_overloaded vuint32mf2_t vzext_vf2(vbool64_t op0, vuint32mf2_t op1, vuint16mf4_t op2, size_t op3){
  return vzext_vf2_u32mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vzext_vf2(vuint16mf2_t op0, size_t op1){
  return vzext_vf2_u32m1(op0, op1);
}

__rvv_overloaded vuint32m1_t vzext_vf2(vbool32_t op0, vuint32m1_t op1, vuint16mf2_t op2, size_t op3){
  return vzext_vf2_u32m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m2_t vzext_vf2(vuint16m1_t op0, size_t op1){
  return vzext_vf2_u32m2(op0, op1);
}

__rvv_overloaded vuint32m2_t vzext_vf2(vbool16_t op0, vuint32m2_t op1, vuint16m1_t op2, size_t op3){
  return vzext_vf2_u32m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m4_t vzext_vf2(vuint16m2_t op0, size_t op1){
  return vzext_vf2_u32m4(op0, op1);
}

__rvv_overloaded vuint32m4_t vzext_vf2(vbool8_t op0, vuint32m4_t op1, vuint16m2_t op2, size_t op3){
  return vzext_vf2_u32m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m8_t vzext_vf2(vuint16m4_t op0, size_t op1){
  return vzext_vf2_u32m8(op0, op1);
}

__rvv_overloaded vuint32m8_t vzext_vf2(vbool4_t op0, vuint32m8_t op1, vuint16m4_t op2, size_t op3){
  return vzext_vf2_u32m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vzext_vf2(vuint32mf2_t op0, size_t op1){
  return vzext_vf2_u64m1(op0, op1);
}

__rvv_overloaded vuint64m1_t vzext_vf2(vbool64_t op0, vuint64m1_t op1, vuint32mf2_t op2, size_t op3){
  return vzext_vf2_u64m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m2_t vzext_vf2(vuint32m1_t op0, size_t op1){
  return vzext_vf2_u64m2(op0, op1);
}

__rvv_overloaded vuint64m2_t vzext_vf2(vbool32_t op0, vuint64m2_t op1, vuint32m1_t op2, size_t op3){
  return vzext_vf2_u64m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m4_t vzext_vf2(vuint32m2_t op0, size_t op1){
  return vzext_vf2_u64m4(op0, op1);
}

__rvv_overloaded vuint64m4_t vzext_vf2(vbool16_t op0, vuint64m4_t op1, vuint32m2_t op2, size_t op3){
  return vzext_vf2_u64m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m8_t vzext_vf2(vuint32m4_t op0, size_t op1){
  return vzext_vf2_u64m8(op0, op1);
}

__rvv_overloaded vuint64m8_t vzext_vf2(vbool8_t op0, vuint64m8_t op1, vuint32m4_t op2, size_t op3){
  return vzext_vf2_u64m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint32mf2_t vzext_vf4(vuint8mf8_t op0, size_t op1){
  return vzext_vf4_u32mf2(op0, op1);
}

__rvv_overloaded vuint32mf2_t vzext_vf4(vbool64_t op0, vuint32mf2_t op1, vuint8mf8_t op2, size_t op3){
  return vzext_vf4_u32mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vzext_vf4(vuint8mf4_t op0, size_t op1){
  return vzext_vf4_u32m1(op0, op1);
}

__rvv_overloaded vuint32m1_t vzext_vf4(vbool32_t op0, vuint32m1_t op1, vuint8mf4_t op2, size_t op3){
  return vzext_vf4_u32m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m2_t vzext_vf4(vuint8mf2_t op0, size_t op1){
  return vzext_vf4_u32m2(op0, op1);
}

__rvv_overloaded vuint32m2_t vzext_vf4(vbool16_t op0, vuint32m2_t op1, vuint8mf2_t op2, size_t op3){
  return vzext_vf4_u32m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m4_t vzext_vf4(vuint8m1_t op0, size_t op1){
  return vzext_vf4_u32m4(op0, op1);
}

__rvv_overloaded vuint32m4_t vzext_vf4(vbool8_t op0, vuint32m4_t op1, vuint8m1_t op2, size_t op3){
  return vzext_vf4_u32m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m8_t vzext_vf4(vuint8m2_t op0, size_t op1){
  return vzext_vf4_u32m8(op0, op1);
}

__rvv_overloaded vuint32m8_t vzext_vf4(vbool4_t op0, vuint32m8_t op1, vuint8m2_t op2, size_t op3){
  return vzext_vf4_u32m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vzext_vf4(vuint16mf4_t op0, size_t op1){
  return vzext_vf4_u64m1(op0, op1);
}

__rvv_overloaded vuint64m1_t vzext_vf4(vbool64_t op0, vuint64m1_t op1, vuint16mf4_t op2, size_t op3){
  return vzext_vf4_u64m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m2_t vzext_vf4(vuint16mf2_t op0, size_t op1){
  return vzext_vf4_u64m2(op0, op1);
}

__rvv_overloaded vuint64m2_t vzext_vf4(vbool32_t op0, vuint64m2_t op1, vuint16mf2_t op2, size_t op3){
  return vzext_vf4_u64m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m4_t vzext_vf4(vuint16m1_t op0, size_t op1){
  return vzext_vf4_u64m4(op0, op1);
}

__rvv_overloaded vuint64m4_t vzext_vf4(vbool16_t op0, vuint64m4_t op1, vuint16m1_t op2, size_t op3){
  return vzext_vf4_u64m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m8_t vzext_vf4(vuint16m2_t op0, size_t op1){
  return vzext_vf4_u64m8(op0, op1);
}

__rvv_overloaded vuint64m8_t vzext_vf4(vbool8_t op0, vuint64m8_t op1, vuint16m2_t op2, size_t op3){
  return vzext_vf4_u64m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vzext_vf8(vuint8mf8_t op0, size_t op1){
  return vzext_vf8_u64m1(op0, op1);
}

__rvv_overloaded vuint64m1_t vzext_vf8(vbool64_t op0, vuint64m1_t op1, vuint8mf8_t op2, size_t op3){
  return vzext_vf8_u64m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m2_t vzext_vf8(vuint8mf4_t op0, size_t op1){
  return vzext_vf8_u64m2(op0, op1);
}

__rvv_overloaded vuint64m2_t vzext_vf8(vbool32_t op0, vuint64m2_t op1, vuint8mf4_t op2, size_t op3){
  return vzext_vf8_u64m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m4_t vzext_vf8(vuint8mf2_t op0, size_t op1){
  return vzext_vf8_u64m4(op0, op1);
}

__rvv_overloaded vuint64m4_t vzext_vf8(vbool16_t op0, vuint64m4_t op1, vuint8mf2_t op2, size_t op3){
  return vzext_vf8_u64m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m8_t vzext_vf8(vuint8m1_t op0, size_t op1){
  return vzext_vf8_u64m8(op0, op1);
}

__rvv_overloaded vuint64m8_t vzext_vf8(vbool8_t op0, vuint64m8_t op1, vuint8m1_t op2, size_t op3){
  return vzext_vf8_u64m8_m(op0, op1, op2, op3);
}

#if defined(__riscv_f)
__rvv_overloaded vfloat32m1_t vloxei8(const float * op0, vuint8mf4_t op1, size_t op2){
  return vloxei8_v_f32m1(op0, op1, op2);
}

__rvv_overloaded vfloat32m1_t vloxei8(vbool32_t op0, vfloat32m1_t op1, const float * op2, vuint8mf4_t op3, size_t op4){
  return vloxei8_v_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m2_t vloxei8(const float * op0, vuint8mf2_t op1, size_t op2){
  return vloxei8_v_f32m2(op0, op1, op2);
}

__rvv_overloaded vfloat32m2_t vloxei8(vbool16_t op0, vfloat32m2_t op1, const float * op2, vuint8mf2_t op3, size_t op4){
  return vloxei8_v_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m4_t vloxei8(const float * op0, vuint8m1_t op1, size_t op2){
  return vloxei8_v_f32m4(op0, op1, op2);
}

__rvv_overloaded vfloat32m4_t vloxei8(vbool8_t op0, vfloat32m4_t op1, const float * op2, vuint8m1_t op3, size_t op4){
  return vloxei8_v_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m8_t vloxei8(const float * op0, vuint8m2_t op1, size_t op2){
  return vloxei8_v_f32m8(op0, op1, op2);
}

__rvv_overloaded vfloat32m8_t vloxei8(vbool4_t op0, vfloat32m8_t op1, const float * op2, vuint8m2_t op3, size_t op4){
  return vloxei8_v_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vloxei8(const float * op0, vuint8mf8_t op1, size_t op2){
  return vloxei8_v_f32mf2(op0, op1, op2);
}

__rvv_overloaded vfloat32mf2_t vloxei8(vbool64_t op0, vfloat32mf2_t op1, const float * op2, vuint8mf8_t op3, size_t op4){
  return vloxei8_v_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vloxei16(const float * op0, vuint16mf2_t op1, size_t op2){
  return vloxei16_v_f32m1(op0, op1, op2);
}

__rvv_overloaded vfloat32m1_t vloxei16(vbool32_t op0, vfloat32m1_t op1, const float * op2, vuint16mf2_t op3, size_t op4){
  return vloxei16_v_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m2_t vloxei16(const float * op0, vuint16m1_t op1, size_t op2){
  return vloxei16_v_f32m2(op0, op1, op2);
}

__rvv_overloaded vfloat32m2_t vloxei16(vbool16_t op0, vfloat32m2_t op1, const float * op2, vuint16m1_t op3, size_t op4){
  return vloxei16_v_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m4_t vloxei16(const float * op0, vuint16m2_t op1, size_t op2){
  return vloxei16_v_f32m4(op0, op1, op2);
}

__rvv_overloaded vfloat32m4_t vloxei16(vbool8_t op0, vfloat32m4_t op1, const float * op2, vuint16m2_t op3, size_t op4){
  return vloxei16_v_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m8_t vloxei16(const float * op0, vuint16m4_t op1, size_t op2){
  return vloxei16_v_f32m8(op0, op1, op2);
}

__rvv_overloaded vfloat32m8_t vloxei16(vbool4_t op0, vfloat32m8_t op1, const float * op2, vuint16m4_t op3, size_t op4){
  return vloxei16_v_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vloxei16(const float * op0, vuint16mf4_t op1, size_t op2){
  return vloxei16_v_f32mf2(op0, op1, op2);
}

__rvv_overloaded vfloat32mf2_t vloxei16(vbool64_t op0, vfloat32mf2_t op1, const float * op2, vuint16mf4_t op3, size_t op4){
  return vloxei16_v_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vloxei32(const float * op0, vuint32m1_t op1, size_t op2){
  return vloxei32_v_f32m1(op0, op1, op2);
}

__rvv_overloaded vfloat32m1_t vloxei32(vbool32_t op0, vfloat32m1_t op1, const float * op2, vuint32m1_t op3, size_t op4){
  return vloxei32_v_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m2_t vloxei32(const float * op0, vuint32m2_t op1, size_t op2){
  return vloxei32_v_f32m2(op0, op1, op2);
}

__rvv_overloaded vfloat32m2_t vloxei32(vbool16_t op0, vfloat32m2_t op1, const float * op2, vuint32m2_t op3, size_t op4){
  return vloxei32_v_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m4_t vloxei32(const float * op0, vuint32m4_t op1, size_t op2){
  return vloxei32_v_f32m4(op0, op1, op2);
}

__rvv_overloaded vfloat32m4_t vloxei32(vbool8_t op0, vfloat32m4_t op1, const float * op2, vuint32m4_t op3, size_t op4){
  return vloxei32_v_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m8_t vloxei32(const float * op0, vuint32m8_t op1, size_t op2){
  return vloxei32_v_f32m8(op0, op1, op2);
}

__rvv_overloaded vfloat32m8_t vloxei32(vbool4_t op0, vfloat32m8_t op1, const float * op2, vuint32m8_t op3, size_t op4){
  return vloxei32_v_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vloxei32(const float * op0, vuint32mf2_t op1, size_t op2){
  return vloxei32_v_f32mf2(op0, op1, op2);
}

__rvv_overloaded vfloat32mf2_t vloxei32(vbool64_t op0, vfloat32mf2_t op1, const float * op2, vuint32mf2_t op3, size_t op4){
  return vloxei32_v_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vloxei64(const float * op0, vuint64m2_t op1, size_t op2){
  return vloxei64_v_f32m1(op0, op1, op2);
}

__rvv_overloaded vfloat32m1_t vloxei64(vbool32_t op0, vfloat32m1_t op1, const float * op2, vuint64m2_t op3, size_t op4){
  return vloxei64_v_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m2_t vloxei64(const float * op0, vuint64m4_t op1, size_t op2){
  return vloxei64_v_f32m2(op0, op1, op2);
}

__rvv_overloaded vfloat32m2_t vloxei64(vbool16_t op0, vfloat32m2_t op1, const float * op2, vuint64m4_t op3, size_t op4){
  return vloxei64_v_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m4_t vloxei64(const float * op0, vuint64m8_t op1, size_t op2){
  return vloxei64_v_f32m4(op0, op1, op2);
}

__rvv_overloaded vfloat32m4_t vloxei64(vbool8_t op0, vfloat32m4_t op1, const float * op2, vuint64m8_t op3, size_t op4){
  return vloxei64_v_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vloxei64(const float * op0, vuint64m1_t op1, size_t op2){
  return vloxei64_v_f32mf2(op0, op1, op2);
}

__rvv_overloaded vfloat32mf2_t vloxei64(vbool64_t op0, vfloat32mf2_t op1, const float * op2, vuint64m1_t op3, size_t op4){
  return vloxei64_v_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vle32(vbool32_t op0, vfloat32m1_t op1, const float * op2, size_t op3){
  return vle32_v_f32m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m2_t vle32(vbool16_t op0, vfloat32m2_t op1, const float * op2, size_t op3){
  return vle32_v_f32m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m4_t vle32(vbool8_t op0, vfloat32m4_t op1, const float * op2, size_t op3){
  return vle32_v_f32m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m8_t vle32(vbool4_t op0, vfloat32m8_t op1, const float * op2, size_t op3){
  return vle32_v_f32m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32mf2_t vle32(vbool64_t op0, vfloat32mf2_t op1, const float * op2, size_t op3){
  return vle32_v_f32mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m1_t vle32ff(vbool32_t op0, vfloat32m1_t op1, const float * op2, size_t * op3, size_t op4){
  return vle32ff_v_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m2_t vle32ff(vbool16_t op0, vfloat32m2_t op1, const float * op2, size_t * op3, size_t op4){
  return vle32ff_v_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m4_t vle32ff(vbool8_t op0, vfloat32m4_t op1, const float * op2, size_t * op3, size_t op4){
  return vle32ff_v_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m8_t vle32ff(vbool4_t op0, vfloat32m8_t op1, const float * op2, size_t * op3, size_t op4){
  return vle32ff_v_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vle32ff(vbool64_t op0, vfloat32mf2_t op1, const float * op2, size_t * op3, size_t op4){
  return vle32ff_v_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vfadd(vfloat32m1_t op0, vfloat32m1_t op1, size_t op2){
  return vfadd_vv_f32m1(op0, op1, op2);
}

__rvv_overloaded vfloat32m1_t vfadd(vbool32_t op0, vfloat32m1_t op1, vfloat32m1_t op2, vfloat32m1_t op3, size_t op4){
  return vfadd_vv_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m2_t vfadd(vfloat32m2_t op0, vfloat32m2_t op1, size_t op2){
  return vfadd_vv_f32m2(op0, op1, op2);
}

__rvv_overloaded vfloat32m2_t vfadd(vbool16_t op0, vfloat32m2_t op1, vfloat32m2_t op2, vfloat32m2_t op3, size_t op4){
  return vfadd_vv_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m4_t vfadd(vfloat32m4_t op0, vfloat32m4_t op1, size_t op2){
  return vfadd_vv_f32m4(op0, op1, op2);
}

__rvv_overloaded vfloat32m4_t vfadd(vbool8_t op0, vfloat32m4_t op1, vfloat32m4_t op2, vfloat32m4_t op3, size_t op4){
  return vfadd_vv_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m8_t vfadd(vfloat32m8_t op0, vfloat32m8_t op1, size_t op2){
  return vfadd_vv_f32m8(op0, op1, op2);
}

__rvv_overloaded vfloat32m8_t vfadd(vbool4_t op0, vfloat32m8_t op1, vfloat32m8_t op2, vfloat32m8_t op3, size_t op4){
  return vfadd_vv_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vfadd(vfloat32mf2_t op0, vfloat32mf2_t op1, size_t op2){
  return vfadd_vv_f32mf2(op0, op1, op2);
}

__rvv_overloaded vfloat32mf2_t vfadd(vbool64_t op0, vfloat32mf2_t op1, vfloat32mf2_t op2, vfloat32mf2_t op3, size_t op4){
  return vfadd_vv_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vfadd(vfloat32m1_t op0, float op1, size_t op2){
  return vfadd_vf_f32m1(op0, op1, op2);
}

__rvv_overloaded vfloat32m1_t vfadd(vbool32_t op0, vfloat32m1_t op1, vfloat32m1_t op2, float op3, size_t op4){
  return vfadd_vf_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m2_t vfadd(vfloat32m2_t op0, float op1, size_t op2){
  return vfadd_vf_f32m2(op0, op1, op2);
}

__rvv_overloaded vfloat32m2_t vfadd(vbool16_t op0, vfloat32m2_t op1, vfloat32m2_t op2, float op3, size_t op4){
  return vfadd_vf_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m4_t vfadd(vfloat32m4_t op0, float op1, size_t op2){
  return vfadd_vf_f32m4(op0, op1, op2);
}

__rvv_overloaded vfloat32m4_t vfadd(vbool8_t op0, vfloat32m4_t op1, vfloat32m4_t op2, float op3, size_t op4){
  return vfadd_vf_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m8_t vfadd(vfloat32m8_t op0, float op1, size_t op2){
  return vfadd_vf_f32m8(op0, op1, op2);
}

__rvv_overloaded vfloat32m8_t vfadd(vbool4_t op0, vfloat32m8_t op1, vfloat32m8_t op2, float op3, size_t op4){
  return vfadd_vf_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vfadd(vfloat32mf2_t op0, float op1, size_t op2){
  return vfadd_vf_f32mf2(op0, op1, op2);
}

__rvv_overloaded vfloat32mf2_t vfadd(vbool64_t op0, vfloat32mf2_t op1, vfloat32mf2_t op2, float op3, size_t op4){
  return vfadd_vf_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vse32(float * op0, vfloat32m1_t op1, size_t op2){
  return vse32_v_f32m1(op0, op1, op2);
}

__rvv_overloaded void vse32(vbool32_t op0, float * op1, vfloat32m1_t op2, size_t op3){
  return vse32_v_f32m1_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse32(float * op0, vfloat32m2_t op1, size_t op2){
  return vse32_v_f32m2(op0, op1, op2);
}

__rvv_overloaded void vse32(vbool16_t op0, float * op1, vfloat32m2_t op2, size_t op3){
  return vse32_v_f32m2_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse32(float * op0, vfloat32m4_t op1, size_t op2){
  return vse32_v_f32m4(op0, op1, op2);
}

__rvv_overloaded void vse32(vbool8_t op0, float * op1, vfloat32m4_t op2, size_t op3){
  return vse32_v_f32m4_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse32(float * op0, vfloat32m8_t op1, size_t op2){
  return vse32_v_f32m8(op0, op1, op2);
}

__rvv_overloaded void vse32(vbool4_t op0, float * op1, vfloat32m8_t op2, size_t op3){
  return vse32_v_f32m8_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse32(float * op0, vfloat32mf2_t op1, size_t op2){
  return vse32_v_f32mf2(op0, op1, op2);
}

__rvv_overloaded void vse32(vbool64_t op0, float * op1, vfloat32mf2_t op2, size_t op3){
  return vse32_v_f32mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m1_t vluxei8(const float * op0, vuint8mf4_t op1, size_t op2){
  return vluxei8_v_f32m1(op0, op1, op2);
}

__rvv_overloaded vfloat32m1_t vluxei8(vbool32_t op0, vfloat32m1_t op1, const float * op2, vuint8mf4_t op3, size_t op4){
  return vluxei8_v_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m2_t vluxei8(const float * op0, vuint8mf2_t op1, size_t op2){
  return vluxei8_v_f32m2(op0, op1, op2);
}

__rvv_overloaded vfloat32m2_t vluxei8(vbool16_t op0, vfloat32m2_t op1, const float * op2, vuint8mf2_t op3, size_t op4){
  return vluxei8_v_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m4_t vluxei8(const float * op0, vuint8m1_t op1, size_t op2){
  return vluxei8_v_f32m4(op0, op1, op2);
}

__rvv_overloaded vfloat32m4_t vluxei8(vbool8_t op0, vfloat32m4_t op1, const float * op2, vuint8m1_t op3, size_t op4){
  return vluxei8_v_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m8_t vluxei8(const float * op0, vuint8m2_t op1, size_t op2){
  return vluxei8_v_f32m8(op0, op1, op2);
}

__rvv_overloaded vfloat32m8_t vluxei8(vbool4_t op0, vfloat32m8_t op1, const float * op2, vuint8m2_t op3, size_t op4){
  return vluxei8_v_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vluxei8(const float * op0, vuint8mf8_t op1, size_t op2){
  return vluxei8_v_f32mf2(op0, op1, op2);
}

__rvv_overloaded vfloat32mf2_t vluxei8(vbool64_t op0, vfloat32mf2_t op1, const float * op2, vuint8mf8_t op3, size_t op4){
  return vluxei8_v_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vluxei16(const float * op0, vuint16mf2_t op1, size_t op2){
  return vluxei16_v_f32m1(op0, op1, op2);
}

__rvv_overloaded vfloat32m1_t vluxei16(vbool32_t op0, vfloat32m1_t op1, const float * op2, vuint16mf2_t op3, size_t op4){
  return vluxei16_v_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m2_t vluxei16(const float * op0, vuint16m1_t op1, size_t op2){
  return vluxei16_v_f32m2(op0, op1, op2);
}

__rvv_overloaded vfloat32m2_t vluxei16(vbool16_t op0, vfloat32m2_t op1, const float * op2, vuint16m1_t op3, size_t op4){
  return vluxei16_v_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m4_t vluxei16(const float * op0, vuint16m2_t op1, size_t op2){
  return vluxei16_v_f32m4(op0, op1, op2);
}

__rvv_overloaded vfloat32m4_t vluxei16(vbool8_t op0, vfloat32m4_t op1, const float * op2, vuint16m2_t op3, size_t op4){
  return vluxei16_v_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m8_t vluxei16(const float * op0, vuint16m4_t op1, size_t op2){
  return vluxei16_v_f32m8(op0, op1, op2);
}

__rvv_overloaded vfloat32m8_t vluxei16(vbool4_t op0, vfloat32m8_t op1, const float * op2, vuint16m4_t op3, size_t op4){
  return vluxei16_v_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vluxei16(const float * op0, vuint16mf4_t op1, size_t op2){
  return vluxei16_v_f32mf2(op0, op1, op2);
}

__rvv_overloaded vfloat32mf2_t vluxei16(vbool64_t op0, vfloat32mf2_t op1, const float * op2, vuint16mf4_t op3, size_t op4){
  return vluxei16_v_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vluxei32(const float * op0, vuint32m1_t op1, size_t op2){
  return vluxei32_v_f32m1(op0, op1, op2);
}

__rvv_overloaded vfloat32m1_t vluxei32(vbool32_t op0, vfloat32m1_t op1, const float * op2, vuint32m1_t op3, size_t op4){
  return vluxei32_v_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m2_t vluxei32(const float * op0, vuint32m2_t op1, size_t op2){
  return vluxei32_v_f32m2(op0, op1, op2);
}

__rvv_overloaded vfloat32m2_t vluxei32(vbool16_t op0, vfloat32m2_t op1, const float * op2, vuint32m2_t op3, size_t op4){
  return vluxei32_v_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m4_t vluxei32(const float * op0, vuint32m4_t op1, size_t op2){
  return vluxei32_v_f32m4(op0, op1, op2);
}

__rvv_overloaded vfloat32m4_t vluxei32(vbool8_t op0, vfloat32m4_t op1, const float * op2, vuint32m4_t op3, size_t op4){
  return vluxei32_v_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m8_t vluxei32(const float * op0, vuint32m8_t op1, size_t op2){
  return vluxei32_v_f32m8(op0, op1, op2);
}

__rvv_overloaded vfloat32m8_t vluxei32(vbool4_t op0, vfloat32m8_t op1, const float * op2, vuint32m8_t op3, size_t op4){
  return vluxei32_v_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vluxei32(const float * op0, vuint32mf2_t op1, size_t op2){
  return vluxei32_v_f32mf2(op0, op1, op2);
}

__rvv_overloaded vfloat32mf2_t vluxei32(vbool64_t op0, vfloat32mf2_t op1, const float * op2, vuint32mf2_t op3, size_t op4){
  return vluxei32_v_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vluxei64(const float * op0, vuint64m2_t op1, size_t op2){
  return vluxei64_v_f32m1(op0, op1, op2);
}

__rvv_overloaded vfloat32m1_t vluxei64(vbool32_t op0, vfloat32m1_t op1, const float * op2, vuint64m2_t op3, size_t op4){
  return vluxei64_v_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m2_t vluxei64(const float * op0, vuint64m4_t op1, size_t op2){
  return vluxei64_v_f32m2(op0, op1, op2);
}

__rvv_overloaded vfloat32m2_t vluxei64(vbool16_t op0, vfloat32m2_t op1, const float * op2, vuint64m4_t op3, size_t op4){
  return vluxei64_v_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m4_t vluxei64(const float * op0, vuint64m8_t op1, size_t op2){
  return vluxei64_v_f32m4(op0, op1, op2);
}

__rvv_overloaded vfloat32m4_t vluxei64(vbool8_t op0, vfloat32m4_t op1, const float * op2, vuint64m8_t op3, size_t op4){
  return vluxei64_v_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vluxei64(const float * op0, vuint64m1_t op1, size_t op2){
  return vluxei64_v_f32mf2(op0, op1, op2);
}

__rvv_overloaded vfloat32mf2_t vluxei64(vbool64_t op0, vfloat32mf2_t op1, const float * op2, vuint64m1_t op3, size_t op4){
  return vluxei64_v_f32mf2_m(op0, op1, op2, op3, op4);
}

#endif

#if defined(__riscv_d)
__rvv_overloaded vfloat64m1_t vloxei8(const double * op0, vuint8mf8_t op1, size_t op2){
  return vloxei8_v_f64m1(op0, op1, op2);
}

__rvv_overloaded vfloat64m1_t vloxei8(vbool64_t op0, vfloat64m1_t op1, const double * op2, vuint8mf8_t op3, size_t op4){
  return vloxei8_v_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vloxei8(const double * op0, vuint8mf4_t op1, size_t op2){
  return vloxei8_v_f64m2(op0, op1, op2);
}

__rvv_overloaded vfloat64m2_t vloxei8(vbool32_t op0, vfloat64m2_t op1, const double * op2, vuint8mf4_t op3, size_t op4){
  return vloxei8_v_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vloxei8(const double * op0, vuint8mf2_t op1, size_t op2){
  return vloxei8_v_f64m4(op0, op1, op2);
}

__rvv_overloaded vfloat64m4_t vloxei8(vbool16_t op0, vfloat64m4_t op1, const double * op2, vuint8mf2_t op3, size_t op4){
  return vloxei8_v_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vloxei8(const double * op0, vuint8m1_t op1, size_t op2){
  return vloxei8_v_f64m8(op0, op1, op2);
}

__rvv_overloaded vfloat64m8_t vloxei8(vbool8_t op0, vfloat64m8_t op1, const double * op2, vuint8m1_t op3, size_t op4){
  return vloxei8_v_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vloxei16(const double * op0, vuint16mf4_t op1, size_t op2){
  return vloxei16_v_f64m1(op0, op1, op2);
}

__rvv_overloaded vfloat64m1_t vloxei16(vbool64_t op0, vfloat64m1_t op1, const double * op2, vuint16mf4_t op3, size_t op4){
  return vloxei16_v_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vloxei16(const double * op0, vuint16mf2_t op1, size_t op2){
  return vloxei16_v_f64m2(op0, op1, op2);
}

__rvv_overloaded vfloat64m2_t vloxei16(vbool32_t op0, vfloat64m2_t op1, const double * op2, vuint16mf2_t op3, size_t op4){
  return vloxei16_v_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vloxei16(const double * op0, vuint16m1_t op1, size_t op2){
  return vloxei16_v_f64m4(op0, op1, op2);
}

__rvv_overloaded vfloat64m4_t vloxei16(vbool16_t op0, vfloat64m4_t op1, const double * op2, vuint16m1_t op3, size_t op4){
  return vloxei16_v_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vloxei16(const double * op0, vuint16m2_t op1, size_t op2){
  return vloxei16_v_f64m8(op0, op1, op2);
}

__rvv_overloaded vfloat64m8_t vloxei16(vbool8_t op0, vfloat64m8_t op1, const double * op2, vuint16m2_t op3, size_t op4){
  return vloxei16_v_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vloxei32(const double * op0, vuint32mf2_t op1, size_t op2){
  return vloxei32_v_f64m1(op0, op1, op2);
}

__rvv_overloaded vfloat64m1_t vloxei32(vbool64_t op0, vfloat64m1_t op1, const double * op2, vuint32mf2_t op3, size_t op4){
  return vloxei32_v_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vloxei32(const double * op0, vuint32m1_t op1, size_t op2){
  return vloxei32_v_f64m2(op0, op1, op2);
}

__rvv_overloaded vfloat64m2_t vloxei32(vbool32_t op0, vfloat64m2_t op1, const double * op2, vuint32m1_t op3, size_t op4){
  return vloxei32_v_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vloxei32(const double * op0, vuint32m2_t op1, size_t op2){
  return vloxei32_v_f64m4(op0, op1, op2);
}

__rvv_overloaded vfloat64m4_t vloxei32(vbool16_t op0, vfloat64m4_t op1, const double * op2, vuint32m2_t op3, size_t op4){
  return vloxei32_v_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vloxei32(const double * op0, vuint32m4_t op1, size_t op2){
  return vloxei32_v_f64m8(op0, op1, op2);
}

__rvv_overloaded vfloat64m8_t vloxei32(vbool8_t op0, vfloat64m8_t op1, const double * op2, vuint32m4_t op3, size_t op4){
  return vloxei32_v_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vloxei64(const double * op0, vuint64m1_t op1, size_t op2){
  return vloxei64_v_f64m1(op0, op1, op2);
}

__rvv_overloaded vfloat64m1_t vloxei64(vbool64_t op0, vfloat64m1_t op1, const double * op2, vuint64m1_t op3, size_t op4){
  return vloxei64_v_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vloxei64(const double * op0, vuint64m2_t op1, size_t op2){
  return vloxei64_v_f64m2(op0, op1, op2);
}

__rvv_overloaded vfloat64m2_t vloxei64(vbool32_t op0, vfloat64m2_t op1, const double * op2, vuint64m2_t op3, size_t op4){
  return vloxei64_v_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vloxei64(const double * op0, vuint64m4_t op1, size_t op2){
  return vloxei64_v_f64m4(op0, op1, op2);
}

__rvv_overloaded vfloat64m4_t vloxei64(vbool16_t op0, vfloat64m4_t op1, const double * op2, vuint64m4_t op3, size_t op4){
  return vloxei64_v_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vloxei64(const double * op0, vuint64m8_t op1, size_t op2){
  return vloxei64_v_f64m8(op0, op1, op2);
}

__rvv_overloaded vfloat64m8_t vloxei64(vbool8_t op0, vfloat64m8_t op1, const double * op2, vuint64m8_t op3, size_t op4){
  return vloxei64_v_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vle64(vbool64_t op0, vfloat64m1_t op1, const double * op2, size_t op3){
  return vle64_v_f64m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m2_t vle64(vbool32_t op0, vfloat64m2_t op1, const double * op2, size_t op3){
  return vle64_v_f64m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m4_t vle64(vbool16_t op0, vfloat64m4_t op1, const double * op2, size_t op3){
  return vle64_v_f64m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m8_t vle64(vbool8_t op0, vfloat64m8_t op1, const double * op2, size_t op3){
  return vle64_v_f64m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vfadd(vfloat64m1_t op0, vfloat64m1_t op1, size_t op2){
  return vfadd_vv_f64m1(op0, op1, op2);
}

__rvv_overloaded vfloat64m1_t vfadd(vbool64_t op0, vfloat64m1_t op1, vfloat64m1_t op2, vfloat64m1_t op3, size_t op4){
  return vfadd_vv_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vfadd(vfloat64m2_t op0, vfloat64m2_t op1, size_t op2){
  return vfadd_vv_f64m2(op0, op1, op2);
}

__rvv_overloaded vfloat64m2_t vfadd(vbool32_t op0, vfloat64m2_t op1, vfloat64m2_t op2, vfloat64m2_t op3, size_t op4){
  return vfadd_vv_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vfadd(vfloat64m4_t op0, vfloat64m4_t op1, size_t op2){
  return vfadd_vv_f64m4(op0, op1, op2);
}

__rvv_overloaded vfloat64m4_t vfadd(vbool16_t op0, vfloat64m4_t op1, vfloat64m4_t op2, vfloat64m4_t op3, size_t op4){
  return vfadd_vv_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vfadd(vfloat64m8_t op0, vfloat64m8_t op1, size_t op2){
  return vfadd_vv_f64m8(op0, op1, op2);
}

__rvv_overloaded vfloat64m8_t vfadd(vbool8_t op0, vfloat64m8_t op1, vfloat64m8_t op2, vfloat64m8_t op3, size_t op4){
  return vfadd_vv_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfadd(vfloat64m1_t op0, double op1, size_t op2){
  return vfadd_vf_f64m1(op0, op1, op2);
}

__rvv_overloaded vfloat64m1_t vfadd(vbool64_t op0, vfloat64m1_t op1, vfloat64m1_t op2, double op3, size_t op4){
  return vfadd_vf_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vfadd(vfloat64m2_t op0, double op1, size_t op2){
  return vfadd_vf_f64m2(op0, op1, op2);
}

__rvv_overloaded vfloat64m2_t vfadd(vbool32_t op0, vfloat64m2_t op1, vfloat64m2_t op2, double op3, size_t op4){
  return vfadd_vf_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vfadd(vfloat64m4_t op0, double op1, size_t op2){
  return vfadd_vf_f64m4(op0, op1, op2);
}

__rvv_overloaded vfloat64m4_t vfadd(vbool16_t op0, vfloat64m4_t op1, vfloat64m4_t op2, double op3, size_t op4){
  return vfadd_vf_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vfadd(vfloat64m8_t op0, double op1, size_t op2){
  return vfadd_vf_f64m8(op0, op1, op2);
}

__rvv_overloaded vfloat64m8_t vfadd(vbool8_t op0, vfloat64m8_t op1, vfloat64m8_t op2, double op3, size_t op4){
  return vfadd_vf_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vle64ff(vbool64_t op0, vfloat64m1_t op1, const double * op2, size_t * op3, size_t op4){
  return vle64ff_v_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vle64ff(vbool32_t op0, vfloat64m2_t op1, const double * op2, size_t * op3, size_t op4){
  return vle64ff_v_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vle64ff(vbool16_t op0, vfloat64m4_t op1, const double * op2, size_t * op3, size_t op4){
  return vle64ff_v_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vle64ff(vbool8_t op0, vfloat64m8_t op1, const double * op2, size_t * op3, size_t op4){
  return vle64ff_v_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vse64(double * op0, vfloat64m1_t op1, size_t op2){
  return vse64_v_f64m1(op0, op1, op2);
}

__rvv_overloaded void vse64(vbool64_t op0, double * op1, vfloat64m1_t op2, size_t op3){
  return vse64_v_f64m1_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse64(double * op0, vfloat64m2_t op1, size_t op2){
  return vse64_v_f64m2(op0, op1, op2);
}

__rvv_overloaded void vse64(vbool32_t op0, double * op1, vfloat64m2_t op2, size_t op3){
  return vse64_v_f64m2_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse64(double * op0, vfloat64m4_t op1, size_t op2){
  return vse64_v_f64m4(op0, op1, op2);
}

__rvv_overloaded void vse64(vbool16_t op0, double * op1, vfloat64m4_t op2, size_t op3){
  return vse64_v_f64m4_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse64(double * op0, vfloat64m8_t op1, size_t op2){
  return vse64_v_f64m8(op0, op1, op2);
}

__rvv_overloaded void vse64(vbool8_t op0, double * op1, vfloat64m8_t op2, size_t op3){
  return vse64_v_f64m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vluxei8(const double * op0, vuint8mf8_t op1, size_t op2){
  return vluxei8_v_f64m1(op0, op1, op2);
}

__rvv_overloaded vfloat64m1_t vluxei8(vbool64_t op0, vfloat64m1_t op1, const double * op2, vuint8mf8_t op3, size_t op4){
  return vluxei8_v_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vluxei8(const double * op0, vuint8mf4_t op1, size_t op2){
  return vluxei8_v_f64m2(op0, op1, op2);
}

__rvv_overloaded vfloat64m2_t vluxei8(vbool32_t op0, vfloat64m2_t op1, const double * op2, vuint8mf4_t op3, size_t op4){
  return vluxei8_v_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vluxei8(const double * op0, vuint8mf2_t op1, size_t op2){
  return vluxei8_v_f64m4(op0, op1, op2);
}

__rvv_overloaded vfloat64m4_t vluxei8(vbool16_t op0, vfloat64m4_t op1, const double * op2, vuint8mf2_t op3, size_t op4){
  return vluxei8_v_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vluxei8(const double * op0, vuint8m1_t op1, size_t op2){
  return vluxei8_v_f64m8(op0, op1, op2);
}

__rvv_overloaded vfloat64m8_t vluxei8(vbool8_t op0, vfloat64m8_t op1, const double * op2, vuint8m1_t op3, size_t op4){
  return vluxei8_v_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vluxei16(const double * op0, vuint16mf4_t op1, size_t op2){
  return vluxei16_v_f64m1(op0, op1, op2);
}

__rvv_overloaded vfloat64m1_t vluxei16(vbool64_t op0, vfloat64m1_t op1, const double * op2, vuint16mf4_t op3, size_t op4){
  return vluxei16_v_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vluxei16(const double * op0, vuint16mf2_t op1, size_t op2){
  return vluxei16_v_f64m2(op0, op1, op2);
}

__rvv_overloaded vfloat64m2_t vluxei16(vbool32_t op0, vfloat64m2_t op1, const double * op2, vuint16mf2_t op3, size_t op4){
  return vluxei16_v_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vluxei16(const double * op0, vuint16m1_t op1, size_t op2){
  return vluxei16_v_f64m4(op0, op1, op2);
}

__rvv_overloaded vfloat64m4_t vluxei16(vbool16_t op0, vfloat64m4_t op1, const double * op2, vuint16m1_t op3, size_t op4){
  return vluxei16_v_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vluxei16(const double * op0, vuint16m2_t op1, size_t op2){
  return vluxei16_v_f64m8(op0, op1, op2);
}

__rvv_overloaded vfloat64m8_t vluxei16(vbool8_t op0, vfloat64m8_t op1, const double * op2, vuint16m2_t op3, size_t op4){
  return vluxei16_v_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vluxei32(const double * op0, vuint32mf2_t op1, size_t op2){
  return vluxei32_v_f64m1(op0, op1, op2);
}

__rvv_overloaded vfloat64m1_t vluxei32(vbool64_t op0, vfloat64m1_t op1, const double * op2, vuint32mf2_t op3, size_t op4){
  return vluxei32_v_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vluxei32(const double * op0, vuint32m1_t op1, size_t op2){
  return vluxei32_v_f64m2(op0, op1, op2);
}

__rvv_overloaded vfloat64m2_t vluxei32(vbool32_t op0, vfloat64m2_t op1, const double * op2, vuint32m1_t op3, size_t op4){
  return vluxei32_v_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vluxei32(const double * op0, vuint32m2_t op1, size_t op2){
  return vluxei32_v_f64m4(op0, op1, op2);
}

__rvv_overloaded vfloat64m4_t vluxei32(vbool16_t op0, vfloat64m4_t op1, const double * op2, vuint32m2_t op3, size_t op4){
  return vluxei32_v_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vluxei32(const double * op0, vuint32m4_t op1, size_t op2){
  return vluxei32_v_f64m8(op0, op1, op2);
}

__rvv_overloaded vfloat64m8_t vluxei32(vbool8_t op0, vfloat64m8_t op1, const double * op2, vuint32m4_t op3, size_t op4){
  return vluxei32_v_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vluxei64(const double * op0, vuint64m1_t op1, size_t op2){
  return vluxei64_v_f64m1(op0, op1, op2);
}

__rvv_overloaded vfloat64m1_t vluxei64(vbool64_t op0, vfloat64m1_t op1, const double * op2, vuint64m1_t op3, size_t op4){
  return vluxei64_v_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vluxei64(const double * op0, vuint64m2_t op1, size_t op2){
  return vluxei64_v_f64m2(op0, op1, op2);
}

__rvv_overloaded vfloat64m2_t vluxei64(vbool32_t op0, vfloat64m2_t op1, const double * op2, vuint64m2_t op3, size_t op4){
  return vluxei64_v_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vluxei64(const double * op0, vuint64m4_t op1, size_t op2){
  return vluxei64_v_f64m4(op0, op1, op2);
}

__rvv_overloaded vfloat64m4_t vluxei64(vbool16_t op0, vfloat64m4_t op1, const double * op2, vuint64m4_t op3, size_t op4){
  return vluxei64_v_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vluxei64(const double * op0, vuint64m8_t op1, size_t op2){
  return vluxei64_v_f64m8(op0, op1, op2);
}

__rvv_overloaded vfloat64m8_t vluxei64(vbool8_t op0, vfloat64m8_t op1, const double * op2, vuint64m8_t op3, size_t op4){
  return vluxei64_v_f64m8_m(op0, op1, op2, op3, op4);
}

#endif


#ifdef __cplusplus
}
#endif // __riscv_vector
#endif // __RISCV_VECTOR_H
